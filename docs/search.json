[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "",
    "text": "Front Matter\nI am putting this out there primarily as a resource for my own students to help them through the installation and provide written instruction for the computational tools we use in the courses EPsy 8251. As such, I will initially focus on R and RStudio, but I will probably add tools (e.g., reference managers, github, make) over time as I have time. (Note: If you want to contribute to this, create a Pull Request or send me an email.) Also, feel free to offer criticism, suggestion, and feedback. You can either open an issue on the book‚Äôs github page or send me an email directly."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nMany thanks to all the students in my courses who have been through previous iterations of this material. Your feedback has been invaluable, and you are the world‚Äôs greatest copyeditors. In particular, I would like to thank the following students who have gone above and beyond in the feedback they have provided: Jonathan Brown, Pablo Vivas Corrales, Amaniel Mrutu, Corissa Rohloff, and Mireya Smith."
  },
  {
    "objectID": "index.html#colophon",
    "href": "index.html#colophon",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "Colophon",
    "text": "Colophon\nArtwork by @allison_horst\nIcon and note ideas and prototypes by Desir√©e De Leon.\nThe book is typeset using Crimson Text for the body font, Raleway for the headings and Sue Ellen Francisco for the title. The color palette was generated using coolors.co.\nStatistical Computing\n\nLaptop icon made by Tomas Knop from www.flaticon.com\nDirectory icon made by Darius Dan from www.flaticon.com\nBrain icon made by Aranagraphics from www.flaticon.com\nInternet icon made by Freepik from www.flaticon.com"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "License",
    "text": "License\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "01-00-statistical-computation.html#footnotes",
    "href": "01-00-statistical-computation.html#footnotes",
    "title": "Introduction to Statistical Computation",
    "section": "",
    "text": "Specifically, RStudio is branded as an ‚Äúintegrated development environment (IDE) [that] includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management.‚Äù‚Ü©Ô∏é"
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#installing-r",
    "href": "01-01-r-and-rstudio-installation.html#installing-r",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.1 Installing R",
    "text": "1.1 Installing R\nTo install R, navigate your web browser to:\n\nhttps://www.r-project.org/\n\nThen,\n\nClick the CRAN link under Download on the left-hand side of the page.\nSelect a mirror site. These should all be the same, but I tend to choose the Iowa State University link under USA.1\nIn the Download and Install R box, choose the binary that matches the operating system (OS) for your computer.\n\nThis is where the installation directions diverge depending on your OS.\nMac Instructions\nSo long as you are running MacOS 10.13 or higher just click the first link for the PKG, which will download the installer for the most current version of R (4.1.1 as of August 16, 2021). Once the download completes, open the installer and follow the directions to install R on your computer.\nIf you are running an older version of MacOS, you will have to install an older version of R. You can find these links under the Binaries for legacy OS X systems heading further down the install page. Click the appropriate PKG link for R your version of MacOS. Once the download completes, open the installer and follow the directions to install R on your computer.\nIf you are unsure which version of the MacOS is running on your computer, select About this Mac from the Apple menu in your toolbar.\nWindows Instructions\nClick the link that says Install R for the first time (or click base; they go to the same place). Then click the Download R 4.1.1 for Windows link, which will download the installer for the most current version of R (4.0.2 as of July 24, 2020). Once the download completes, open the installer and follow the directions to install R on your computer.\nLinux Instructions\nIf you are running Linux, you should know how to install things on your computer. üòÄ"
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#installing-rstudio-desktop",
    "href": "01-01-r-and-rstudio-installation.html#installing-rstudio-desktop",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.2 Installing RStudio Desktop",
    "text": "1.2 Installing RStudio Desktop\nAfter you have installed R, you next need to install RStudio Desktop. To do this, navigate your web browser to:\n\nhttps://rstudio.com/products/rstudio/download/\n\nThen,\n\nSelect the blue Download button under the free, open-source version of RStudio Desktop.\nSelect the installer associated with your computer‚Äôs OS.\nOnce the download completes, open the installer and follow the directions to install RStudio Desktop on your computer."
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#checking-that-things-worked",
    "href": "01-01-r-and-rstudio-installation.html#checking-that-things-worked",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.3 Checking that Things Worked",
    "text": "1.3 Checking that Things Worked\nFrom your Applications or Programs folder, open RStudio. If you have successfully downloaded both programs, this should open the application and you should see a message indicating that you are using ‚ÄúR version 4.1.1‚Äù (or whichever version of R you installed) in the console pane.\n\n\n\n\n\nOnce you open RStudio, you should see a message indicating that you are using R version 4.1.1 (or whichever version of R you installed) in the console pane. Here the console pane is on the left-side, but it may be in a different location for you. Your RStudio may also have a white background rather than the black background seen here."
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#customizing-rstudio",
    "href": "01-01-r-and-rstudio-installation.html#customizing-rstudio",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.4 Customizing RStudio",
    "text": "1.4 Customizing RStudio\nWhile the information in this section is not crucial for making things work, it is useful to get RStudio looking good and setting some default settings. Open the Tools &gt; Options menu (Windows) or RStudio &gt; Preferences (Mac).\n\n\n\n\n\nThe RStudio options/preferences menu has many settings to customize RStudio.\n\n\n\n\n\nIn the General &gt; Basic settings, change the option on Save workspace to .Rdata on exit to be ‚ÄúNever‚Äù. Click the ‚ÄúApply‚Äù button.\nIn the Appearance settings, customize the look of RStudio to something aesthetically appealing to you. When you are finished, click the ‚ÄúApply‚Äù button.\nThere are also options you can set in the Accessibility settings if you use a screen reader. If you change anything, don‚Äôt forget to click the ‚ÄúApply‚Äù button.\n\nWhen you are finished customizing RStudio, click the ‚ÄúOK‚Äù button."
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#install-rtoolscommand-line-tools",
    "href": "01-01-r-and-rstudio-installation.html#install-rtoolscommand-line-tools",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.5 Install Rtools/Command Line Tools",
    "text": "1.5 Install Rtools/Command Line Tools\nYou may need to install some additional functionality to your system in order to get certain packages to install or load properly. On a Windows machine, you might need to install Rtools. Mac users might need to add the Command Line Tools. These tools also allow you to write and compile your own R packages. RStudio has well written instructions for adding these tools at: https://support.rstudio.com/hc/en-us/articles/200486498-Package-Development-Prerequisites."
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#footnotes",
    "href": "01-01-r-and-rstudio-installation.html#footnotes",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "",
    "text": "When internet used to be dial-up (i.e., super slow), you wanted to choose a mirror site that was closest in proximity to your location as it sped up the download. This is less of a concern now that internet download speeds are much faster.‚Ü©Ô∏é"
  },
  {
    "objectID": "01-02-getting-started-with-r.html#computing-in-the-console",
    "href": "01-02-getting-started-with-r.html#computing-in-the-console",
    "title": "2¬† Getting Started with R",
    "section": "2.1 Computing in the Console",
    "text": "2.1 Computing in the Console\nThere are a several ways to interact with R within RStudio. One of those methods is to issue commands in the RStudio console pane. Computing in the console is similar to working with a calculator: you enter syntax and R runs the syntax. The &gt; symbol in the console pane is called the ‚ÄúR prompt‚Äù and is prompting you to enter syntax. After you enter any syntax, you hit the  or  key to execute the syntax.\n\n\n\n\n\nThe console pane in RStudio is one way to compute with R. Syntax is entered at the R prompt and executed by hitting the  or  key.\n\n\n\n\nTo get started, we will have R carry out some arithmetic. At the prompt enter each of the following lines of syntax. After each line, hit the &lt;return&gt; or &lt;enter&gt; key.\n\n# Addition\n2 + 3\n\n# Subtraction\n6 - 10\n\n# Multiplication\n4 * 5\n\n# Division\n23 / 2\n\n# Exponents\n10 ^ 3\n\nExecuting each line of syntax returns the results of the computation in the console pane. The result, in R parlance, is referred to as a ‚Äúreturned value‚Äù. After executing the computation, the R prompt reappears and you can issue a new line of syntax.\nContinuation Prompt: At some point in your computational career, you will likely encounter the continuation prompt. Symbolized by +, this prompt appears instead of the R prompt to indicate that you did not complete the syntax you entered prior to hitting the  key. For example, suppose while entering the division syntax from above you got excited and hit the &lt;enter&gt; key after inputting the slash; before inputting the 2. You would see the continuation prompt:\n&gt; 23 /\n+ \nThe continuation prompt tells you that the syntax you started to enter is still active. If you now enter 2 and hit the &lt;enter&gt; key, the syntax will be executed as if you had not inadvertently hit &lt;enter&gt; in the middle of the computation. If you are in the middle of a more complex piece of syntax, you could also hit the &lt;esc&gt; key until the R prompt is re-shown. Then you can start the computation over.\nSpace in Syntax: For the computation in R, space is irrelevant. For example, each of the following syntactical statements is equivalent:\n\n4 * 5\n4*5\n4    *            5\n\nThat being said, well-written code includes space! Space in code makes it easier to read and debug, in the same way that including space in written prose helps us read and parse words, sentences, and paragraphs."
  },
  {
    "objectID": "01-02-getting-started-with-r.html#functions-the-workhorse-of-r",
    "href": "01-02-getting-started-with-r.html#functions-the-workhorse-of-r",
    "title": "2¬† Getting Started with R",
    "section": "2.2 Functions: The Workhorse of R",
    "text": "2.2 Functions: The Workhorse of R\nAlmost all commands in R are built around the use of a function. Functions carry out operations on their inputs (called arguments) and produce an output (called a returned value).\n\n\n\n\n\nLEFT: Arguments are inputted into a function which returns an output. RIGHT: The value 25 is inputted into the square root function which returns the value of 5.\n\n\n\n\nThe syntax for using most functions in R follows a simple structure: The name of the function is followed by a pair of parentheses. Argument values (inputs) are specified inside the parentheses. In general,\n\nfunction_name(argument)\n\nBelow are several example of this structure for some common mathematical functions.\n\n#Square root\nsqrt(100)\n\n[1] 10\n\n#Absolute value\nabs(-23)\n\n[1] 23\n\n#Factorial\nfactorial(5)\n\n[1] 120\n\n\nFunctions can take multiple arguments (inputs). If there is more than one argument, the arguments are always separated by a comma.\n\nfunction_name(argument_1, argument_2, ...)\n\nFor example, the seq() function creates a sequence of values that have a particular start and end value.\n\nseq(1, 5)\n\n[1] 1 2 3 4 5\n\n\nNote that the order of the arguments matters! Reversing the order of the arguments inputted to the seq() function returns different output.\n\nseq(5, 1)\n\n[1] 5 4 3 2 1\n\n\nEach of the arguments actually has a name, and if those names are used to assign the values we are inputting to the function, then the order of the arguments is irrelevant.\n\n# Named arguments\nseq(from = 1, to = 5)\n\n[1] 1 2 3 4 5\n\n# Order no longer matters\nseq(to = 5, from = 1)\n\n[1] 1 2 3 4 5\n\n\nIt is a good habit to use named arguments when you are writing your syntax. It makes the code more readable and easier to adapt if you come back to it later. Sometimes when the initial argument of a function is well-established, that first argument is left unnamed, but all other arguments used are named. A good example of this is the use of the lm() function in which the initial formula= argument is typically unnamed, but other arguments (e.g., data=) are named."
  },
  {
    "objectID": "01-02-getting-started-with-r.html#connecting-computations",
    "href": "01-02-getting-started-with-r.html#connecting-computations",
    "title": "2¬† Getting Started with R",
    "section": "2.3 Connecting Computations",
    "text": "2.3 Connecting Computations\nOne powerful aspect of computing is that the output from a function can be used as input into another function. This is akin to calculations you may have encountered in mathematics course like algebra. For example,\n\\[\n\\sqrt{\\log(100)}\n\\]\nIn carrying out this calculation, you would first compute the logarithm of 100 and then take the square root of that result. Using function notation, your algebra teacher might have written\n\\[\ng(~f(x)~)\n\\]\nwhere \\(f(x)\\) is the logarithm function and \\(g(x)\\) is the square root function. Regardless of how we express this,the idea is that the output of the logarithm function is used as input to the square root function. Using R, there are two primary ways to connect computations in this manner: chaining and assignment.\n\n\n2.3.1 Chaining\nChaining is a direct reflection of the functional notation \\(g(~f(x)~)\\) in that you embed one computation directly in another. For example, to find the absolute value of all the integers between \\(-5\\) and \\(-1\\), we can chain the abs() function and the seq() functions:\n\nabs( seq(from = -5, to = -1) )\n\n[1] 5 4 3 2 1\n\n\nNote here that the output/returned value is not a single value, but five values. The absolute value function was applied to each of the values in the sequence. Compare this to the result from the following chained computations:\n\nmean( seq(from = -5, to = -1) )\n\n[1] -3\n\n\nHere the mean function applied to the sequence of values returns a single value as output. When a function is applied to a set of multiple values (i.e., a vector), some functions will apply their computations separately on each element/value (element-wise computation returns multiple values), while others will apply the computation to the set of elements as a whole (vector-wise computation returns a single value). Most of the time it will be clear from the function name or description whether the output returns a single value or multiple values.\nWe can chain as many computations together as we would like. For example here we find the square root of the absolute value of all the integers between \\(-5\\) and \\(-1\\).\n\nsqrt( abs( seq(from = -5, to = -1) ) )\n\n[1] 2.236068 2.000000 1.732051 1.414214 1.000000\n\n\n\n\n\n2.3.2 Assignment\nWe can also connect computations through assignment. With assignment, we store the output of a computation by assigning it to a named object. We can then use that named object in another computation. For example, here we first store the integers between \\(-5\\) and \\(-1\\) in an object called chili. Then we find the absolute value of each value by using chili as the argument in the abs() function.\n\n# Assign the sequence to the object chili\nchili = seq(from = -5, to = -1) \n\n# Compute the absolute values\nabs(chili)\n\n[1] 5 4 3 2 1\n\n\nTo view the contents of an object, just print the name of the object. Below, after creating the object sadie, we view its contents.\n\n# Assign values to sadie\nsadie = rep(3, times = 5) \n\n# View contents of sadie\nsadie\n\n[1] 3 3 3 3 3\n\n\nPretty much any name can be used when you create an object, with some caveats: object names cannot begin with a digit nor include hyphens or spaces. Although they are legal object names, chili and sadie are not particularly good object names. Better object names would describe the contents of the object.\nIn my own workflow, I tend to use all lowercase letters in my object names and I use underscores for word breaks. For example,\n\nses, gpa, occupation\nact_math, mothers_educ\n\n\n\n\n2.3.3 Objects in the R Working Environment\nWe can continue to use the objects you created (e.g., chili and sadie) in our computations, so long as the objects remain in our R working environment.\n\n# Sum the pairwise elements of the two objects\nchili + sadie\n\n[1] -2 -1  0  1  2\n\n# Sum all the elements in chili\nsum(chili)\n\n[1] -15\n\n# Product of all the elements in sadie\nprod(sadie)\n\n[1] 243\n\n\nIn RStudio you can see which objects are in your working environment by examining the Environment pane.\n\n\n\n\n\nThe enivironment pane shows the objects in the R working environment. It also displays the object‚Äôs class and gives a preview of the the contents.\n\n\n\n\nNot only does this pane indicate the name of the objects in the working environment, but is also displays each object‚Äôs class. In this case we can tell that chili is an integer vector and sadie is a numeric vector.1 Moreover, we are told that each vector includes five elements, shown in the environment pane as [1:5]. Lastly, we are given a preview of each object‚Äôs contents. Since these vectors only contain five elements, we see all the values in the preview.\nYou can also use syntax to obtain a list of objects that are in your working environment using the ls() function with no arguments.\n\n# List the objects in working environment\nls()\n\n[1] \"chili\"           \"has_annotations\" \"sadie\"          \n\n\nWhen an object name is re-used, the previous value of the object is lost.\n\n# Assign the values 1 to 10 in chili\nchili = seq(from = 1, to = 10)\n\nAfter assigning new values to chili, we can see the information in the environment pane has been updated to reflect the new contents of the object.\n\n\n\n\n\nThe object chili although still an integer vector, now includes 10 elements.\n\n\n\n\nAny computations carried out with chili will use the new object.\n\n# Sum all the elements in chili\nsum(chili)\n\n[1] 55\n\n\nIf you want the previous version of chili you need to re-create the object. If you close your R session all of the objects you created will be lost."
  },
  {
    "objectID": "01-02-getting-started-with-r.html#script-files-recording-your-syntax",
    "href": "01-02-getting-started-with-r.html#script-files-recording-your-syntax",
    "title": "2¬† Getting Started with R",
    "section": "2.4 Script Files: Recording Your Syntax",
    "text": "2.4 Script Files: Recording Your Syntax\nIt is important to be able to record the syntax you use. This acts as a way of ‚Äúsaving‚Äù your work, and it also acts as a record of the analysis for your collaborators in the spirit of reproducible work. One way to record the R syntax you use is to employ a script file. You can create a new script file by selecting File &gt; New File &gt; R Script from the RStudio menu bar. You can also obtain a new R script by clicking the New File icon (document with the plus-sign) on the tool bar and selecting R Script.\n\n\n\n\n\nLEFT: Create a new script file using RStudio‚Äôs File menu. RIGHT: Create a new script file by clicking on the New File icon in the toolbar.\n\n\n\n\nScript files should only include your R syntax and comments. Script files should NOT include:\n\nprompts (&gt;)\noutput\n\nComments, which are human-readable annotations or explanations of the syntax, are written using the hashtag (#). These can be placed on their own line in the script file, or can be placed at the end of a line with syntax. The comment continues until you hit the  key. Comments help other people understand your syntax and also act as a reminder for the future you of what your code actually does. Get is the habit of including comments in your syntax. Not only is it good coding practice, but it also will help you become familiar with and learn the R syntax as you describe the purpose of the syntax you are writing.\n\n\n\n\n\nExample script file with comments.\n\n\n\n\nScript files can be saved and opened the same as any other document. So, no more worrying about losing your work or objects that you created when you close your R sesssion. Just open your saved script file, highlight the parts you want to re-run, and click the Run button!\n\n\n2.4.1 Executing Syntax from a Script File\nNot only does the script file record your syntax, but it can also act as the vehicle from which you run your R syntax. Syntax in the script file can be executed by highlighting it and pressing the Run button in the toolbar. You can run one line at a time, or highlight multiple lines and execute all of them sequentially.\n\n\n\n\n\nTo execute syntax from the script file, highlight the syntax you want to run and then click the Run button in the toolbar.\n\n\n\n\nWriting syntax directly in the script file and running it is a groovy workflow for using R. Writing syntax directly in the script file also saves you from having to copy-and-paste syntax you want to save from the console. In my own work, I use this workflow almost daily."
  },
  {
    "objectID": "01-02-getting-started-with-r.html#installing-and-loading-r-packages",
    "href": "01-02-getting-started-with-r.html#installing-and-loading-r-packages",
    "title": "2¬† Getting Started with R",
    "section": "2.5 Installing and Loading R Packages",
    "text": "2.5 Installing and Loading R Packages\nEvery R function is housed in a package. To use the functions in a particular package, the package needs to be (1) installed, and (2) loaded into memory.\n\n\n\n\n\nPackages need to be installed and loaded.\n\n\n\n\nYou can see the packages (and which version of each package) are installed by examining the Packages tab in RStudio. Every package listed there has been installed. You will also be able to see the version number of the package that is installed. Some of those packages may be checked. These are the packages that are also loaded into memory.\n\n\n\n\n\nThe packages tab shows which packages are installed. The list of packages you have installed will likely be different. Checked packages are loaded into memory. In the packages seen here, only the base package is loaded into memory.\n\n\n\n\nTwenty-nine packages were included when you installed R on your computer. When you start an R session by opening RStudio, some of those packages are also loaded into memory.\n\n\n\n\n\nThe 29 packages installed as part of R. The base, datasets, graphics, grDevices, methods, stats, and utils packages are loaded into memory when you start an R session. The other 22 packages are installed but not loaded into memory.\n\n\n\n\n\n\n2.5.1 Loading Packages into Memory\nTo load a package that is installed, you use the library() function and include the name of the package you want to load in as the sole argument. For example, to load the {splines} package, use the following syntax:\n\n# Load splines package\nlibrary(splines)\n\nSome packages requires other packages (dependencies) to work. For example, the {lme4} package is dependent on the {Matrix} package. When you load packages that have dependencies, R will also load the dependencies (assuming you have them installed). When it does this, a message will be printed after you execute library(). For example, here is what happens when we load the {lme4} package.\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\n\n\nOnce the package is loaded, all of the functions, data sets, etc. in that package are available to you. Packages will need to be loaded every time you launch a new R session.\n\n\n\n2.5.1.1 Masked Objects\nSometimes you will get a message about objects being masked. This is not a problem. It is just informative and means that the package you just loaded has a function that has the exact same name as a previously loaded package. If you use that particular function, the most recently loaded package‚Äôs version of the function will be used. For example, after loading the {dplyr} library the following message is printed:\nAttaching package: ‚Äòdplyr‚Äô\n\nThe following objects are masked from ‚Äòpackage:stats‚Äô:\n\n    filter, lag\n\nThe following objects are masked from ‚Äòpackage:base‚Äô:\n\n    intersect, setdiff, setequal, union\nThis tells me that the {dplyr} package includes six functions that have the same name as functions included in other packages that have already been loaded into memory (two from the {stats} package and four from the {base} package.) Since {dplyr} was the most recently loaded package, if you were to use the filter() function, R would use {dplyr}‚Äôs filter() function rather than that from the {stats} package2.\n\n\n\n2.5.1.2 Error Loading a Package\nOnce in a while, when loading a package, you may get an error. Don‚Äôt panic. There are two errors that are common. The first error you may get indicates that the package did not get installed. For example, if the {ggplot2} package was not installed, trying to use the library() function to load that package would result in an error.\n\nlibrary(ggplot2)\n\nError in library(ggplot2) : there is no package called ‚Äòggplot2‚Äô\nSimply install the package and then re-try loading it.\nThe second error that you might run across when trying to load a package occurs when the installation did not include the package dependencies. For example,\n\nlibrary(odbc)\n\nError: package or namespace load failed for ‚Äòodbc‚Äô in loadNamespace(j &lt;- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\nthere is no package called ‚ÄòRcpp‚Äô\nAgain, don‚Äôt panic! Here the error message is saying that the {Rcpp} package is a dependency and it is not installed. To fix this, install the {Rcpp} package and then try again. (You may need to open a new R session first.) You may need to install more than one dependency, so just keep installing what is missing until it works.\n\n\n\n\n2.5.2 Adding Functionality: Installing Packages\nYou can also install other packages onto your R system. R, in fact, has a repository called CRAN3, that includes 16,000 different packages (as of July 2020). The easiest way to install a package from CRAN onto your computer is to use the Install button in the `Packages tab of RStudio.\nThis will open a pop-up window where you can type the CRAN package you want to install in a text box. Ensure that the ‚ÄúInstall dependencies‚Äù box is checked (this will also install any package dependencies), and then click ‚ÄúInstall‚Äù.\n\n\n\n\n\nPop-up window to install packages. Here we are installing the dplyr package. Note that the ‚ÄòInstall dependencies‚Äô box is checked.\n\n\n\n\nYou may be prompted to choose a nearest mirror. If so, choose a mirror location. If you are successful in installing the package, you will get a message like the following:\nInstalling package into ‚Äò/Users/zief0002/Library/R/4.0/library‚Äô\n(as ‚Äòlib‚Äô is unspecified)\ntrying URL 'https://cran.rstudio.com/bin/macosx/contrib/4.0/dplyr_1.0.0.tgz'\nContent type 'application/x-gzip' length 1209135 bytes (1.2 MB)\n==================================================\ndownloaded 1.2 MB\n\n\nThe downloaded binary packages are in\n    /var/folders/s3/sqlc9xw92w54166w86dgkd000000gr/T//Rtmps80Uf8/downloaded_packages\nThe message you get on Windows may be slightly different, but the key is that there is not an error. Furthermore, you should immediately be able to load the package using the library() function.\nAn equivalent manner of installing a package via syntax is to use the install.packages() function. For example, to install the {dplyr} package we could have used the following syntax:\n\ninstall.packages(\"dplyr\", dependencies = TRUE)\n\nNote that the name of the package is included in quotation marks (it is a character string). The argument dependencies=TRUE installs all package dependencies, similar to checking the ‚ÄúInstall dependencies‚Äù box in the pop-up menu.\n\n\n2.5.2.1 Installing Packages from GitHub\nCRAN is not the only place to get R packages. Many developers add packages to a website called GitHub. Packages hosted on GitHub can be installed using the install_github() function from the {remotes} package.\nFirst, you will need to install the {remotes} package from CRAN and then load it using the library() function. Then, you can use the install_github() function to actually install the package. This function is provided a character string that specifies the user name and GitHub repository for the package, separated by a slash. You can find this in the part of the URL that follows ‚Äúhttps://github.com/‚Äù in your web browser. For example, the URL for the {educate} package is: ‚Äúhttps://github.com/zief0002/educate‚Äù, so to install this we would use:\n\n# Load remotes package\nlibrary(remotes)\n\n# Install dplyr from GitHub\ninstall_github(\"zief0002/educate\")\n\nThe message I get when installing this is\nInstalling package into ‚Äò/Users/zief0002/Library/R/4.0/library‚Äô\n(as ‚Äòlib‚Äô is unspecified)\n* installing *source* package ‚Äòeducate‚Äô ...\n** using staged installation\n** R\n** inst\n** byte-compile and prepare package for lazy loading\n** help\n*** installing help indices\n*** copying figures\n** building package indices\n** installing vignettes\n** testing if installed package can be loaded from temporary location\n** testing if installed package can be loaded from final location\n** testing if installed package keeps a record of temporary installation path\n* DONE (educate)\nThe ‚ÄúDONE‚Äù message typically signified successful installation. Note that you may be prompted to update some packages. If you get this message, choose the option to update ‚ÄúALL‚Äù packages. As with packages installed from CRAN, if things worked you should be able to load the package you just installed using the library() function without any errors.\n\n\n\n\n2.5.3 Install Rtools/Command Line Tools\nYou may need to install some additional functionality to your system in order to get certain packages to install or load properly. On a Windows machine, you might need to install Rtools. Mac users might need to add the Command Line Tools. These tools also allow you to write and compile your own R packages. RStudio has well written instructions for adding these tools at: https://support.rstudio.com/hc/en-us/articles/200486498-Package-Development-Prerequisites."
  },
  {
    "objectID": "01-02-getting-started-with-r.html#footnotes",
    "href": "01-02-getting-started-with-r.html#footnotes",
    "title": "2¬† Getting Started with R",
    "section": "",
    "text": "The difference between the two classes is technical and related to how R internally stores the information in the vector.‚Ü©Ô∏é\nIf you really wanted to use the filter() function from the {stats} package you could specify this in the syntax using the :: operator, stats::filter(). This operator also allows you to use a function without loading the package with the library() function.‚Ü©Ô∏é\n‚ÄúCRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R.‚Äù‚Ü©Ô∏é"
  },
  {
    "objectID": "01-03-data-structures-in-r.html#vectors",
    "href": "01-03-data-structures-in-r.html#vectors",
    "title": "3¬† Data Structures in R",
    "section": "3.1 Vectors",
    "text": "3.1 Vectors\nVectors (the single-column bookcases in our metaphor) are perhaps the most common data structure you will encounter in R. In fact, even the data frame is composed of vectors; each column is a vector. There are many ways to create a vector in R, in fact you have already been introduced to a couple of them: seq() and rep(). These are useful to create sequences of values and vectors with repeated values, respectively. But what if you wanted to create the vector of the Spice Girls‚Äô ages when the band was formed in 1994 (the values in the second column in the picture above)?\nTo create a vector of these ages, we can use the c() function to input each of the five ages. Within this function, each age is separated by a comma‚Äîeach input is a separate argument to the c() function. We will also assign this to an object called age.\n\n# Create age vector\nage = c(19, 20, 18, 22, 20)\n\n# View vector\nage\n\n[1] 19 20 18 22 20\n\n\nNote that once we assign create age it shows up in our global environment. In the technical language of R, each age is an element of the vector. All of the elements in the age vector are numeric values. This is the vector‚Äôs type.3 Lastly, there are five elements in the vector.\nOnce you have created a numeric vector, you can compute on it. For example in the syntax below we compute the mean age, the standard deviation of the ages, and count the elements in the vector.\n\n# Compute mean\nmean(age)\n\n[1] 19.8\n\n# Compute standard deviation\nsd(age)\n\n[1] 1.48324\n\n# Count elements\nlength(age)\n\n[1] 5\n\n\n\n\n3.1.1 Logical Vectors\nAnother common vector type you will encounter is the logical vector. Each element in a logical vector is either TRUE or FALSE (all uppercase letters). You could use the c() function to create a logical vector. For example, to create the original_member vector we could use the following syntax:\n\n# Create logical vector\noriginal_member = c(TRUE, TRUE, FALSE, TRUE, FALSE)\n\n# View vector\noriginal_member\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE\n\n\nIt is more common to create logical vectors through computation using logical operators. For example we might ask which elements of the age object are greater than 20.\n\n# Which elements of age &gt; 20\nage &gt; 20\n\n[1] FALSE FALSE FALSE  TRUE FALSE\n\n\nThe result of using the logical operator &gt; is a logical vector. There are several logical operators in addition to &gt;:\n\n# greater than or equal to 20\nage &gt;= 20\n\n[1] FALSE  TRUE FALSE  TRUE  TRUE\n\n# less than 20\nage &lt; 20\n\n[1]  TRUE FALSE  TRUE FALSE FALSE\n\n# less than or equal to 20\nage &lt;= 20\n\n[1]  TRUE  TRUE  TRUE FALSE  TRUE\n\n# equal to 20\nage == 20\n\n[1] FALSE  TRUE FALSE FALSE  TRUE\n\n# not equal to 20\nage != 20\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\n\nNote that the logical operator for ‚Äúequal to‚Äù is two equals signs. This is because = (one equal sign) is what we use for assignment . If you wrote age=20 you would be assigning the value 20 to age, not asking whether the elements in age are equal to 20!\nLogical elements have numeric values associated with them, namely,\n\nFALSE = 0; and\nTRUE = 1.\n\nThis means we can apply computations to a logical vector. For example, we could count the number of Spice Girls that were original members by summing the logical values in the original_members object. (Since all FALSE values are 0, this amounts to counting the number of TRUE values.)\n\n# Count original members\nsum(original_member)\n\n[1] 3\n\n\nWe could also count the number of Spice Girls who are under the age of 20.\n\n# Count members with age &lt; 20\nsum(age &lt; 20)\n\n[1] 2\n\n\n\n\n\n3.1.2 Character Vectors\nA third type of vector you will work with is a character vector. Character vectors (a.k.a., strings, literals) are vectors in which each element is a string of characters delimited by quotation marks. For example, the Spice names column is a character vector. We can again create this vector using the c() function.\n\n# Create character vector\nspice = c(\"Scary\", \"Sporty\", \"Baby\", \"Ginger\", \"Posh\")\n\n# View vector\nspice\n\n[1] \"Scary\"  \"Sporty\" \"Baby\"   \"Ginger\" \"Posh\"  \n\n\nMany computations that worked on numeric vectors do not work on character vectors. These will often return an error or unexpected result. In the syntax below, for example, we are told that the mean() function expects a numeric or logical vector, and since what we used was not either of those, the result returned was NA.\n\n# Find mean name\nmean(spice)\n\nWarning in mean.default(spice): argument is not numeric or logical: returning\nNA\n\n\n[1] NA\n\n\nSome computations work the same way.\n\n# Count the number of elements\nlength(spice)\n\n[1] 5"
  },
  {
    "objectID": "01-03-data-structures-in-r.html#data-frames",
    "href": "01-03-data-structures-in-r.html#data-frames",
    "title": "3¬† Data Structures in R",
    "section": "3.2 Data Frames",
    "text": "3.2 Data Frames\nData frames (the multi-column bookcases in our metaphor) are a more complex data structures than vectors. There are again, multiple ways to create a data frame in R. We will examine two methods for creating a data frame: using the data.frame() function and importing data from a spreadsheet or CSV file.\nTo create a data frame from scratch, using R, we can use the data.frame() function. Each argument to this function is a named vector that will correspond to a column within the data frame, and each argument (vector) is separated by commas. For example, to create the Spice Girls data frame from our example, we could use the following syntax:\n\n# Create data frame\nspice_girls = data.frame(\n  spice = c(\"Scary\", \"Sporty\", \"Baby\", \"Ginger\", \"Posh\"),\n  age = c(19, 20, 18, 22, 20),\n  original_member = c(TRUE, TRUE, FALSE, TRUE, FALSE),\n  solo_nominations = c(4, 26, 14, 13, 12),\n  real_name = c(\"Mel B\", \"Mel C\", \"Emma\", \"Geri\", \"Victoria\")\n)\n\n# View data frame\nspice_girls\n\n\n\n  \n\n\n\nNote that we also assigned the data frame to an object called spice_girls so we can compute on it. You will learn how to compute on data frames in the chapters Data Wrangling with dplyr and Plotting with ggplot2."
  },
  {
    "objectID": "01-03-data-structures-in-r.html#importing-data-from-a-csv-file",
    "href": "01-03-data-structures-in-r.html#importing-data-from-a-csv-file",
    "title": "3¬† Data Structures in R",
    "section": "3.3 Importing Data From a CSV File",
    "text": "3.3 Importing Data From a CSV File\nIn professional practice, you will often enter data into a spreadsheet and rather than typing it into R. When you save this work, many spreadsheet programs use a proprietary format for saving the information (e.g., Excel saves as a XLSX file; Google Sheets saves as a GSHEET file). These often include extraneous information (e.g., formatting) that is irrelevant to the raw data. While R includes libraries and functions that can import data in the XLSX and GSHEETS formats, it is generally easier to save or export your data to a CSV (comma separated value) file from within your spreadsheet program prior to importing it into R.\n\n\n\n\n\n\nHere are some tips for entering data into a spreadsheet:\n\nThe first row should be the variable names. Do not use spaces in variable names.\nCharacter strings should be entered without quotation marks in a spreadsheet.\nIf you have missing data, leave the cell blank.\n\nFor more tips on entering data, see Broman & Woo (2018).\n\nOnce your data are saved as a CSV file, it can be easily imported into R. To do so,\n\nClick the Import Dataset button under the Environment tab in RStudio and choose ‚ÄúFrom Text (readr)‚Äù.\nIf the CSV file is a file stored on your computer, click the Browse button and navigate to where you saved your CSV file, select the file, and click ‚ÄúOpen‚Äù. If the CSV file is hosted on the web, type the URL into the ‚ÄúFile/URL‚Äù text box and click ‚ÄúUpdate‚Äù.\n\n\n\n3.3.1 Importing the Spice Girls Data\nThe file spice-girls.csv is accessible at https://raw.githubusercontent.com/zief0002/toolkit/master/data/spice_girls.csv.\n\nCopy and paste that URL into the ‚ÄúFile/URL‚Äù text box.\nClick the ‚ÄúUpdate‚Äù button.\n\nClicking ‚ÄúUpdate‚Äù will open a preview of your data. Check to be sure the variable names are correct and that the data looks like what you entered into your spreadsheet.\n\nChange the text in the name box to correspond to the object name you want to use in R.\nFinally, click the Import button to import your data.\n\nAfter importing the data you should see the object in your global environment.\n\n\n\n\n\n\n\n\n3.3.2 Importing Data Using a Script File\nEven though you used the Import button‚Äîa point-and-click feature in RStudio‚Äîto import the data, behind the scenes, syntax was generated that was actually used to import the data into R. When we selected ‚ÄúFrom Text (readr)‚Äù, the read_csv() function from the {readr} package was used to import the data. You can see the syntax generated in the Code Preview window after you selected your CSV file.\n\n\n\n\n\nIn the first line of syntax, the {readr} package is loaded using the library() function. The data is imported in the second line of syntax and assigned to an object, in this case spice_girls. The read_csv() function includes an unnamed argument providing the URL for the CSV file.4 The View() function in the third line of syntax simply opens the spice_girls object in a view tab in RStudio.\nIt is a good idea to copy the first two lines of syntax from the Code Preview window into your script file. It will be faster to import the data in the future by running it from a script file rather than trying to reproduce all the steps to import your data. The third line of syntax, using View(), is not essential to importing your data..\n\nSince there are better ways to actually ‚Äúsee‚Äù the contents of the data object (e.g., print()), you should not include the View() syntax line in your script file.\n\nBelow are the two lines I would include in the script file. I would also comment them.\n\n# Load readr library\nlibrary(readr)\n\n# Import data\nspice_girls &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/toolkit/master/data/spice_girls.csv\")\n\n\nThe syntax &lt;- is another way to write the assignment operator. You can use either = or &lt;- for the assignment operator. Whichever you choose, be consistent!"
  },
  {
    "objectID": "01-03-data-structures-in-r.html#validity-check-on-imported-data",
    "href": "01-03-data-structures-in-r.html#validity-check-on-imported-data",
    "title": "3¬† Data Structures in R",
    "section": "3.4 Validity Check on Imported Data",
    "text": "3.4 Validity Check on Imported Data\nOnce you import data, you should always perform a validity check to ensure that the entire dataset was imported and that things look OK. There are several functions that are useful for this examination. Three that I use regularly are print(), glimpse() and summary().\nThe print() function gives us a quick look at the data.\n\n# View data\nprint(spice_girls)\n\n# A tibble: 5 √ó 5\n  spice_name   age original_member solo_nominations real_name\n  &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;                      &lt;dbl&gt; &lt;chr&gt;    \n1 Scary         19 TRUE                           4 Mel B    \n2 Sporty        20 TRUE                          26 Mel C    \n3 Baby          18 FALSE                         14 Emma     \n4 Ginger        22 TRUE                          13 Geri     \n5 Posh          20 FALSE                         12 Victoria \n\n\nNote that from this output we can see that the read_csv() function actually imports the data as a tibble. Tibbles are essentially the same data structure as data frames. The only difference is that when you use print() (and some other functions) to examine the data object, what is printed to the screen is slightly different.5 For tibbles,\n\nThe number of rows and columns is displayed;\nThe first 10 rows are shown;\nOnly the columns that fit on screen are printed; and\nEach column type is reported\n\nHere the size of the data object is 5 x 5, which indicates that there are five rows (first value) and five columns (second value). We are also informed which columns are numeric, which are logical, and which are character.6\nThe summary() function computes summary statistics for each column in the data object. Different measures are computed depending on the column type. For character columns, only the length of the column is computed. The count of TRUE and FALSE values are computed for logical columns, and several measures are computed for numeric columns.\n\n# Compute summary measures for each column\nsummary(spice_girls)\n\n  spice_name             age       original_member solo_nominations\n Length:5           Min.   :18.0   Mode :logical   Min.   : 4.0    \n Class :character   1st Qu.:19.0   FALSE:2         1st Qu.:12.0    \n Mode  :character   Median :20.0   TRUE :3         Median :13.0    \n                    Mean   :19.8                   Mean   :13.8    \n                    3rd Qu.:20.0                   3rd Qu.:14.0    \n                    Max.   :22.0                   Max.   :26.0    \n  real_name        \n Length:5          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nThis is another good validity check to ensure that numeric columns have appropriate minimum and maximum values, etc. Here we see that the the age and solo_nominations columns have reasonable values. In practice you would undertake many more validity checks, but for now this is a good start."
  },
  {
    "objectID": "01-03-data-structures-in-r.html#references",
    "href": "01-03-data-structures-in-r.html#references",
    "title": "3¬† Data Structures in R",
    "section": "References",
    "text": "References\n\n\n\n\nBroman, K. W., & Woo, K. H. (2018). Data organization in spreadsheets. The American Statistician, 72(1), 2‚Äì10. https://doi.org/10.1080/00031305.2017.1375989"
  },
  {
    "objectID": "01-03-data-structures-in-r.html#footnotes",
    "href": "01-03-data-structures-in-r.html#footnotes",
    "title": "3¬† Data Structures in R",
    "section": "",
    "text": "Technically, a data frame can have a single column, but in practice most data frames you encounter will have many columns.‚Ü©Ô∏é\nIn this case, everything in the column would be turned into a character string.‚Ü©Ô∏é\nThe technical type is ‚Äúdouble‚Äù, which is commonly referred to as numeric.‚Ü©Ô∏é\nThis argument for the read_csv() function can also be a pathname to the location of the CSV file on your computer. If you are computing on a Mac, you may need to add ~/ to the beginning of this path name.‚Ü©Ô∏é\nFor data frames only the first six rows are displayed, all the columns are printed regardless of size, and column type is not reported.‚Ü©Ô∏é\nNote that just typing the name of the data frame also allows you to view the data. However, using print allows us more flexibility when the data set is larger.‚Ü©Ô∏é"
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#piping-the-key-to-using-dplyr",
    "href": "01-04-data-wrangling-with-dplyr.html#piping-the-key-to-using-dplyr",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.1 Piping: The Key to Using dplyr",
    "text": "4.1 Piping: The Key to Using dplyr\nRecall that functions work by taking arguments as inputs and then producing an output. For example, the glimpse() function takes the comics data frame as its input.\n\n# View data\nglimpse(comics)\n\nWe could get the same result by using the pipe operator (|&gt;). This operator takes a DATA FRAME, or a tibble, (given immediately before the operator) and uses it as the FIRST argument in the function that comes immediately after the pipe operator.\n\n# The pipe operator makes comics the first argument of the glimpse() function\ncomics |&gt; glimpse()\n\nRows: 23,272\nColumns: 14\n$ character         &lt;chr&gt; \"14\", \"88\", \"99\", \"107\", \"'Spinner\", \"\\\"Thumper\\\" Mo‚Ä¶\n$ comic             &lt;chr&gt; \"Marvel\", \"Marvel\", \"Marvel\", \"Marvel\", \"Marvel\", \"M‚Ä¶\n$ reality           &lt;chr&gt; \"Earth-616\", \"Earth-616\", \"Earth-616\", \"Earth-616\", ‚Ä¶\n$ identity          &lt;chr&gt; \"Secret Identity\", \"Public Identity\", \"Secret Identi‚Ä¶\n$ alignment         &lt;chr&gt; \"Bad\", \"Bad\", \"Neutral\", \"Neutral\", \"Good\", \"Bad\", \"‚Ä¶\n$ eye_color         &lt;chr&gt; NA, \"Blue\", \"Blue\", \"Green\", NA, NA, NA, \"Blue\", NA,‚Ä¶\n$ hair_color        &lt;chr&gt; NA, \"Blond\", NA, NA, NA, \"Bald\", NA, \"White\", NA, \"B‚Ä¶\n$ sex               &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"M‚Ä¶\n$ lgbtq             &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"‚Ä¶\n$ lgbtq_note        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ alive             &lt;chr&gt; \"Living\", \"Living\", \"Living\", \"Living\", \"Living\", \"L‚Ä¶\n$ appearances       &lt;dbl&gt; 1, 3, 1, 1, NA, NA, 1, 1, 1, 1, 3, 1, 2, 1, 1, 10, N‚Ä¶\n$ first_appear_date &lt;chr&gt; \"1994, November 01\", \"1994, March 01\", \"1994, Novemb‚Ä¶\n$ first_appear_year &lt;dbl&gt; 1994, 1994, 1994, 1994, 2007, 1965, 1991, 2010, 2011‚Ä¶\n\n\nNote since the glimpse() function did NOT include any additional arguments, we do not include anything between the parentheses after we pipe. Here is another example that illustrate the use of the pipe operator.\n\n# Count number of rows in comics data frame\nnrow(comics)\n\n[1] 23272\n\n# Can be written using the pipe operator as...\ncomics |&gt; nrow()\n\n[1] 23272\n\n\nOne last example will show how we use the additional arguments in the function following the pipe operator. For example, say we wanted to use the print() function to print the tibble/data frame, and we wanted to show all of the columns. The print() function would include not only the name of the tibble we wanted to print, but also the argument width=Inf. Here is the syntax for this:\n\n# Print all columns of comics tibble\nprint(comics, width = Inf)\n\nUsing piping, the syntax would be:\n\n# Print all columns of comics tibble\ncomics |&gt; print(width = Inf)\n\n# A tibble: 23,272 √ó 14\n   character                  comic  reality   identity        alignment\n   &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;    \n 1 \"14\"                       Marvel Earth-616 Secret Identity Bad      \n 2 \"88\"                       Marvel Earth-616 Public Identity Bad      \n 3 \"99\"                       Marvel Earth-616 Secret Identity Neutral  \n 4 \"107\"                      Marvel Earth-616 Secret Identity Neutral  \n 5 \"'Spinner\"                 Marvel Earth-616 Secret Identity Good     \n 6 \"\\\"Thumper\\\" Morgan\"       Marvel Earth-616 Secret Identity Bad      \n 7 \"11-Ball\"                  Marvel Earth-616 Secret Identity Bad      \n 8 \"115 (Legion Personality)\" Marvel Earth-616 Secret Identity Neutral  \n 9 \"181 (Legion Personality)\" Marvel Earth-616 Secret Identity Neutral  \n10 \"1X\"                       Marvel Earth-616 Public Identity Good     \n   eye_color hair_color sex    lgbtq lgbtq_note alive  appearances\n   &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;\n 1 &lt;NA&gt;      &lt;NA&gt;       Female No    &lt;NA&gt;       Living           1\n 2 Blue      Blond      Male   No    &lt;NA&gt;       Living           3\n 3 Blue      &lt;NA&gt;       Male   No    &lt;NA&gt;       Living           1\n 4 Green     &lt;NA&gt;       Male   No    &lt;NA&gt;       Living           1\n 5 &lt;NA&gt;      &lt;NA&gt;       Male   No    &lt;NA&gt;       Living          NA\n 6 &lt;NA&gt;      Bald       Male   No    &lt;NA&gt;       Living          NA\n 7 &lt;NA&gt;      &lt;NA&gt;       Male   No    &lt;NA&gt;       Living           1\n 8 Blue      White      Female No    &lt;NA&gt;       Living           1\n 9 &lt;NA&gt;      &lt;NA&gt;       &lt;NA&gt;   No    &lt;NA&gt;       Living           1\n10 &lt;NA&gt;      Blond      Male   No    &lt;NA&gt;       Living           1\n   first_appear_date first_appear_year\n   &lt;chr&gt;                         &lt;dbl&gt;\n 1 1994, November 01              1994\n 2 1994, March 01                 1994\n 3 1994, November 01              1994\n 4 1994, November 01              1994\n 5 2022, November 07              2007\n 6 1965, February 01              1965\n 7 1991, July 01                  1991\n 8 2022, August 10                2010\n 9 2022, July 11                  2011\n10 1940, March 01                 1940\n# ‚Ñπ 23,262 more rows\n\n\nHere, comics will be inputted as the FIRST argument in the print() function, and any additional arguments are simply included in the print() function itself.\n\nIt is a good coding practice to use multiple lines when you are piping rather than putting all the syntax on a single line. When you do this, the pipe operator (|&gt;) needs to come at the end of the line. You can see this in the code below, where the pipe operator is placed at the end of the first line of syntax; not at the beginning of the second line of syntax. Include a line break after every pipe operator you use.\n\n# Print all columns of comics tibble\ncomics |&gt; \n  print(width = Inf)"
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#common-dplyr-functions-for-data-wrangling",
    "href": "01-04-data-wrangling-with-dplyr.html#common-dplyr-functions-for-data-wrangling",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.2 Common dplyr Functions for Data Wrangling",
    "text": "4.2 Common dplyr Functions for Data Wrangling\nHere are some common operations that researchers use to prepare data for analysis (i.e., data preparation, data wrangling, data cleaning) and the corresponding {dplyr} functions.\n\n\n\nCommon data wrangling activities and the corresponding {dplyr} functions.\n\n\n\n\n\n\nData wrangling activity\ndplyr function\n\n\n\n\nSelect a subset of rows from a data frame.\nfilter()\n\n\nSelect a subset of columns from a data frame.\nselect()\n\n\nAdd new columns to a data frame.\nmutate()\n\n\nSort and re-order data in a data frame.\narrange()\n\n\nCompute summaries of columns in a data frame.\nsummarize()\n\n\nGroup the data to carry out computations for each group.\ngroup_by()"
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#sorting-the-data-arranging",
    "href": "01-04-data-wrangling-with-dplyr.html#sorting-the-data-arranging",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.3 Sorting the Data: Arranging",
    "text": "4.3 Sorting the Data: Arranging\nTo answer our initial set of research questions related to early representation of LGBTQ characters in comics, it is useful to sort the data by both LGBTQ status and year of first appearance. The arrange() function sorts the data based on the values within one or more specified columns. The data is ordered based on the column name provided in the argument(s). The syntax below sorts the rows in the comics data frame from earliest to most recent year of first appearance.\n\n# Sort data from earliest to most recent year of first appearance\ncomics |&gt;\n  arrange(first_appear_year)\n\n\n\n  \n\n\n\nHere we see the earliest character in these data (Richard Occult) appeared in 1935. This, however, does not give us the first LBGTQ character. To determine this, we need to sort on LGBTQ status in addition to year of first appearance.\nProviding the arrange() function multiple arguments sort initially by the column name given in first argument, and then by the columns given in subsequent arguments. Here the data are sorted first by LGBTQ status (alphabetically since lgbtq is a character string) and then by year of first appearance.\n\n# Sort data by LGBTQ status and then from earliest to most recent year of first appearance\ncomics |&gt;\n  arrange(lgbtq, first_appear_year)\n\n\n\n  \n\n\n\nBecause No is alphabetically before Yes, the non-LGBTQ characters are printed first. Because only the first 10 rows of a tibble are printed (and all 10 are non-LGBTQ characters), we still can‚Äôt quite answer our research question. If you want to see all of the sorted data or operate on it further, you need to (a) explicitly tell R to print all of the rows, or (b) assign the output into an object which can be viewed and scrolled through by clicking on the object in the RStudio Environment pane.\nTo print all of the rows to the console, we can pipe the sorted data into the print() function, and include the argument N=Inf. Reminder: Best practice is to start a new line after each pipe operator!\n\n# Sort data by LGBTQ status and then from earliest to most recent year of first appearance\n# Print all the rows\ncomics |&gt;\n  arrange(lgbtq, first_appear_year) |&gt;\n  print(N = Inf)\n\n# A tibble: 23,272 √ó 14\n   character   comic reality identity alignment eye_color hair_color sex   lgbtq\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;\n 1 Richard Oc‚Ä¶ DC    New Ea‚Ä¶ Secret ‚Ä¶ &lt;NA&gt;      Grey      Black      Male  No   \n 2 Arthur Pen‚Ä¶ DC    New Ea‚Ä¶ Public ‚Ä¶ Good      Brown     Brown      Male  No   \n 3 Bedivere    DC    New Ea‚Ä¶ &lt;NA&gt;     &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;       Male  No   \n 4 Franklin D‚Ä¶ DC    New Ea‚Ä¶ Public ‚Ä¶ Good      &lt;NA&gt;      Grey       Male  No   \n 5 Gareth      DC    New Ea‚Ä¶ &lt;NA&gt;     &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;       Male  No   \n 6 Gawain      DC    New Ea‚Ä¶ Public ‚Ä¶ Good      &lt;NA&gt;      &lt;NA&gt;       Male  No   \n 7 Guinevere   DC    New Ea‚Ä¶ Public ‚Ä¶ Good      &lt;NA&gt;      Blond      Fema‚Ä¶ No   \n 8 Lady of th‚Ä¶ DC    New Ea‚Ä¶ &lt;NA&gt;     Good      Blue      Blue       Fema‚Ä¶ No   \n 9 Lancelot    DC    New Ea‚Ä¶ Public ‚Ä¶ Good      &lt;NA&gt;      &lt;NA&gt;       Male  No   \n10 Merlin      DC    New Ea‚Ä¶ Secret ‚Ä¶ Neutral   Black     White      Male  No   \n# ‚Ñπ 23,262 more rows\n# ‚Ñπ 5 more variables: lgbtq_note &lt;chr&gt;, alive &lt;chr&gt;, appearances &lt;dbl&gt;,\n#   first_appear_date &lt;chr&gt;, first_appear_year &lt;dbl&gt;\n\n\nAnother way to view the entire set of data is to assign the sorted data into an object and then click on that object in the environment pane.\n\n# Sort data by LGBTQ status and then from earliest to most recent year of first appearance\n# Assign to the object 'sorted_comics'\nsorted_comics = comics |&gt;\n  arrange(lgbtq, first_appear_year)\n\n\n\n\n\n\nClicking the sorted_comics data object in the Environment pane will display the data in the RStudio data viewer.\n\n\n\n\nBased on an examination of the sorted data, we find the first appearance of an LQBTQ character is Jack Casey in 1940.\n\n\n\n\n\n\n4.3.1 Sorting in Descending Order\nRather than scrolling through the data, we could also have sorted the data so that the characters with LGBTQ status of ‚ÄúYes‚Äù are printed first. To do this we want to sort the data initially (using thelgbtq column) in reverse alphabetical order (‚ÄúYes‚Äù followed by ‚ÄúNo‚Äù).\nUse the desc() function on a column name to sort the data in descending order. Here the data are sorted in descending order by LGBTQ status and then by year of first appearance (in ascending order).\n\n# Sort data by LGBTQ status and then from earliest to most recent year of first appearance\ncomics |&gt;\n  arrange(desc(lgbtq), first_appear_year)"
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#obtain-a-subset-of-rows-filtering",
    "href": "01-04-data-wrangling-with-dplyr.html#obtain-a-subset-of-rows-filtering",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.4 Obtain a Subset of Rows: Filtering",
    "text": "4.4 Obtain a Subset of Rows: Filtering\nThere are many times in research applications that an educational scientist will need to select a subset of data cases. This type of application, for example, is quite common when we carry out demographic analyses (e.g., select the special education students, select students on free/reduced-price lunch). To select a subset of rows from a tibble or data frame, we will pipe the data frame we want to select rows from into the filter() function.\nThe argument(s) for the filter() function are logical expressions that will be used to select the rows. For example, suppose we wanted to select the LGBTQ characters (i.e., rows) from the comics data frame. We would need a logical expression that returns a TRUE value for all the LGBTQ characters. One such logical expression is: lgbtq==\"Yes\". Recall that a single equals sign (=) is the assignment operator and that to say ‚Äúis equal to‚Äù, we need to use two equals signs (==). Including this logical expression in the filter() function, the syntax for selecting the LQBTQ characters is then:\n\n# Select the LGBTQ characters\ncomics |&gt;\n  filter(lgbtq == \"Yes\")\n\n\n\n  \n\n\n\nNote that the output from this computation (data for the LGBTQ characters) is only printed to the screen. If you want to keep the filtered data or operate on it further, you need to assign the output into an object.\n\n# Select the LGBTQ characters\nlgbtq_characters = comics |&gt;\n  filter(lgbtq == \"Yes\")\n\n# Count the number of rows\nnrow(lgbtq_characters)\n\n[1] 155\n\n\nWe could have found the same result exclusively using piping; without the interim assignment.\n\n# Select the LGBTQ characters and count the rows\ncomics |&gt;\n  filter(lgbtq == \"Yes\") |&gt;\n  nrow()\n\n[1] 155\n\n\nThe first pipe operator uses the comics data frame in the filter() function to select the LGBTQ characters. This output (only the LGBTQ characters) is then used in the nrow() function to count the number of rows. It is akin to a constant pipeline of chaining functions together (i.e., nrow(filter(comics, lgbtq == \"Yes\"))); the output of a computation is used as the input into the next computation in the pipeline.\nBased on this result (and the results from the earlier glimpse() output), we can now answer our first research question: What percentage of comic characters identify as LQBTQ?\n\n# Compute percentage of LGBTQ characters\n155 / 23272\n\n[1] 0.006660364\n\n\nOnly 0.6% of comic characters identified as LGBTQ (at least as of 2014). This is well below 7.1%, the percentage of U.S. adults who self-identify as lesbian, gay, bisexual, transgender or something other than heterosexual according to a 2022 Gallup Poll. (This is even below the 2012 estimate of 3.5%.) This suggests that the LQBTQ population is likely underrepresented in comic culture.\n\n\n\n\n\n\n4.4.1 Filtering on Multiple Attributes\nYou can filter on multiple attributes by including more than one logical statement in the filter() function. For example, say we wanted to determine if the Pride Movement had an impact on LGBTQ representation in comics. The first Pride parade took place in March 1970, so we could look at the percentage of LGBTQ comic characters introduced prior to 1970 and compare it to the percentage of LGBTQ comic characters introduced in 1970 or later.\nThe syntax below counts the number of LGBTQ comic characters introduced prior to 1970. We also compute the total number of character introduced prior to 1970 to compute the correct percentage.\n\n# Count LGBTQ characters introduced prior to 1970\ncomics |&gt;\n  filter(lgbtq == \"Yes\", first_appear_date &lt; 1970) |&gt;\n  nrow()\n\n[1] 11\n\n# Count all characters introduced prior to 1970\ncomics |&gt;\n  filter(first_appear_date &lt; 1970) |&gt;\n  nrow()\n\n[1] 4002\n\n# Compute percentage\n11 / 4002\n\n[1] 0.002748626\n\n\nOf the 4002 characters introduced prior to 1970, 0.27% identified as LGBTQ.\nHere, when we included multiple logical expressions in the filter() function, separated by a comma, they were linked using the AND (&) operator. This means that both expressions have to evaluate as TRUE to be included. We could also have explicitly used the & operator to link the two statements.\n\ncomics |&gt;\n  filter(lgbtq == \"Yes\", sex == \"Female\")\n\n# Is equivalent to...\ncomics |&gt;\n  filter(lgbtq == \"Yes\" & sex == \"Female\")\n\n\n\n\n\n\nWe can also filter() using the OR (|) operator. This means that if EITHER logical expression included in the filter() function evaluates as TRUE, the row is included in the output. For example, say we wanted to count the number of comic characters who are either female or identify as LGBTQ. The syntax for this would be:\n\n# Count character who are LQBTQ or are female\ncomics |&gt;\n  filter(lgbtq == \"Yes\" | sex == \"Female\") |&gt;\n  nrow()\n\n[1] 5890"
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#selecting-a-subset-of-columns",
    "href": "01-04-data-wrangling-with-dplyr.html#selecting-a-subset-of-columns",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.5 Selecting a Subset of Columns",
    "text": "4.5 Selecting a Subset of Columns\nSuppose a journalist at Lavender Magazine is writing a story about the representation of LGBTQ comic characters and has asked you to create a new dataset for their work that only includes the LGBTQ comic characters. Moreover, this new dataset should also only include the characters‚Äô name, year of first appearance, and the LGBTQ note. To complete this task, we need to select not only a subset of rows from the original data, but also a subset of the columns.\nTo select a subset of columns, we will use the select() function. The argument(s) for this function are the column names of the data frame that you want to select. For example, to select the character, first_appear_year, and lgbtq_note columns from the comics data frame we would use the following syntax:\n\n# Select a subset of columns\ncomics |&gt;\n  select(character, first_appear_year, lgbtq_note)\n\n\n\n  \n\n\n\nWe can combine this column selection with our filtering to select the LGBTQ characters. Note that since the filter() function uses the data in the lgbtq column, we need to apply the filter before we selecting the three columns we want. If we use select() prior to filtering, we will get an error since the column lgbtq was not included in the select() function.\n\n# This order produces and error\ncomics |&gt;\n  select(character, first_appear_year, lgbtq_note) |&gt;\n  filter(lgbtq == \"Yes\")\n\nError in `filter()`:\n‚Ñπ In argument: `lgbtq == \"Yes\"`.\nCaused by error:\n! object 'lgbtq' not found\n\n# This order gets us the data we want\ncomics |&gt;\n  filter(lgbtq == \"Yes\") |&gt;\n  select(character, first_appear_year, lgbtq_note)\n\n\n\n  \n\n\n\nLastly, in order to get this data to the journalist, we need to export the data from R to our computer. The {readr} package includes several functions that allow us to export data from R in a variety of formats. Here we will use the write_csv() function to export the data into a CSV file. This function necessitates that we provide the path and filename for where we want to save the exported CSV file. For example, to write a CSV file called lgbtq-comic-characters.csv to the desktop on a Mac we could use the following syntax:\n\n# Subset data and export it\ncomics |&gt;\n  filter(lgbtq == \"Yes\") |&gt;\n  select(character, first_appear_year, lgbtq_note) |&gt;\n  write_csv(\"/Users/username/Desktop/lgbtq-comic-characters.csv\")\n\nThe syntax to do this on a PC would be something like the following:\n\n# Subset data and export it\ncomics |&gt;\n  filter(lgbtq == \"Yes\") |&gt;\n  select(character, first_appear_year, lgbtq_note) |&gt;\n  write_csv(\"C:\\Users\\username\\Desktop\\lgbtq-comic-characters.csv\")\n\nIn both of the Mac and PC examples, the part of the pathname called username needs to be modified to be the user name for your computer. Typically this is the username you use to login to your computer.\n\n\n\n\n\n\n4.5.1 Helper Functions for select()\nThere are a number of helper functions you can use within the select() function. For example, starts_with(), ends_with(), and contains(). These let you quickly match larger blocks of columns that meet some criterion. The syntax below illustrates a couple of these functions. You can read about other helper functions and see examples here.\n\n# Select all the columns that have a column name that ends in 'r'\ncomics |&gt;\n  select(ends_with(\"r\"))\n\n\n\n  \n\n\n# Select all the columns that have a column name that contains an underscore\ncomics |&gt;\n  select(contains(\"_\"))\n\n\n\n  \n\n\n\n\n\n\n4.5.2 Renaming Columns\nYou can rename a column by using the rename() function. Here we select the character, eye_color, and hair_color columns from the comics data frame and then rename the eye_color and hair_color columns to eye and hair, respectively. Note that this works similar to assignment in that the new column name is to the left of the equal sign.\n\n# Select 3 columns and rename 2 of them\ncomics |&gt;\n  select(character, eye_color, hair_color) %&gt;%\n  rename(eye = eye_color, hair = hair_color)"
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#create-new-columns-mutating",
    "href": "01-04-data-wrangling-with-dplyr.html#create-new-columns-mutating",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.6 Create New Columns: Mutating",
    "text": "4.6 Create New Columns: Mutating\nTo create new columns, we will use the mutate() function. Here we create a new column called num_years based on subtracting the year of the character‚Äôs first appearance from the current year (2022 as of this writing).\n\ncomics |&gt;\n  mutate(\n    num_years = 2022 - first_appear_year\n    )\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nIf you are running this in the console, the num_years column won‚Äôt be displayed because of the default printing options for tibbles; the new column is created, just not displayed. To view it, we can use the print() function with the argument width=Inf, which displays all columns in the tibble.\n\n# Add a new column and display all the columns\ncomics |&gt;\n  mutate(\n    num_years = 2022 - first_appear_year\n    ) |&gt;\n  print(width = Inf)\n\n\n\n\n4.6.1 Creating Multiple New Columns\nYou can create multiple new columns within the same mutate() function. Simply include each new column as an argument. Below we again create num_years, but we also additionally create centered_appearances which computes the difference between the number of appearances for each character and the mean number of appearances.\n\n# Add two new columns\ncomics |&gt;\n  mutate(\n    num_years = 2022 - first_appear_year,\n    centered_appearances = appearances - mean(appearances, na.rm = TRUE)\n    )\n\n\n\n  \n\n\n\nNote that the mean() function includes the optional argument na.rm=TRUE which allows the mean computation when there are NA values; it tells the mean() function to remove the NAs in the computation. (If you didn‚Äôt remove the NAs, the result of the computation would be an NA.)\n\nIf you want to continue to use the newly created columns, you need to assign the output into an object. If you do not assign the output into an object, the data with the new columns is printed to the screen and then the new columns are promptly ‚Äúforgotten‚Äù by R. If you are sure of your syntax, you can re-assign the data into the original object. Here we create the new columns and re-assign this into the comics object.\n\n# Add two new columns and re-assign to 'comics'\ncomics = comics |&gt;\n  mutate(\n    num_years = 2022 - first_appear_year,\n    centered_appearances = appearances - mean(appearances, na.rm = TRUE)\n    )"
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#computing-summaries-of-data-in-a-column",
    "href": "01-04-data-wrangling-with-dplyr.html#computing-summaries-of-data-in-a-column",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.7 Computing Summaries of Data in a Column",
    "text": "4.7 Computing Summaries of Data in a Column\nThe summarize() function is used to compute summaries of data in a given column. Here we compute the mean number of appearances for all comic characters in the data.\n\ncomics |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE)\n    )\n\n\n\n  \n\n\n\n\nBecause the appearance column includes missing values (NAs), we need to include the argument na.rm=TRUE in the mean() function. Including this will compute the mean only using the cases that have values. If there are missing values and the argument is not included, the result of the mean computation will be NA.\n\nThe output from summarize() is a data frame with a single row and one or more columns, depending on how many summaries you computed. Here we computed a single summary so there is only one column. We also named the column M within the summarize() function.\nMultiple summaries can be computed by providing more than one argument to the summarize() function. The output is still a single row data frame, but now there will be multiple columns, one for each summary computation. Here we compute the mean number of appearances for all comic characters in the data and also the standard deviation.\n\ncomics |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE),\n    SD = sd(appearances, na.rm = TRUE)\n    )"
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#computations-on-groups",
    "href": "01-04-data-wrangling-with-dplyr.html#computations-on-groups",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.8 Computations on Groups",
    "text": "4.8 Computations on Groups\nWhile we have leaned that, on average, comic characters appear about 20 times. And, that the variation is quite large (\\(SD=93.8\\)), telling us that there are characters who appear many more times (e.g., Spiderman, Susan Storm, Wonder Woman). Although a useful first step in an analysis, this alone does not answer our research question about how the average number of appearances for comic characters identifying as LQBTQ differ from those who don‚Äôt. To answer this, we need to compute these summary measures for LGBTQ and non-LGBTQ characters separately.\nThe group_by() function groups the data by a specified variable. By itself, this function essentially does nothing. But it is powerful when the grouped output is piped into other functions, such as summarize(). Here we use group_by(lgbtq) to compute the mean number of appearances and also the standard deviation for both LGBTQ and non-LGBTQ characters.\n\ncomics |&gt;\n  group_by(lgbtq) |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE),\n    SD = sd(appearances, na.rm = TRUE)\n    )\n\n\n\n  \n\n\n\nFrom this analysis we can see that characters that identify as LGBTQ appear, on average, about 75 times, while those that do not identify as LGBTQ appear only about 20 times. Both groups of characters have a large standard deviation implying that there is a lot of variation in the number of appearances for both groups.\nYou can also use group_by() with multiple attributes. Simply add additional column names in the group_by() function to create more conditional groups. For example to compute to compute the mean number of appearances and also the standard deviation for both LGBTQ and non-LGBTQ characters conditioned on comic company, we can use the following syntax.\n\ncomics |&gt;\n  group_by(lgbtq, comic) |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE),\n    SD = sd(appearances, na.rm = TRUE)\n    )\n\n\n\n  \n\n\n\nThis produces the summary measures for each of the combinations of the lgbtq and comic variables. So while we see that for both DC and Marvel, LGBTQ characters have more appearances, on average, than non-LGBTQ characters, this difference is more more pronounced for Marvel characters.\nIn one last analysis, we might also compute the sample size associated with these combinations.\n\ncomics |&gt;\n  group_by(lgbtq, comic) |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE),\n    SD = sd(appearances, na.rm = TRUE),\n    N = n()\n    )\n\n\n\n  \n\n\n\nThis added information reminds us that while the average number of appearances for LGBTQ characters is higher than for non-LGBTQ characters (for both DC and Marvel), overwhelming majority of comic characters are non-LGBTQ."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#some-background",
    "href": "01-05-visualizing-with-ggplot2.html#some-background",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.1 Some Background",
    "text": "5.1 Some Background\nThe gg in {ggplot2} stands for grammar of graphics. The grammar of graphics (Wilkinson, 2005) is a formal system of expressive grammatical rules for creating perceivable graphs. The grammar of graphics includes things such as aesthetics, geometries, scales, facets, and guides. Hadley Wickham adopted this grammar into the initial {ggplot} package, which he then re-wrote and updated to create the {ggplot2} package. As you learn how to create plots using {ggplot2}, you will also begin to learn the grammar of graphics. Understanding this grammar will help you describe, and create almost any visualization you can imagine."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#understanding-the-basic-syntax",
    "href": "01-05-visualizing-with-ggplot2.html#understanding-the-basic-syntax",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.2 Understanding the Basic Syntax",
    "text": "5.2 Understanding the Basic Syntax\nPlots in {ggplot2} are built by layering different components. For example, consider the following syntax which creates a scatterplot using the income and CO2 emissions attributes:\n\nggplot(data = gapminder, aes(x = income, y = co2)) + \n  geom_point() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIn this syntax there are three layers used to create the plot:\n\na global layer,\na geometric layer, and\na theme layer.\n\nThe layers are literally summed together to form the plot. We will look at each of these layers in turn.\n\n\n5.2.1 The Global Layer\nThe first layer (referred to as the global layer) in every plot you create employs the function ggplot(). It contains a reference to the source data (data=) and any global aesthetic mappings (more about this later). The first layer only sets up the plot, it doesn‚Äôt actually plot anything.\n\nggplot(data = gapminder, aes(x = income, y = co2))\n\n\n\n\nThe background layer for the plot is drawn. The domain (x-values) and range (y-values) is based on data in the income and co2 attributes.\n\n\n\n\n\nThe data= argument indicates the source data frame.\nThe aes= argument sets the aesthetic mapping(s).\n\n\n\n\n5.2.2 Aesthetics and Aesthetic Mappings\nAesthetics define what we, as humans, perceive in a given plot; that is the visual properties of a plot. For example, the position of certain elements in the plot (where they are located), or the color or transparency of an element. These aesthetics can be fixed or variable. For example, consider the color of a set of points. If the color is fixed, it would be the same for all the points. If the color is variable, it might be red for some points and blue for other points. Often, this variability in the aesthetic is based on some attribute in our dataset (e.g., points representing Democrats are colored blue, while those representing Republicans are colored red).\nLinking an aesthetic to an attribute in the data, is referred to as an aesthetic mapping. That is because aesthetic mappings map visual properties in the plot (e.g., position, color) to the values in a particular attributes in the data. Aesthetic mappings are specified in an aes() function. In our earlier example syntax, there were two aesthetic mappings that were defined:\n\nIncome values from the data will be mapped to the x-position.\nCO2 values from the data will be mapped to the y-position.\n\nThese mappings were used to define the domain (x-values) and range (y-values) for the blank plot created by the ggplot() global layer.\n\nImportant\nAll aesthetic mappings need to be specified in an aes() function. Because aesthetic mappings use information in the attribute to apply the specified visual properties, the aesthetics (e.g., x=, y=, color=) need to be set to an attribute name in the data frame. For example, both income and co2 are attribute names in the gapminder data object.\n\n\n\n\n5.2.3 Adding Layers\nAfter starting with the global layer, we can modify our visualization by adding layers to the global layer. For example, the layer that includes the function geom_point() is being added to the global layer in the syntax below.\n\n#: fig-cap: Points are added on top of the plot's background layer.\nggplot(data = gapminder, aes(x = income, y = co2)) + \n  geom_point()\n\n\n\n\n\n\n\n\nGeometric layers (geom_*) are used to add things like points, lines, histograms, densities, etc. The geom_point() layer in our plot is actually drawing the points of the scatter plot. These layers draw on the aesthetic mappings defined in the global layer to know where to draw these geometric objects. For example, the data in the income and co2 variables define the x- and y-positions of the points, respectively.\nWhen layers are added they are ‚Äústacked‚Äù on top of previous layers. For example, consider the two sets of syntax below. Each will again create our scatterplot by adding a set of points based on the data in the global layer. Each will also draw a loess smoother (a sort of trend line). However, in the first set of syntax, the smoother is drawn on top of the points, and in the second set of syntax, the points are drawn on top of the loess smoother. (The argument alpha=1 sets the transparency of the smoother to be completely opaque.)\n\n# LEFT: Draw smoother on top of points\nggplot(data = gapminder, aes(x = income, y = co2)) + \n  geom_point() +\n  geom_smooth(alpha = 1)\n\n\n# RIGHT: Draw points on top of smoother\nggplot(data = gapminder, aes(x = income, y = co2)) + \n  geom_smooth(alpha = 1) +\n  geom_point()\n\n\n\n\n\n\n\nLEFT: The smoother is drawn on top of the points. RIGHT: The points are drawn on top of the smoother.\n\n\n\n\n\n\n\nLEFT: The smoother is drawn on top of the points. RIGHT: The points are drawn on top of the smoother.\n\n\n\n\n\nA useful metaphor might be to imagine putting together a collage of many different photographs. Some parts of some of the photographs (especially those you put down first) might be covered up by photographs that you add later.\n\nProtip\nWhen you are creating plots, you might need to switch the order of some of the layers to get the visualization you want.\n\n\n\n\n5.2.4 Good Syntactic Habits\nAs we add multiple layers to build up our plot, it is a good habit to use multiple lines for the syntax. Generally we put one layer on each line.\n\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point()\n\nThe + sign needs to be at the end of the line (not at the beginning). If you are using a script file (which you should be), highlight ALL layers in the plot and click Run to create the plot.\n\nProtip\nIf you write your {ggplot2} syntax across multiple lines, it makes it not only easier to read, but also easier to try out different layers or features. For example, you can comment out lines to remove layers as you are building the plot without losing the syntax you wrote.\nYou can also debug syntax by highlighting all lines up to a given + sign and running the syntax. By subsequently highlighting and running additional lines of syntax, you can often figure out where any errors show up!"
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#global-vs.-local-aesthetic-mappings",
    "href": "01-05-visualizing-with-ggplot2.html#global-vs.-local-aesthetic-mappings",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.3 Global vs.¬†Local Aesthetic Mappings",
    "text": "5.3 Global vs.¬†Local Aesthetic Mappings\nAs you learned earlier, we use the aes() function to set aesthetic mappings (i.e., linking attributes to aesthetics). Aesthetic mappings are often set globally (in the initial ggplot() layer). When we include aesthetic mappings in the global layer they are applied to all layers in the plot. For example, the syntax below maps data in the income attribute to the x-position, data from the co2 attribute to the y-position, and data from the region attribute to color for both the loess smoother and the points.\n\n# All aesthetic mappings are global\nggplot(data = gapminder, aes(x = income, y = co2, color = region)) +  \n  geom_smooth() +\n  geom_point()\n\n\n\n\nThe global aesthetic mappings of x- and y-positioning, as well as, color are applied to the smoother and point layers.\n\n\n\n\n\nNotice when we use non-positional aesthetic mappings (e.g., color) a legend, or guide in the grammar of graphics, will be automatically added to our plot for each aesthetic mapping.\n\nAesthetic mappings can also be set locally in a specific layer. Aesthetic mappings set in a specific layer only apply to that particular layer. Below, we continue to globally map data from the income attribute to the x-position, and data from the co2 attribute to the y-position. Both the smoother layer and point layer will utilize that. However, only the point layer will map data from the region attribute to color. Note that regardless of whether the aesthetic mapping is global or local, we still make this mapping inside an aes() function.\n\n# Aesthetic mappings for x- and y-position are global\n# Aesthetic mapping for color only applies to the points layer\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(aes(color = region))\n\n\n\n\nThe global aesthetic mappings of x- and y-positioning are applied to the smoother and point layers. The aesthetic mapping of color is only applied to the point layer."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#fixed-aesthetics",
    "href": "01-05-visualizing-with-ggplot2.html#fixed-aesthetics",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.4 Fixed Aesthetics",
    "text": "5.4 Fixed Aesthetics\nFixed aesthetics assign the exact same value for the visual property for all the observations; it is not based on the data. Fixed aesthetics do not go inside of the aes() function. (Remember: Inside of the aes() function the mapping has to be to an attribute name!) The following syntax uses the following aesthetics:\n\nGlobal aesthetic mapping: Data from the income attribute mapped to the x-position.\nGlobal aesthetic mapping: Data from the co2 attribute mapped to the y-position.\nFixed local aesthetic: All points are given a shape of 22 (filled square with a border). You can see all the shape options here.\nFixed local aesthetic: All points are given a size of 4 (slightly bigger). The default size is 3.\nLocal aesthetic mapping: Data from the region attribute mapped to fill for the points layer only. Because we are using a different shape we use fill= rather than color= to color the observations.\nFixed local aesthetic: All points are given a border color of black (for this shape border color is set using color=).\n\n\n# Aesthetic mappings for x- and y-position are global\n# Aesthetic mapping for fill only applies to the points layer\n# All points are the same shape, size, and border color\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(aes(fill = region), shape = 22, size = 4, color = \"black\")\n\n\n\n\nThe global aesthetic mappings of x- and y-positioning are applied to the smoother and point layers. The aesthetic mapping of color is only applied to the point layer. The point layer also includes several fixed aesthetics."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#faceting-separate-plots-for-subgroups",
    "href": "01-05-visualizing-with-ggplot2.html#faceting-separate-plots-for-subgroups",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.5 Faceting: Separate Plots for Subgroups",
    "text": "5.5 Faceting: Separate Plots for Subgroups\nFaceting creates a separate plot for different levels of a attribute. This is useful, for example, when you want a separate plot for different subgroups. To facet on a single attribute include the facet_wrap() layer. The wiggle, or tilde, (~) sets the attribute to facet on. In the following syntax, we create a separate plot for each region.\n\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  facet_wrap(~region)\n\n\n\n\nScatterplot of per person CO2 emissions versus income for 193 countries. This plot is shown for each of the four world regions.\n\n\n\n\nWe can format the output of the facetted plots by setting the number of rows (nrow=) or columns (ncol=). For example, the following syntax outputs all four subplots in a single row.\n\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  facet_wrap(~region, nrow = 1)\n\n\n\n\nScatterplot of per person CO2 emissions versus income for 193 countries. This plot is shown for each of the four world regions.\n\n\n\n\n\n\n5.5.1 Facetting on Multiple Variables\nTo facet on multiple attributes, use facet_grid() rather than facet_wrap(). The facet_grid() layer also uses the wiggle or tilde, but in this function we will include an attribute before the tilde and a second attribute after the tilde. This defines the layout of the plot grid, so that the attribute that comes prior to the tilde will be facetted into separate rows, and the attribute that comes after the tilde will be facetted into different columns (i.e., rows ~ columns). The syntax below facets on both world region (rows) and CO2 change (columns).\n\n# Facet: regions in rows; \nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  facet_grid(region ~ co2_change)\n\n\n\n\nScatterplot of per person CO2 emissions versus income for 193 countries. This plot is shown for each of the four world regions and whether or not CO2 emissions increased or decreased since 2007."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#working-with-the-axes",
    "href": "01-05-visualizing-with-ggplot2.html#working-with-the-axes",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.6 Working with the Axes",
    "text": "5.6 Working with the Axes\nMany of the functions and layers employed in {ggplot2} syntax is to fine-tune the plot and make it ready for publication. One place this happens is on the axes of the plot. Changing the labels, the limits, or even where breakpoints occur are all things you may want to adjust as you ready a plot for publication.\n\n\n5.6.1 Changing the Axis Label\nTwo commonly used layers are xlab() and ylab(). These layers are used to change the label on the x- and y-axes, respectively. Here we change the axis label on both the x- and y-axes to give more information about the attributes being plotted.\n\n# Change the labels on the x- and y-axis\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  xlab(\"Per-person income (in thousands of international dollars, fixed for 2017 prices)\") +\n  ylab(\"Per-person CO2 emissions (in metric tonnes)\")\n\n\n\n\n\n\n\n\n\n\n\n5.6.2 Changing the Axis Limits\nAnother set of commonly used layers are xlim() and ylim(). These layers are used to set the limits on the x-axis and y-axis, respectively. These functions take two values which set the limits on the particular axis. The first value provided is the minimum, and the second value given is the maximum. Here, for example, the x-limits in the plot will be 0 to 125, and the y-axis will be 0 to 50.\n\n# Change the limits on the x- and y-axis\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  xlab(\"Per-person income (in thousands of international dollars, fixed for 2017 prices)\") +\n  ylab(\"Per-person CO2 emissions (in metric tonnes)\") +\n  xlim(0, 125) +\n  ylim(0, 50)\n\n\n\n\n\n\n\n\n\n\n\n5.6.3 Fine-Tuning Axis Scales\nThe xlab(), ylab(), xlim() and ylim() functions we used are shortcuts to using scaling layers. The use of scaling layers allows much more fine-tuning and control of the axis scales. There are four different scaling functions you can use depending on which axis (x or y) you want to control and whether the variable plotted along that axis is continuous or discrete. The four functions are:\n\nscale_x_continuous(),\nscale_x_discrete(),\nscale_y_continuous(), and\nscale_y_discrete().\n\nFor example, in our plot, to fine-tune the x-axis we could use scale_x_continuous() since income is a continuous variable and we want to fine-tune the x-axis.\n\n# Fine-tune the x-axis\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  scale_x_continuous(\n    name = \"Per-person income (in thousands of international dollars, fixed for 2017 prices)\",\n    limits = c(0, 125),\n    breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120)\n  ) +\n  ylab(\"Per-person CO2 emissions (in metric tonnes)\") +\n  ylim(0, 50)\n\n\n\n\nScale on the x-axis set to have a label, as well as, specific limits, and break lines.\n\n\n\n\nThe name= option labels the scale‚Äîit replaces xlab(). The limits= argument takes a vector of the minimum and maximum values‚Äîit replaces xlim(). The breaks= option adds break lines on the axis. There are several other options including labels= for labeling the break lines, etc.\n\n\n\n5.6.4 Customizing the Color and Fill\nScaling functions can also be used to fine-tune colors and fills. For these you need to specify the aesthetic, either color or fill, and also the palette you want to use. For example, scale_fill_manual() can be used to manually set the colors when the fill= aesthetic mapping is used, whereas scale_color_manual() can be used to manually set the colors when the color= aesthetic mapping is used.\nIn an earlier example, we used the fill= mapping to fill the points using the region attribute. Because of this we will use the layer scale_fill_manual() to change the fill colors. We use the values= argument to set the colors. Since the region attribute includes four values, we need to give the values= argument a vector of four different colors.\n\n# Specify fill colors using color names\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, aes(fill = region)) +\n  scale_fill_manual(values = c(\"skyblue\", \"plum\", \"orange\", \"chartreuse\"))\n\n\n\n\nColor palette set manually using named color values.\n\n\n\n\nHere, the alphabetic order of the values in the region variable correspond to the order of colors given in the values= argument of scale_color_manual(). In our examples:\n\nAfrica ‚Äì&gt; ‚Äúskyblue‚Äù\nAmericas ‚Äì&gt; ‚Äúplum‚Äù\nAsia ‚Äì&gt; ‚Äúorange‚Äù\nEurope ‚Äì&gt; ‚Äúchartreuse‚Äù\n\nThe color names used are built-in color names that R knows. There are 657 different named colors that you can use. To see them all, use the colors() function (with no arguments).\n\n\n5.6.4.1 Specifying Colors: RGB Color Model\nColors can also be defined using an RGB color model. This model uses a triplet of values to indicate the intensity of red (R), green (G), and blue (B) hues in the color. Each value in the triplet takes a value from 0 (none of that hue) to 255 (complete hue). For example, the color ‚Äúskyblue‚Äù is equivalent to the RGB value of (135, 206, 235), where the triplet values correspond to:\n\nRed: 135\nGreen: 206\nBlue: 235\n\nUsing the RGB color model, we can obtain 16,777,216 different colors! To specify a color using the RGB color model, we use the rgb() function. This function takes the arguments red=, green= and blue=. We also need to indicate the maximum color value1, in our case 255 using maxColorValue=. The syntax to re-create the colors from the previous plot using the RGB color model is shown below.\n\n# Specify fill colors using RGB color model\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    values = c(\n      rgb(red = 135, green = 206, blue = 235, maxColorValue = 255), #skyblue\n      rgb(red = 221, green = 160, blue = 221, maxColorValue = 255), #plum\n      rgb(red = 255, green = 165, blue = 0,   maxColorValue = 255), #orange\n      rgb(red = 127, green = 255, blue = 0,   maxColorValue = 255) #chartreuse\n    )\n  )\n\n\n\n\nColor palette set manually using RGB triplets.\n\n\n\n\n\n\n\n5.6.4.2 Specifying Colors: HEX\nColors can also be defined using hexadecimal (hex) notation. This notation takes the three RGB color model values (from 0‚Äì255) and converts each of those to a two-digit base-16 value. For example ‚Äúskyblue‚Äù, which in the RGB color model was (135, 206, 235) in hex is:\n\nRed: 135 (RGB) ‚Äì&gt; 87 (hex)\nGreen: 206 (RGB) ‚Äì&gt; CE (hex)\nBlue: 235 (RGB) ‚Äì&gt; EB (hex)\n\nThere are many websites that will convert between RGB values and hex, including Google. (Just type the following search string into Google: ‚Äúconvert 135, 206, 235 to hex‚Äù.) The hex notation for color is the six-digit value of the three concatenated two-digit color values. So skyblue is denoted:\n\nSkyblue: #87CEEB\n\nWhen we specify hex notation as a color in R, the six-digit color value is always preceeded by a hashtag (#). This is given as a character string instead of a color name. So to specify the colors in our plot using hex notation, the syntax is as follows.\n\n# Specify fill colors using hex notation\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"))\n\n\n\n\nColor palette set manually using hex notation.\n\n\n\n\n\nUsing lower-case letters in the hex notation would also work. Just remember to always include a hashtag when specifying hex."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#selecting-a-color-palette",
    "href": "01-05-visualizing-with-ggplot2.html#selecting-a-color-palette",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.7 Selecting a Color Palette",
    "text": "5.7 Selecting a Color Palette\nSelecting a color palette can be challenging. It should be aesthetically pleasing, but needs to convey the differences and nuances in the data that you are using color to display. In addition, roughly 8% of males and 0.5% of females have some form of color vision deficiency which will affect how they see and interpret the plot. Here are a few resources for thinking about color palettes:\n\nPicking a Colour Scale for Scientific Graphics\nColor Universal Design (CUD): How to Make Figures and Presentations that are Friendly to Colorblind People\nColor Palettes in R\n\nIf you are creating visualizzations for a particular organization, there may be a palette of official colors associated with their brand. For example, the University of Minnesota‚Äôs two official primary colors in hex notation (for electronic display) are:\n\n#ffcc33 (gold)\n#7a0019 (maroon)\n\nYou can see more on the University Relations Colors and Type page. They also have a palette of complementary colors available.\n\n\n5.7.1 Pre-Selected Color Palettes\nThere are several ‚Äúbuilt-in‚Äù palettes available for use in {ggplot2}.\n\n\n\n\n\n\n\n\nFill Scale\nColor Scale\nDescription\n\n\n\n\nscale_fill_hue()\nscale_color_hue()\nColors evenly spaced around the color wheel\n\n\nscale_fill_grey()\nscale_color_grey()\nGrey scale palette\n\n\nscale_fill_brewer()\nscale_color_brewer()\nColorBrewer palettes\n\n\n\nIf you do not specify the colors to use, the plots created in{ggplot2} will default to a palette that is evenly spaced around the color wheel. To use one of the other built-in palettes, we use the appropriate scale from the table above instead of the scale_fill_manual() or scale_color_manual() layer.\nFor example, to use a greyscale color palette, useful if you are printing in black-and-white, we can use the following syntax:\n\n# Specify greyscale for fill colors\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_grey()\n\n\n\n\nGreyscale color palette good for black-and-white printing.\n\n\n\n\nAnother set of built-in palettes are the Brewer palettes. These paleetes were chosen by Cynthia Brewer, a cartographer and artist, to be both colorblind friendly and aesthetically pleasing. Moreover, the palettes were designed to help humans make sense of the visualized data based on how we perceive the colors that are displayed. Martin Krzywinski has written a very readable introduction to the Brewer color palettes that I recommend.\nShe has palettes for three different types of data\n\nQualitative/Categorical: Colors do not have a perceived order\nSequential: Colors have a perceived order and perceived difference between successive colors is uniform\nDiverging: Two back-to-back sequential palettes starting from a common color (e.g., for Likert scale data)\n\n\n\n\n\n\n\n\n\n\nTo use one of Cynthia Brewer‚Äôs color palettes, we employ scale_color_brewer() or scale_fill_brewer(). Within these functions, we need to specify a palette using the palette= argument. The palette names can be found at https://colorbrewer2.org/. In our example, the region values constitute qualitative/categorical data, so we could choose any of the qualitative color palettes. To use the qualitative color palette called ‚ÄúSet1‚Äù we use:\n\n# Specify Brewer color palette (qualitative, Set 1)\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\nSet1 qualitative color palette from the Brewer color palette.\n\n\n\n\nFinally, we note that there are several packages that can extend the number of built-in color palettes. Some of my favorite extension packages include:\n\n{ggthemes} includes palettes used by FiveThirtyEight and Tableau [see here];\n{wesanderson} includes palettes based on Wes Anderson movies [see here]; and\n{nationalparkcolors} includes palettes based on National Park posters and images [see here; this needs to be installed from GitHub].\n\nEmil Hvitfeldt has also put together a package called {paletteer}, that includes a comprehensive collection of color palettes in R that can be called using a common interface [see here].\n\n\nCode\n# Load libraries\nlibrary(ggthemes)\n\n# FiveThirtyEight fill colors\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_fivethirtyeight()\n\n\n\n\n\nFiveThirtyEight color palette from the {ggthemes} package.\n\n\n\n\n\n\nCode\n# Load libraries\nlibrary(wesanderson)\n\n\n# BottleRocket2 fill colors\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(values = wes_palette(name = \"BottleRocket2\", n = 4))\n\n\n\n\n\nBottleRocket2 color palette from the {wesanderson} package.\n\n\n\n\n\n\nCode\n# Load libraries\nlibrary(nationalparkcolors)\n\n\n# Acadia fill colors\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(values = park_palette(\"Acadia\", n = 4))\n\n\n\n\n\nAcadia color palette from the {nationalparks} package."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#customizing-the-legendguide",
    "href": "01-05-visualizing-with-ggplot2.html#customizing-the-legendguide",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.8 Customizing the Legend/Guide",
    "text": "5.8 Customizing the Legend/Guide\nScaling functions can also be used to change the name and labels in the legend or guide. When we used the color scales, the guide included both the name of the attribute being plotted, and each value of the attribute along with its corresponding fill color. To change the , We can include the argument name= to edit the text of the attribute name in the guide. We can also use labels= to edit the text for each of the attribute vaslues. For example, below we change the text of the attribute in the guide to read ‚ÄúWorld Region‚Äù and the text of ‚ÄúAmericas‚Äù to instead read ‚ÄúThe Americas‚Äù. Note that because there are four attribute values, the labels= argument needs to have a vector with four values; we can‚Äôt only include the text we want to change.\n\n# Specify Brewer color palette (qualitative, Set 1)\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  )\n\n\n\n\nSet1 qualitative color palette from the Brewer color palette."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#themes-changing-the-look-of-your-plot",
    "href": "01-05-visualizing-with-ggplot2.html#themes-changing-the-look-of-your-plot",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.9 Themes: Changing the Look of Your Plot",
    "text": "5.9 Themes: Changing the Look of Your Plot\nThere are several ‚Äúbuilt-in‚Äù themes that you can use to change the look of your plot: theme_grey(), theme_minimal(), theme_linedraw(), theme_light(), theme_dark(), theme_minimal(), theme_classic(), theme_void(), and theme_test(). The default theme is theme_grey(). Here we use the layer theme_minimal() to modify the look of our plot. This theme uses a minimal black-and-white background (rather than grey).\n\n# Using the `theme_minimal()` layer to update the look of the plot\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  theme_minimal()\n\n\n\n\nUsing the theme_minimal() layer to update the look of the plot.\n\n\n\n\n\n\n5.9.1 The ggthemes Package\nThe {ggthemes} package includes 20 additional themes that you can use to style your plot (see here to view the different themes available). Here I use a theme similar to that from plots that appear in the Wall Street Journal.\n\n# Load library\nlibrary(ggthemes)\n\n# Using the `theme_wsj()` layer to update the look of the plot\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  theme_wsj()\n\n\n\n\nUsing the theme_wsj() layer from the {ggthemes} package to update the look of the plot to look like plots in the Wall Street Journal.\n\n\n\n\n\n\n\n5.9.2 Customizing a Theme\nThe theme() layer can be used to change every element in the plot (e.g., grid lines, font, color, etc.). See here for more detail. In the syntax below, we call theme_minimal() to get the minimal black-and-white them from before, and the use arguments in the theme() layer to change the font face and color on the axes labels.\n\n# Using the `theme_minimal()` layer to update the look of the plot\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  theme_minimal() +\n  theme(\n    axis.title.x = element_text(face = \"bold\", color = \"blue\"),\n    axis.title.y = element_text(face = \"italic\")\n  )\n\n\n\n\nYou can customize almost any part of the theme using the theme() layer. In this plot we changed the font face and color on the axes labels.\n\n\n\n\nThe theme() function can also be used to create your own {ggplot2} theme. This is useful if you always want your plots to look a certain way (e.g., to fit an organizations style guide) or are always using the same modifications to the theme in your plots. Below, I create a theme called theme_andy() that\n\n# Create theme_andy()\ntheme_andy = function() {\n  theme_minimal() +\n  theme(\n    # add border\n    panel.border = element_rect(colour = \"#7a0019\", fill = NA, linetype = 1),\n    # modify grid\n    panel.grid.major.x = element_line(color = \"#7a0019\", linetype = 1, size = 0.25),\n    panel.grid.minor.x = element_line(color = \"#ffb71e\"),\n    panel.grid.major.y = element_line(color = \"#7a0019\", linetype = 1, size = 0.25),\n    panel.grid.minor.y = element_line(color = \"#ffb71e\"),\n    # modify text, axis and color\n    axis.text = element_text(colour = \"#5b0013\", face = \"italic\", family = \"Times New Roman\"),\n    axis.title = element_text(colour = \"#5b0013\", family = \"Times New Roman\"),\n    axis.ticks = element_line(colour = \"#5b0013\"),\n    # legend at the bottom\n    legend.position = \"bottom\"\n  )\n}\n\n# Use theme_andy() to theme the plot\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  theme_andy()\n\n\n\n\nYou can also create your own theme to use with any plot."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#ggplot2-extension-packages",
    "href": "01-05-visualizing-with-ggplot2.html#ggplot2-extension-packages",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.10 {ggplot2} Extension Packages",
    "text": "5.10 {ggplot2} Extension Packages\nThere are several packages that extend the functionality of {ggplot2}. Many of these packages are listed at the ggplot2 Extensions page.\n\n\n\n\n\n\n\n\n\nOne useful extension package is the {scales} package. The functions and layers in this package are useful for transforming and labeling scales that are used to create your plot. For example, one of the functions in the {scales} package. label_number(), can be used to add a character prior to, or after all the numericval values labelled on an axis (very useful if the attribute being plotted is dollars). There is a nice web tutorial on using the {scales} package here.\nHere we add\n\n# Load library\nlibrary(scales)\n\n# Use the `{scales}` package to add $ in front of labels and k at the end on the x-axis\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  scale_x_continuous(\n    name = \"Income (in international dollars, fixed for 2017 prices)\",\n    labels = label_number(prefix = \"$\", suffix = \"k\")\n  ) +\n  theme_minimal()\n\n\n\n\nThe {scales} package helps format labels on the axes. Here we have used it to add a dollar sign in front of labels on the x-axis."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#captions-and-figure-numbering",
    "href": "01-05-visualizing-with-ggplot2.html#captions-and-figure-numbering",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.11 Captions and Figure Numbering",
    "text": "5.11 Captions and Figure Numbering\n\nIt is easier to use a word-processor (e.g., MS Word) to add the figure title and caption than to try and get it formatted correctly using R. This is especially true when trying to mimic the APA format.\n\nHere is one workflow for saving plots, importing the saved plot into your word-processing application, and adding a figure number and caption.\n\nCreate your plot in R.\nExport it (Click the Export button above the plot in RStudio.\nSelect Save as Image...\nClick `Directory to indicate where you want to save the image\nGive the plot a name in the File name box\nChange the height and width values until you have a good aspect ratio for the plot. You can preview the image to see that it looks good.\nClick Save\nIn Word or Google Docs, import the image from where you saved it.\nResize the image to take up less space if you can. (It needs to be readable, but not too big.)\nAdd the figure number and caption using your word-processing document. :::"
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#using-piping-with-ggplot2",
    "href": "01-05-visualizing-with-ggplot2.html#using-piping-with-ggplot2",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.12 Using Piping with {ggplot2}",
    "text": "5.12 Using Piping with {ggplot2}\nSince output from the piping operator produces a data frame, we can pipe the data into the ggplot() global layer rather than using the argument data=. For example:\n\n# Use piping to indicate the data\ngapminder |&gt;\n  ggplot(aes(x = income, y = co2)) +  \n    geom_smooth() +\n    geom_point() \n\nThis is useful if you are wrangling data and want to see a plot. Here for example we filter to obtain the African countries and create the plot using only those countries. Note that since we only have observations from one region, we can now change the fill= to a fixed aesthetic.\n\ngapminder |&gt;\n  filter(region == \"Africa\") |&gt;\n  ggplot(aes(x = income, y = co2)) +  \n    geom_smooth() +\n    geom_point(shape = 21, size = 4, fill = \"#87CEEB\") +\n    theme_minimal()\n\n\n\n\nUsing {dplyr} functions and piping to plot athe African countries."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#practice-practice-practice",
    "href": "01-05-visualizing-with-ggplot2.html#practice-practice-practice",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.13 Practice, Practice, Practice",
    "text": "5.13 Practice, Practice, Practice\nThe key to becoming a {ggplot2} ninja is to practice by creating visualizations. They don‚Äôt have to be fancy! Even by creating simple visualizations, you will hone your skills. As you become more confident try changing the color, or the labels, or really anything.\nIf you are unsure where to start, one practice method I have found helpful is to try and re-create a plot that someone else has already created. There are many datasets available online that people have created plots for. One source of these is the Tidy Tuesday Repository.\nThere are also several resources to help you get started and continue your gg_journey! Here are a few I have found helpful:\n\nData visualization with ggplot2 cheatsheet : A one-page (front and back) cheatsheet of ggplot2 syntax with pictures https://www.rstudio.com/resources/cheatsheets/\nCookbook for R: Web-based version of Winston Chang‚Äôs R Graphics Cookbook http://www.cookbook-r.com/Graphs/ (The UMN library has electronic access to the actual book. Just search for ‚ÄúR Graphics Cookbook‚Äù and log-in with your x500.)\nData Visualization: A Practical Introduction: Online book about data viz using ggplot2 https://socviz.co/\n\nHappy Plotting!!! üìâ üéà"
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#references",
    "href": "01-05-visualizing-with-ggplot2.html#references",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "References",
    "text": "References\n\n\n\n\nWilkinson, L. (2005). The grammar of graphics (2nd ed.). Springer."
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#footnotes",
    "href": "01-05-visualizing-with-ggplot2.html#footnotes",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "",
    "text": "Computer scientists often use a 0‚Äì1 scale of intensity rather than a 0‚Äì255. In that case, our color of ‚Äúskyblue‚Äù would have an RGB triplet of (0.5294118 0.8078431 0.9215686). Here the original RGB triplet values are divided by 255.‚Ü©Ô∏é"
  },
  {
    "objectID": "02-00-regression-basics.html",
    "href": "02-00-regression-basics.html",
    "title": "Regression Basics",
    "section": "",
    "text": "In this unit we will introduce the ideas of regression. You will learn about using the simple regression model to describe the relationship between two quantitative variables. You will also learn how the parameters for this model are estimated and how correlation and regression are related. Finally you will learn how to carry out statistical inference on the regression parameters."
  },
  {
    "objectID": "02-01-simple-regression-description.html#data-exploration",
    "href": "02-01-simple-regression-description.html#data-exploration",
    "title": "6¬† Simple Linear Regression‚ÄîDescription",
    "section": "6.1 Data Exploration",
    "text": "6.1 Data Exploration\nAny analysis should start with an initial exploration of the data. During this exploration, you should examine each of the variables that you will be including in the regression analysis. This will help you understand the results you get in later analyses, and will also help foreshadow potential problems with the analysis. This blog post describes initial ideas of data exploration reasonably well. You could also refer to almost any introductory statistics text for additional detail.\nIt is typical to begin by exploring the distribution of each variable used in the analysis separately. These distributions are referred to as marginal distributions. After that, it is appropriate to explore the relationships between the variables.\n\n\n6.1.1 Marginal Distribution of Income\nTo begin this exploration, we will examine the marginal distribution of employee incomes. We can plot a marginal distribution using functionality from the {ggplot2} package.\n\nggplot(data = city, aes(x = income)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Income (in thousands of dollars)\") +\n  ylab(\"Probability density\")\n\n\n\n\nDensity plot of employee incomes.\n\n\n\n\nThis plot suggests that the distribution of employee incomes is unimodal and most of the incomes are between roughly $50,000 and $70,000. The smallest income in the sample is about $25,000 and the largest income is over $80,000. This indicates there is a fair amount of variation in the data.\nTo further summarize the distribution, it is typical to compute and report summary statistics such as the mean and standard deviation. One way to compute these values is to use functions from the {dplyr} library.\n\ncity |&gt;\n  summarize(\n    M = mean(income),\n    SD = sd(income)\n    )\n\n\n\n  \n\n\n\nDescribing this variable we might write,\n\nThe marginal distribution of income is unimodal with a mean of approximately $53,700. There is variation in employees‚Äô salaries (SD = $14,500).\n\n\n\n\n6.1.2 Marginal Distribution of Education Level\nWe will also examine the marginal distribution of the education level variable.\n\n# Plot\nggplot(data = city, aes(x = education)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Education level\") +\n  ylab(\"Probability density\")\n\n\n\n\nDensity plot of employee education levels.\n\n\n\n\n\n# Summary statistics\ncity |&gt;\n  summarize(\n    M = mean(education),\n    SD = sd(education)\n    )\n\n\n\n  \n\n\n\nAgain, we might write,\n\nThe marginal distribution of education is unimodal with a mean of 16 years. There is variation in employees‚Äô level of education (SD = 4.4).\n\n\n\n\n6.1.3 Relationship Between Variables\nAlthough examining the marginal distributions is an important first step, those descriptions do not help us directly answer our research question. To better understand any relationship between income and education level we need to explore how the distribution of income differs as a function of education. To do this, we will create a scatterplot of income versus education.\n\nggplot(data = city, aes(x = education, y = income)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Education (in years)\") +\n  ylab(\"Income (in U.S. dollars)\")\n\n\n\n\nScatterplot displaying the relationship between employee education levels and incomes.\n\n\n\n\nThe plot suggests a relationship (at least for these employees) between level of education and income. When describing the relationship we want to touch on four characteristics of the relationship:\n\nFunctional form of the relationship\nDirection\nStrength\nObservations that do not fit the trend (outliers)"
  },
  {
    "objectID": "02-01-simple-regression-description.html#statistical-model-mathematical-description-of-the-data",
    "href": "02-01-simple-regression-description.html#statistical-model-mathematical-description-of-the-data",
    "title": "6¬† Simple Linear Regression‚ÄîDescription",
    "section": "6.2 Statistical Model: Mathematical Description of the Data",
    "text": "6.2 Statistical Model: Mathematical Description of the Data\nSince the relationship‚Äôs functional form seems reasonably linear, we will use a linear model to describe the data. We can express this model mathematically as,\n\\[\nY_i = \\beta_0 + \\beta_1(X_i) + \\epsilon_i\n\\]\nIn this equation,\n\n\\(Y_i\\) is the outcome/response value; it has an \\(i\\) subscript because it can vary across cases/individuals.\n\\(\\beta_0\\) is the intercept of the line that best fits the data; it does not vary across individuals.\n\\(\\beta_1\\) is the slope of the line that best fits the data; it does not vary across individuals.\n\\(X_i\\) is the predictor value; it has an \\(i\\) subscript because it can vary across cases/individuals.\n\\(\\epsilon_i\\) is the error term; it has an \\(i\\) subscript because it can vary across cases/individuals.\n\nThe linear statistical model (i.e., the regression model) can be separated into two components: a systematic (or fixed) component and a random (or stochastic) component.\n\\[\nY_i = \\underbrace{\\beta_0 + \\beta_1(X_i)}_{\\substack{\\text{Systematic} \\\\ \\text{(Fixed)}}} + \\underbrace{\\epsilon_i}_{\\substack{\\text{Random} \\\\ \\text{(Stochastic)}}}\n\\]\n\n\n6.2.1 Systematic Part of the Statistical Model\nThe systematic (fixed) part of the equation gives the mean value of Y given a particular X-value. The mean of Y given a particular X-value is referred to as a conditional mean of Y. The notation for the conditional mean of Y given a particular X value is \\(\\mu_{Y \\vert X_i}\\). We express the systematic part of the linear regression model mathematically as,\n\\[\n\\mu_{Y \\vert X_i} = \\beta_0 + \\beta_1(X_i)\n\\]\nNote that the systematic part of the equation does not include the error term. The error term is a part of the random component of the model. Statisticians also use \\(\\hat{Y_i}\\) to indicate the conditional mean of Y at a particular X. Thus, the systematic part of the linear regression model can also be written as,\n\\[\n\\hat{Y_i} = \\beta_0 + \\beta_1(X_i)\n\\]\nThe terms \\(\\beta_0\\) and \\(\\beta_1\\) in the systematic part of the model are referred to as the regression parameters. One of the primary goals of a regression analysis is to estimate the values of the regression parameters (i.e., the intercept and slope terms). Thus the systematic part of the regression model is a description, in mathematical form, of how the conditional mean Y is related to X. The equation here indicates that the conditional mean of Y (\\(\\hat{Y_i}\\)) is a linear function of X. This implies that the conditional mean value of Y differs by a constant amount for a constant difference in X.\nFor example, the difference between the mean income for those employees who have 10 years of education and those that have 11 years of education is the same as the difference between the mean income for those employees who have 17 years of education and those that have 18 years of education. Or, the difference between the mean income for those employees who have 4 years of education and those that have 8 years of education is the same as the difference between the mean income for those employees who have 20 years of education and those that have 24 years of education.\n\n\n\n6.2.2 Visual Representation of the Regression Model\nTo help better understand the model, consider the following plot:\n\n\n\n\n\nPlot displaying conditional distribution of Y at several X values. The OLS fitted regression line (dotted) is also shown. The red points show the mean value of Y for each conditional distribution.\n\n\n\n\nAt each value of X there is a distribution of Y. For example, there would be a distribution of incomes for the employees with an education level of 10 years (in the population). There would be another distribution of incomes for the employees with an education level of 11 years (in the population). And so on. These are the conditional distributions of Y.\nEach conditional distribution of Y has a mean; the conditional mean or \\(\\hat{Y_i}\\). These conditional means can be connected using a line. This is what it means to be able to express the conditional mean of Y as a linear function of X, or to say that the relationship between X and Y is linear.\n\n\n\n6.2.3 Random Part of the Statistical Model\nFrom the visual representation of the model, we can see that there is a distribution of Y-values at each X-value; this is represented by the normal distributions in the picture. In our example, there are many employees who have the same education level, but have different incomes. The error term in the statistical model accounts for this variation in Y for those cases that have the same X-value. Mathematically we can understand this by re-writing the statistical model, substituting \\(\\mu_{Y \\vert X_i}\\) into the systematic part of the model.\n\\[\n\\begin{split}\nY_i &= \\beta_0 + \\beta_1(X_i) + \\epsilon_i \\\\\nY_i &= \\mu_{Y \\vert X_i} + \\epsilon_i\n\\end{split}\n\\]\nThis equation implies that each observed Y-value is the sum of the conditional mean value of Y (which is based on the X-value) and some residual (or error) term. Re-arranging the terms, we can mathematically express the residual term as,\n\\[\n\\epsilon_i = Y_i - \\mu_{Y \\vert X_i}\n\\]\nOr, using the \\(\\hat{Y_i}\\) notation,\n\\[\n\\epsilon_i = Y_i - \\hat{Y_i}\n\\]\nTo compute an observation‚Äôs residual, we compute the difference between the observation‚Äôs Y-value and its conditional mean value. When the observed value of Y is larger than the conditional mean value of Y the residual term will be positive (underprediction). If the observed value of Y is smaller than the conditional mean value of Y the residual term will be negative (overprediction).\nTo further understand the residual term, consider the plot below. This figure shows the relationship between education and income we plotted earlier, and also includes the regression line.\n\n\n\n\n\nScatterplot displaying the relationship between employee education levels and incomes. The OLS fitted regression line is also displayed.\n\n\n\n\nConsider the three employees that have an education level of 10 years. The conditional mean income for these three employees is approximately $37,800. This is denoted by the blue point. Remember, the conditional means are on the regression line. The error (residual) term allows for a discrepancy between the conditional mean of Y and the observed Y. In other words, none of these three employees have an actual income of $37,800. The residual represents the difference between the employee‚Äôs observed income and the conditional mean income based on their education level.\nGraphically, the residual is represented by the vertical distance between the line and a given point on the scatterplot. Some of those points are above the line (they have a positive residual) and some are below the line (they have a negative residual). Also note that for some observations the error term is smaller than for others."
  },
  {
    "objectID": "02-01-simple-regression-description.html#estimating-parameters-in-the-regression-model",
    "href": "02-01-simple-regression-description.html#estimating-parameters-in-the-regression-model",
    "title": "6¬† Simple Linear Regression‚ÄîDescription",
    "section": "6.3 Estimating Parameters in the Regression Model",
    "text": "6.3 Estimating Parameters in the Regression Model\nThe regression model describes the relationship between Y-values and X-values in the population. Every term in the model denoted using a Greek letter is an unknown parameter in this model. In the model we have written there are three unknown parameters denoted in the model: the intercept term (\\(\\beta_0\\)), the slope term (\\(\\beta_1\\)), and the residual term (\\(\\epsilon_i\\)).1\nIn most statistical analyses, you will use a sample of data (not the entire population) to estimate the parameter values. Because a sample is only a subset of the population, the values we obtain for the parameters are imperfect estimates. To denote that the parameters are sample-based estimates, we add a hat to each parameter we are estimating. For example, estimates of the parameter estimates of \\(\\hat\\beta_0\\) and \\(\\hat\\beta_1\\) (referred to as regression coefficients) are typically reported in a regression analysis and should include hats.\nApplied researchers and statisticians tend to focus their analysis on the systematic (fixed) part of the model, and are thus often most interested in the values of the regression coefficients. After fitting the model to data, the estimated conditional means can be expressed mathematically as:\n\\[\n\\hat\\mu_{Y \\vert X_i} = \\hat\\beta_0 + \\hat\\beta_1(X_i)\n\\]\nOr, using the notation \\(\\hat{Y}_i\\) rather than \\(\\hat\\mu_{Y \\vert X_i}\\), as:\n\\[\n\\hat{Y_i} = \\hat\\beta_0 + \\hat\\beta_1(X_i)\n\\]\nWe use the hats when we are indicating sample-based estimates of these values, so hats should be used when you are reporting the values obtained after using a sample of data to obtain the values.2 The two estimated parameters of interest here (\\(\\hat\\beta_0\\) and \\(\\hat\\beta_1\\)) are referred to as the estimated regression coefficients, and this equation is often referred to as the fitted regression equation, or simply the fitted equation.\n\n\n6.3.1 Estimating Residuals\nNote that we can also use the estimated regression coefficients to obtain estimates for the residuals, often referred to as the observed residuals. Here we make use of the earlier idea that the residual term was the difference between the observed value of Y and the conditional mean of Y for a given X-value. Mathematically,\n\\[\n\\epsilon_i = Y_i - \\mu_{Y \\vert X_i}\n\\]\nOnce we use data to obtain estimates for the intercept and slope (\\(\\hat\\beta_0\\) and \\(\\hat\\beta_1\\)) we can substitute those into the fitted equation and obtain an estimate for the conditional mean (\\(\\hat{\\mu}_{Y \\vert X_i}\\)). This value can then be used to obtain an estimate for the residual.\n\\[\n\\hat\\epsilon_i = Y_i - \\hat{\\mu}_{Y \\vert X_i}\n\\]\nOr, using the ‚ÄúY-hat‚Äù notation,\n\\[\n\\hat\\epsilon_i = Y_i - \\hat{Y_i}\n\\]\nRemember, the hat on the residual indicates it is an estimate based on values obtained from the data!"
  },
  {
    "objectID": "02-01-simple-regression-description.html#fitting-a-regression-model-to-data-using-r",
    "href": "02-01-simple-regression-description.html#fitting-a-regression-model-to-data-using-r",
    "title": "6¬† Simple Linear Regression‚ÄîDescription",
    "section": "6.4 Fitting a Regression Model to Data Using R",
    "text": "6.4 Fitting a Regression Model to Data Using R\nTo fit the regression model to data using R, we will use the lm() function. The syntax for this function looks like this:\n\nlm(outcome ~ 1 + predictor, data = dataframe)\n\nwhere outcome is the name of the outcome/response variable, predictor is the name of the predictor variable, and dataframe is the name of the data frame. (The 1 on the right side of the tilde tells R to include the intercept in its computation.) When we fit a regression model in R, we will also assign the output to a new object in R. Below, we fit the model using education level to predict income. Here the output is assigned to an object called lm.a. We can print the regression parameter estimates by typing the lm() object name and hitting enter.\n\n# Fit regression model\nlm.a = lm(income ~ 1 + education, data = city)\n\n# Print regression coefficients\nlm.a\n\n\nCall:\nlm(formula = income ~ 1 + education, data = city)\n\nCoefficients:\n(Intercept)    education  \n     11.321        2.651  \n\n\nHere the parameter estimates (or regression coefficients) are:\n\n\\(\\hat{\\beta}_0 = 11.321\\)\n\\(\\hat{\\beta}_1 = 2.651\\)\n\nRemember that these are estimates and need the hats. The systematic part of the fitted regression model (or fitted equation) is:\n\\[\n\\hat{\\mathrm{Income}_i} = 11.321 + 2.651(\\mathrm{Education~Level}_i)\n\\]\n\n\n6.4.1 Intercept Interpretation\nThe estimate for the intercept was 11.321. Graphically, this value indicates the value where the line passes through the Y-axis (i.e., Y-intercept). As such, it gives the \\(\\hat{Y}_i\\) or predicted value when \\(X=0\\). Algebraically we get the same thing if we substitute 0 in for \\(X_i\\) in the fitted regression equation.\n\\[\n\\begin{split}\n\\hat{Y}_i &= \\hat{\\beta}_0 + \\hat{\\beta}_1(0) \\\\\n\\hat{Y}_i &= \\hat{\\beta}_0\n\\end{split}\n\\]\nTo interpret this value, remember that \\(\\hat{Y}_i\\) is a conditional mean. In this case, it represents the model predicted mean income for all employees that have an education level of 0 years. Graphically this looks like the following.\n\n\n\n\n\nFigure¬†6.1: Plot displaying conditional distribution of Y at \\(X=0\\). The OLS fitted regression line (dotted) is also shown. The red points show the mean value of Y for this conditional distribution‚Äîwhich corresponds to the intercept value of the regression line.\n\n\n\n\nInterpreting the intercept coefficient from our example,\n\nThe model predicted mean income for all employees that have an education level of 0 years is $11,321.\n\n\n\n\n6.4.2 Slope Interpretation\nRecall from algebra that the slope of a line describes the change in Y versus the change in X. In regression, the slope describes the predicted change in \\(\\hat{Y}\\) for a one-unit difference in X. In our example,\n\\[\n\\hat{\\beta}_1 = \\frac{\\Delta\\hat{Y}}{\\Delta X} = \\frac{2.651}{1}\n\\]\nAgain, because \\(\\hat{Y}\\) is a conditional mean, the slope represents the difference in predicted mean incomes for each one-year difference in education level. Graphically,\n\n\n\n\n\nPlot displaying conditional distribution of Y at \\(X=0\\) and \\(X=1\\). The OLS fitted regression line (dotted) is also shown. The red points show the mean value of Y for these conditional distributions‚Äîthe relative change which corresponds to the slope value of the regression line.\n\n\n\n\nInterpreting the slope coefficient in our example,\n\nEach one-year difference in education level is associated with a model predicted difference of $2,651 in mean income.\n\nTo better understand this, consider the mean income for city employees with three different education levels. The first set of employees have an education level of 10 years. The second set has an education level of 11 years, and the third set has an education level of 12 years. Now let‚Äôs compute each set of employees‚Äô mean income using the estimated regression coefficients.\n\\[\n\\begin{split}\n\\mathbf{Education=10:~}\\hat{\\mathrm{Income}} &= 11.321 + 2.651(10) \\\\\n&= 37.831\n\\end{split}\n\\]\n\\[\n\\begin{split}\n\\mathbf{Education=11:~}\\hat{\\mathrm{Income}} &= 11.321 + 2.651(11) \\\\\n&= 40.482\n\\end{split}\n\\]\n\\[\n\\begin{split}\n\\mathbf{Education=12:~}\\hat{\\mathrm{Income}} &= 11.321 + 2.651(12) \\\\\n&= 43.133\n\\end{split}\n\\]\nEach set of employees‚Äô education levels differ by one year (10 to 11 to 12). The difference in predicted mean incomes for these employees differs by 2.651 thousand dollars.\n\n\n\n6.4.3 Estimating Residuals\nConsider the 25th case in the data frame.\n\ncity |&gt;\n  filter(row_number() == 25)\n\n\n\n  \n\n\n\nThis employee (Employee 25) has an education level of 20 years (\\(X_{25}=20\\)). Her income is 54.672 thousand dollars (\\(Y_{25}=54.672\\)). Using the fitted regression equation, we can compute the model predicted mean income for employees with 20 years of education as,\n\n# Y_hat = b0 + b1 * X\n11.321 + 2.651 * 20\n\n[1] 64.341\n\n\n\\[\n\\hat{Y}_{25} = 64.341\n\\]\nWe could also report this using the conditional mean notation,\n\\[\n\\hat\\mu_{Y \\vert X=20} = 64.341\n\\]\nNow we can use the estimated conditional mean to also compute Employee 25‚Äôs residual.\n\n# e = Y - Y_hat\n54.672 - 64.341\n\n[1] -9.669\n\n\nUsing mathematical notation,\n\\[\n\\hat\\epsilon_{25} = -9.669\n\\]\nThe negative residual, \\(\\hat\\epsilon_{25} = -9.669\\), suggests that this employee earns $9,669 less than the average predicted income for employees with 20 years of education. We can also represent these values graphically.\n\n\n\n\n\nPlot displaying the OLS fitted regression line (blue) between employee education levels and incomes. The 25th employee‚Äôs observed data (black dot) is plotted, and a visual representation of the employee‚Äôs residual (red line) is also displayed."
  },
  {
    "objectID": "02-01-simple-regression-description.html#answering-the-research-question",
    "href": "02-01-simple-regression-description.html#answering-the-research-question",
    "title": "6¬† Simple Linear Regression‚ÄîDescription",
    "section": "6.5 Answering the Research Question",
    "text": "6.5 Answering the Research Question\nRemember that this whole analysis was driven because we wanted to answer a question, namely whether education level is related to income for the Riverview employees. The results from the regression analysis allow us to answer this question.\n\nTo answer the question of whether education level is related to income, a linear regression model was fitted to the data using ordinary least squares estimation. The results of this analysis suggested that education level is positively related to income for the 32 employees (\\(\\hat\\beta_1 = 2.65\\)). Each year of education is associated with a $2,651 difference in income, on average.\n\nHere the regression analysis provides a quantitative summary of the relationship between education level and income. It provides us with information about the direction of the relationship (positive) and the magnitude of that relationship. Although this can give us a description of the relationship, it is only for the sample of data you looked at (i.e., for these 32 employees). To make further statements about whether there is a relationship between education level and income in a broader population (e.g., all Riverview employees, or all California residents), we need more information, namely whether the sample is representative of the larger population and also statistical information about the amount of sampling error we have. (We will cover sampling error in Chapter 5.)"
  },
  {
    "objectID": "02-01-simple-regression-description.html#footnotes",
    "href": "02-01-simple-regression-description.html#footnotes",
    "title": "6¬† Simple Linear Regression‚ÄîDescription",
    "section": "",
    "text": "Technically there are many unknown residuals, one for each case, but the assumptions we put on the linear model make it so that we only care about the variance of the residuals, hence a single unknown.‚Ü©Ô∏é\nSometimes people use Roman letters when referring to sample estimates rather than hatting the Greek letters. For example, the sample-based equation might be denoted: \\(\\hat{Y}_i = b_0 + b_1(X_i) + e_i\\).‚Ü©Ô∏é"
  },
  {
    "objectID": "02-02-ols-estimation.html#ordinary-least-squares-estimation",
    "href": "02-02-ols-estimation.html#ordinary-least-squares-estimation",
    "title": "7¬† Ordinary Least Squares (OLS) Estimation",
    "section": "7.1 Ordinary Least Squares Estimation",
    "text": "7.1 Ordinary Least Squares Estimation\nHow does R determine the coefficient values of \\(\\hat{\\beta}_0=11.321\\) and \\(\\hat{\\beta}_1=2.651\\)? These values are estimated from the data using a method called Ordinary Least Squares (OLS). To understand how OLS works, consider the following toy data set of five observations:\n\n\n\n\n\n  \n  Table¬†7.1:  Toy data set with predictor (X) and outcome (Y) for five\nobservations. \n  \n    \n    \n      Xi\n      Yi\n    \n  \n  \n    30\n63\n    10\n44\n    30\n40\n    50\n68\n    20\n25\n  \n  \n  \n\n\n\n\n\nWhich of the following two models fits these data better?\n\nModel A: \\(~~\\hat{Y_i} = 28 + 0.8(X_i)\\)\nModel B: \\(~~\\hat{Y_i} = 20 + 1(X_i)\\)\n\nWe could plot the data and both lines and try to determine which seems to fit better.\n\n\n\n\n\n\n\nScatterplot of the observed toy data and the OLS fitted regression line for Model A.\n\n\n\n\n\n\n\n\n\nScatterplot of the observed toy data and the OLS fitted regression line for Model B."
  },
  {
    "objectID": "02-02-ols-estimation.html#datamodel-fit",
    "href": "02-02-ols-estimation.html#datamodel-fit",
    "title": "7¬† Ordinary Least Squares (OLS) Estimation",
    "section": "7.2 Data‚ÄìModel Fit",
    "text": "7.2 Data‚ÄìModel Fit\nIn this case, the lines are similar and it is difficult to make a determination of which fits the data better by eyeballing the two plots. Instead of guessing which model fits better, we can actually quantify the fit for the data by computing the residuals (errors) for each model and then comparing both sets of residuals; larger errors indicate a worse fitting model (i.e., more misfit to the data).\nRemember, to compute the residuals, we will first need to compute the predicted value (\\(\\hat{Y}_i\\)) for each of the five observations for both models.\n\n\n\n\n\n  \n  Table¬†7.2:  Observed values, predicted values and residuals for Model A. \n  \n    \n    \n      Xi\n      Yi\n      YÃÇi\n      ŒµÃÇi\n    \n  \n  \n    30\n63\n52\n11\n    10\n44\n36\n8\n    30\n40\n52\n-12\n    50\n68\n68\n0\n    20\n25\n44\n-19\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n  \n  Table¬†7.3:  Observed values, predicted values and residuals for Model B. \n  \n    \n    \n      Xi\n      Yi\n      YÃÇi\n      ŒµÃÇi\n    \n  \n  \n    30\n63\n50\n13\n    10\n44\n30\n14\n    30\n40\n50\n-10\n    50\n68\n70\n-2\n    20\n25\n40\n-15\n  \n  \n  \n\n\n\n\n\nEyeballing the numeric values of the residuals is also problematic. The size of the residuals is similar for both Models. Also, the eyeballing method would be impractical for larger datasets. So, we have to further quantify the model fit (or misfit). The way we do that in practice is to consider the total amount of error across all the observations. Unfortunately, we cannot just sum the residuals to get the total because some of our residuals are negative and some are positive. To alleviate this problem, we first square the residuals, then we sum them.\n\\[\n\\begin{split}\n\\mathrm{Total~Error} &= \\sum\\hat{\\epsilon}_i^2 \\\\\n&= \\sum \\left( Y_i - \\hat{Y}_i\\right)^2\n\\end{split}\n\\]\nThis is called a sum of squared residuals or sum of squared error (SSE; good name, isn‚Äôt it). Computing the squared residuals for Model A and Model B we get:\n\n\n\n\n\n  \n  Table¬†7.4:  Observed values, predicted values, residuals, and squared residuals\nfor Model A. \n  \n    \n    \n      Xi\n      Yi\n      YÃÇi\n      ŒµÃÇi\n      ŒµÃÇi2\n    \n  \n  \n    30\n63\n52\n11\n121\n    10\n44\n36\n8\n64\n    30\n40\n52\n-12\n144\n    50\n68\n68\n0\n0\n    20\n25\n44\n-19\n361\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n  \n  Table¬†7.5:  Observed values, predicted values, residuals, and squared residuals\nfor Model B. \n  \n    \n    \n      Xi\n      Yi\n      YÃÇi\n      ŒµÃÇi\n      ŒµÃÇi2\n    \n  \n  \n    30\n63\n50\n13\n169\n    10\n44\n30\n14\n196\n    30\n40\n50\n-10\n100\n    50\n68\n70\n-2\n4\n    20\n25\n40\n-15\n225\n  \n  \n  \n\n\n\n\n\nSumming these squared values for each model we obtain:\n\nModel A: SSE = 690\nModel B: SSE = 694\n\nOnce we have quantified the model misfit, we can choose the model that has the least amount of error. Since Model A has a lower SSE than Model B, we would conclude that Model A is the better fitting model to the data.\n\n\n7.2.1 Visualizing the SSE\nTo further understand the sum of squared error, we can examine a visual representation of the SSE for Model A. Recall that visually, the residual is the vertical distance between an observation and the fitted value (which lie on the fitted line). The residual indicates how different these two quantities are on the Y-metric. In the formula we squared each of the residuals. Visually, this is equivalent to producing the area of a square that has a side length equal to the absolute value of the residual.\n\n\n\n\n\n\n\n\nThis plot visually displays the residual values as line segments with negative residuals shown as dashed lines.\n\n\n\n\n\n\n\n\n\nThis plot visually displays the squared residuals as the area of a square with side length equal to the absolute value of the residual.\n\n\n\n\n\nFigure¬†7.1: Scatterplot of the observed toy data and the OLS fitted regression line for Model A.\n\n\nThe SSE is simply the total area encompassed by all of the squares. Note that the observation that is directly on the line has a residual of 0 and thus does not contribute a quantity to the SSE. If you computed the SSE for a line with different intercept or slope values, the SSE will be different. The plot below shows what this might look like for the flat line produced by \\(~~\\hat{Y_i} = 50\\).\n\n\n\n\n\nScatterplot of the observed toy data and the fitted flat line with Y-intercept of 50. The plot visually shows the squared residuals as the area of a square with side length equal to the absolute value of the residual.\n\n\n\n\nPowell & Lehe (2015) created an interactive website to help understand how the SSE is impacted by changing the intercept or slope of a line. You can also see how individual observations impact the SSE value."
  },
  {
    "objectID": "02-02-ols-estimation.html#best-fitting-model",
    "href": "02-02-ols-estimation.html#best-fitting-model",
    "title": "7¬† Ordinary Least Squares (OLS) Estimation",
    "section": "7.3 ‚ÄúBest‚Äù Fitting Model",
    "text": "7.3 ‚ÄúBest‚Äù Fitting Model\nIn the vocabulary of statistical estimation, the process we just used to adopt Model A over Model B was composed of two parts:\n\nQuantification of Model Fit: We quantify how well (or not well) the estimated model fits the data; and\nOptimization: We find the ‚Äúbest‚Äù model based on that quantification. (This boils down to finding the model that produces the biggest or smallest measure of model fit.)\n\nIn our example we used the SSE as the quantification of model fit, and then we optimized by selecting the model with the lower SSE. When we use lm() to fit a regression analysis to the data, R needs to consider not just two models like we did in our example, but all potential models (i.e., any intercept and slope). The model coefficients that lm() returns are the ‚Äúbest‚Äù in that no other values for intercept or slope would produce a lower SSE. The model returned has the lowest SSE possible thus least squares. For our toy dataset, the model that produces the smallest residuals is\n\\[\n\\hat{Y}_i = 28.682 + 8.614(X_i)\n\\]\nThis model gives the following predicted values and residuals:\n\n\n\n\n\n  \n  Table¬†7.6:  Observed values, predicted values, residuals, and squared residuals\nfor the ‚Äòbest‚Äô fitting model. \n  \n    \n    \n      Xi\n      Yi\n      YÃÇi\n      ŒµÃÇi\n      ŒµÃÇi2\n    \n  \n  \n    30\n63\n49.61364\n13.386364\n179.1947\n    10\n44\n33.47727\n10.522727\n110.7278\n    30\n40\n49.61364\n-9.613636\n92.4220\n    50\n68\n65.75000\n2.250000\n5.0625\n    20\n25\n41.54545\n-16.545455\n273.7521\n  \n  \n  \n\n\n\n\n\nThe SSE is 661.16. This is the smallest SSE possible for a linear model. Any other value for the slope or intercept would result in a higher SSE.\n\n\n7.3.1 Mathematical Optimization\nFinding the intercept and slope that give the lowest SSE is referred to as an optimization problem in the field of mathematics. Optimization is such an important (and sometimes difficult) problem that there have been several mathematical and computational optimization methods that have been developed over the years. You can read more about mathematical optimization on Wikipedia if you are interested.\nOne common mathematical method to find the minimum SSE involves calculus. We would write the SSE as a function of\\(\\beta_0\\) and \\(\\beta_1\\), compute the partial derivatives (w.r.t. each of the coefficients), set these equal to zero, and solve to find the values of the coefficients.  The lm() function actually uses an optimization method called QR decomposition to obtain the regression coefficients. The actual mechanics and computation of these methods are beyond the scope of this course. We will just trust that the lm() function is doing things correctly in this course."
  },
  {
    "objectID": "02-02-ols-estimation.html#computing-the-sse-for-the-model-fitted-to-the-riverview-data",
    "href": "02-02-ols-estimation.html#computing-the-sse-for-the-model-fitted-to-the-riverview-data",
    "title": "7¬† Ordinary Least Squares (OLS) Estimation",
    "section": "7.4 Computing the SSE for the Model Fitted to the Riverview Data",
    "text": "7.4 Computing the SSE for the Model Fitted to the Riverview Data\nSince the regression model is based on the lowest SSE, it is often useful to compute and report the model‚Äôs SSE. We can use R to compute the SSE by carrying out the computations underlying the formula for SSE. Recall that the SSE is\n\\[\n\\mathrm{SSE} = \\sum \\left( Y_i - \\hat{Y}_i\\right)^2\n\\]\nWe need to compute the:\n\nPredicted values (\\(\\hat{Y}_i\\));\nResiduals (\\(e_i\\));\nSquared residuals (\\(e_i^2\\)); and finally,\nSum of the squared residuals (\\(\\sum e_i^2\\)).\n\nFrom the Riverview data set we have the observed X (education level) and Y (income) values, and from the fitted lm() we have the intercept and slope estimates for the ‚Äòbest‚Äô fitting regression model.\n\n# Step 1: Compute the predicted values of Y\ncity |&gt;\n  mutate(\n    y_hat = 11.321 + 2.651 * education\n    )\n\n\n\n  \n\n\n# Step 2: Compute the residuals\ncity |&gt;\n  mutate(\n    y_hat = 11.321 + 2.651 * education,\n    errors = income - y_hat\n    )\n\n\n\n  \n\n\n# Step 3: Compute the squared residuals\ncity |&gt;\n  mutate(\n    y_hat = 11.321 + 2.651 * education,\n    errors = income - y_hat,\n    sq_errors = errors ^ 2\n  )\n\n\n\n  \n\n\n# Step 4: Compute the sum of the squared residuals\ncity |&gt;\n  mutate(\n    y_hat = 11.321 + 2.651 * education,\n    errors = income - y_hat,\n    sq_errors = errors ^ 2\n  ) |&gt;\n  summarize(\n    SSE = sum(sq_errors)\n  )\n\n\n\n  \n\n\n\nThe SSE gives us information about the variation in Y (the outcome variable) that is left over (residual) after we fit the regression model. Since the regression model is a function of X, the SSE tells us about the variation in Y that is left over after we remove the variation associated with, or accounted for by X. In our example it tells us about the residual variation in incomes after we account for employee education level.\nIn practice, we often report the SSE, but we do not interpret the actual value. The value of the SSE is more useful when comparing models. When researchers are considering different models, the SSEs from these models are compared to determine which model produces the least amount of misfit to the data (similar to what we did earlier).\n\n\n7.4.1 Evaluating the Impact of a Predictor Using SSE\nConsider again the general equation for the statistical model that includes a single predictor,\n\\[\nY_i = \\beta_0 + \\beta_1(X_i) + \\epsilon_i\n\\]\nOne way that statisticians evaluate a predictor is to compare a model that includes that predictor to the same model that does not include that predictor. For example, comparing the following two models allows us to evaluate the impact of \\(X_i\\).\n\\[\n\\begin{split}\nY_i &= \\beta_0 + \\beta_1(X_i) + \\epsilon_i \\\\\nY_i &= \\beta_0 + \\epsilon_i\n\\end{split}\n\\]\nThe second model, without the effect of X, is referred to as the intercept-only model. This model implies that the value of Y is not a function of X. In our example it suggests that the mean income is not conditional on education level. The fitted equation,\n\\[\n\\hat{Y}_i = \\hat{\\beta}_0\n\\]\nindicates that the predicted Y would be the same (constant) regardless of what X is. In our example, this would be equivalent to saying that the mean income is the same, regardless of employee education level.\n\n\n\n7.4.2 Fitting the Intercept-Only Model\nTo fit the intercept-only model, we just omit the predictor term on the right-hand side of the lm() formula.\n\nlm.0 = lm(income ~ 1, data = city)\nlm.0\n\n\nCall:\nlm(formula = income ~ 1, data = city)\n\nCoefficients:\n(Intercept)  \n      53.74  \n\n\nThe fitted regression equation for the intercept-only model can be written as,\n\\[\n\\hat{\\mathrm{Income}_i} = 53.742\n\\]\nGraphically, the fitted line is a flat line crossing the \\(y\\)-axis at 53.742 (see plot below).\n\n\n\n\n\nScatterplot of employee incomes versus education levels. The OLS fitted regression line for the intercept-only model is also displayed.\n\n\n\n\nDoes the estimate for \\(\\beta_0\\), 53.742, seem familiar? If not, go back to the exploration of the response variable in the Simple Linear Regression‚ÄîDescription chapter. The estimated intercept in the intercept-only model is the marginal mean value of the response variable. This is not a coincidence.\nRemember that the regression model estimates the mean. Here, since the model is not a conditional model (no X predictor) the expected value (mean) is the marginal mean.\n\\[\n\\begin{split}\n\\mu_Y &= \\beta_0 \\\\\n\\end{split}\n\\]\nPlotting this we get,\n\n\n\n\n\nPlot displaying the OLS fitted regression line for the intercept-only model. Histogram showing the marginal distributon of incomes is also shown.\n\n\n\n\nThe model itself does not consider any predictors, so on the plot, the X variable is superfluous; we could just collapse it to its margin. This is why the mean of all the Y values is sometimes referred to as the marginal mean.\nYet another way to think about this is that the model is choosing a single income (\\(\\hat{\\beta}_0\\)) to be the predicted income for all the employees. Which value would be a good choice? Remember the lm() function chooses the ‚Äúbest‚Äù value for the parameter estimate based on minimizing the sum of squared errors. The marginal mean is the value that minimizes the squared deviations (errors) across all of the observations, regardless of education level. This is one reason the mean is often used as a summary measure of a set of data.\n\n\n\n7.4.3 SSE for the Intercept-Only Model\nSince the intercept-only model does not include any predictors, the SSE for this model is a quantification of the total variation in the outcome variable. It can be used as a baseline measure of the error variation in the data. Below we compute the SSE for the intercept-only model (if you need to go through the steps one-at-a-time, do so.)\n\ncity |&gt;\n  mutate(\n    y_hat = 53.742,\n    errors = income - y_hat,\n    sq_errors = errors ^ 2\n  ) |&gt;\n  summarize(\n    SSE = sum(sq_errors)\n  )\n\n\n\n  \n\n\n\n\n\n\n7.4.4 Proportion Reduction in Error\nThe SSE for the intercept-only model represents the total amount of variation in the sample incomes. As such we can use it as a baseline for comparing other models that include predictors. For example,\n\nSSE (Intercept-Only): 6566\nSSE (w/Education Level Predictor): 2418\n\nOnce we account for education in the model, we reduce the SSE. Moreover, since the only difference between the intercept-only model and the predictor model was the inclusion of the effect of education level, any difference in the SSE is attributable to including education in the model. Since the SSE is smaller after we include education level in the model it implies that improving the data‚Äìmodel fit (smaller error).\nHow much did the amount of error improve? The SSE was reduced by 4148 after including education level in the model. Is this a lot? To answer that question, we typically compute and report this reduction as a proportion of the total variation; called the proportion of the reduction in error, or PRE.\n\\[\n\\mathrm{PRE} = \\frac{\\mathrm{SSE}_{\\mathrm{Intercept\\mbox{-}Only}} - \\mathrm{SSE}_{\\mathrm{Predictor\\mbox{-}Model}}}{\\mathrm{SSE}_{\\mathrm{Intercept\\mbox{-}Only}}}\n\\]\nFor our particular example,\n\\[\n\\begin{split}\n\\mathrm{PRE} &= \\frac{6566 - 2418}{6566} \\\\\n&= \\frac{4148}{6566} \\\\\n&= 0.632\n\\end{split}\n\\]\nIncluding education level as a predictor in the model reduced the error by 63.2%."
  },
  {
    "objectID": "02-02-ols-estimation.html#partitioning-variation",
    "href": "02-02-ols-estimation.html#partitioning-variation",
    "title": "7¬† Ordinary Least Squares (OLS) Estimation",
    "section": "7.5 Partitioning Variation",
    "text": "7.5 Partitioning Variation\nUsing the SSE terms we can partition the total variation in \\(Y\\) (the SSE value from the intercept-only model) into two parts: (1) the part that is explained by the model, and (2) the part that remains unexplained. The unexplained variation is just the SSE from the regression model that includes \\(X\\); remember it is residual variation. Here is the partitioning of the variation in income.\n\\[\n\\underbrace{6566}_{\\substack{\\text{Total} \\\\ \\text{Variation}}} = \\underbrace{4148}_{\\substack{\\text{Explained} \\\\ \\text{Variation}}} + \\underbrace{2418}_{\\substack{\\text{Unexplained} \\\\ \\text{Variation}}}\n\\]\nEach of these three terms is a sum of squares (SS). The first is referred to as the total sum of squares, as it represents the total amount of variation in \\(Y\\). The second term is commmonly called the model sum of squares (or, regression sum of squares), as it represents the variation explained by the model. The last term is the error sum of squares (or, residual sum of squares) as it represents the left-over variation that is unexplained by the model.\nMore generally,\n\\[\n\\mathrm{SS_{\\mathrm{Total}}} = \\mathrm{SS_{\\mathrm{Model}}} + \\mathrm{SS_{\\mathrm{Error}}}\n\\]\n\n\n7.5.1 Variation Accounted For\nIt is often convenient to express these values as proportions of the total variation. To do this we can divide each term in the partitioning by the total sum of squares.\n\\[\n\\frac{\\mathrm{SS_{\\mathrm{Total}}}}{\\mathrm{SS_{\\mathrm{Total}}}} = \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}} + \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\n\\]\nUsing the values from our example,\n\\[\n\\begin{split}\n\\frac{6566}{6566} &= \\frac{4148}{6566} + \\frac{2418}{6566} \\\\[2ex]\n1 &= 0.632 + 0.368\n\\end{split}\n\\]\nThe first term on the right-hand side of the equation, \\(\\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\\), is 0.632. This is the PRE value we computed earlier. Since the \\(\\mathrm{SS_{\\mathrm{Model}}}\\) represents the model-explained variation, many researchers interpret this value as the percentage of variation explained or accounted for by the model. They might say,\n\nThe model accounts for 63.2% of the variation in incomes.\n\nSince the only predictor in the model is education level, an alternative interpretation of this value is,\n\nDifferences in education level account for 63.2% of the variation in incomes.\n\nBetter models explain more variation in the outcome. They also have small errors. Aside from conceptually making some sense, this is also shown in the mathematics of the partitioning of variation.\n\\[\n1 = \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}} + \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\n\\]\nSince the denominator is the same on both terms, and the sum of the two terms must be one, this implies that the smaller the amount of error, the smaller the last term (proportion of unexplained variation ) must be and the larger the first term (the proportion of explained variation) has to be.\n\n\n\n7.5.2 R-Squared\nAnother way to think about measuring the quality of a model is that ‚Äògood‚Äô models should reproduce the observed outcomes, after all they explain variation in the outcome. How well do the fitted (predicted) values from our model match wih the outcome values? To find out, we can compute the correlation between the model fitted values and the observed outcome values. To compute a correlation, we will use the correlate() function from the {corrr} package.\n\n# Load library\nlibrary(corrr)\n\n# Create fitted values and correlate them with the outcome\ncity |&gt;\n  mutate(\n    y_hat = 11.321 + 2.651*education\n  ) |&gt;\n  select(y_hat, income) |&gt;\n  correlate()\n\n\n\n  \n\n\n\nThe correlation between the observed and fitted values is 0.795. This is a high correlation indicating that the model fitted values and the observed values are similar. We denote this value using the uppercase Roman letter \\(R\\).\n\\[\nR = 0.795\n\\]\nNow square this value.\n\\[\nR^2 = 0.795^2 = 0.632\n\\]\nAgain we get the PRE value! All three ways of expressing this metric of model quality are equivalent:\n\n\\(\\frac{\\mathrm{SSE}_{\\mathrm{Intercept\\mbox{-}Only}} - \\mathrm{SSE}_{\\mathrm{Predictor\\mbox{-}Model}}}{\\mathrm{SSE}_{\\mathrm{Intercept\\mbox{-}Only}}}\\)\n\\(\\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\\)\n\\(R^2\\)\n\nAlthough these indices seem to measure different aspects of model quality‚Äîreduction in error variation, model explained variation, and alignment of the model fitted and observed values‚Äîwith OLS fitted linear models, these values are all equal. This will not necessarily be true when we estimate model parameters using a different estimation method (e.g., maximum likelihood). Most of the time this value will be reported in applied research as \\(R^2\\), but as you can see, there are many interpretations of this value under the OLS framework.\n\n\n\n7.5.3 Back to Partitioning\nUsing the fact that \\(R^2 = \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\\), we can substitute this into the partitioning equation from earlier.\n\\[\n\\begin{split}\n\\frac{\\mathrm{SS_{\\mathrm{Total}}}}{\\mathrm{SS_{\\mathrm{Total}}}} &= \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}} + \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}} \\\\[2ex]\n1 &= R^2 + \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}} \\\\[2ex]\n1 - R^2 &= \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\n\\end{split}\n\\]\nThis suggests that the last term in the partititoning, \\(\\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\\) is simply the difference between 1 and \\(R^2\\). In our example,\n\n\\(R^2 = 0.632\\), and\n\\(1 - R^2 = 0.368\\)\n\nRemember that one interpretation of \\(R^2\\) is that 63.2% of the variation in incomes was explained by the model. Alternatively, 36.8% of the variation in income is not explained by the model; it is residual variation. If the unexplained variation is too large, it suggests to an applied analyst that she could include additional predictors in the model. We will explore this in future chapters.\nFor now, recognize that OLS estimation gives us the ‚Äòbest‚Äô model in terms of minimizing the sum of squared residuals, which in turn maximizes the explained variation. But, the ‚Äòbest‚Äô model may not be a ‚Äògood‚Äô model. One way to measure the quality of the model is through the metric of \\(R^2\\). Understanding whether \\(R^2\\) is large or small is based on the domain science. For example in some areas of educational research, an \\(R^2\\) of 0.4 might indicate a really great model, whereas the same \\(R^2\\) of 0.4 in some areas of biological research might be quite small and indicate a poor model."
  },
  {
    "objectID": "02-02-ols-estimation.html#references",
    "href": "02-02-ols-estimation.html#references",
    "title": "7¬† Ordinary Least Squares (OLS) Estimation",
    "section": "7.6 References",
    "text": "7.6 References\n\n\n\n\nPowell, V., & Lehe, L. (2015). Ordinary least squares regression: Explained visually. Explained Visually: A Setosa Project. https://setosa.io/ev/ordinary-least-squares-regression/"
  },
  {
    "objectID": "02-03-correlation.html#data-exploration",
    "href": "02-03-correlation.html#data-exploration",
    "title": "8¬† Correlation and Standardized Regression",
    "section": "8.1 Data Exploration",
    "text": "8.1 Data Exploration\nWe begin by looking at the marginal distributions of both time spent on homework and GPA. We will also examine summary statistics of these variables (output presented in Table¬†8.1). Finally, we also examine a scatterplot of GPA versus time spent on homework. (Note that the syntax is not shown.)\n\n\n\n\n\n\n\n\n\nFigure¬†8.1: Density plots of the marginal distribution of GPA.\n\n\n\n\n\n\n\n\n\nFigure¬†8.2: Density plots of the marginal distribution of time spent on homework.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†8.3: Scatterplot showing the relationship between GPA and time spent on homework.\n\n\n\n\n\n\n\n\n\n\n\n  \n  Table¬†8.1:  Summary measures for 8th-Grade students‚Äô GPA and time spent on\nhomework \n  \n    \n    \n      Measure\n      M\n      SD\n    \n  \n  \n    GPA\n80.47\n7.62\n    Time spent on homework\n5.09\n2.06\n  \n  \n  \n\n\n\n\n\nWe might describe the results of this analysis as follows:\n\nThe marginal distributions of GPA and time spent on homework are both unimodal. The average amount of time these 8th-grade students spend on homework each week is 5.09 hours (SD = 2.06). These 8th-grade students have a mean GPA of 80.47 (SD = 7.62) on a 100-pt scale. There is a moderate, positive, linear relationship between time spent on homework and GPA for these students. This suggests that 8th-grade students who spend less time on homework tend to have lower GPAs, on average, than students who spend more time on homework."
  },
  {
    "objectID": "02-03-correlation.html#correlation",
    "href": "02-03-correlation.html#correlation",
    "title": "8¬† Correlation and Standardized Regression",
    "section": "8.2 Correlation",
    "text": "8.2 Correlation\nTo numerically summarize the linear relationship between variables, we typically compute correlation coefficients. The correlation coefficient is a quantification of the direction and strength of the relationship. (It is important to note that the correlation coefficient is only an appropriate summarization of the relationship if the functional form of the relationship is linear.)\nTo compute the correlation coefficient, we use the correlate() function from the {corrr} package. We can use the dplyr-type syntax to select the variables we want correlations between, and then pipe that into the correlate() function. Typically the response (or outcome) variable is the first variable provided in the select() function, followed by the predictor.\n\n# Compute correlation between GPA and time spent on HW\nkeith |&gt;\n  select(gpa, homework) |&gt;\n  correlate()\n\n\n\n  \n\n\n\nWhen reporting the correlation coefficient between variables it is conventional to use a lower-case r and report the value to two decimal places.1 Subscripts are also generally used to indicate the variables. For example,\n\\[\nr_{\\mathrm{GPA,~Homework}} = 0.33\n\\]\nIt is important to keep in mind this value is only useful as a measure of the strength of the relationship when the relationship between variables is linear. Here is an example where the correlation coefficient would be misleading about the strength of the relationship.\n\n\n\n\n\nFigure¬†8.4: Hours of daylight versus day of the year for \\(n=75\\) days in Minneapolis.\n\n\n\n\nHere there is a perfect relationship between day of the year and hours of daylight. If you fitted a nonlinear model here, your ‚Äúline‚Äù would match the data exactly (no residual error!). But the correlation coefficient does not reflect that (\\(r=-0.34\\)).\n\nYou should always create a scatterplot to examine the relationship graphically before computing a correlation coefficient to numerically summarize it.\n\nAnother situation in which correlation can mislead is when you have subpopulations in your data. Here is an example of that.\n\n\n\n\n\n\n\nFigure¬†8.5: Salary versus neuroticism (0 = not at all neurotic; 7= very neurotic) as measured by the Big Five personality survey for \\(n=1000\\) employees from a Fortune 500 company.\n\n\n\n\n\n\n\n\n\nFigure¬†8.6: Salary versus neuroticism (0 = not at all neurotic; 7= very neurotic) as measured by the Big Five personality survey for \\(n=1000\\) employees from a Fortune 500 company. The data are colored by education level.\n\n\n\n\n\n\nIf we treat these data as one population (an assumption for using the correlation) the relationship between neurotocism and salary is positive; employees who are more neurotic tend to have higher salaries, on average. However, if we account for education level, the relationship between neurotocism and salary is negative for each of the education levels; once we account for education level, employees who are more neurotic tend to have lower salaries, on average. This reversal of the direction of the relationship once we account for other variables is quite common (so common it has a name, Simpson‚Äôs Paradox) and makes it difficult to be sure about the ‚Äútrue‚Äù relationship between variables in observational data."
  },
  {
    "objectID": "02-03-correlation.html#understanding-correlation",
    "href": "02-03-correlation.html#understanding-correlation",
    "title": "8¬† Correlation and Standardized Regression",
    "section": "8.3 Understanding Correlation",
    "text": "8.3 Understanding Correlation\nThere are many equivalent computational formulas for calculating the correlation coefficient. Each of these were useful in the days when we needed to hand-calculate the correlation. In practice, we now just use the computer to calculate the value of the correlation coefficient. That being said, some of these formulas are useful in helping us better understand what the correlation coefficient is measuring. Below is one such expression:\n\\[\nr_{xy} = \\frac{1}{n-1}\\sum_{i=1}^n\\bigg(\\frac{x_i - \\bar{x}}{s_x}\\bigg)\\bigg(\\frac{y_i - \\bar{y}}{s_y}\\bigg)\n\\]\nwhere, n is the sample size; \\(x_i\\) and \\(y_i\\) are the values for observation i of the variables x and y, respectively; \\(\\bar{x}\\) and \\(\\bar{y}\\) are the mean values for the variables x and y, respectively; and \\(s_x\\) and \\(s_y\\) are the standard deviations for the variables x and y, respectively.\nNote that the terms in the parentheses are the z-scores for the x- and y-values for a particular observation. Thus, this formula can be re-written as:\n\\[\nr_{xy} = \\frac{1}{n-1}\\sum_{i=1}^n\\bigg(z_{xi}\\bigg)\\bigg(z_{yi}\\bigg)\n\\]\nThis formula essentially says, multiply the z-scores of x and y together for each observation; add them together, and divide by the sample size.2 Adding things together and dividing by the sample size is the way we calculate an average. The correlation coefficient is an average of sorts! It is essentially the average product of the z-scores.\nAs we consider the product of the z-scores for x and y, recall that the z-score gives us information about how many standard deviations an observation is from the mean. Moreover, it gives us information about whether the observation is above the mean (positive z-score) or below the mean (negative z-score). Consider an observation that has both an x-value and y-value above the mean. That observation‚Äôs product would be positive.\n\\[\n\\begin{split}\n\\mathrm{\\scriptsize +} z_{x_i} &\\times \\mathrm{\\scriptsize +} z_{y_i} \\\\\n\\mathrm{positive~number} &\\times \\mathrm{positive~number}\n\\end{split}\n\\]\nThis would also be true for an observation that has both an x-value and y-value below the mean.\n\\[\n\\begin{split}\n-z_{x_i} &\\times -z_{y_i} \\\\\n\\mathrm{negative~number} &\\times \\mathrm{negative~number}\n\\end{split}\n\\]\nObservations the are above the mean on one variable and below the mean on the other would have a negative product. Here is a plot of the standardized GPA versus the standardized time spent on homework for the 100 observations. The mean values are also displayed.\n\n\n\n\n\nFigure¬†8.7: Plot of the standardized GPA versus the standardized time spent on homework for the 100 observations. The mean values are also displayed.\n\n\n\n\nIn this case there more observations having a positive product of z-scores than a negative product of z-scores. This suggests that the sum of all of these products will be positive; the correlation coefficient will be positive.3\nConceptually, that sum of products of z-scores in the formula for the correlation coefficient gives us an indication of the patterns of deviation from the mean values of x and y for the propensity of the data. The division by \\(n-1\\) serves to give us an indication of the magnitude of the ‚Äúaverage‚Äù product. This is why we interpret positive and negative relationships the way we do; a positive relationship suggests that higher values of x are typically associated with higher values of y and that lower values of x are typically associated with lower values of y. (Note that the words ‚Äúhigher‚Äù and ‚Äúlower‚Äù in that interpretation could more accurately be replaced with ‚Äúvalues above the mean‚Äù and ‚Äúvalues below the mean‚Äù, respectively.)\nWhen we say the direction of the relationship is positive, we statistically mean that the average product of z-scores is positive, which means that the propensity of the data has values of both variables either above or below the mean.\nOf course, we don‚Äôt have to use z-scores to see this pattern, afterall we typically look at a scatterplot of the unstandardized values to make this interpretation.\n\n\n\n\n\nFigure¬†8.8: Plot of GPA versus the time spent on homework (both unstandardized) for the 100 observations. The mean values are also displayed.\n\n\n\n\nConverting to z-scores is only useful to remove the metrics from the unstandardized values and place them on a common scale. This way values of the correlation coefficient are not dependent on the scales used in the data. This is why we do not put a metric on the correlation coefficient (e.g., it is just 0.30, not 0.30 feet)."
  },
  {
    "objectID": "02-03-correlation.html#correlations-relationship-to-regression",
    "href": "02-03-correlation.html#correlations-relationship-to-regression",
    "title": "8¬† Correlation and Standardized Regression",
    "section": "8.4 Correlation‚Äôs Relationship to Regression",
    "text": "8.4 Correlation‚Äôs Relationship to Regression\nThe correlation coefficient and the slope of the regression line are directly related to one another. Mathematically, the estimated slope of the simple regression line can be computed as:\n\\[\n\\hat\\beta_1 = r_{xy} \\times \\frac{s_y}{s_x}\n\\]\nwhere, \\(s_x\\) and \\(s_y\\) are the standard deviations for the variables \\(x\\) and \\(y\\), respectively, and \\(r_{xy}\\) is the correlation between \\(x\\) and \\(y\\). If we are carrying out a regression analysis, there must be variation in both \\(x\\) and \\(y\\), which implies that both \\(s_x\\) and \\(s_y\\) are greater than 0. This in turn implies that the ratio of the standard deviations (the second term on the right-hand side of the equation) is also a positive number. This means the sign of the slope is completely dependent on the sign of the correlation coefficient. If \\(r_{xy}&gt;0\\) then \\(\\hat\\beta_1&gt;0\\). If \\(r_{xy}&lt;0\\) then \\(\\hat\\beta_1&lt;0\\).\nThe magnitude of the regression slope (sometimes referred to as the effect of \\(x\\) on \\(y\\)) is impacted by three factors: the magnitude of the correlation between \\(x\\) and \\(y\\), the amount of variation in \\(y\\), and the amount of variation in \\(x\\). In general, there is a larger effect of \\(x\\) on \\(y\\) when:\n\nThere is a stronger relationship (higher correlation; positive or negative) between x and y;\nThere is more variation in the outcome; or\nThere is less variation in the predictor."
  },
  {
    "objectID": "02-03-correlation.html#standardized-regression",
    "href": "02-03-correlation.html#standardized-regression",
    "title": "8¬† Correlation and Standardized Regression",
    "section": "8.5 Standardized Regression",
    "text": "8.5 Standardized Regression\nIn standardized regression, the correlation plays a more obvious role. Standardized regression is simply regression performed on the standardized variables (z-scores) rather than on the unstandardized variables. To carry out a standardized regression:\n\nStandardize the outcome and predictor(s)\nFit a model by regressing \\(z_y\\) on \\(z_x\\)\n\nHere we will perform a standardized regression on the Keith data.\n\n# Standardize the outcome and predictor\nkeith = keith |&gt;\n  mutate(\n    z_gpa = (gpa - mean(gpa)) / sd(gpa),\n    z_homework = (homework - mean(homework)) / sd(homework),\n  )\n\n# View updated data\nhead(keith)\n\n\n\n  \n\n\n# Fit standardized regression\nlm.z = lm(z_gpa ~ 1 + z_homework, data = keith)\nlm.z\n\n\nCall:\nlm(formula = z_gpa ~ 1 + z_homework, data = keith)\n\nCoefficients:\n(Intercept)   z_homework  \n  7.627e-17    3.274e-01  \n\n\nThe fitted regression equation is:\n\\[\n\\hat{z}_{\\mathrm{GPA}_i} = 0 + 0.327(z_{\\mathrm{Homework}_i})\n\\]\nThe intercept in a standardized regression is always 0.4 Notice that the slope of the standardized regression is the correlation between the unstandardized variables. If we interpret these coefficients:\n\nThe predicted mean standardized GPA for all students who have a standardized value of homework of 0 is 0.\nEach one-unit difference in the standardized value of homework is associated with a 0.327-unit difference in predicted standardized GPA.\n\nRemember that standardized variables have a mean equal to 0 and a standard deviation equal to 1. Using that, these interpretations can be revised to:\n\nThe predicted mean GPA for all students who spend the mean amount of time on homework is the mean GPA.\nEach one-standard deviation difference in time spent on homework is associated with a 0.327-standard deviation difference in predicted GPA.\n\nHere is a scatterplot of the standardized variables along with the fitted standardized regression line. This will help you visually see the results of the standardized regression analysis.\n\nggplot(data = keith, aes(x = z_homework, y = z_gpa)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Time spent on homework (standardized)\") +\n  ylab(\"GPA (standardized)\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_abline(intercept = 0, slope = 0.327)\n\n\n\n\nPlot of the standardized GPA versus the standardized time spent on homework for the 100 observations. The mean values are also displayed (dashed lines) along with the fitted regression line (solid line).\n\n\n\n\nUsing standardized regression results allows us to talk about the effect of \\(x\\) on \\(y\\) in a standard metric (standard deviation difference). This can be quite helpful when the unstandardized metric is less meaningful. This is also why some researchers refer to correlation as an effect, even though the value of \\(R^2\\) is more useful in summarizing the usefulness of the model. Standardized regression also makes the intercept interpretable, since the mean value of \\(x\\) is not extrapolated.\n\n\n8.5.1 A Slick Property of the Regression Line\nNotice from the previous scatterplot of the standardized regression results that the standardized regression line goes through the point \\((0,0)\\). Since the variables are standardized, this is the point \\((\\bar{x}, \\bar{y})\\). The regression line will always go through the point \\((\\bar{x}, \\bar{y})\\) even if the variables are unstandardized. This is an important property of the regression line.\nWe can show this property mathematically by predicting \\(y\\) when \\(x\\) is at its mean. The predicted value when \\(x=\\bar{x}\\) is then\n\\[\n\\hat{Y}_i = \\hat\\beta_0 + \\hat\\beta_1(\\bar{x})\n\\]\nUsing a common formula for the regression intercept,\n\\[\n\\hat\\beta_0 = \\bar{y} - \\hat\\beta_1(\\bar{x}),\n\\]\nand substituting this into the prediction equation:\n\\[\n\\begin{split}\n\\hat{Y}_i &= \\hat\\beta_0 + \\hat\\beta_1(\\bar{x}) \\\\\n&= \\bar{y} - \\hat\\beta_1(\\bar{x}) + \\hat\\beta_1(\\bar{x}) \\\\\n&= \\bar{y}\n\\end{split}\n\\]\nThis implies that \\((\\bar{x}, \\bar{y})\\) is always on the regression line and that the predicted value of \\(y\\) for \\(x\\)-values at the mean is always the mean of \\(y\\).\n\n\n\n8.5.2 Variance Accounted For in a Standardized Regression\nThe \\(R^2\\) value for the standardized and unstandardized regression models are identical. That is because the correlation between \\(x\\) and \\(y\\) and that between \\(z_x\\) and \\(z_y\\) are identical (see below). Thus the squared correlation will also be the same, in this case \\(R^2 = 0.327^2 = 0.107\\).\n\nkeith |&gt;\n  select(z_gpa, z_homework) |&gt;\n  correlate()\n\n\n\n  \n\n\n\nWe can also compute \\(R^2\\) as the proportion reduction in error variation (PRE) from the intercept-only model. To do so we again compute the sum of squared error (SSE) for the standardized models (intercept-only and intercept-slope) and determine how much variation was explained by including the standardized amount of time spent on homework as a predictor.\nRemember that the intercept-only model is referred to as the marginal mean model‚Äîit predicts the marginal mean of \\(y\\) regardless of the value of \\(x\\). Since the variables are standardized, the marginal mean of \\(y\\) is 0. Thus the equation for the intercept-only model when the variables are standardized is:\n\\[\n\\hat{z}_{\\mathrm{GPA}} = 0\n\\]\nYou could also fit the intercept-only model to obtain this result, lm(z_gpa ~ 1, data = keith). We can now compute the SSE based on the intercept-only model.\n\n# Compute the SSE for the standardized intercept-only model\nkeith |&gt;\n  mutate(\n    y_hat = 0,\n    errors = z_gpa - y_hat,\n    sq_errors = errors ^ 2\n  ) |&gt;\n  summarize(\n    SSE = sum(sq_errors)\n  )\n\n\n\n  \n\n\n\nWe also compute the SSE for the standardized model that includes the standardized predictor of time spent on homework.\n\n# Compute the SSE for the standardized slope-intercept model\nkeith |&gt;\n  mutate(\n    y_hat = 0 + 0.327 * z_homework,\n    errors = z_gpa - y_hat,\n    sq_errors = errors ^ 2\n  ) |&gt;\n  summarize(\n    SSE = sum(sq_errors)\n  )\n\n\n\n  \n\n\n\nThe proportion reduction in SSE is:\n\\[\nR^2 = \\frac{99 - 88.39}{99} = 0.107\n\\]\nWe can say that differences in time spent on homework explains 10.7% of the variation in GPAs, and that 89.3% of the varition in GPAs remains unexplained. Note that if we compute the SSEs for the unstandardized models, they will be different than the SSEs for the standardized models (after all, they are in a different metric), but they will be in the same proportion, which produces the same \\(R^2\\) value."
  },
  {
    "objectID": "02-03-correlation.html#correlation-between-observed-values-fitted-values-and-residuals",
    "href": "02-03-correlation.html#correlation-between-observed-values-fitted-values-and-residuals",
    "title": "8¬† Correlation and Standardized Regression",
    "section": "8.6 Correlation Between Observed Values, Fitted Values, and Residuals",
    "text": "8.6 Correlation Between Observed Values, Fitted Values, and Residuals\nHere we examine a correlation matrix displaying the correlations between:\n\nThe observed values (\\(y_i\\)) and the fitted values (\\(\\hat{y}_i\\)),\nThe observed values (\\(y_i\\)) and the residuals (\\(e_i\\)), and\nThe fitted values and the residuals.\n\nIt doesn‚Äôt matter whether you use the unstandardized or standardized regression model here, but to illustrate, we will use the unstandardized model.\n\nkeith |&gt;\n  mutate(\n    y_hat = 74.290 + 1.214 * homework,\n    errors = gpa - y_hat\n  ) |&gt;\n  select(gpa, y_hat, errors) |&gt;\n  correlate()\n\n\n\n  \n\n\n\nThe first correlation between the observed values and the fitted values is 0.327. This is the same as the correlation between x and y. This is because the fitted values are just a linear transformation of x. In other words, the fitted values have the same relationship with y as x has with y. Note that if we square this value we get the \\(R^2\\) value for the model. So another way of computing \\(R^2\\) is to square the correlation between y and \\(\\hat{y}\\).\n\\[\nR^2 = (r_{y,\\hat{y}})^2\n\\]\nThe second correlation between the observed values and the residuals is 0.945. This is the value you get if you take the unexplained amount of variation from the model (0.893) and take its square root. Thus it gives us an indication of the unexplained variation in the model.\n\\[\n1 - R^2 = (r_{y,e})^2\n\\]\nThe last correlation between the fitted values and the residuals is 0. That is because the regression model assumes that the errors are independent of the fitted values. We have pulled out all of the information related to x out of the observed y-values (the fitted values) and what is left over is completely unrelated to x (the residuals). When a correlation is 0, statisticians say they two variables are independent of one another. Thus the fitted values and the residuals are said to be independent of one another.\n\\[\nr_{\\hat{y},e} = 0\n\\]"
  },
  {
    "objectID": "02-03-correlation.html#footnotes",
    "href": "02-03-correlation.html#footnotes",
    "title": "8¬† Correlation and Standardized Regression",
    "section": "",
    "text": "The correlation coefficient between observed outcome values and model predicted values uses an upper-case \\(R\\) rather than the lower-case r.‚Ü©Ô∏é\nTechnically divide by the total degrees of freedom, but for large values of n this difference is minor.‚Ü©Ô∏é\nThe sum also depends on the magnitude of the products. For example, if the magnitude of each the negative products is much higher than that for each of the positive products, the sum will be negative despite more positive products.‚Ü©Ô∏é\nR or other statistical software might round this to a very small number. The intercept should always be reported as zero, or dropped from the fitted equation.‚Ü©Ô∏é"
  },
  {
    "objectID": "02-04-coefficient-level-inference.html#statistical-inference",
    "href": "02-04-coefficient-level-inference.html#statistical-inference",
    "title": "9¬† Coefficient-Level Inference",
    "section": "9.1 Statistical Inference",
    "text": "9.1 Statistical Inference\nWhat if we want to understand the relationship between time spent on homework and GPA for a larger population of 8th-grade students, say all of them in the district? The problem is that if we had drawn a different sample of \\(n=100\\) 8th-grade students, all the regression estimates (\\(\\hat\\beta_0, \\hat\\beta_1,\\) and \\(R^2\\)) would be different than the ones we obtained from our sample. This makes it difficult to say, for example, how the conditional mean GPA differs for students with differing amounts of time spent on homework. In our observed sample, \\(\\hat\\beta_1\\) was 1.21. But, had we sampled different students, we might have found that \\(\\hat\\beta_1\\) was 2.03. And a different random sample of employees we might have produced a \\(\\hat\\beta_1\\) of 0.96.\nThis variation in the estimates arises because of the random nature of the sampling. One of the key findings in statistical theory is that the amount of variation in estimates under random sampling is completely predictable (this variation is called sampling error). Being able to quantify the sampling error allows us to provide a more informative answer to the research question. For example, it turns out that based on the quantification of sampling error in our example, we believe that the actual \\(\\beta_1\\) is between 0.51 and 1.92.\nStatistical inference allows us to learn from incomplete or imperfect data Gelman & Hill (2007). In many studies, the primary interest is to learn about one or more characteristics about a population. These characteristics must be estimated from sample data. This is the situation in our example, where we have only a sample of 8th-grade students and we want to understand the relationship between time spent on homework and GPA for ALL 8th-grade students in the district.\nIn the example, the variation in estimates arises because of sampling variation. It is also possible to have variation because of imperfect measurement. This is called measurement error. Despite these being very different sources of variation, in practice they are often combined (e.g., we measure imperfectly and we want to make generalizations).\nRegardless of the sources of variation, the goals in most regression analyses are two-fold:\n\nEstimate the parameters from the observed data; and\nSummarize the amount of uncertainty (e.g., quantify the sampling error) in those estimates.\n\nThe first goal we addressed in the Simple Linear Regression‚ÄîDescription chapter. It is the second goal that we will explore in this chapter."
  },
  {
    "objectID": "02-04-coefficient-level-inference.html#quantification-of-uncertainty",
    "href": "02-04-coefficient-level-inference.html#quantification-of-uncertainty",
    "title": "9¬† Coefficient-Level Inference",
    "section": "9.2 Quantification of Uncertainty",
    "text": "9.2 Quantification of Uncertainty\nBefore we talk about estimating uncertainty in regression, let me bring you back in time to your Stat I course. In that course, you probably spent a lot of time talking about sampling variation for the mean. The idea went something like this: Imagine you have a population that is infinitely large. The observations in this population follow some probability distribution. (This distribution is typically unknown in practice, but for now, let‚Äôs pretend we know what that distribution is.) For our purposes, let‚Äôs assume the population is normally distributed with a mean of \\(\\mu\\) and a standard deviation of \\(\\sigma\\).\nSample n observations from that population. Based on the n sampled observations, find the mean. We will call this \\(\\hat\\mu_1\\) since it is an estimate for the population mean (the subscript just says it is the first sample). In all likelihood, \\(\\hat\\mu_1\\) is not the exact same value as \\(\\mu\\). It varies from the population mean because of sampling error.\nNow, sample another n observations from the population. Again, find the mean. We will call this estimate \\(\\hat\\mu_2\\). Again, it probably varies from \\(\\mu\\), and may be different than \\(\\hat\\mu_1\\) as well. Continue to repeat this process: randomly sample n observations from the population; and find the mean.\n\n\n\n\n\nFigure¬†9.2: Thought experiment for sampling samples of size n from the population to obtain the sampling distribution of the mean.\n\n\n\n\nThe distribution of the sample means, it turns out, is quite predictable using statistical theory. Theory predicts that the distribution of the sample means will be normally distributed. It also predicts that the mean, or expected value, of all the sample means will be equal to the population mean, \\(\\mu\\). Finally, theory predicts that the standard deviation of this distribution, called the standard error, will be equal to the population standard deviation divided by the square root of the sample size. Mathematically, we would write all this as,\n\\[\n\\hat\\mu_n\\sim\\mathcal{N}\\left(\\mu, \\dfrac{\\sigma}{\\sqrt{n}}\\right).\n\\]\nThe important thing is not that you memorize this result, but that you understand that the process of randomly sampling from a known population can lead to predictable results in the distribution of statistical summaries (e.g., the distribution of sample means). The other crucial thing is that there the sampling variation can be quantified. The standard error is the quantification of that sampling error. In this case, it gives a numerical answer to the question of how variable the sample mean will be because of random sampling.\n\n\n9.2.1 Quantification of Uncertainty in Regression\nWe can extend these ideas to regression. Now the thought experiment goes something like this: Imagine you have a population that is infinitely large. The observations in this population have two attributes, call them X and Y. The relationship between these two attributes can be expressed via a regression equation as: \\(\\hat{Y}=\\beta_0 + \\beta_1(X)\\). Randomly sample n observations from the population. This time, rather than computing a mean, regress the sample Y values on the sample X values. Since the sample regression coefficients are estimates of the population parameters, we will write this as: \\(\\hat{Y}=\\hat{\\beta}_{0,1} + \\hat{\\beta}_{1,1}(X)\\). Repeat the process. This time the regression equation is: \\(\\hat{Y}=\\hat{\\beta}_{0,2} + \\hat{\\beta}_{1,2}(X)\\). Continue this process an infinite number of times.\n\n\n\n\n\nFigure¬†9.3: Thought experiment for sampling samples of size n from the population to obtain the sampling distribution of the regression coefficients.\n\n\n\n\nStatistical theory again predicts the characteristics of the two distributions, that of \\(\\hat{\\beta}_0\\) and that of \\(\\hat{\\beta}_1\\). The distribution of \\(\\hat{\\beta}_0\\) can be expressed as,\n\\[\n\\hat\\beta_0\\sim\\mathcal{N}\\left(\\beta_0,~ \\sigma_\\epsilon\\sqrt{\\dfrac{1}{n} + \\dfrac{\\mu_X^2}{\\sum(X_i-\\mu_X)^2}}\\right).\n\\]\nSimilarly, the distribution of \\(\\hat{\\beta}_1\\) can be expressed as,\n\\[\n\\hat\\beta_1\\sim\\mathcal{N}\\left(\\beta_1,~ \\dfrac{\\sigma_\\epsilon}{\\sigma_x\\sqrt{n-1}}\\right).\n\\]\nAgain, don‚Äôt panic over the formulae. What is important is that theory allows us to quantify the variation in both \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) that is due to sampling error. In practice, our statistical software will give us the numerical estimates of the two standard errors.\n\n\n\n9.2.2 Obtaining SEs for the Regression Coefficients\nTo obtain the standard errors for the regression coefficients, we will use the tidy() function from the {broom} package to display the fitted regression output. We provide the fitted regression object as the input to this function.\n\n# Display the coefficient-level output\ntidy(lm.a)\n\n\n\n  \n\n\n\nIn the displayed output, we now obtain the estimates for the standard errors in addition to the coefficient estimates. We can use these values to quantify the amount of uncertainty due to sampling error. For example, the estimate for the slope, 1.21, has a standard error of 0.35. One way to envision this is as a distribution. Our best guess (mean) for the slope parameter is 1.21. The standard deviation of this distribution is 0.35, which indicates the precision (uncertainty) of our estimate.\n\n\n\n\n\nFigure¬†9.4: Sampling distribution of the slope coefficient. The distribution is approximately normal with a mean of 1.21 and a standard error of 0.35.\n\n\n\n\nIn the social sciences, it is typical to express uncertainty as \\(\\pm2(SE)\\). Here we would say that becquse of sampling variation, the slope is likely between 0.51 and 1.91. Interpreting this, we might say,\n\nFor all 8th-graders in the district, each one-hour difference in time spent on homework per week is associated with a difference in overall GPA between 0.51 and 1.91, on average.\n\nSimilarly, we could express the uncertainty in the intercept as,\n\\[\n74.29 \\pm 2(1.94) = \\left[70.41,~78.17\\right]\n\\]\nInterpreting this, we might say,\n\nThe average GPA for all 8th-grade students in the district who spend zero hopurs per week on homework is between 70.41 and 78.17.\n\nWe can use the conf.int=TRUE argument in the tidy() function to obtain these limits directly. By default this will compute a 95% CI. This can be changed using the conf.level= argument.1\n\n# Include CIs in the coefficient-level output\ntidy(lm.a, conf.int = TRUE, conf.level = 0.95)"
  },
  {
    "objectID": "02-04-coefficient-level-inference.html#hypothesis-testing",
    "href": "02-04-coefficient-level-inference.html#hypothesis-testing",
    "title": "9¬† Coefficient-Level Inference",
    "section": "9.3 Hypothesis Testing",
    "text": "9.3 Hypothesis Testing\nSome research questions point to examining whether the value of some regression parameter differs from a specific value. For example, it may be of interest whether a particular population model (e.g., one where \\(\\beta_1=0\\)) could produce the sample result of a particular \\(\\hat\\beta_1\\). To test something like this, we state the value we want to test in a statement called a [null hypothesis](https://en.wikipedia.org/wiki/Null_hypothesis. For example,\n\\[\nH_0: \\beta_1 = 0\n\\]\nThe hypothesis is a statement about the population. Here we hypothesize \\(\\beta_1=0\\). It would seem logical that one could just examine the estimate of the parameter from the observed sample to answer this question, but we also have to account for sampling uncertainty. The key is to quantify the sampling variation, and then see if the sample result is unlikely given the stated hypothesis.\nOne question of interest may be: Is there evidence that the average GPA differs for different amounts of time spent on homework? In our example, we have a \\(\\hat\\beta_1=1.21\\). This is sample evidence, but does 1.21 differ from 0 more than we would expect because of random sampling? If it doesn‚Äôt, we cannot really say that the average GPA differs for different amounts of time spent on homework. To test this, we make an assumption that there is no relationship between time spent on homework and GPA, in other words, the slope of the line under this assumption would be 0. Before we talk about how to test this, we need to introduce one wrinkle into the procedure."
  },
  {
    "objectID": "02-04-coefficient-level-inference.html#estimating-variation-from-sample-data-no-longer-normal",
    "href": "02-04-coefficient-level-inference.html#estimating-variation-from-sample-data-no-longer-normal",
    "title": "9¬† Coefficient-Level Inference",
    "section": "9.4 Estimating Variation from Sample Data: No Longer Normal",
    "text": "9.4 Estimating Variation from Sample Data: No Longer Normal\nIn theory, the sampling distribution for two regression coefficients were both normally distributed. This is the case when we know the variation parameters in the population. For example, for the sampling distribution of the slope to be normally distributed, we would need to know \\(\\sigma_\\epsilon\\) and \\(\\sigma_x\\).\nIn practice these values are typically unknown and are estimated from the sample data. Anytime we are estimating things we introduce additional uncertainty. In this case, the uncertainty affects the shape of the sampling distribution.\n\n\n\n\n\nFigure¬†9.5: Comparison of two distributions. The normal distribution (solid, blue) and one with additional uncertainty (dashed, orange).\n\n\n\n\nCompare the normal distribution (solid, blue) to the distribution with additional uncertainty (dashed, orange). From the figure you can see that the additional uncertainty slightly changed the shape of the distribution from normal.\n\nIt is still symmetric and unimodal (like the normal distribution).\nThe additional uncertainty makes more extreme values more likely than they are in the normal distribution.\nThe additional uncertainty makes values in the middle less likely than they are in the normal distribution.\n\nIt is important to note that the amount of uncertainty affects how closely the shape of the distribution matches the normal distribution. And, that the sample size directly affects the amount of uncertainty we have. All things being equal, we have less uncertainty when we have larger samples. The following figure illustrates this idea.\n\n\n\n\n\nFigure¬†9.6: The normal distribution (solid, blue) and two t-distributions; one based on df=10 (dashed, orange), and the other based on df=4 (dotted, green).\n\n\n\n\n\n\n9.4.1 The t-Distribution\nAs pointed out, the distributions with uncertainty introduced from using a sample of data are not normally distributed. Thus, it doesn‚Äôt make sense to use a normal distribution as a model for describing the sampling variation. Instead, we will a t-distribution; a family of distributions that have several advantageous properties:\n\nThey are unimodal and symmetric.\nThey have more variation (uncertainty) than the normal distribution resulting in a distribution that has thicker tails and is shorter in the middle than a normal distribution.\nHow thick the tails are and how short the middle of the distribution is, is related to the sample size.\n\nSpecifically, the t-distribution is unimodal and symmetric with a mean of 0. The variance of the distribution (which also specifies the exact shape), is\n\\[\n\\mathrm{Var} = \\frac{\\textit{df}}{\\textit{df} - 2}\n\\]\nfor \\(\\textit{df}&gt;2\\) where \\(\\textit{df}\\) is referred to as the degrees of freedom.\n\n\n\n9.4.2 Back to the Hypothesis Test\nRecall that we are interested in testing the following hypothesis,\n\\[\nH_0: \\beta_1 = 0\n\\]\nTo test this we compute the number of standard errors that our observed slope (\\(\\hat\\beta_1=1.21\\)) is from the hypothesized value of zero (stated in the null hypothesis). Since we already obtained the standard error for the slope (\\(SE=0.354\\)), we just use some straight-forward algebra to compute this:\n\\[\n\\frac{1.21 - 0}{0.354} = 3.42\n\\]\nInterpreting this, we can say,\n\nThe observed slope of 1.21 is 3.42 standard errors from the expected value of 0.\n\nThis value is referred to as the observed t-value. (It is similar to a z-value in the way it is computed; it is standardizing the distance from the observed slope to the hypothesized value of zero. But, since we had to estimate the SE using the data, we introduced additional uncertainty; hence a t-value.)\nWe can evaluate this t-value within the appropriate t-distribution. For regression coefficients, the t-distribution we will use for evaluation has degrees of freedom that are a function of the sample size and the number of coefficients being estimated in the regression model, namely,\n\\[\n\\textit{df} = n - (\\textrm{number of coefficients}).\n\\]\nIn our example the sample size (n) is 100, and the number of coefficients being estimated in the regression model is two (\\(\\hat\\beta_0\\) and \\(\\hat\\beta_1\\)). Thus,\n\\[\n\\textit{df} = 100 - 2 = 98\n\\]\nBased on this, we will evaluate our observed t-value of 3.42 using a t-distribution with 98 degrees of freedom. Using this distribution, we can compute the probability of obtaining a t-value (under random sampling) at least as extreme as the one in the data under the assumed model. This is equivalent to finding the area under the probability curve for the t-distribution that is greater than or equal to 3.42.2 This is called the p-value.\n\n\n\n\n\nFigure¬†9.7: Plot of the probability curve for the t(98) distribution. The shaded area under the curve represents the p-value for a two-tailed test evaluating whether the population slope is zero using an observed t-value of 73.42.\n\n\n\n\nThe p-value is computed for us and displayed in the tidy() output, along with the t-value (provided in the statistic column). In our example, \\(p=0.000885\\). (Note that the p-value might be printed in scientific notation. For example, it may be printed as 8.85e-04, which is equivalent to \\(8.85 \\times 10^{-4}\\).) To interpret this we would say,\n\nThe probability of observing a t-value of 3.42, or a t-value that is more extreme, under the assumption that \\(\\beta_1=0\\) is 0.000885.\n\nThis is equivalent to saying:\n\nThe probability of observing a sample slope of 1.21, or a slope that is more extreme, under the assumption that \\(\\beta_1=0\\) is 0.000885.\n\nThis is quite unlikely, and indicates that the empirical data are inconsistent with the hypothesis that \\(\\beta_1=0\\). As such, it serves as evidence against the hypothesized model. In other words, it is likely that \\(\\beta_1\\neq0\\).\n\n\n\n9.4.3 Testing the Intercept\nThe hypothesis being tested for the intercept is \\(H_0:\\beta_0=0\\). The tidy() output also provides information about this test:\n\n# Coefficient-level output\ntidy(lm.a)\n\n\n\n  \n\n\n\nThe results indicate that the observed intercept of 74.28 is 38.26 standard errors from the hypothesized value of 0;\n\\[\nt = \\frac{74.28 - 0}{1.94} = 38.26\n\\]\nAssuming the null hypothesis that \\(\\beta_0=0\\) is true, the probability of observing a sample intercept of 74.28 or one that is more extreme, is \\(1.01 \\times 10^{-60}\\). (Any p-value less than .001 is typically reported as \\(p&lt;.001\\).) This is evidence against the hypothesized model. Because of this, we would say the empirical data are inconsistent with the hypothesis that \\(\\beta_0=0\\); it is unlikely that the intercept in the population is zero."
  },
  {
    "objectID": "02-04-coefficient-level-inference.html#statistical-significance-an-outdated-idea-for-research",
    "href": "02-04-coefficient-level-inference.html#statistical-significance-an-outdated-idea-for-research",
    "title": "9¬† Coefficient-Level Inference",
    "section": "9.5 ‚ÄòStatistical Significance‚Äô: An Outdated Idea for Research",
    "text": "9.5 ‚ÄòStatistical Significance‚Äô: An Outdated Idea for Research\nYou may have read papers or taken statistics courses that emphasized the language ‚Äústatistically significant‚Äù. This adjective was typically used when the empirical evidence was inconsistent with a hypothesized model, and the researcher subsequently ‚Äúrejected the null hypothesis‚Äù. In the social sciences this occurred when the \\(p\\)-value was less than or equal to 0.05.\nIn 2019, the American Statistical Association put out a special issue in one of their premier journals, stating,\n\n‚Ä¶it is time to stop using the term ‚Äòstatistically significant‚Äô entirely. Nor should variants such as ‚Äòsignificantly different,‚Äô ‚Äòp &lt; 0.05,‚Äô and ‚Äònonsignificant‚Äô survive, whether expressed in words, by asterisks in a table, or in some other way. Regardless of whether it was ever useful, a declaration of ‚Äòstatistical significance‚Äô has today become meaningless. (Wasserstein & Schirm, 2019, p. 2)\n\nThey went on to say,\n\n‚Ä¶no p-value can reveal the plausibility, presence, truth, or importance of an association or effect. Therefore, a label of statistical significance does not mean or imply that an association or effect is highly probable, real, true, or important. Nor does a label of statistical nonsignificance lead to the association or effect being improbable, absent, false, or unimportant. (Wasserstein & Schirm, 2019, p. 2)\n\nThis is not to say that p-values should not be reported; they should. But rather that we should not arbitrarily dichotomize a continuous measure into two categories whose labels are at best meaningless and at worst misleading. The goal of scientific inference (which is much broader than statistical inference for a single study) is replicability and empirically generalizable results and findings. And, as Hubbard et al. (2019) point out, declaring findings as ‚Äòsignificant‚Äô or ‚Äònot significant‚Äô works in direct opposition to the broader culmination of knowledge and evidence in a field.\nInstead, we want to begin to see the p-value as a measure of incompatibility between the empirical data and a very specific model, one in which a certain set of assumptions are true. Both the empirical data (which are unique to the specific study) and the model‚Äôs set of assumptions often make the p-value unique to the specific study carried out and less useful in the broader goal of scientific inference. As such we need to come to view the p-value for what it is, one measure of evidence, for one very particular model, in one very localized study. As Ron Wasserstein reminds us,\n\nSmall p-values are like a right-swipe in Tinder. It means you have an interest. It doesn‚Äôt mean you‚Äôre ready to book the wedding venue."
  },
  {
    "objectID": "02-04-coefficient-level-inference.html#confidence-intervals-as-compatibility-intervals",
    "href": "02-04-coefficient-level-inference.html#confidence-intervals-as-compatibility-intervals",
    "title": "9¬† Coefficient-Level Inference",
    "section": "9.6 Confidence Intervals as Compatibility Intervals",
    "text": "9.6 Confidence Intervals as Compatibility Intervals\nTo build on this, let‚Äôs return to the reporting and interpretation of confidence intervals. In our example, the 95% CI was:\n\n# Coefficient-level output with CI\ntidy(lm.a, conf.int = TRUE, conf.level = 0.95)\n\n\n\n  \n\n\n\nOne way of interpreting this interval is that every value in the interval is a parameter value that is reasonably compatible with the empirical data. For example, in considering the CI for the slope parameter, population slope \\((\\beta_1)\\) values between 0.51 and 1.92 are all reasonably compatible with the empirical data (with the caveat that, again, all the assumptions used to create the interval are satisfied). As applied researchers, we should describe the practical implications of all values inside the interval, especially the observed effect (or point estimate) and the limits.\nFor us this means describing the practical implications of the true slope being 1.21, as low as 0.51, and as high as 1.92. Are these meaningful differences in GPA (measure on a 100-pt.¬†scale)? Given that the SD for GPA was 7.62, a one-hour difference in time spent on homework is associated with at most a 0.25 SD difference in GPA or as little as a 0.07 SD difference in GPA. This is not a large difference, however whether it is meaningful depends on previous research about GPA.3\nConfidence intervals help us keep an open-mind about uncertainty, after all they suggest several values that are compatible with the empirical data. However, they can also be misleading. Amrhein et al. (2019) point out four key points fo us to remember as we use CIs:\n\nJust because the interval gives the values most compatible with the data, given the assumptions, it does not mean values outside it are incompatible; they are just less compatible.\nNot all values inside are equally compatible with the data, given the assumptions. The point estimate is the most compatible, and values near it are more compatible than those near the limits.\nLike the 0.05 threshold from which it came, the default 95% used to compute intervals is itself an arbitrary convention.\nLast, and most important of all, be humble: compatibility assessments hinge on the correctness of the statistical assumptions used to compute the interval. In practice, these assumptions are at best subject to considerable uncertainty.\n\n\n\n9.6.1 Coefficient Plot\nOne plot that helps visualize the estimates of the regression coefficients and the associated uncertainty is a coefficient plot. This plot, recommended by Gelman & Hill (2007), is a graphical representation of the information provided in the tidy() output.\n\n\n\n\n\nFigure¬†9.8: Coefficient plot for the model regressing GPA on time spent on homework. Uncertainty based on the 95% confidence intervals are displayed.\n\n\n\n\nThe coefficient plot shows the estimates of the regression coefficients (dots) and the uncertainty in those estimates via the confidence intervals (blue shading). Notice that darker shading is associated with parameter values that are more probable given the empirical data; the sample estimates are the most likely values for the regression parameters.\nTo create a coefficient plot, we will use the dwplot() function from the {dotwhisker} package. This function takes the ouput of tidy() as input. Since the function will identify the model, we also mutate a column called model into the tidy output giving the name of the model. Since dwplot() is based on ggplot() syntax, we can add layers to customize the plot in the same manner as if we were building a ggplot. The syntax I used to create the coefficient plot above is:\n\n# Load library\nlibrary(dotwhisker)\n\n# Store output from tidy\nmod_1 = tidy(lm.a) |&gt;\n  mutate(model = \"Model A\")\n\n# Create plot\ndwplot(mod_1, show_intercept = TRUE) +\n  theme_bw() +\n  scale_color_manual(name = \"Model\", values = c(\"#c62f4b\")) +\n  scale_x_continuous(name = \"Estimate\") +\n  scale_y_discrete(name = \"Coefficients\", labels = c(\"Time spent\\non homework\", \"Intercept\"))\n\nBy default, the plot will display 95% CI. To display a different level of confidence, specify conf.level= argument in tidy(). There are several variations of this plot. For example, below I omit the intercept from this plot. To do this, I use the filter() function to omit the row in the tidy() output that includes the intercept.4 I also change the limits on the x-axis to better fit the homework interval.\n\n\n\n\n\nFigure¬†9.9: Coefficient plot for the model regressing GPA on time spent on homework. Uncertainty based on the 95% confidence interval is displayed. Note that the intercept has been omitted.\n\n\n\n\n\n\n\n\n\nAmrhein, V., Greenland, S., & McShane, B. (2019). Retire statistical significance. Nature, 567, 305‚Äì307.\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge University Press.\n\n\nHubbard, R., Haig, B. D., & Parsa, R. A. (2019). The limited role of formal statistical inference in scientific inference. The American Statistician, 73, 91‚Äì98. https://doi.org/10.1080/00031305.2018.1464947\n\n\nWasserstein, R., & Schirm, A. (2019). Moving to a world beyond \\(p &lt; .05\\). Keynote presentation at the United States Conference on Teaching Statistics."
  },
  {
    "objectID": "02-04-coefficient-level-inference.html#footnotes",
    "href": "02-04-coefficient-level-inference.html#footnotes",
    "title": "9¬† Coefficient-Level Inference",
    "section": "",
    "text": "The actual limits from the 95% CI are computed using a multiplier that is slightly different than two; thus the discrepancy between our off-the-cuff computation earlier and the result from tidy(). Using a multiplier of two is often close enough for practical purposes, especially when the sample size is large.‚Ü©Ô∏é\nWe actually compute the area under the probability curve that is greater than or equal to 3.42 AND that is less than or equal to \\(-3.42\\).‚Ü©Ô∏é\nIt turns out this is quite a complicated question and the effects of homework depend on a variety of student factors, including age, culture, household income, etc. Many studies have also found a non-linear effect of homework, indicating there may be an optimum amount for some groups of students.‚Ü©Ô∏é\nThe intercept could also be dropped using show.intercept=FALSE which is the default for dwplot(). The filter() method, however, allows you to drop or select different predictors for display as well as the intercept.‚Ü©Ô∏é"
  },
  {
    "objectID": "02-05-model-level-inference.html#model-level-inference",
    "href": "02-05-model-level-inference.html#model-level-inference",
    "title": "10¬† Model-Level Inference",
    "section": "10.1 Model-Level Inference",
    "text": "10.1 Model-Level Inference\nIn the previous chapter, we looked at how to carry out statistical tests of hypotheses and quantify the uncertainty associated with the coefficients in the simple regression model. Sometimes you are interested in the model as a whole, rather than the individual parameters. For example, you may be interested in whether a set of predictors together explains variation in the outcome. Model-level information is displayed using the glance() output from the {broom} package. Below we fit a model by regressing GPA on time spent on homework, store those results in an object called lm.a, and then print the model-level output.\n\n# Fit regression model\nlm.a = lm(gpa ~ 1 + homework, data = keith)\n\n# Model-level output\nglance(lm.a)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.107        0.0981  7.24      11.8 0.000885     1  -339.  684.  691.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    5136.          98   100\n\n\nThe r.squared column indicates the proportion of variation in the outcome explained by differences in the predictor in the sample. Here, differences in time spent on homework explains 10.7% of the variation in students‚Äô GPAs for the 100 students in the sample. The inferential question at the model-level is: Does the model explain variation in the outcome, in the population? This can formally be expressed in a statistical hypothesis as,\n\\[\nH_0: \\rho^2 = 0\n\\]\nTo test this, we need to be able to obtain the sampling distribution of \\(R^2\\) to estimate the uncertainty in the sample estimate. The thought experiment for this goes something like this: Imagine you have a population that is infinitely large. The observations in this population have two attributes, call them \\(X\\) and \\(Y\\). There is NO relationship between these two attributes; \\(\\rho^2 = 0\\). Randomly sample \\(n\\) observations from the population. Fit the regression and compute the \\(R^2\\) value. Repeat the process an infinite number of times.\n\n\n\n\n\nFigure¬†10.1: Thought experiment for sampling samples of size n from the population to obtain the sampling distribution of R-squared.\n\n\n\n\nBelow is a density plot of the sampling distribution for \\(R^2\\) based on 1,000 random samples of size 32 drawn from a population where \\(\\rho^2=0\\). (Not an infinite number of draws, but large enough that we should have an idea of what the distribution might look like.)\n\n\n\n\n\nFigure¬†10.2: Sampling distribution based on 1000 simple random samples of size 32 drawn from a population where \\(\\rho^2=0\\).\n\n\n\n\nMost of the \\(R^2\\) values are near 0, although there is some variability that is due to sampling error. This sampling distribution is right-skewed. (WHY???) This means that we cannot use a t-distribution to model this distribution‚Äîremember the t-distribution is symmetric around zero. It turns out that this sampling distribution is better modeled using an F-distribution.\n\n\n10.1.1 The F-Distribution\nIn theoretical statistics the F-distribution is the ratio of two chi-squared statistics,\n\\[\nF = \\frac{\\chi^2_1 / \\mathit{df}_1}{\\chi^2_2 / \\mathit{df}_2}\n\\]\nwhere \\(\\mathit{df}_1\\) and \\(\\mathit{df}_2\\) are the degrees of freedom associated with each of the chi-squared statistics, respectively. For our purposes, we don‚Äôt need to pay much attention to this other than to the fact that an F-distribution is defined using TWO parameters: \\(\\mathit{df}_1\\) and \\(\\mathit{df}_2\\). Knowing these two values completely parameterize the F-distribution (they give the shape, expected value, and variation).\nIn regression analysis, the F-distribution associated with model-level inference is based on the following degrees of freedom:\n\\[\n\\begin{split}\n\\mathit{df}_1 &= p \\\\\n\\mathit{df}_2 &= \\mathit{df}_{\\mathrm{Total}}-p\n\\end{split}\n\\]\nwhere p is the number of predictors used in the model and \\(\\mathrm{Total}\\) is the total degrees of freedom in the data used in the regression model (\\(\\mathrm{Total}=n-1\\)). In our example, \\(\\mathit{df}_1=1\\) and \\(\\mathit{df}_2=99-1=98\\). Using these values, we have defined the \\(F(1,98)\\)-distribution.\nThe F-distribution is the sampling distribution of F-values (not \\(R^2\\)-values). But, it turns out that we can easily convert an \\(R^2\\)-value to an F-value using,\n\\[\nF = \\frac{R^2}{1 - R^2} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1}\n\\]\nIn our example,\n\\[\n\\begin{split}\nF &= \\frac{0.107}{1 - 0.107} \\times \\frac{98}{1} \\\\[1em]\n&= 0.1198 \\times 98 \\\\[1em]\n&= 11.74\n\\end{split}\n\\]\nThus, our observed F-value is: \\(F(1,98)=11.74\\). To evaluate this under the null hypothesis, we find the area under the \\(F(1,98)\\) density curve that corresponds to F-values at least as extreme as our observed F-value of 11.74.\n\n\n\n\n\nFigure¬†10.3: Plot of the probability curve for the F(1,98) distribution. The shaded area under the curve represents the p-value for a test evaluating whether the population rho-squared is zero using an observed F-value of 11.74.\n\n\n\n\nThis area (which is one-sided in the \\(F\\)-distribution) corresponds to the \\(p\\)-value. In our case this \\(p\\)-value is 0.000885. The probability of observing an F-value at least as extreme as we the one we observed (\\(F=11.74\\)) under the assumption that the null hypothesis is true is 0.000885. This suggests that the empirical data are inconsistent with the hypothesis that \\(\\rho^2=0\\), and it is unlikely that the model explains no variation in students‚Äô GPAs.\n\n\n\n10.1.2 Using the F-distribution in Practice\nIn practice, all of this information is provided in the output of the glance() function.\n\nglance(lm.a)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.107        0.0981  7.24      11.8 0.000885     1  -339.  684.  691.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    5136.          98   100\n\n\nThe observed F-value is given in the statistic column and the associated degrees of freedom are provided in the df and df.residual columns. Lastly, the p-value is given in the p.value column. When we report results from an F-test, we need to report the values for both degrees of freedom, the F-value, and the p-value.\n\nThe model-level test suggested that the empirical data are not consistent with the null hypothesis that the model explains no variation in GPAs; \\(F(1,98)=11.8\\), \\(p&lt;0.001\\).\n\n\n\n\n10.1.3 ANOVA Decomposition\nWe can also get the model-level inferential information from the anova() output. This gives us the ANOVA decomposition for the model.\n\n# Obtain ANOVA decomposition\nanova(lm.a)\n\n\n\n  \n\n\n\nNote that the two df values for the model-level F-statistic correspond to the df in each row of the ANOVA table. The first df (in this case, 1) is the model degrees-of-freedom, and the second df (in this case, 98) is the residual degrees-of-freedom. Note the p-value is the same as that from the glance() function.\nThis ANOVA decomposition also breaks out the sum of squared values into the variation explained by the model (616.5) and that which is unexplained by the model (residual variation; 5136.4). Summing these two values will give the total amount of variation which can be used to compute \\(R^2\\); \\(R^2 = \\mathrm{SS}_{\\mathrm{Model}}/\\mathrm{SS}_{\\mathrm{Total}}\\).\nThis decomposition also gives us another way to consider the F-statistic. Recall that the F-statistic had a direct relationship to \\(R^2\\)\n\\[\nF = \\frac{R^2}{1 - R^2} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1}\n\\]\nSince \\(R^2 = \\mathrm{SS}_{\\mathrm{Model}}/\\mathrm{SS}_{\\mathrm{Total}}\\) we can rewrite this as:\n\\[\nF = \\frac{\\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}}{1 - \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1}\n\\]\nUsing algebra,\n\\[\n\\begin{split}\nF &= \\frac{\\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}}{\\frac{\\mathrm{SS}_{\\mathrm{Total}}}{\\mathrm{SS}_{\\mathrm{Total}}} - \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1} \\\\[2ex]\n&= \\frac{\\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}}{\\frac{\\mathrm{SS}_{\\mathrm{Total}} - \\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1} \\\\[2ex]\n&= \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}} - \\mathrm{SS}_{\\mathrm{Model}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1} \\\\[2ex]\n&= \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Error}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1} \\\\[2ex]\n\\end{split}\n\\]\nThis expression of the F-statistic helps us see that the F-statistic is proportional to the ratio of the explained and unexplained variation. So long as the degrees of freedom remain the same, if the model explains more variation, the numerator of the F-statistic gets larger and the denominator will be smaller. Thus, larger F-values are associated with more explained variation by the model. We could also have seen this in the earlier expression of the F-statistic using \\(R^2\\).\n\n\n\n10.1.4 The F-Statistic as the Ratio of Two Variance Estimates\nIn statistical theory, a sum of squares divided by a degrees of freedom is referred to as a mean squared value‚Äîthe average amount of variation per degree of freedom. Since \\(\\mathit{df}_1\\) is the model degrees of freedom and \\(\\mathit{df}_2\\) is the residual (or error) degrees of freedom we could also express the F-statistic as:\n\\[\n\\begin{split}\nF &= \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Error}}} \\times \\frac{\\mathit{df}_{\\mathrm{Error}}}{\\mathit{df}_{\\mathrm{Model}}} \\\\[2ex]\n&= \\frac{\\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathit{df}_{\\mathrm{Model}}}}{\\frac{\\mathrm{SS}_{\\mathrm{Error}}}{\\mathit{df}_{\\mathrm{Error}}}} \\\\[2ex]\n&= \\frac{\\mathrm{MS}_{\\mathrm{Model}}}{\\mathrm{MS}_{\\mathrm{Error}}}\n\\end{split}\n\\]\nThus the F-value is the ratio of the average variation explained by the model and the average variation that remains unexplained. In our example\n\\[\n\\begin{split}\n\\mathrm{MS}_{\\mathrm{Model}} &= \\frac{616.5}{1} = 616.5 \\\\[2ex]\n\\mathrm{MS}_{\\mathrm{Error}} &= \\frac{5136.4}{98} = 52.41 \\\\\n\\end{split}\n\\]\nThese values are also printed in the anova() output.\n\n# Obtain ANOVA decomposition\nanova(lm.a)\n\n\n\n  \n\n\n\n\\[\nF = \\frac{616.5}{52.41} = 11.76\n\\]\nThe observed F-value of 11.76 indicates that the average explained variation is 11.76 times that of the average unexplained variation. There is an awful lot more explained variation than unexplained variation, on average. Another name for a mean squared value is a variance estimate. A variance estimate is literally the average amount of variation (in the squared metric) per degree of freedom. For example, go back to the introductory statistics formula for using sample data to estimate a variance:\n\\[\n\\hat\\sigma^2_Y = \\frac{\\sum(Y_i - \\bar{Y})^2}{n-1}\n\\]\nThis numerator is a sum of squares; namely the \\(\\mathrm{SS}_{\\mathrm{Total}}\\). The denominator is the total degrees of freedom. We could have also referred to this as a mean square\n\\[\n\\begin{split}\n\\hat\\sigma^2_Y &= \\frac{\\mathrm{SS}_{\\mathrm{Total}}}{\\mathit{df}_{\\mathrm{Total}}} \\\\[2ex]\n&= \\mathrm{MS}_{\\mathrm{Total}}\n\\end{split}\n\\]\nNote that the \\(\\mathrm{MS}_{\\mathrm{Total}}\\) is not printed in the anova() output. However, it can be computed from the values that are printed. The \\(\\mathrm{SS}_{\\mathrm{Total}}\\) is just the sum of the printed sum of squares, and likewise the \\[\\mathit{df}_{\\mathrm{Total}}\\] is the sum of the df values.\n\\[\n\\begin{split}\n\\mathrm{SS}_{\\mathrm{Total}} &= 616.5 + 5136.4 = 5752.9 \\\\[2ex]\n\\mathit{df}_{\\mathrm{Total}} &= 1 + 98 = 99\n\\end{split}\n\\]\nThen the \\(\\mathrm{MS}_{\\mathrm{Total}}\\) is the ratio of these values,\n\\[\n\\mathrm{MS}_{\\mathrm{Total}} = \\frac{5752.9}{99} = 58.11\n\\]\nSince this is an estimate of the outcome variable‚Äôs variance, we could also have computed the sample variance of the outcome variable, gpa, using the var() function.\n\n# Compute variance for outcome\nkeith %&gt;%\n  summarize(V_gpa = var(gpa))\n\n\n\n  \n\n\n\nThe total mean square, or variance estimate, is also the mean square estimate of the residuals from the intercept-only model.\n\n# Fit intercept-only model\nlm.0 = lm(gpa ~ 1, data = keith)\n\n# ANOVA decomposition\nanova(lm.0)\n\n\n\n  \n\n\n\nRemember the sum of squared residuals is \\((Y_i - \\hat{Y_i})^2\\), but in the intercept-only model \\(\\hat{Y_i}\\) is the marginal mean, i.e., \\(\\hat{Y_i} = \\bar{Y}\\). This is the numerator of the sample variance estimate and is why the mean square error from the intercept-only model and the sample variance for GPA are equivalent!\n\n\n\n10.1.5 Relationship Between Coefficient-Level and Model-Level Inference\nLastly, we point out that in simple regression models (models with only one predictor), the results of the model-level inference (i.e., the p-value) are exactly the same as that for the coefficient-level inference for the slope.\n\n# Model-level inference\nglance(lm.a)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.107        0.0981  7.24      11.8 0.000885     1  -339.  684.  691.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    5136.          98   100\n\n\n\n# Coefficient-level inference\ntidy(lm.a)\n\n\n\n  \n\n\n\nThat is because the model is composed of a single predictor, so asking whether the model accounts for variation in GPA is the same as asking whether GPA is different, on average, for students who spend a one-hour difference in time on homework. Once we have multiple predictors in the model, the model-level results and predictor-level results will not be the same."
  },
  {
    "objectID": "02-05-model-level-inference.html#confidence-envelope-for-the-model",
    "href": "02-05-model-level-inference.html#confidence-envelope-for-the-model",
    "title": "10¬† Model-Level Inference",
    "section": "10.2 Confidence Envelope for the Model",
    "text": "10.2 Confidence Envelope for the Model\nRe-consider our thought experiment. Again, imagine you have a population that is infinitely large. The observations in this population have two attributes, call them X and Y. The relationship between these two attributes can be expressed via a regression equation as: \\(\\hat{Y}=\\beta_0 + \\beta_1(X)\\). Randomly sample n observations from the population, and compute the fitted regression equation, this time plotting the line (rather than only paying attention to the numerical estimates of the slope or intercept). Continue sampling from this population, each time drawing the fitted regression equation.\n\n\n\n\n\nFigure¬†10.4: Thought experiment for sampling samples of size n from the population to obtain the fitted regression line.\n\n\n\n\nNow, imagine superimposing all of these lines on the same plot.\n\n\n\n\n\nFigure¬†10.5: Plot showing the fitted regression lines for many, many random samples of size n.\n\n\n\n\nExamining where the sampled lines fall gives a visual interpretation of the uncertainty in the model. This two-dimensional display of uncertainty is referred to as a confidence envelope. In practice we estimate the uncertainty from the sample data and plot it around the fitted line from the sample.\nFor simple regression models, we can plot this directly by including the geom_smooth() layer in our plot. This adds a smoother to the plot. To add the fitted simple regression line, we use the argument method=\"lm\". This will add the fitted regression line and confidence envelope to the plot based on fitting a linear model to the variables included in the x= and y= arguments in the aesthetic mapping defined in aes().1 The color of the fitted line and of the confidence envelope can be set using color= and fill= respectively.\n\n# Create plot\nggplot(data = keith, aes(x = homework, y = gpa)) +\n  geom_smooth(method = \"lm\", color = \"#c62f4b\", fill = \"#696969\") +\n  xlab(\"Time spent on homework\") +\n  ylab(\"GPA (on a 100-pt. scale)\") +\n  theme_bw()\n\n\n\n\nFigure¬†10.6: GPA plotted as a function of time spent on homework. The OLS regression line (raspberry) and confidence envelope (grey shaded area) are also displayed.\n\n\n\n\nNote that we want to indicate the confidence envelope or make reference to the uncertainty in the figure caption. We pointed out that the confidence envelope indicates uncertainty by displaying the sampling variation associated with the location of the fitted regression line.\nWe can also use this plot to make inferences about the mean Y-value conditioned on X. For example, using the fitted regression equation, the model predicts that the mean GPA for students who spend 6 hours each week on homework is 81.6. Graphically this is the point on the fitted regression line associated with \\(X=6\\).\nHowever, we also now understand that there is uncertainty associated with estimates obtained from sample data. How much uncertainty is there in that estimate of 81.6? We can use the bounds of the confidence envelope at \\(X=6\\) to answer this question. The lower bound of the confidence envelope at \\(X=6\\) is approximately 80 and the upper bound is approximately 83. This tells, based on the sample data, we think the mean GPA for students who spend 6 hours each week on homework is between 80 and 83. Graphically, we can see these values in the plot.\n\n\n\n\n\nFigure¬†10.7: GPA plotted as a function of time spent on homework. The OLS regression line (raspberry) and confidence envelope (grey shaded area) are also displayed. The fitted value at X=6 is displayed as a point and the uncertainty in the estimate is displayed as an error bar.\n\n\n\n\nThis uncertainty estimate is technically a 95% confidence interval for the mean GPA for students who spend 6 hours each week on homework. As such, a more formal interpretation is:\n\nWith 95% confidence, the mean GPA for students who spend 6 hours each week on homework is between 80 and 83.\n\nNotice that there is more uncertainty for the mean GPA for some values of X than for others. This is because of the amount of information at each X. We have more information in the data around the mean X-value and less information at extreme X-values. That implies that we have more certainty in the estimates we make for the mean GPA for students who spend around 5 hours of homework each week than we do in students who only spend 1 hour a week or those who spend 11 hours a week on homework."
  },
  {
    "objectID": "02-05-model-level-inference.html#footnotes",
    "href": "02-05-model-level-inference.html#footnotes",
    "title": "10¬† Model-Level Inference",
    "section": "",
    "text": "The confidence envelope can be omitted by using the argument se=FALSE.‚Ü©Ô∏é"
  },
  {
    "objectID": "03-00-deeper-understanding.html",
    "href": "03-00-deeper-understanding.html",
    "title": "Deeper Understanding",
    "section": "",
    "text": "In this unit we will deepen your understanding of the regression model. You will learn about using multiplle regression model to describe and infer about the relationship between a quantitative outcome and multiple predictor variables. You will also learn about statistical control. Finally you will learn about the distributional assumption that underlie the regression model."
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#observational-data-and-alternative-explanations",
    "href": "03-01-intro-to-multiple-regression.html#observational-data-and-alternative-explanations",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "11.1 Observational Data and Alternative Explanations",
    "text": "11.1 Observational Data and Alternative Explanations\nIn a previous chapter, we fitted a model regressing employees‚Äô incomes on education level. We will do that again, but now we will also evaluate the inferential evidence around the effect of education on incomes.\n\n# Fit regression model\nlm.a = lm(income ~ 1 + education, data = city)\n\n# Obtain model-level results\nglance(lm.a)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic      p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.632         0.619  8.98      51.5 0.0000000556     1  -115.  235.  240.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    2418.          30    32\n\n\n\n# Obtain coefficient-level results\ntidy(lm.a)\n\n\n\n  \n\n\n\nThe fitted equation,\n\\[\n\\hat{\\mathrm{Income}_i} = 11.321 + 2.651(\\mathrm{Education~Level}_i),\n\\]\nsuggests that the estimated mean income for employees with education levels that differ by one year varies by 2.651 thousand dollars, on average. We also found that differences in education level explained 63.2% of the variation in income, and that the empirical evidence is inconsistent with the hypothesis that education level explains none of the variation in incomes (\\(p&lt;.001\\)). All this suggests that education level is likely related to income.\nIf the data had been collected as part of an experiment where we could have randomly assigned cases in our sample to the different levels of education (i.e., different values of X), the analysis would be done and we could conclude that education has a positive effect on income. Unfortunately, the data we used in the analysis is observational‚Äîwe did not assign levels of the predictor to the cases in the sample. This means there could be other variables that are correlated with the predictor that are influencing the effect we saw in the data.\nFor example, we know that in civil service jobs, pay is influenced by seniority. So, one question is whether the distribution of seniority is similar across employees with different education levels. If not, it may be that those employees with higher education levels have higher levels of seniority. If that is the case, perhaps some (or all) of the positive effect of education on income that we observed is really just a function of higher seniority. To determine whether this is the case, we need to include seniority as another predictor in the model along with education level and see whether there is still an effect of education on income."
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#examining-the-seniority-predictor",
    "href": "03-01-intro-to-multiple-regression.html#examining-the-seniority-predictor",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "11.2 Examining the Seniority Predictor",
    "text": "11.2 Examining the Seniority Predictor\nBefore we begin modeling, it behooves us to explore the seniority predictor. Below we examine the marginal distribution of seniority for the 32 employees in the sample.\n\n# Examine the marginal distribution\nggplot(data = city, aes(x = seniority)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Seniority level (in years)\") +\n  ylab(\"Probability density\")\n\n\n\n\nFigure¬†11.1: Density plot of the marginal distribution of seniority.\n\n\n\n\nWe also compute numerical summaries of the distribution.\n\n# Compute mean and standard deviation\ncity |&gt;\n  summarize(\n    M = mean(seniority),\n    SD = sd(seniority)\n    )\n\n\n\n  \n\n\n\n\nSeniority is symmetric with a typical employee having roughly 15 years of seniority. There is quite a lot of variation in seniority, with most employees having between 8 and 22 years of seniority.\n\nAfter we examine the marginal distribution, we should examine the relationships among all of the three variables we are considering in the analysis. Typically researchers will examine the scatterplot between each predictor and the outcome (to evaluate the functional forms of the relationships with the outcome) and also examine the correlation matrix. Since we have already looked at the scatterplot between education-level and income, we focus here on the relationship between seniority and income.\n\n# Relationship between income and seniority\nggplot(data = city, aes(x = seniority, y = income)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Seniority (in years)\") +\n  ylab(\"Income (in thousands of dollars)\")\n\n\n\n\nFigure¬†11.2: Scatterplot showing the relationship between seniority level and income.\n\n\n\n\nThe correlation matrix between all three variables is also examined.\n\n# Correlation matrix\ncity |&gt;\n  select(income, education, seniority) |&gt;\n  correlate()\n\n\n\n  \n\n\n\n\nThe relationship between seniority and income seems linear and positive (\\(r=0.58\\)). This suggests that employees with more seniority also tend to have higher incomes. Education level and seniority are also modestly correlated (\\(r=0.34\\)), indicating that employees with higher education levels tend to also have more seniority.\n\nBecause there is a positive correlation between seniority and income in the sample, it suggests that city employees with more seniority level tend to have higher incomes. The correlation between the two predictors (education level and seniority) is also positive suggesting that city employees with higher education levels tend to have more seniority.\n\n\n11.2.1 Simple Regression Model: Seniority as a Predictor of Income\nIt is also instructive to fit and examine the results from the simple regression model using seniority as a predictor of variation in income.\n\nlm.b = lm(income ~ 1 + seniority, data = city)\n\n# Model-level results\nglance(lm.b)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.339         0.317  12.0      15.4 0.000477     1  -124.  254.  258.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    4342.          30    32\n\n\n\n# Coefficient-level results\ntidy(lm.b)\n\n\n\n  \n\n\n\nThe fitted equation,\n\\[\n\\hat{\\mathrm{Income}_i} = 35.690 + 1.219(\\mathrm{Seniority~Level}_i)\n\\]\nsuggests that the estimated mean income for employees with seniority levels that differ by one year varies by 1.219 thousand dollars. We also find that differences in seniority level explain 33.9% of the variation in income, and that this empirical evidence is inconsistent with the hypothesis that seniority explains none of the variation in incomes (\\(p&lt;.001\\)).\nOur research question is focused on examining the relationship between education level and income. The relationships observed in this correlation matrix are consistent with the issues we were concerned about earlier, namely that the positive effect of education level on income may be due to the fact that employees with higher education levels have more seniority. And, the positive relationship between seniority and income is clouding the ‚Äúreal‚Äù underlying relationship between education and income.\nWhat we need to know in order to determine the effect of education on incomes is whether after we account for any distributional differences in seniority across education level is there is still a relationship between education level and income. To answer this question, we will fit a model that includes both predictors."
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#multiple-regression-model-education-level-and-seniority-as-a-predictors-of-income",
    "href": "03-01-intro-to-multiple-regression.html#multiple-regression-model-education-level-and-seniority-as-a-predictors-of-income",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "11.3 Multiple Regression Model: Education Level and Seniority as a Predictors of Income",
    "text": "11.3 Multiple Regression Model: Education Level and Seniority as a Predictors of Income\nTo fit the multiple regression model, we will just add (literally) additional predictors to the right-hand side of the lm() formula.\n\n# Fit multiple regression model\nlm.c = lm(income ~ 1 + education + seniority, data = city)\n\n\n\n11.3.1 Model-Level Results\nTo interpret multiple regression results, begin with the model-level information.\n\n# Model-level results\nglance(lm.c)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic       p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.742         0.724  7.65      41.7 0.00000000298     2  -109.  226.  232.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    1695.          29    32\n\n\nIn a multiple regression model there are multiple predictors that are being used to explain variation in the outcome variable. We can begin by examining the \\(R^2\\) value from the output. Interpreting this value, we say:\n\nDifferences in education level AND seniority explain 74.2% of the variation in income, in the sample.\n\nThe model-level test allows us to evaluate whether, together, these predictors explain variation in the outcome or whether any explained variation in the sample is attributable to sampling error. The formal model-level null hypothesis that tests this can be written mathematically as,\n\\[\nH_0:\\rho^2 = 0.\n\\]\nThis is a test of whether all the predictors together explain variation in the outcome variable. The results of this test, \\(F(2,29)=41.65\\), \\(p&lt;.001\\), suggest that the empirical evidence is inconsistent with the null hypothesis; it is likely that together education level and seniority level do explain variation in the population.\nEquivalently, we can also write the model null hypothesis as a function of the predictor effects, namely,\n\\[\nH_0:\\beta_{\\mathrm{Education~Level}} = \\beta_{\\mathrm{Seniority}} = 0.\n\\]\nIn plain English, this is akin to stating that there is NO EFFECT for every predictor included in the model. If the empirical data are inconsistent with this null hypothesis, it suggests that AT LEAST ONE of the predictor effects is likely not zero.\nAlthough the two expressions of the model-level null hypothesis look quite different, they are answering the same question, namely whether the model predicts more variation in income than is attributable to sampling variation. Based on the results of the model-level hypothesis test we believe there is an effect of education-level on income, an effect of seniority on income, OR there is an effect of both predictors on income. The model-level results, however, do not allow us to determine which of the predictors has an effect on the outcome variable. For that we need to evaluate the coefficient-level results.\n\n\n\n11.3.2 Coefficient-Level Results\nNow we turn to the coefficient-level results produced in the tidy() output.\n\n# Coefficient-level results\ntidy(lm.c)\n\n\n\n  \n\n\n\nFirst we will write the fitted multiple regression equation,\n\\[\n\\hat{\\mathrm{Income}_i} = 6.769 + 2.252(\\mathrm{Education~Level}_i) + .739(\\mathrm{Seniority~Level}_i)\n\\]\nThe slopes (of which there are now more than one) are referred to as partial regression slopes or partial effects. They represent the effect of the predictor AFTER accounting for the effects of the other predictors included in the model. For example,\n\n\nThe partial effect of education level is 2.252. This indicates that a one year difference in education level is associated with a 2.252 thousand dollar difference in income (on average), after accounting for differences in seniority level.\nThe partial effect of seniority is 0.739. This indicates that a one year difference in seniority level is associated with a 0.739 thousand dollar difference in income (on average), after accounting for differences in education level.\n\n\n\nThe language ‚Äúafter accounting for‚Äù is not ubiquitous in interpreting partial regression coefficients. Some researchers instead use ‚Äúcontrolling for‚Äù, ‚Äúholding constant‚Äù, or ‚Äúpartialling out the effects of‚Äù. For example, the education effect could also be interpreted these ways:\n\nA one year difference in education level is associated with a 2.252 thousand dollar difference in income (on average), after controlling for differences in seniority.\nA one year difference in education level is associated with a 2.252 thousand dollar difference in income (on average), after holding the effect of seniority constant.\nA one year difference in education level is associated with a 2.252 thousand dollar difference in income (on average), after partialling out the effect of seniority.\n\n\nLastly, we can also interpret the intercept:\n\nThe average income for all employees with 0 years of education AND 0 years of seniority is estimated to be 6.769 thousand dollars.\n\nThis is the predicted average Y value when ALL the predictors have a value of 0. As such, it is often an extrapolated prediction and is not of interest to most applied researchers. For example, in our data, education level ranges from 8 to 24 years and seniority level ranges from 1 to 27 years. We have no data that has a zero value for either predictor, let alone for both. This makes prediction of the average Y value tenuous at these X values.\n\n\n\n11.3.3 Coefficient-Level Inference\nAt the coefficient-level, the hypotheses being tested are about each individual predictor. The mathematical expression of the hypothesis is\n\\[\nH_0: \\beta_k = 0.\n\\]\nIn plain English, the statistical null hypothesis states: After accounting for ALL the other predictors included in the model, there is NO EFFECT of X on Y. These hypotheses are evaluated using a t-test. For example, consider the test associated with the education level coefficient.\n\\[\nH_0: \\beta_{\\mathrm{Education~Level}} = 0\n\\]\nThis is akin to stating there is NO EFFECT of education level on income after accounting for differences in seniority level. The empirical evidence is inconsistent with this hypothesis, \\(t(29)=6.73\\), \\(p&lt;.001\\), suggesting that there is likely an effect of education on income after controlling for differences in seniority level. (Note that the df for the t-test for all of the coefficient tests is equivalent to the error, or denominator, df for the model-level F-test.)\nIt is important to note that the p-value at the model-level is different from any of the coefficient-level p-values. This is because when we include more than one predictor in a model, the hypotheses being tested at the model- and coefficient-levels are different. The model-level test is a simultaneous test of all the predictor effects, while the coefficient-level tests are testing the added effect of a particular predictor."
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#multiple-regression-statistical-model",
    "href": "03-01-intro-to-multiple-regression.html#multiple-regression-statistical-model",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "11.4 Multiple Regression: Statistical Model",
    "text": "11.4 Multiple Regression: Statistical Model\nThe multiple regression model says that each case‚Äôs outcome (Y) is a function of two or more predictors (\\(X_1\\), \\(X_2\\), , \\(X_k\\)) and some amount of error. Mathematically it can be written as\n\\[\nY_i = \\beta_0 + \\beta_1(X1_{i}) + \\beta_2(X2_{i}) + \\ldots + \\beta_k(Xk_{i}) + \\epsilon_i\n\\]\nAs with simple regression we are interested in estimating the values for each of the regression coefficients, namely, \\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\), ‚Ä¶, \\(\\beta_k\\). To do this, we again employ least squares estimation to minimize the sum of the squared error terms.\nSince we have more than one X term in the fitted equation, the structural part of the model no longer mathematically defines a line. For example, the fitted equation from earlier,\n\\[\n\\hat{Y_i} = 6.769 + 2.252(X1_i) + 0.739(X2_i),\n\\]\nmathematically defines a regression plane. (Note we have three dimensions, Y, \\(X1\\), and \\(X2\\). If we add predictors, we have four or more dimensions and we describe a hyperplane.)\nThe data and regression plane defined by the education level, seniority level, and income for the Riverview employees is shown below. The regression plane is tilted up in both the education level direction (corresponding to a positive partial slope of education) and in the seniority level direction (corresponding to a positive partial slope of seniority). The blue points are above the plane (employees with a positive residual) and the yellow points are below the plane (employees with a negative residual).\n\n\n\n\n\nFigure¬†11.3: Three-dimensional scatterplot showing the relationship between education level, seniority, and income. The fitted regression plane is also shown. Blue observations have a positive residual and yellow observations have a negative residual.\n\n\n\n\nGraphically, the residuals from this model are the vertical distance between the observed points and the regression plane. Mathematically, they can be computed as,\n\\[\n\\hat{\\epsilon_i} = Y_i - \\hat{Y_i}\n\\]"
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#anova-decomposition",
    "href": "03-01-intro-to-multiple-regression.html#anova-decomposition",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "11.5 ANOVA Decomposition",
    "text": "11.5 ANOVA Decomposition\nAs with the simple regression model, we are interested in whether the model explains any of the unexplained variation identified in the baseline intercept-only model. As a reminder, we quantify the amount of unexplained variation through the residual sum of squares,\n\\[\n\\mathrm{SS}_{\\mathrm{Residuals}} = \\sum \\hat{\\epsilon_i}^2\n\\]\nThe residual sum of squares can be obtained using the anova() function.\n\n# Obtain ANOVA decomposition\nanova(lm.c)\n\n\n\n  \n\n\n\nHere the \\(\\mathrm{SS}_{\\mathrm{Residuals}} = 1695\\). Because the model was fitted with OLS, any other plane defined with the predictors of education and seniority level; (i.e., different coefficient values for the intercept and predictors) would produce a higher sum of squared residuals value. Comparing the squared sum of residual from this model to that from the intercept-only model (\\(\\mathrm{SS}_{\\mathrm{Residuals}} = 6566\\)), we find that there is less unexplained variation after including education and seniority level in the model. Here is the partitioning of the variation in income.\n\\[\n\\underbrace{6566}_{\\substack{\\text{Total} \\\\ \\text{Variation}}} = \\underbrace{4871}_{\\substack{\\text{Explained} \\\\ \\text{Variation}}} + \\underbrace{1695}_{\\substack{\\text{Unexplained} \\\\ \\text{Variation}}}\n\\]\nDividing each term in the partitioning by the total sum of squares,\n\\[\n\\begin{split}\n\\frac{6566}{6566} &= \\frac{4871}{6566} + \\frac{1695}{6566} \\\\[2ex]\n1 &= 0.742 + 0.258\n\\end{split}\n\\]\nThe proportion of variance explained by the model is the same as the \\(R^2\\) value we obtained from the glance() function. We can also obtain the model sum of squares (4871) by adding the sum of squared term for the education predictor (4147) and that for the seniority predictor (723) from the anova() output. The total sum of squared (6566) can be computed by summing all the sum of squared terms in the anova() output:\n\\[\n4147.3 + 722.9 + 1695.3 = 6565.5\n\\]\nwhich is within rounding error of 6566.\nNote that the output from anova() also partitions the df among the predictor terms and the residuals. Each predictor has 1 df associated with it, which gives the model 2 df. The residuals have 29 df associated with them. The model and residual df are the df used in the F-test and given in the glance() output. The total df in the data are \\(2+29 = 31\\), which is \\(n-1\\). Lastly, we point out that the residual df value from the anova() output (29) is the df associated with the t-tests for the coefficient-level tests (presented earlier).\n\n\n11.5.1 Hypotheses Tested in the ANOVA Output\nThe F-values given in the anova() output do not match the F-test given in the glance() output. This is because the hypotheses being tested in the anova() output are different than that being tested in the glance() output. To understand the tests that are being performed, we need to understand how the variation is being partitioned in the model we fitted. The order the predictors in the anova() output (which is connected to the order they were included in the lm() function) shows this partitioning numerically. We can also create a diagram that shows this partitioning.\n\n\n\n\n\nFigure¬†11.4: Partitioning of variation associated with the model in which education-level is included prior to seniority-level.\n\n\n\n\nIn the diagram, the total unexplained variation is first explained by including education-level in the model (the first predictor included in the lm() function). This predictor explains some variation and leaves some of the variation unexplained. Then, seniority-level is allowed to explain any residual (unexplained) variation that remains.\nThe hypothesis that is being tested by an F-test is whether the explained variation is more than we expect because of sampling error. The way we quantify this is to compute \\(R^2\\) which is a ratio of the explained variation to the total variation the predictor(s) is allowed to explain. The key here is that the numerator and denominator for \\(R^2\\) are different depending on what is being tested.\nConsider the F-test at the model-level from the glance() output. This is testing whether the model-level \\(R^2\\) is more than we expect because of sampling error. In the diagram, the explained variation in the model-level \\(R^2\\) is the total sum of all the blue circles since the model includes both education-level and seniority-level. The denominator is the baseline unexplained variation. Mathematically,\n\\[\n\\begin{split}\nR^2_{\\mathrm{Model}} &= \\frac{4147 + 723}{6566} \\\\[2ex]\n&= \\frac{4879}{6566}\n\\end{split}\n\\]\nThis F-test examines whether this fraction (or proportion) is statistically different than 0. Here the results are those given in glance(), namely, \\(F(2,29)=41.65\\), \\(p&lt;.001\\).\nIn the anova() output, results from two different F-tests are presented. The F-test in the first line of this output is associated with the education-level predictor. This is testing whether education-level (by itself) explains variation in the outcome given the model fitted. In the diagram, the explained variation for the education-level \\(R^2\\) is the blue circles associated with adding education to the model first. The denominator is the unexplained variation if we only consider the education and residual variation. Mathematically,\n\\[\n\\begin{split}\nR^2_{\\mathrm{Education\\mbox{-}Level}} &= \\frac{4147}{4147 + 1695} \\\\[2ex]\n&= 0.710\n\\end{split}\n\\]\nThe F-test examines whether this fraction (or proportion) is statistically different than 0. Here the results are those given in the first line of the anova() output, namely, \\(F(1,29)=70.94\\), \\(p&lt;.001\\). The numerator df for the F-test is given in the Df column of the anova() output and the denominator df is the model‚Äôs residual df.\nThe F-test in the second line of this output is associated with the seniority-level predictor. This is testing whether seniority-level explains variation in the outcome AFTER education-level has already been allowed to explain any unexplained variation. In the diagram, the explained variation for the seniority-level \\(R^2\\) is the blue circle associated with adding seniority-level to the model. The denominator is the unexplained variation that remains after education-level has explained all the variation it can (this is no longer the baseline unexplained variation). Mathematically,\n\\[\n\\begin{split}\nR^2_{\\mathrm{Seniority\\mbox{-}Level} \\vert \\mathrm{Education\\mbox{-}Level}} &= \\frac{723}{723 + 1695} \\\\[2ex]\n&= 0.299\n\\end{split}\n\\]\nThis F-test examines whether this fraction (or proportion) is statistically different than 0. Here the results are those given in the second line of the anova() output, namely, \\(F(1,29)=12.37\\), \\(p=.001\\).\nThis second test is asking whether there is an effect of seniority-level after accounting for education-level given the model fitted. This is equivalent to the hypothesis we tested for seniority-level in the coefficient-level output. In fact, the p-value from the tidy() output for the seniority-level effect is equivalent to the p-value associated with the seniority-level in the second line of the anova() output.\n\n\n\n11.5.2 Changing the Order of the Predictors\nLet‚Äôs re-fit the model, but this time we will include seniority-level in the model first and education-level second.\n\n# Fit model with different predictor order\nlm.d = lm(income ~ 1 + seniority + education, data = city)\n\n# ANOVA decomposition\nanova(lm.d)\n\n\n\n  \n\n\n\nExamining the ANOVA decomposition, we see that some of the values in the table are the same and others are different. To understand why, we will again compose the partitioning diagram.\n\n\n\n\n\nFigure¬†11.5: Partitioning of variation associated with the model in which seniority-level is included prior to education-level.\n\n\n\n\nConsider the model-level F-test which tests whether the model-level \\(R^2\\) is more than we expect because of sampling error. In the diagram, the explained variation in the model-level \\(R^2\\) is the total sum of all the blue circles since the model includes both education-level and seniority-level. The denominator is the baseline unexplained variation. Mathematically,\n\\[\n\\begin{split}\nR^2_{\\mathrm{Model}} &= \\frac{2223 + 2647}{6566} \\\\[2ex]\n&= \\frac{4879}{6566}\n\\end{split}\n\\]\nThis is the same model-level \\(R^2\\) value we obtained earlier. Thus the results given in glance(), namely, \\(F(2,29)=41.65\\), \\(p&lt;.001\\) are identical regardless of the order the predictors are included in the model.\n\n# Model-level output\nglance(lm.d)\n\n\n\n  \n\n\n\nThe F-test in the first line of this output is associated with the seniority-level predictor. This is testing whether seniority-level (by itself) explains variation in the outcome given the model. Mathematically,\n\\[\n\\begin{split}\nR^2_{\\mathrm{Seniority\\mbox{-}Level}} =& \\frac{2223}{2223+1695} \\\\[2ex]\n&= 0.567\n\\end{split}\n\\]\nThe F-test examines whether this fraction (or proportion) is statistically different than 0. Here the results are those given in the first line of the anova() output, namely, \\(F(1,29)=38.03\\), \\(p&lt;.001\\).\nThe F-test in the second line of this output is testing whether education-level explains variation in the outcome AFTER seniority-level has already been allowed to explain any unexplained variation, given the model. Mathematically,\n\\[\n\\begin{split}\nR^2_{\\mathrm{Education\\mbox{-}Level} \\vert \\mathrm{Seniority\\mbox{-}Level}} &= \\frac{2647}{2647 + 1695} \\\\[2ex]\n&= 0.610\n\\end{split}\n\\]\nThe F-test examines whether this fraction (or proportion) is statistically different than 0. Here the results are those given in the second line of the anova() output, namely, \\(F(1,29)=45.28\\), \\(p&lt;.001\\). This test is asking whether there is an effect of education-level after accounting for seniority-level. The p-value from this test is equivalent to the p-value associated with the education-level effect in the tidy() output.\n\n# Coefficient-level output\ntidy(lm.d)\n\n\n\n  \n\n\n\nNote that the output from tidy() is also the same, regardless of predictor order. This means that whichever order you include the predictors in the model, the tests of the partial effects (does a predictor explain variation AFTER all other predictors have already explained a much variation as they can) will be the same. Additionally, the fitted equation will be the same."
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#argh-which-set-of-results-should-i-use",
    "href": "03-01-intro-to-multiple-regression.html#argh-which-set-of-results-should-i-use",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "11.6 Argh! Which Set of Results Should I Use?",
    "text": "11.6 Argh! Which Set of Results Should I Use?\nFrom all these different F-tests and \\(R^2\\) values, we see that there are different ways of computing the amount of ‚Äúvariation accounted for‚Äù for any given predictor. The sum of squares for a particular predictor depends on whether we are considering it in isolation, or whether it is being considered in conjunction with other predictors. Not only that, but it also depends on the order that the predictor is included in the model! Similarly the amount of total unexplained variation depends on whether we consider all the unexplained variation in a variable, or whether we condition on a particular model.\nIn a regression analysis, we typically want to understand the amount of variation explained by a predictor after accounting for all the other predictors. That means, that when computing an \\(R^2\\) value, the numerator will be based on the sum of squares if that predictor is last in the model. Similarly, the denominator will be based on the total variation available to explain after accounting for all the other predictors. To determine this, we include the predictor of interest last in the lm() and then examine the anova() output to obtain the sums of squares for the predictor and residuals. The \\(R^2\\) value can then be computed based on those two values.\nTo evaluate whether that proportion of explained variation is more than we expect because of chance, we can evaluate the p-value for that predictor from the tidy() output. This is equivalent to asking: Is a particular predictor statistically important after controlling for the other predictors in the model? Again, this is the same p-value you get from the anova() output if the predictor is last in thr lm().\n\nSome statisticians and quantitative methodologists have attempted to capture some of the differences in the various ways to compute ‚Äúvariance accounted for‚Äù by referring to different types of sums of squares. For example, the sums of squares in the anova() output is sometimes referred to as Type 1 Sums of Squares or Sequential Sums of Squares. While these terms can be helpful, they are not universally adopted and as a result often add more confusion than they solve. It is probably best to view them as different ways of partitioning and accounting for variation, and understand that how you decide to do this has an impact on how much variation a particular predictor explains and subsequently the p-value associated with it."
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#presenting-results",
    "href": "03-01-intro-to-multiple-regression.html#presenting-results",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "11.7 Presenting Results",
    "text": "11.7 Presenting Results\nIt is quite common for researchers to present the results of their regression analyses in table form. Different models are typically presented in different columns and predictors are presented in rows. (Because it is generally of less substantive value, the intercept is often presented in the last row.)\nNote that we DO NOT INCLUDE stars to indicate ‚Äústatistical significance‚Äù as is the recommendation of the American Statistical Association. (Wasserstein & Schirm, 2019)\n\n\n\nUnstandardized coefficients (standard errors) for a taxonomy of OLS regression models to explain variation in Riverview city employee‚Äôs incomes. All models were fitted with n=32 observations.\n\n\n\n\nPredictor\n\n\nModel A\n\n\nModel B\n\n\nModel C\n\n\n\n\n\n\nEducation level\n\n\n2.651(0.370)\n\n\n\n\n2.252(0.335)\n\n\n\n\nSeniority level\n\n\n\n\n1.219(0.311)\n\n\n0.739(0.210)\n\n\n\n\nConstant\n\n\n11.321(6.123)\n\n\n35.690(5.073)\n\n\n6.769(5.373)\n\n\n\n\nR2\n\n\n0.632\n\n\n0.339\n\n\n0.742\n\n\n\n\nRMSE\n\n\n8.978\n\n\n12.031\n\n\n7.646\n\n\n\n\n\nBased on the results of fitting the three models, we can now go back and answer our research questions. Do differences in education level explain variation in incomes? Based on Model A, the empirical evidence suggests the answer is yes. Is this true even after accounting for differences in seniority? The empirical evidence from Model C suggests that, again, the answer is yes. (Since it is not necessary for answering the RQ, some researchers might choose to not present the results from Model B.)"
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#coefficient-plot",
    "href": "03-01-intro-to-multiple-regression.html#coefficient-plot",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "11.8 Coefficient Plot",
    "text": "11.8 Coefficient Plot\nTo create a coefficient plot for a multiple regression, we will again use the dwplot() function from the {dotwhisker} package. To create coefficient plots for multiple models we need to create a data frame based on the tidy() output for each fitted model. We also need to append a column that identifies the model name in these data frames. Finally, we need to combine these data frames into a single data frame that we will use in the dwplot() function.1 Here we presented the coefficient plot for all three models. Another option would be to create this plot for only the ‚Äúfinal‚Äù adopted model (e.g., Model C).\n\n# Load library\nlibrary(dotwhisker)\n\n# Create tidy() data frames with model names\nmod_1 = tidy(lm.a) |&gt;\n  mutate(model = \"Model A\")\n\nmod_2 = tidy(lm.b) |&gt;\n  mutate(model = \"Model B\")\n\nmod_3 = tidy(lm.c) |&gt;\n  mutate(model = \"Model C\")\n\n# Combine into single data frame\nall_models = rbind(mod_1, mod_2, mod_3)\n\n# Create plot\ndwplot(all_models, show_intercept = FALSE) +\n  theme_bw() +\n  scale_color_manual(name = \"Model\", values = c(\"#c62f4b\", \"#c62f4b\", \"#c62f4b\")) +\n  scale_x_continuous(name = \"Estimate\") +\n  scale_y_discrete(name = \"Coefficients\", labels = c(\"Seniority\", \"Education\")) +\n  facet_wrap(~model) +\n  guides(color = FALSE)\n\n\n\n\nFigure¬†11.6: Coefficient plot for the model regressing income on education. Uncertainty is displayed based on the 95% confidence intervals.\n\n\n\n\nThis plot shows graphically what we observed in the numerical results. There does seem to be a positive effect of education-level on employee income. After including seniority-level in the model, the effect of education-level is somewhat tempered, but it is still positive. There is, however, some uncertainty in the exact magnitude of the size of the effect as is shown in the wide 95% confidence interval for education-level in the plot.\n\n\n\n\n\nWasserstein, R., & Schirm, A. (2019). Moving to a world beyond \\(p &lt; .05\\). Keynote presentation at the United States Conference on Teaching Statistics."
  },
  {
    "objectID": "03-01-intro-to-multiple-regression.html#footnotes",
    "href": "03-01-intro-to-multiple-regression.html#footnotes",
    "title": "11¬† Introduction to Multiple Regression",
    "section": "",
    "text": "It is critical when you are changing labels on the axes that you double-check the actual tidy() output so that you don‚Äôt erroneously mislabel the coefficients. Here for example, the tidy() output indicates that in Model C the coefficient for education level is 2.25 and the seniority coefficient is 0.739. This corresponds to what we see in the plot.‚Ü©Ô∏é"
  },
  {
    "objectID": "03-02-understanding-statistical-control.html#data-exploration-of-parent-education-level",
    "href": "03-02-understanding-statistical-control.html#data-exploration-of-parent-education-level",
    "title": "12¬† Understanding Statistical Control",
    "section": "12.1 Data Exploration of Parent Education Level",
    "text": "12.1 Data Exploration of Parent Education Level\nFigure¬†12.1 (syntax not shown) suggests that the distribution of parent education level is slightly right-skewed. The mean level of education is approximately 14 years (SD = 2 years). Parent-level of education is positively correlated with GPA and with time spent on homework.\n\n\n\n\n\nFigure¬†12.1: Density plot of thr parent education predictor.\n\n\n\n\n\n\n\n\n\n  \n  Table¬†12.1:  Correlations between three student attributes. Means (standard\ndeviations) are displayed on the main diagonal. \n  \n    \n    \n      \n      1.\n      2.\n      3.\n    \n  \n  \n    1. GPA\n80.47 (7.62)\n‚Äî\n‚Äî\n    2. Time spent on homework\n .33\n5.09 (2.06)\n‚Äî\n    3. Parent education level\n .29\n .28\n14.03 (1.93)\n  \n  \n  \n\n\n\n\n\nParent education level is moderately and positively correlated with student GPA (in the sample). Moreover, time spent on homework is also moderately and positively correlated with parent education level. This set of relationships is in line with our alternative explanation of the relationship between time spent on homework and students‚Äô GPAs. Namely that students who have parent with more education tend to spend more time on homework and thus have higher GPAs."
  },
  {
    "objectID": "03-02-understanding-statistical-control.html#regression-analysis",
    "href": "03-02-understanding-statistical-control.html#regression-analysis",
    "title": "12¬† Understanding Statistical Control",
    "section": "12.2 Regression Analysis",
    "text": "12.2 Regression Analysis\nTable¬†12.1 shows the results from fitting a series of models to examine the effect of time spent on homework on student GPA.\n\n# Simple regression model to examine effect of time spent on homework\nlm.a = lm(gpa ~ 1 + homework, data = keith)\n#glance(lm.a)\n#tidy(lm.a)\n\n# Control for parent education level\nlm.b = lm(gpa ~ 1 + homework + parent_ed, data = keith)\n#glance(lm.b)\n#tidy(lm.b)\n\n\n\n\nUnstandardized coefficients (standard errors) for a taxonomy of OLS regression models fitted to explore the effect of time spent on homework on GPA. All models were fitted with n=100 observations.\n\n\n\n\nPredictor\n\n\nModel 1\n\n\nModel 2\n\n\n\n\n\n\nTime spent on homework\n\n\n2.65(0.37)\n\n\n0.99(0.36)\n\n\n\n\nParent education level\n\n\n\n\n0.87(0.38)\n\n\n\n\nConstant\n\n\n11.32(6.12)\n\n\n63.2(5.24)\n\n\n\n\n\n\n\n\nR2\n\n\n0.107\n\n\n0.152\n\n\n\n\nRMSE\n\n\n7.24\n\n\n7.09\n\n\n\n\n\nThe results from Model 1 are consistent with time spent on homework having a positive association with GPA (\\(p&lt;.001\\)). Each one hour difference in time spent on homework is associated with a 1.21-point difference in GPA, on average. This positive association is seen, even after controlling for parent education level (see Model 2; \\(p=.026\\)), although the effect is somewhat smaller, with each one hour difference in time spent on homework is associated with a 0.98-point difference in GPA, on average.\nThese results argue against the alternative explanation that it is really parent education level that is explaining both time spent on homework and students‚Äô GPAs. The results from the multiple regression model argue that after we account for the fact that parent education is related to both those variables, there is still a positive, albeit smaller, relationship between time spent on homework and students‚Äô GPAs. To understand why we can rule out this alternative explanation of the relationship, we need to understand the idea of statistical control."
  },
  {
    "objectID": "03-02-understanding-statistical-control.html#understanding-statistical-control-via-predicted-values",
    "href": "03-02-understanding-statistical-control.html#understanding-statistical-control-via-predicted-values",
    "title": "12¬† Understanding Statistical Control",
    "section": "12.3 Understanding Statistical Control via Predicted Values",
    "text": "12.3 Understanding Statistical Control via Predicted Values\nThe fitted equation for Model 2 is,\n\\[\n\\hat{\\mathrm{GPA}_i} = 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{Parent~Education}_i)\n\\]\nLet‚Äôs predict the average GPA for students who spend differing amounts of time on homework,\n\nTime spent on homework = 1 hour\nTime spent on homework = 2 hours\nTime spent on homework = 3 hours\n\nLet‚Äôs also assume that these student all have parent education level of 12 years.\n\n\n\n\n\n  \n  Table¬†12.2:  Predicted average GPA for students who spend 1, 2, and 3 hours a week\non homework with parent education level of 12 years. \n  \n    \n    \n      Homework\n      Parent Education\n      Model Predicted GPA\n    \n  \n  \n    1\n12\n63.22 + 0.99(1) + 0.87(12) = 74.65\n    2\n12\n63.22 + 0.99(2) + 0.87(12) = 75.64\n    3\n12\n63.22 + 0.99(3) + 0.87(12) = 76.63\n  \n  \n  \n\n\n\n\n\nIn this example, the value of parent_ed is ‚Äúconstant‚Äù across the three types of students. Time spent on homework differs by one-hour between each subsequent type of student. The difference in model predicted average GPA between these students is 0.99. When we hold level of parent education constant, the predicted difference in average GPA between students who spend an additional hour on homework is 0.99.\nWhat if we had chosen a parent education level of 13 years instead?\n\n\n\n\n\n  \n  Table¬†12.3:  Predicted average GPA for students who spend 1, 2, and 3 hours a week\non homework with parent education level of 13 years. \n  \n    \n    \n      Homework\n      Parent Education\n      Model Predicted GPA\n    \n  \n  \n    1\n13\n63.22 + 0.99(1) + 0.87(13) = 75.52\n    2\n13\n63.22 + 0.99(2) + 0.87(13) = 76.51\n    3\n13\n63.22 + 0.99(3) + 0.87(13) = 77.50\n  \n  \n  \n\n\n\n\n\nThe model predicted average GPAS are higher for these students because they have a higher parent education level. But, again, when we hold parent education level constant, the predicted difference in average GPA between students who spend an additional hour on homework is 0.99. Moreover, this difference in average GPAs for any one hour difference in time spent on homework will be 0.99, regardless of the value we pick for parent level of education.\nBy fixing the value of parent level of education to a particular value (holding it constant) we can ‚Äúfairly‚Äù compare the average predicted GPA for different values of time spent on homework. This allows us to evaluate the association between time spent on homework and GPA without worrying that the GPAs we are comparing have different values for parent level of education. By holding parent level of education constant, we remove it as a potential confounding explanation of the relationship between time spent on homework and students‚Äô GPAs."
  },
  {
    "objectID": "03-02-understanding-statistical-control.html#understanding-statistical-control-via-the-fitted-model",
    "href": "03-02-understanding-statistical-control.html#understanding-statistical-control-via-the-fitted-model",
    "title": "12¬† Understanding Statistical Control",
    "section": "12.4 Understanding Statistical Control via the Fitted Model",
    "text": "12.4 Understanding Statistical Control via the Fitted Model\nLet us return to the fitted equation for Model 2,\n\\[\n\\hat{\\mathrm{GPA}_i} = 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{Parent~Education}_i)\n\\]\nBut this time, instead of computing predicted values, let‚Äôs focus on the fitted equation for students with a specified parent education level, say 12 years. We can substitute this value into the fitted equation and reduce the result.\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{12}) \\\\[2ex]\n&= 63.22 + 0.99(\\mathrm{Homework}_i) + 10.44 \\\\[2ex]\n&= 73.66 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nBy substituting in a constant value for parent education level, we can write the model so that GPA is a function of time spent on homework. Interpreting the coefficients,\n\nStudents with a parent education level of 12 years and who spend 0 hours a week on homework are predicted to have a mean GPA of 73.66.\nFor students with a parent education level of 12 years, each additional hour spent on homework is associated with a 0.99-pt difference in GPA, on average.\n\nWhat about the students whose parent education level is 13? Substituting this value into the fitted equation and reducing the result, we get,\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{13}) \\\\[2ex]\n&= 63.22 + 0.99(\\mathrm{Homework}_i) + 11.31 \\\\[2ex]\n&= 74.53 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nInterpreting these coefficients,\n\nStudents with a parent education level of 13 years and who spend 0 hours a week on homework are predicted to have a mean GPA of 74.53.\nFor students with a parent education level of 13 years, each additional hour spent on homework is associated with a 0.99-pt difference in GPA, on average.\n\nThe key here is that the slope for these two sets of students is the same. The relationship between time spent on homework and GPA is exactly the same regardless of parent education level."
  },
  {
    "objectID": "03-02-understanding-statistical-control.html#understanding-statistical-control-via-the-plot-of-the-fitted-model",
    "href": "03-02-understanding-statistical-control.html#understanding-statistical-control-via-the-plot-of-the-fitted-model",
    "title": "12¬† Understanding Statistical Control",
    "section": "12.5 Understanding Statistical Control via the Plot of the Fitted Model",
    "text": "12.5 Understanding Statistical Control via the Plot of the Fitted Model\nTo create a plot that helps us interpret the results of a multiple regression analysis, we pick fixed values for all but one of the predictors and substitute those into the fitted equation. We can then rewrite the equation and use geom_abline() to draw the fitted line. Below I illustrate this by choosing three fixed values for parent level of education (namely 8, 12, and 16) and rewriting the three equations.\nParent education level = 8\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{8}) \\\\[2ex]\n&= 70.18 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nParent education level = 12\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{12}) \\\\[2ex]\n&= 73.66 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nParent education level = 16\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{16}) \\\\[2ex]\n&= 77.14 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nNow I will create a plot of the outcome versus the predictor we left as a variable in the three equations (time spent on homework) and use geom_abline() to include the line for each of the three rewritten equations. Note that since I have three different equations (one for each of the three parent education levels), I will need to include three layers of geom_abline() in the plot syntax.\n\nggplot(data = keith, aes(x = homework, y = gpa)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Time spent on homework\") +\n  ylab(\"Model predicted GPA\") +\n  geom_abline(intercept = 70.18, slope = 0.99, color = \"#003f5c\", linetype = \"dotdash\") +\n  geom_abline(intercept = 73.66, slope = 0.99, color = \"#f26419\", linetype = \"solid\") +\n  geom_abline(intercept = 77.14, slope = 0.99, color = \"#b40f20\", linetype = \"dashed\") \n\n\n\n\nFigure¬†12.2: Model predicted GPA as a function of time spent on homework for students with a parent education level of 8 years (blue, dot-dashed line), 12 years (orange, solid line), and 16 years (red, dashed line).\n\n\n\n\nFrom the plot we can see the effect of time spent on homework in the slopes of the fitted lines. Regardless of the level of parent education (8, 12, or 16), the slope of the line is 0.99, which means the three lines are parallel. The intercepts of these three lines vary reflecting the different level of parent education.\nWe can interpret the effect of parent level of education by fixing time spent on homework to a particular value on the same plot. For example, fixing time spent on homework to 6, we see that the average GPA varies for the three levels of parent education displayed in the plot.\n\nggplot(data = keith, aes(x = homework, y = gpa)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Time spent on homework\") +\n  ylab(\"Model predicted GPA\") +\n  geom_abline(intercept = 70.18, slope = 0.99, color = \"#003f5c\", linetype = \"dotdash\") +\n  geom_abline(intercept = 73.66, slope = 0.99, color = \"#f26419\", linetype = \"solid\") +\n  geom_abline(intercept = 77.14, slope = 0.99, color = \"#b40f20\", linetype = \"dashed\") +\n  geom_point(x = 6, y = 76.11908, color = \"#003f5c\", size = 2) +\n  geom_point(x = 6, y = 79.60157, color = \"#f26419\", size = 2) +\n  geom_point(x = 6, y = 83.08407, color = \"#b40f20\", size = 2)\n\n\n\n\nFigure¬†12.3: Model predicted GPA as a function of time spent on homework for students with a parent education level of 8 years (blue, dot-dashed line), 12 years (orange, solid line), and 16 years (red, dashed line). The model predicted GPAs for students who spend six hours a week on homework are also displayed.\n\n\n\n\nHow much do the model predicted GPAs vary for these three parent education levels?\n\n\n\n\n\n  \n  Table¬†12.4:  Predicted GPA for students who spend six hours a week on homework\nwith 8, 12, and 16 years of parent education. \n  \n    \n    \n      Homework\n      Parent Education\n      Model Predicted GPA\n    \n  \n  \n    6\n8\n76.12\n    6\n12\n79.60\n    6\n16\n83.08\n  \n  \n  \n\n\n\n\n\nThe difference between each of these subsequent model predicted GPA values is 3.48. This is constant because we chose parent education levels that differ by the same amount, in this case each value of parent education differs by four years.\n\n\n12.5.1 Effect of Parent Education Level\nWhat if we would have chosen parent education levels that differed by one year rather than by four years?\n\n\n\n\n\n  \n  Table¬†12.5:  Predicted GPA for students who spend six hours a week on homework\nwith with parent education of 8, 9, and 10 years \n  \n    \n    \n      Homework\n      Parent Education\n      Model Predicted GPA\n    \n  \n  \n    6\n8\n76.12\n    6\n9\n76.99\n    6\n10\n77.86\n  \n  \n  \n\n\n\n\n\nNow a one-year difference in parent education level is associated with a 0.87-point difference in predicted GPA, holding time spent on homework constant. We could also have calculated this directly from the earlier result. Since a four-year difference in parent education is associated with a 3.48-point difference in predicted GPA, a one-year difference in parent education is associated with a \\(3.48 / 4=0.87\\)-point difference in predicted GPA. This algebra works since the relationship is constant (i.e., linear)."
  },
  {
    "objectID": "03-02-understanding-statistical-control.html#triptych-plots-displaying-the-results-from-a-multiple-regression-model",
    "href": "03-02-understanding-statistical-control.html#triptych-plots-displaying-the-results-from-a-multiple-regression-model",
    "title": "12¬† Understanding Statistical Control",
    "section": "12.6 Triptych Plots: Displaying the Results from a Multiple Regression Model",
    "text": "12.6 Triptych Plots: Displaying the Results from a Multiple Regression Model\nRemember, to create a plot that helps us interpret the results of a multiple regression analysis, we pick fixed values for all but one of the predictors and substitute those into the fitted equation. We can then rewrite the equation and use geom_abline() to draw the fitted lines. We illustrated this earlier by choosing three fixed values for parent level of education (namely 8, 12, and 16) and rewriting the three equations:\n\\[\n\\begin{split}\n\\mathbf{Parent~Education=8:} \\quad\\hat{\\mathrm{GPA}_i} &= 70.18 + 0.99(\\mathrm{Homework}_i) \\\\[2ex]\n\\mathbf{Parent~Education=12:} \\quad\\hat{\\mathrm{GPA}_i} &= 73.66 + 0.99(\\mathrm{Homework}_i) \\\\[2ex]\n\\mathbf{Parent~Education=16:} \\quad\\hat{\\mathrm{GPA}_i} &= 77.14 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nThe plot we created earlier put all three fitted lines on the same plot. An alternative plot is to show each line in a different plot, and to place this plots side-by-side in a ‚Äútriptych‚Äù. (I borrow this terminology from McElreath (2016) who coined this in his Statistical Rethinking book.) To do this we save each plot into an object and then use functionality from the patchwork package to put the plots side-by-side.\n\n# Load package\nlibrary(patchwork)\n\n# Create plot 1\np1 = ggplot(data = keith, aes(x = homework, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 70.18, slope = 0.99) +\n      theme_bw() +\n      xlab(\"Time spent on homework\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Parent Education = 8 Years\")\n\n# Create plot 2\np2 = ggplot(data = keith, aes(x = homework, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 73.66, slope = 0.99) +\n      theme_bw() +\n      xlab(\"Time spent on homework\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Parent Education = 12 Years\")\n\n# Create plot 3\np3 = ggplot(data = keith, aes(x = homework, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 77.14, slope = 0.99) +\n      theme_bw() +\n      xlab(\"Time spent on homework\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Parent Education = 16 Years\")\n\n# Put plots side-by-side\np1 | p2 | p3\n\n\n\n\nFigure¬†12.4: Model predicted GPA as a function of time spent on homework for students with a parent education level of 8, 12, and 16 years.\n\n\n\n\n\n\n12.6.1 Emphasis on the Effect of Parent Level of Education\nWith two (or more) effects in the model we have more than one potential way to display the fitted results. In general, we will display one predictor through the slope of the line plotted (same as we did with only one predictor), and EVERY OTHER predictor will be shown through one or more lines. In the previous plots, below, we have displayed the effect of time spent on homework (on the x-axis) through the slope of the lines, and the effect of parent level of education through the vertical distance between the three different lines.\nIn general, the partial effect seen via the slope of the line is more cognitively apparent than the vertical distance between different lines. Thus whichever effect you want to emphasize should be placed on the x-axis; or left as a variable when you algebraically simplify the fitted regression equation.\nFor example, what if we wanted to emphasize parent level of education? In that case, we would choose fixed values for time spent on homework, substitute these into the fitted equation, and simplify. Here we choose fixed values for time spent on homework of 2, 5, and 10 hours. Rewriting the three equations:\n\\[\n\\begin{split}\n\\mathbf{Homework=2:}  \\quad\\hat{\\mathrm{GPA}_i} &= 65.18 + 0.87(\\mathrm{Parent~Education}_i) \\\\[2ex]\n\\mathbf{Homework=5:} \\quad\\hat{\\mathrm{GPA}_i} &= 68.14 + 0.87(\\mathrm{Parent~Education}_i) \\\\[2ex]\n\\mathbf{Homework=10:} \\quad\\hat{\\mathrm{GPA}_i} &= 73.08 + 0.87(\\mathrm{Parent~Education}_i)\n\\end{split}\n\\]\nThen we create the triptych plot showing the resulting equations:\n\n# Create plot 1\np4 = ggplot(data = keith, aes(x = parent_ed, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 65.18, slope = 0.87) +\n      theme_bw() +\n      xlab(\"Parent education (in years)\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Time Spent on Homework = 2 Hours\")\n\n# Create plot 2\np5 = ggplot(data = keith, aes(x = parent_ed, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 68.14, slope = 0.87) +\n      theme_bw() +\n      xlab(\"Parent education (in years)\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Time Spent on Homework = 5 Hours\")\n\n# Create plot 3\np6 = ggplot(data = keith, aes(x = parent_ed, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 73.08, slope = 0.87) +\n      theme_bw() +\n      xlab(\"Parent education (in years)\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Time Spent on Homework = 10 Hours\")\n\n# Put plots side-by-side\np4 | p5 |p6\n\n\n\n\nFigure¬†12.5: Model predicted GPA as a function of parent education level for students who spend 2 hours, 5 hours, and 10 hours a week on homework."
  },
  {
    "objectID": "03-02-understanding-statistical-control.html#only-displaying-a-single-effect",
    "href": "03-02-understanding-statistical-control.html#only-displaying-a-single-effect",
    "title": "12¬† Understanding Statistical Control",
    "section": "12.7 Only Displaying a Single Effect",
    "text": "12.7 Only Displaying a Single Effect\nSometimes you only want to show the effect of a single predictor from the model. For example, in educational studies we often control for SES and mother‚Äôs level of education when we fit the model, but we don‚Äôt want to display those effects in our plot. There is no rule that just because you included an effect in the fitted model that you are obligated to display it.\nAny effect that you do not want to display graphically can be fixed to a single value, typically the mean value. Fixing the effect to a single value will produce only one line. For example, here we set the parent education value to the its mean value of 14.03 years. After substituting this value into the fitted equation, this results in,\n\\[\n\\hat{\\mathrm{GPA}_i} = 75.43 + 0.99(\\mathrm{Homework}_i)\n\\]\nPlotting this we get a single line which displays the effect of time spent on homework on GPA. Even though the effect of parent education is not displayed, it is still included as the intercept value of the plotted line is based on fixing this effect to its mean.\n\nggplot(data = keith, aes(x = homework, y = gpa)) +\n geom_point(alpha = 0) +\n geom_abline(intercept = 75.43, slope = 0.99) +\n theme_bw() +\n xlab(\"Time spent on homework\") +\n ylab(\"Model predicted GPA\")\n\n\n\n\nFigure¬†12.6: Model predicted GPA as a function of time spent on homework for students with an average parent education level (14.03 years).\n\n\n\n\n\n\n\n\n\nMcElreath, R. (2016). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press."
  },
  {
    "objectID": "03-03-assumptions.html#four-distributional-assumptions-needed-for-validity-of-regression-results",
    "href": "03-03-assumptions.html#four-distributional-assumptions-needed-for-validity-of-regression-results",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.1 Four Distributional Assumptions Needed for Validity of Regression Results",
    "text": "13.1 Four Distributional Assumptions Needed for Validity of Regression Results\nRecall that the simple regression model is expressed as:\n\\[\nY_i = \\beta_0 + \\beta_1(X_i) + \\epsilon_i\n\\]\nThere are several distributional assumptions we make about the errors (\\(\\epsilon_i\\) values) in the regression model in order for the results we obtain from fitting this model (e.g., coefficient estimates, \\(p\\)-values, CIs) to be valid.\n\n[L]inearity\n[I]ndependence\n[N]ormality\n[E]qual variances (Homoskedasticity)\n\nYou can remember these assumptions using the mnemonic LINE. To better understand these assumptions, imagine that we had the population of X- and Y-values in which all the distributional assumptions were valid. Now imagine we plotted the ordered pairs, \\((x_i,y_i)\\), and we also regressed the Y-values on the X-values and plotted this regression line as well. A visual depiction of this is shown in Figure¬†13.1.\n\n\n\n\n\nFigure¬†13.1: A visual depiction of X- and Y-values and regression line from a population in which the distributional assumptions are valid.\n\n\n\n\nIn Figure¬†13.1, the normal distributions depicted are the distribution of Y-values at each value of X, or what we refer to as the conditional distributions of Y. Although only three conditional distributions are shown in Figure 1, there is a conditional distribution for EVERY value of X.\nAlthough the distributional assumptions are about the model‚Äôs errors, we can also apply the assumptions to the conditional Y-values since they are linear transformations of the error terms. This allows us to use Figure¬†13.1 to expand upon each of the distributional assumptions listed earlier.\n\nLinearity: The linearity assumption implies that the MEAN values of \\(Y\\) from all the conditional distributions all fall on the same line. If this is the case, we would say that the conditional mean \\(Y\\)-values are linear.\nIndependence: This is not shown in the figure. The assumption is that each \\(Y\\)-value in a particular conditional distribution is independent from every other \\(Y\\)-value in that same distribution.\nNormality: This assumption indicates that every one of the conditional distributions of \\(Y\\)-values is normally distributed.\nEqual variances: This assumption says that the variance (or standard deviation) of all of the conditional distributions is exactly the same.\n\n\n\n13.1.1 Distributional Assumptions are Really About the Residuals\nStating these distributional assumptions in terms of the the conditional distributions of Y was useful in helping us visualize them within a typical representation of the regression model through the relationship between X- and Y-values. Technically, however, all the distributional assumptions are about the conditional distributions of the residuals.1 Think about how we compute the residuals:\n\\[\n\\epsilon_i = Y_i - \\hat{Y}_i\n\\] In Figure¬†13.1, the \\(\\hat{Y}_i\\) value is the \\(Y\\)-value that corresponds to the point on the line. Within each conditional distribution of Y, the \\(\\hat{Y}_i\\) is constant; in other words all of the observations with the same X-value will have the same \\(\\hat{Y}_i\\)-value. That means within a conditional distribution, to compute the residual values, we are subtracting a constant:\n\\[\n\\epsilon_i = Y_i - C\n\\]\nRemember from the chapter on standardized regression, subtracting a constant from each value in a distribution shifts the center of the distribution. Pick any conditional distribution from Figure 1, which is a normal distribution centered at the \\(\\hat{Y}_i\\) value. Now subtract the \\(\\hat{Y}_i\\)-value from each Y-value. This will re-center the normal distribution at 0. Thus, the conditional distribution of residuals is normally distributed, has a mean of 0, and has the same variance (or standard deviation) as the conditional distribution of Y-values. If we transform every Y-value in the population, from Figure¬†13.1, to a residual value, and re-plot them, the visual depiction now looks like this.\n\n\n\n\n\nFigure¬†13.2: A visual depiction of the simple regression model‚Äôs assumptions about the residuals.\n\n\n\n\nSo if we restate the assumptions in terms of the residuals and the conditional distributions of the residuals,\n\nLinearity: The MEAN value of each of the conditional distributions of the residuals is 0.\nIndependence: Again, this is not shown in the figure. The assumption is that each residual value in a particular conditional distribution is independent from every other residual value in that same distribution.\nNormality: This assumption indicates that each of the conditional distributions of residuals is normally distributed.\nEqual variance: The variance (or standard deviation) of all of the conditional distributions of residuals is exactly the same.\n\nThese assumptions can also be expressed mathematically as,\n\\[\n\\epsilon_{i|X} \\overset{\\mathrm{i.i.d~}}{\\sim} \\mathcal{N}\\left(0, \\sigma^2\\right)\n\\]\nThe ‚Äúi.i.d‚Äù stands for independent and identically distributed. The mathematical expression says the residuals conditioned on X (having the same X-value) are independent and identically normally distributed with a mean of 0 and some variance (\\(\\sigma^2\\))."
  },
  {
    "objectID": "03-03-assumptions.html#evaluating-the-distributional-assumptions",
    "href": "03-03-assumptions.html#evaluating-the-distributional-assumptions",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.2 Evaluating the Distributional Assumptions",
    "text": "13.2 Evaluating the Distributional Assumptions\nBefore beginning to evaluate the distributional assumptions using our empirical data, it is important to point out that the assumptions are about the residuals in the population. Because in most analyses, we only have a sample of data, we can never really evaluate whether these assumptions are true. We can only offer a guess as to whether they are tenable given the data we see. The strongest arguments for justification for meeting any of the distibutional assumptions is a theoretical argument based on existing literature in the discipline.\n\n\n13.2.1 Linearity\nThe linearity assumption is critical in specifying the structural part of the model. Fitting a linear model when the TRUE relationship between X and Y is non-linear may be quite problematic. Coefficients may be wrong. Predictions may also be wrong, especially at the extreme values for X. More importantly, mis-specified models lead to misinformed understandings of the world.\n\n\n\n\n\n\n\nFigure¬†13.3: The left-hand plot shows observations simulated from a nonlinear model. The right-hand plot shows the same data and the results of fitting a linear model to non-linear data. Using the linear fitted model to make predictions would be quite misleading, especially at extreme values of X.\n\n\n\n\n\n\nIn the left-hand plot of Figure¬†13.3, when the correct nonlinear model is fitted to the data, the conditional Y-values are scattered above and below the line at each X-value. In the right-hand plot of Figure¬†13.3, when a linear model was fitted to data generated from a non-linear function, the data tend to either be consistently above, or below the line, depending on the X-value. This type of systematic deviation would be evidence that the linearity assumption is not tenable. When evaluating this assumption, we want to see data in the scatterplot that is ‚Äúequally‚Äù above and below the fitted regression line at each value of X.\nSince the linearity assumption also means that the average residual is 0, if we are evaluating this assumption by looking at a plot of the residuals, we would want to see residuals above (positive) and below (negative) 0. Figure 4 shows scatterplots of the residuals versus the X-values from the two fitted lines. In the left-hand plot, when the residuals are based on the true model, we see that the residuals are scattered above and below 0 at each value of X. In the right-hand plot, in which the residuals were computed based on a mis-specified linear model, we again see that the residuals are clustered above, or below 0, depending on the value of X.\n\n\n\n\n\nFigure¬†13.4: The left-hand plot shows the residuals from the true nonlinear model versus the X-values. The right-hand plot shows the residuals from the mis-specified linear model versus the X-values. A reference line at \\(Y=0\\) has also been added to the plot to aid interpretation.\n\n\n\n\n\n\n\n13.2.2 Independence\nThe definition of independence relies on formal mathematics. Loosely speaking a set of observations is independent if knowing that one observation is above (or below) the mean value in a conditional distribution conveys no information about whether any other observation in the same conditional distribution is above (or below) its mean value. If observations are not independent, we say they are dependent or correlated.\nIndependence is not an assumption we can check graphically. To evaluate this assumption we need to know something about the how the data were collected or assigned to values of X. Using random chance in the design of the study, to either select observations (random sampling) or assign them to levels of the predictor (random assignment) will guarantee independence of the observations. Outside of this, independence is often difficult to guarantee, and often has to be a logical argument.\nThere are a few times that we can ascertain that the independence assumption would be violated. These instances often result from aspects of the data collection process. One such instance common to social science research is when the observations (i.e., cases, subjects) are collected within a physical or spatial proximity to one another. For example, this is typically the case when a researcher gathers a convenience sample based on location, such as sampling students from the same school. Another violation of independence occurs when observations are collected over time (longitudinally), especially when the observations are repeated measures from the same subjects.\nOne last violation of independence occurs when the observation level used to assign cases to the different predictor values (e.g., treatment or control) does not correspond to the observation level used in the analysis. For example, in educational studies whole classrooms are often assigned to treatment or control. That means that the cases used in the analysis, in order to satisfy the independence assumption, would need to be at the classroom level (e.g., the cases would need to be classroom means), not individual students. This can be deleterious for sample size.\nIf the independence assumption is violated, almost every value you get in the tidy() and glance() output‚Äîthe standard errors, t-values, F-values, p-values, and residual standard errors (RMSE)‚Äîare wrong. If you suspect that the independence assumption is violated, then you will need to use a method (not OLS regression) that accommodates non-independence.2\n\n\n\n13.2.3 Normality and Equal Variances\nThe assumption about normality is about the conditional distribution of errors at each value of X. This assumption is less critical than the assumptions of linearity and independence. It is only problematic for the OLS regression results if there are egregious violations of normality. In general, if the violations of these assumptions are only minor, the results of the OLS regression are still valid; we would say the results from an OLS regression are robust to violations of normality. Even if the violations are bad, there are many transformations of the data that can alleviate this problem.3\nNormal distributions are symmetric with the density of observations close to the mean. This means that in the scatterplot of the residuals versus the X-values, we want to see symmetry around 0 at each X-value and that most of the residuals are ‚Äúclose‚Äù to 0 (‚ÄúClose‚Äù is hard to define as it depends on the standard deviation, remember that 68% of the residuals should be within one standard deviation, 95% within two standard deviations, etc.)\n\n\n\n\n\nFigure¬†13.5: The left-hand plot shows conditional distributions of normally distributed residuals. The right-hand plot shows conditional distributions that are not normally distributed. The line \\(Y=0\\) has also been included to aid interpretation.\n\n\n\n\nThe residuals in the left-hand plot of Figure 4 are symmetric around 0 for each X-value. The bulk of the residuals at each X-value is near 0 and they become less dense the further from 0 they are, for both the positive and negative residual values. This is the pattern we want to see in empirical residuals. The residuals in the right-hand plot of Figure 4, are not symmetric around 0. They are also more dense in the negative values and then become less dense for higher positive values. This is evidence that the normality assumption is violated.\nIn the examples given in Figure 4, the number of observations and the shape of the conditional distributions make deviations from normality easier to spot. Evaluating the normality assumption in empirical data, which are often composed of fewer observations, is much more of a challenge. Moreover, evaluating the shape of distributions in a scatterplot is not an easy task.\nResearchers often evaluate the normality assumption by examining the shape of the marginal distribution of the residuals. Figure 5 shows density plots of the marginal distributions for the same two sets of residuals plotted in Figure 4.\n\n\n\n\n\nFigure¬†13.6: The left-hand plot shows conditional distributions of normally distributed residuals. The right-hand plot shows conditional distributions that are not normally distributed. The line \\(Y=0\\) has also been included to aid interpretation.\n\n\n\n\nThe marginal distribution in the right-hand plot clearly shows deviation from normality and we could safely say that the normality assumption is violated. We may be tempted to say that the marginal distribution in the left-hand plot also violates the assumption of normality as the density plot does not look normal. This would be a mistake. Remember that the assumptions are about the residuals in the population; the sample residuals may deviate from normality simply because of sampling error. Moreover, this looks like a minor violation of the normality assumption and is probably not an issue for the regression results.\n\n\n13.2.4 Equal Variances\nSimilar to the assumption about normality, the assumption of equal variances (homoskedasticity) is is less critical than the assumptions of linearity and independence, and only egregious violations of the assumption is problematic for the validity of the regression results.4\n\n\n\n\n\nFigure¬†13.7: The left-hand plot shows conditional distributions of normally distributed residuals with equal variances. The center plot shows conditional distributions that are not normally distributed but still have equal variances. The right-hand plot shows conditional distributions that are normally distributed but have unequal variances. The line \\(Y=0\\) has also been included in all plots to aid interpretation.\n\n\n\n\nWhen evaluating the assumption of equal variances, we want to see that the range of residual values at each X-value is roughly the same. For the left-hand and center plots in Figure 6, the range of residual values is roughly the same at each X-value, so we can conclude that the equal variances assumption is tenable. In the right-hand plot, the residuals show a pattern of variances that seems to be increasing for larger X-values. That is, the range of the residual values at smaller X-values is smaller than the range of the residual values at larger X-values. This is a violation of the equal variances assumption."
  },
  {
    "objectID": "03-03-assumptions.html#empirically-evaluating-the-distributional-assumptions",
    "href": "03-03-assumptions.html#empirically-evaluating-the-distributional-assumptions",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.3 Empirically Evaluating the Distributional Assumptions",
    "text": "13.3 Empirically Evaluating the Distributional Assumptions\nWe can use the residuals computed from the empirical data to evaluate the distributional assumptions of linearity, normality, and equal variances. (The assumption of independence is difficult to evaluate using the data, and is better left to a logical argument that refers to the study design.) Recall that the assumptions are about the residuals. To compute the residuals, we will use the augment() function from the broom package. We will also write those results into an object, aug_a, so we can compute on it later.\n\n# Load library\nlibrary(broom)\n\n# Augment the model to get residuals\naug_a = augment(lm.a)\n\n# View augmented data\nhead(aug_a)\n\n\n\n# A tibble: 6 √ó 8\n    gpa homework .fitted .resid   .hat .sigma  .cooksd .std.resid\n  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1    78        2    76.7   1.28 0.0328   7.28 0.000550      0.180\n2    79        6    81.6  -2.57 0.0120   7.27 0.000776     -0.358\n3    79        1    75.5   3.50 0.0500   7.27 0.00646       0.495\n4    89        5    80.4   8.64 0.0100   7.22 0.00728       1.20 \n5    82        3    77.9   4.07 0.0204   7.26 0.00336       0.568\n6    77        4    79.1  -2.15 0.0128   7.27 0.000579     -0.298\n\n\nThe cases in the augmented data frame are in the same order as the cases in the keith data frame. For example, the first case had a GPA of 78 and spent 2 hours a week on homework. The augmented data also includes several other useful measures for evaluating regression models. For now, we will focus on the .fitted column and the .resid column. Those columns contain the fitted values (\\(\\hat{Y_i}\\)) and the residuals for each case based on the model fitted in lm.a.\nWe will examine two residual plots to help us evaluate the tenability of the assumptions: (1) a density plot of the marginal distribution of residuals, and (2) a scatterplot of the residuals versus the X-values. The density plot will allow us to eval;uate the normality assumption, and the scatterplot will allow us to evaluate the linearity and equal variances assumption. As we make these evaluations, remember that we do not have the entire population of residuals (we obtained our residuals by fitting a regression to a sample of data), so we do not expect that our residuals will actually meet the assumptions perfectly (remember, sampling error). Examining the sample residuals, is however, a reasonable way to evaluate the tenability of assumptions in practice. We just have to keep in mind that the sample residuals may deviate a bit from these assumptions.\n\n# Density plot of the residuals\np1 = ggplot(data = aug_a, aes(x = .resid)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Residual\") +\n  ylab(\"Probability density\")\n\n# Scatterplot of the residuals versus X\np2 = ggplot(data = aug_a, aes(x = homework, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  theme_bw() +\n  xlab(\"Time spent on homework (in hours)\") +\n  ylab(\"Residual\")\n\n# Layout plots\np1 | p2\n\n\n\n\nFigure¬†13.8: LEFT: Density plot of the marginal distribution of residuals from the fitted regression model. RIGHT: Scatterplot of the residuals versus time spent on homework. The \\(Y=0\\) line has been included as a reference for interpretation.\n\n\n\n\nThe marginal distribution of residuals looks symmetric and bell-shaped. Based on this plot, the normality assumption seems tenable (or at least there is negligable violation of the assumption). The scatterplot of residuals versus time spent on homework shows random scatter around the line \\(Y=0\\). This suggests that the average residual is roughly 0 at each X-value, and that the linearity assumption seems tenable. The range of the residuals at each X-value seems similar indicating that the assumption of equal variances is also tenable. Lastly, since the observations were randomly sampled (see data codebook) we believe the independence assumption is satisfied."
  },
  {
    "objectID": "03-03-assumptions.html#standardized-residuals",
    "href": "03-03-assumptions.html#standardized-residuals",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.4 Standardized Residuals",
    "text": "13.4 Standardized Residuals\nOften researchers standardize the residuals before performing the assumption checking. Using standardized residuals rather than unstandardized (raw) residuals does not change any of the previous findings. In fact, since standardizing is a linear transformation, the scatterplot and density plot look identical whether you use the unstandardized residuals or the standardized residuals. The only thing that changes is the scale on the residual axis of the plots.\nTo standardize a residual, we subtract the mean of its conditional distribution and divide by the standard deviation. The distributional assumptions stated that the mean of each conditional distribution of the residuals is 0 and the standard deviation is the same, although unknown, namely \\(\\sigma_{\\epsilon}\\). Mathematically, we standardize using:\n\\[\nz_{\\epsilon} = \\frac{\\epsilon - 0}{\\mathrm{\\sigma}_{\\epsilon}}\n\\]\nUnfortunately, we do not know what the value for \\(\\sigma_{\\epsilon}\\), so we need to estimate it from the data. This adds uncertainty to the calculation of the standardized residual in the same way estimating the standard error in a normal distribution adds uncertainty and makes the distribution t-distributed. As such, we write the formula for the standardized residuals using a t rather than z and compute it as:\n\\[\nt_{\\epsilon} = \\frac{\\epsilon - 0}{\\mathrm{\\hat\\sigma}_{\\epsilon}}\n\\]\nSince the t-distribution is also referred to as Student‚Äôs distribution, standardized residuals are also sometimes referred to as studentized residuals.5 What standardizing does for us is to put the residuals on a scale that uses the standard error. This allows us to judge whether particular residuals that look extreme (either highly positive or negative) are actually extreme or not. The standardized residuals are given in the augmented output in the .std.resid column.\n\n# Density plot of the residuals\np1 = ggplot(data = aug_a, aes(x = .std.resid)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n# Scatterplot of the residuals versus X\np2 = ggplot(data = aug_a, aes(x = homework, y = .std.resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  theme_bw() +\n  xlab(\"Time spent on homework (in hours)\") +\n  ylab(\"Standardized residual\")\n\n# Layout plots\np1 | p2\n\n\n\n\nFigure¬†13.9: LEFT: Density plot of the marginal distribution of standardized residuals from the fitted regression model. RIGHT: Scatterplot of the standardized residuals versus time spent on homework. The \\(Y=0\\) line has been included as a reference for interpretation.\n\n\n\n\nThe only thing that has changed between these plots and the previous plots of the unstandardized residuals is the scale. However, now we can identify observations with extreme residuals, because we can make use of the fact that most of the residuals (~95%) should fall within two standard errors from the mean of 0. There are four students who have residuals of more than two standard errors. Given that we have \\(N=100\\) observations, it is not surprising to see four observations more extreme than two standard errors; remember we expect to see 5% just by random chance. If observations have really extreme residuals (e.g., \\(|t_{\\epsilon}|&gt;3.5\\)), it is often worth a second look since these extreme observations are interesting and may point to something going on in the data.\nWe can also filter() the augmented data to find these observations and to determine the exact value of the standardized residuals. Recall that the vertical line (|) means ‚ÄúOR‚Äù.\n\n# Identify extreme observations\naug_a |&gt; \n  filter(.std.resid &lt;= -2 | .std.resid &gt;= 2)"
  },
  {
    "objectID": "03-03-assumptions.html#distributional-assumptions-for-the-multiple-regression-model",
    "href": "03-03-assumptions.html#distributional-assumptions-for-the-multiple-regression-model",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.5 Distributional Assumptions for the Multiple Regression Model",
    "text": "13.5 Distributional Assumptions for the Multiple Regression Model\nRecall that the model for a multiple regression (with two predictors) is a plane that is fitted using observations composed of ordered triples, \\((X_1,X_2,Y)\\). Figure 8 visually shows the multiple regression model‚Äôs assumptions.\n\n\n\n\n\nFigure¬†13.10: A visual depiction of the multiple regression model‚Äôs assumptions.\n\n\n\n\nNow the conditional distributions that we put the assumptions on are the residuals (or Y-values) at each combination of (\\(X_1\\), \\(x_2\\)). The assumptions for the multiple regression model are similar to those for the simple model, namely,\n\nLinearity: Notice from the visual that the MEAN values of each combination (\\(X_1\\), \\(X_2\\)) are linear in both the \\(X_1\\) and the \\(X_2\\) directions. This implies that the mean of each of the conditional distributions of residuals is zero at (\\(X_1\\), \\(X_2\\)).\nIndependence: Again, this is not shown in the figure. The assumption is that each residual value in a particular conditional distribution is independent from every other residual value in that same distribution.\nNormality: This assumption indicates that each of the conditional distributions of residuals is normally distributed.\nHomoskedasticity: The variance (or standard deviation) of all of the conditional distributions of residuals is exactly the same.\n\nTo evaluate these assumptions, we will create the exact same plots we created to evaluate the assumptions in the simple regression model, with one twist. Rather than creating the scatterplot by plotting the standardized residuals versus the X-value, we will plot them against the FITTED values (i.e., the \\(\\hat{Y}_i\\) values). The fitted values from a multiple regression represent the weighted combination of both predictors, and thus give us the appropriate conditioning when we examine the distributions. (Remember, we want to consider the distribution of residuals at each (\\(X_1\\), \\(X_2\\)) combination.)\nAs an example, we will regress student GPAs on both time spent on homework and parent education levels.\n\n# Fit the multiple regression model\nlm.b = lm(gpa ~ 1 + homework + parent_ed, data = keith)\n\n# Augment the model to obtain the fitted values and residuals\naug_b = augment(lm.b)\nhead(aug_b)\n\n\n\n\n\n\nFigure¬†13.11: LEFT: Density plot of the marginal distribution of standardized residuals from the fitted regression model. RIGHT: Scatterplot of the standardized residuals versus time spent on homework. The \\(Y=0\\), \\(Y=-2\\) and \\(Y=2\\) lines have been included as a references for interpretation.\n\n\n# Density plot of the standardized residuals\np1 = ggplot(data = aug_b, aes(x = .std.resid)) +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n# Plot the standardized residuals versus the fitted values\np2 = ggplot(data = aug_b, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  geom_hline(yintercept = c(-2, 2), linetype = \"dashed\") +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n# Layout plots\np1 | p2\n\n\n\n\nFigure¬†13.12: LEFT: Density plot of the marginal distribution of standardized residuals from the fitted regression model. RIGHT: Scatterplot of the standardized residuals versus time spent on homework. The \\(Y=0\\), \\(Y=-2\\) and \\(Y=2\\) lines have been included as a references for interpretation.\n\n\n\n\nThe density plot of the marginal distribution of standardized residuals is unimodal and roughly symmetric. There is deviation from normality, although this deviation seems minor and we note that the assumption of normality is robust to minor violations. The scatterplot shows random scatter around the \\(Y=0\\) line which indicates that the mean residual value is close to 0 (linearity) for all fitted values. The range of the standardized residuals at each fitted value also seem roughly the same indicating that the equal variances assumption is also tenable. Lastly, since the observations were randomly sampled we believe the independence assumption is satisfied.\nIf any of the assumptions (aside from the independence assumption) do not seem reasonably satisfied, you can re-plot the residual plots based on the different simple regression models. (In this case we would look at the residuals versus time spent on homework and then the residuals versus parent education). This might help you identify if one, or both. of the predictors is the cause of the problem.\nThe reference lines in the scatterplot at \\(Y=-2\\) and \\(Y=2\\) help us identify observations with extreme residuals. (For large sample sizes these reference lines can be placed at \\(Y=-3\\) and \\(Y=3\\).) There are a few observations that have residuals that are more than two standard errors from the mean. This indicates students that have relatively high (positive residual) or low (negative residual) GPAs given the time they spend each week on homework and their parent education level."
  },
  {
    "objectID": "03-03-assumptions.html#regression-model-revisited",
    "href": "03-03-assumptions.html#regression-model-revisited",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.6 Regression Model Revisited",
    "text": "13.6 Regression Model Revisited\nTo this point, we have been writing the regression model as a mathematical expression of the relationship between some outcome (\\(Y\\)) and a set of predictors (\\(X_1,X_2,\\ldots,X_k\\)), namely as,\n\\[\nY_i = \\beta_0 + \\beta_1(X_{1i}) + \\beta_2(X_{2i}) + \\ldots + \\beta_k(X_{ki}) + \\epsilon_i\n\\]\nThis is partially correct. A statistical model needs to represent the data generating process, which also embodies the set of underlying distributional assumptions. This implies that when we write out the regression model, it should include the mathematical relationship and the underlying distributional assumptions.\n\\[\n\\begin{gathered}\nY_i = \\beta_0 + \\beta_1(X_{1i}) + \\beta_2(X_{2i}) + \\ldots + \\beta_k(X_{ki}) + \\epsilon_i \\\\[2ex]\n\\mathrm{where}~\\quad\\epsilon_{i|X} \\overset{\\mathrm{i.i.d~}}{\\sim}  \\mathcal{N}\\left(0, \\sigma^2\\right)\n\\end{gathered}\n\\]"
  },
  {
    "objectID": "03-03-assumptions.html#advanced-plotting-accounting-for-sampling-uncertainty-in-the-density-plot",
    "href": "03-03-assumptions.html#advanced-plotting-accounting-for-sampling-uncertainty-in-the-density-plot",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.7 Advanced Plotting: Accounting for Sampling Uncertainty in the Density Plot",
    "text": "13.7 Advanced Plotting: Accounting for Sampling Uncertainty in the Density Plot\nSo far, when we have evaluated the normality assumption we have relied on our intuition (and experience) about whether the density plot of the marginal distribution of residuals was close to (or at least close enough to) normal. One thing we could do to help with this evaluation is to include a reference line showing normality as a basis of comparison. For example, here we again plot the marginal distribution of the standardized residuals from the fitted multiple regression. But this time, we also include the normal reference density.\n\n# Density plot of the standardized residuals\nggplot(data = aug_b, aes(x = .std.resid)) +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = \"black\", linetype = \"dashed\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n\n\n\nFigure¬†13.13: Density plot of the marginal distribution of standardized residuals from the fitted regression model (raspberry, solid line). The density for a ~N(0,1) distribution (black, dashed line) have been included as a comparative reference.\n\n\n\n\nThe stat_function() layer uses the dnorm() function to plot the normal density. Since this is for the standardized residuals, we assume a mean of 0 and a standard deviation of 1 for this normal distribution. These parameters are included in the args=list() argument. The density of the standardized residuals is close to that for the normal distribution, although it is not perfect (e.g., flatter peak than normal). The big question is whether this deviation is more than we would expect because of sampling error?\nTo answer this question, we need to be able to visualize the uncertainty that is due to sampling error. To include\n\n\n\n\n\nFigure¬†13.14: The density for a ~N(0,1) distribution (black, dashed line) and the sampling uncertainty associated with that normal distribution (blue shaded area).\n\n\n\n\nIn this plot, the black, dashed line corresponds to where the density curve would lie if the distribution was normally distributed. The blue shaded area is the confidence envelope for the normal distribution. In other words, it shows the area we would expect a density curve to lie in if it came from the normal distribution.\nTo create this confidence envelope, we will use the stat_density_confidence() layer from the {educate} package (see below for instructions on how to install the {educate} package). We provide this layer the argument model=\"normal\".\n\n# Load library\nlibrary(educate)\n\n# Density plot of the standardized residuals\nggplot(data = aug_b, aes(x = .std.resid)) +\n  stat_density_confidence(model = \"normal\") +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n\n\n\nFigure¬†13.15: Density plot of the marginal distribution of standardized residuals from the fitted regression model (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area).\n\n\n\n\nThe raspberry line depicting the density of the marginal distribution of standardized residuals lies completely within the blue area. This suggests that the deviation we saw earlier from the normal distribution is consistent with just being sampling error. Thus we conclude that the normality assumption is tenable.\n\n\n13.7.1 Installing the educate Package\nThe {educate} package is not available on CRAN, thus you cannot install it using the Install button in RStudio. To install this package, we need to use the install_github() function from the {remotes} package.\n\nUse the Install button in RStudio to install the remotes package.\nOnce the {remotes} package has successfully installed, use the following syntax to install the {educate} package:\n\n\nremotes::install_github(\"zief0002/educate\")"
  },
  {
    "objectID": "03-03-assumptions.html#advanced-plotting-loess-smooth-to-help-evaluate-linearity",
    "href": "03-03-assumptions.html#advanced-plotting-loess-smooth-to-help-evaluate-linearity",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.8 Advanced Plotting: Loess Smooth to Help Evaluate Linearity",
    "text": "13.8 Advanced Plotting: Loess Smooth to Help Evaluate Linearity\nIn the scatterplot of the standardized residuals versus the fitted values, if the assumption of ‚Äúlinearity‚Äù is tenable, we would expect that the average value of the residual at a given fitted value would be 0‚Äîwithin sampling error. Because the fitted values and the residuals (or standardized residuals) are independent a fitted regression line in this plot would be at \\(Y=0\\). We can use the geom_smooth() function with the argument method=\"lm\" to include this line The argument se=TRUE in this function will also add the confidence envelope.\n\nggplot(data = aug_b, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) + #ADD Line and confidence envelope\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n\n\n\nFigure¬†13.16: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption.‚Äù\n\n\n\n\nThe confidence envelope shows us how much variation we might expect from the line \\(Y=0\\) because of sampling error.\nThe second thing we want to add to the plot is the loess smoother. This smoother helps us visualize the mean pattern in the actual data. To do this we will add a second geom_smooth() function with the arguments method=\"loess\" and se=TRUE. This will include the loess smoother without a confidence envelope around it.\n\nggplot(data = aug_b, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) + #ADD Line and confidence envelope\n  geom_smooth(method = \"loess\", se = FALSE) + #ADD loess smoother\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n\n\n\nFigure¬†13.17: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption. The loess line (blue) and uncertainty bands (grey shaded area) are also displayed.\n\n\n\n\nWe can then evaluate if the loess smoother is encompassed inside the confidence envelope of what is expected if the assumption that the average residual is equal to 0 is actually met. In Figure¬†13.17 the plot suggests the assumption of ‚Äúlinearity‚Äùis tenable‚Äîthe loess smoother does not deviate from inside the confidence envelope."
  },
  {
    "objectID": "03-03-assumptions.html#advanced-plotting-identify-observations-with-extreme-residuals",
    "href": "03-03-assumptions.html#advanced-plotting-identify-observations-with-extreme-residuals",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "13.9 Advanced Plotting: Identify Observations with Extreme Residuals",
    "text": "13.9 Advanced Plotting: Identify Observations with Extreme Residuals\nIt can be useful to identify particular observations in the residual plots directly. This can be useful as you explore the plots, and also to create plots for publications in which you wish to highlight particular cases. Rather than plotting points (geom_point()) for each observation, we can plot text for each observation using geom_text(). For example, you might imagine writing the name of each student in place of their point on the scatterplot. To do this, we need to:\n\nCreate an ID variable in the augmented data.\nUse geom_text() rather than geom_point() in the ggplot syntax. In the geom_text() function we will set label= to the newly created ID variable, and since it is a variable in the data set, we will put that in an aes() function.\n\nSince the original data set does not include an ID variable (e.g., names), we will use the row number from the original data as the ID. In other words the student in the first row will have an ID of 1, the student in the second row will have an ID of 2, etc.\n\n# Create ID variable in the augmented data\naug_b = aug_b |&gt; \n  mutate(id = row.names(keith))\n\n# View new data\nhead(aug_b)\n\n\n\n\n\n\nFigure¬†13.18: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. The values plotted indicate the students‚Äô row numbers in the data. A horizontal line at \\(Y=0\\) is included to aid interpretation.\n\n\n# Plot the id variable as text rather than points in the scatterplot\nggplot(data = aug_b, aes(x = .fitted, y = .std.resid)) +\n  geom_text(aes(label = id), size = 4) +\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  geom_hline(yintercept = -2, linetype = \"dotted\") +\n  geom_hline(yintercept = 2, linetype = \"dotted\") +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residuals\")\n\n\n\n\nFigure¬†13.19: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. The values plotted indicate the students‚Äô row numbers in the data. A horizontal line at \\(Y=0\\) is included to aid interpretation.\n\n\n\n\nWe can also plot points for some students and ID label for other students. For example, suppose we wanted to give the ID number for only those students with a standardized residual that was less than \\(-2\\) or greater than 2, and plot a point otherwise. To do this, we would create the ID variable in the augmented data (which we have already done), then split the data frame into two data frames: one for those students with extreme residuals and one for those that have a non-extreme residual. Then we will call geom_point() for those in the non-extreme data set, and geom_text() for those in the extreme set. We do this by including a data= argument in one of those functions to reference a different data frame.\n\n# Create different data sets for the extreme and non-extreme observations\nextreme = aug_b |&gt; \n  filter(.std.resid &lt;= -2 | .std.resid &gt;= 2)\n\nnonextreme = aug_b |&gt; \n  filter(.std.resid &gt; -2 & .std.resid &lt; 2)\n\n# Plot using text for the extreme observations and points for the non-extreme\nggplot(data = extreme, aes(x = .fitted, y = .std.resid)) +\n  geom_text(aes(label = id), size = 4, color = \"red\") +\n  geom_point(data = nonextreme) +\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n\n\n\nFigure¬†13.20: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. Students with standardized residuals more than two standard errors from 0 are identified by their row number. A horizontal line at \\(Y=0\\) is included to aid interpretation."
  },
  {
    "objectID": "03-03-assumptions.html#footnotes",
    "href": "03-03-assumptions.html#footnotes",
    "title": "13¬† Distributional Assumptions Underlying the Regression Model",
    "section": "",
    "text": "This is true for other statistical models as well (e.g., ANOVA, t-test).‚Ü©Ô∏é\nWe cover some of these methods in EPsy 8252.‚Ü©Ô∏é\nWe will cover some of those transformations in EPsy 8252.‚Ü©Ô∏é\nAgain, there are many transformations of the data that can alleviate this problem.‚Ü©Ô∏é\nTechnically they are internally studentized residuals.‚Ü©Ô∏é"
  }
]