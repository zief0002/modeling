[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "",
    "text": "Front Matter\nThe content in this ‚Äúbook‚Äù, as the title suggests, is related to statistical modeling and computation. More specifically, the content focuses on using the General Linear Model (GLM) to provide statistical evidence that can help answer substantive questions in the educational and social sciences. It is a book intended for applied practitioners in the educational or social sciences. The statistical content is hopefully presented in a manner that these domain scientists will find useful, including practical suggestions for analysis and the presentation of results intended to help researchers clearly communicate the results of a data analysis.\nWhile the content is not overly mathematical in nature, the reader will need a solid understanding of the principles in algebra for maximum benefit. The burden of calculation that typically accompanied statistical work in previous generations is now primarily carried out in a scientific computing environment. As Thisted & Velleman (1992) point out, ‚Äúcomputational advances have changed the face of statistical practice by transforming what we do and by challenging how we think about scientific problems.‚Äù To support and help facilitate the use of scientific computing, examples using the R computer language will be used throughout this work.\nThe organization of content is consistent with the sequence this content is taught in EPsy 8251, the first of two applied statistics courses that form the foundational sequence for many graduate students in the educational and social sciences at the University of Minnesota. This course require that students have taken a previous statistics course at either the undergraduate or graduate level. Because of that, many introductory ideas are assumed.",
    "crumbs": [
      "Front Matter"
    ]
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "Resources",
    "text": "Resources\nThis book refers to and uses several data sets throughout the text. Each of these data sets and their codebooks are available online at the book‚Äôs github repository, https://github.com/zief0002/modeling/.",
    "crumbs": [
      "Front Matter"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nMany thanks to all the students in my courses who have been through previous iterations of this material. Your feedback has been invaluable, and you are the world‚Äôs greatest copyeditors. In particular, I would like to thank the following students who have gone above and beyond in the feedback they have provided: Jonathan Brown, Pablo Vivas Corrales, Amaniel Mrutu, Corissa Rohloff, and Mireya Smith.",
    "crumbs": [
      "Front Matter"
    ]
  },
  {
    "objectID": "index.html#colophon",
    "href": "index.html#colophon",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "Colophon",
    "text": "Colophon\nArtwork by @allison_horst\nIcon and note ideas and prototypes by Desir√©e De Leon.\nThe book is typeset using Crimson Text for the body font, Raleway for the headings and Sue Ellen Francisco for the title. The color palette was generated using coolors.co.\nStatistical Computing\n\nLaptop icon made by Tomas Knop from www.flaticon.com\nDirectory icon made by Darius Dan from www.flaticon.com\nBrain icon made by Aranagraphics from www.flaticon.com\nInternet icon made by Freepik from www.flaticon.com",
    "crumbs": [
      "Front Matter"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Statistical Modeling and Computation for Educational Scientists",
    "section": "License",
    "text": "License\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.\nNote: If you want to contribute to this, create a Pull Request or send me an email.) Also, feel free to offer criticism, suggestion, and feedback. You can either open an issue on the book‚Äôs github page or send me an email directly.\n\n\n\n\nThisted, R. A., & Velleman, P. F. (1992). Computers and modern statistics. In D. C. Hoaglin & D. S. Moore (Eds.), Perspectives on contemporary statistics, MAA notes no. 21 (pp. 41‚Äì53). Mathematical Association of America.",
    "crumbs": [
      "Front Matter"
    ]
  },
  {
    "objectID": "01-00-statistical-computation.html#footnotes",
    "href": "01-00-statistical-computation.html#footnotes",
    "title": "Introduction to Statistical Computation",
    "section": "",
    "text": "Specifically, RStudio is branded as an ‚Äúintegrated development environment (IDE) [that] includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management.‚Äù‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Statistical Computation"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html",
    "href": "01-01-r-and-rstudio-installation.html",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "",
    "text": "1.1 Installing R\nTo install R, navigate your web browser to:\nhttps://www.r-project.org/\nThen,\nThis is where the installation directions diverge depending on your OS.\nMac Instructions\nSo long as you are running MacOS 10.13 or higher just click the first link for the PKG, which will download the installer for the most current version of R (4.1.1 as of August 16, 2021). Once the download completes, open the installer and follow the directions to install R on your computer.\nIf you are running an older version of MacOS, you will have to install an older version of R. You can find these links under the Binaries for legacy OS X systems heading further down the install page. Click the appropriate PKG link for R your version of MacOS. Once the download completes, open the installer and follow the directions to install R on your computer.\nIf you are unsure which version of the MacOS is running on your computer, select About this Mac from the Apple menu in your toolbar.\nWindows Instructions\nClick the link that says Install R for the first time (or click base; they go to the same place). Then click the Download R 4.1.1 for Windows link, which will download the installer for the most current version of R (4.0.2 as of July 24, 2020). Once the download completes, open the installer and follow the directions to install R on your computer.\nLinux Instructions\nIf you are running Linux, you should know how to install things on your computer. üòä",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#installing-r",
    "href": "01-01-r-and-rstudio-installation.html#installing-r",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "",
    "text": "Click the CRAN link under Download on the left-hand side of the page.\nSelect a mirror site. These should all be the same, but I tend to choose the Iowa State University link under USA.1\nIn the Download and Install R box, choose the binary that matches the operating system (OS) for your computer.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#installing-rstudio-desktop",
    "href": "01-01-r-and-rstudio-installation.html#installing-rstudio-desktop",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.2 Installing RStudio Desktop",
    "text": "1.2 Installing RStudio Desktop\nAfter you have installed R, you next need to install RStudio Desktop. To do this, navigate your web browser to:\n\nhttps://rstudio.com/products/rstudio/download/\n\nThen,\n\nSelect the blue Download button under the free, open-source version of RStudio Desktop.\nSelect the installer associated with your computer‚Äôs OS.\nOnce the download completes, open the installer and follow the directions to install RStudio Desktop on your computer.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#checking-that-things-worked",
    "href": "01-01-r-and-rstudio-installation.html#checking-that-things-worked",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.3 Checking that Things Worked",
    "text": "1.3 Checking that Things Worked\nFrom your Applications or Programs folder, open RStudio. If you have successfully downloaded both programs, this should open the application and you should see a message indicating that you are using ‚ÄúR version 4.1.1‚Äù (or whichever version of R you installed) in the console pane.\n\n\n\n\n\nOnce you open RStudio, you should see a message indicating that you are using R version 4.1.1 (or whichever version of R you installed) in the console pane. Here the console pane is on the left-side, but it may be in a different location for you. Your RStudio may also have a white background rather than the black background seen here.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#customizing-rstudio",
    "href": "01-01-r-and-rstudio-installation.html#customizing-rstudio",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.4 Customizing RStudio",
    "text": "1.4 Customizing RStudio\nWhile the information in this section is not crucial for making things work, it is useful to get RStudio looking good and setting some default settings. Open the Tools &gt; Options menu (Windows) or RStudio &gt; Preferences (Mac).\n\n\n\n\n\nThe RStudio options/preferences menu has many settings to customize RStudio.\n\n\n\n\n\nIn the General &gt; Basic settings, change the option on Save workspace to .Rdata on exit to be ‚ÄúNever‚Äù. Click the ‚ÄúApply‚Äù button.\nIn the Appearance settings, customize the look of RStudio to something aesthetically appealing to you. When you are finished, click the ‚ÄúApply‚Äù button.\nThere are also options you can set in the Accessibility settings if you use a screen reader. If you change anything, don‚Äôt forget to click the ‚ÄúApply‚Äù button.\n\nWhen you are finished customizing RStudio, click the ‚ÄúOK‚Äù button.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#install-rtoolscommand-line-tools",
    "href": "01-01-r-and-rstudio-installation.html#install-rtoolscommand-line-tools",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.5 Install Rtools/Command Line Tools",
    "text": "1.5 Install Rtools/Command Line Tools\nYou may need to install some additional functionality to your system in order to get certain packages to install or load properly. On a Windows machine, you might need to install Rtools. Mac users might need to add the Command Line Tools. These tools also allow you to write and compile your own R packages. RStudio has well written instructions for adding these tools at: https://support.rstudio.com/hc/en-us/articles/200486498-Package-Development-Prerequisites.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#footnotes",
    "href": "01-01-r-and-rstudio-installation.html#footnotes",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "",
    "text": "When internet used to be dial-up (i.e., super slow), you wanted to choose a mirror site that was closest in proximity to your location as it sped up the download. This is less of a concern now that internet download speeds are much faster.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html",
    "href": "01-02-getting-started-with-r.html",
    "title": "2¬† Getting Started with R",
    "section": "",
    "text": "2.1 Computing in the Console\nOne method of computing in RStudio is to run syntax directly in the RStudio console pane. Computing in the console is similar to working with a calculator: you enter syntax and R runs the syntax. Then it forgets what you entered and is ready for the next bit of syntax.\nThe &gt; symbol in the console pane is called the ‚ÄúR prompt‚Äù and is prompting you to enter syntax. After you enter any syntax, you hit the  or  key to execute the syntax.\nThe console pane in RStudio is one way to compute with R. Syntax is entered at the R prompt and executed by hitting the  or  key.\nTo get started, we will have R carry out some arithmetic. At the prompt enter each of the following lines of syntax. After each line, hit the &lt;return&gt; or &lt;enter&gt; key.\n# Addition\n2 + 3\n\n# Subtraction\n6 - 10\n\n# Multiplication\n4 * 5\n\n# Division\n23 / 2\n\n# Exponents\n10 ^ 3\nExecuting each line of syntax returns the results of the computation in the console pane. The result, in R parlance, is referred to as a ‚Äúreturned value‚Äù. After executing the computation, the R prompt reappears and you can issue a new line of syntax.\nContinuation Prompt: At some point in your computational career, you will likely encounter the continuation prompt. Symbolized by +, this prompt appears instead of the R prompt to indicate that you did not complete the syntax you entered prior to hitting the  key. For example, suppose while entering the division syntax from above you got excited and hit the &lt;enter&gt; key after inputting the slash; before inputting the 2. You would see the continuation prompt:\nThe continuation prompt tells you that the syntax you started to enter is still active. If you now enter 2 and hit the &lt;enter&gt; key, the syntax will be executed as if you had not inadvertently hit &lt;enter&gt; in the middle of the computation. If you are in the middle of a more complex piece of syntax, you could also hit the &lt;esc&gt; key until the R prompt is re-shown. Then you can start the computation over.\nSpace in Syntax: For the computation in R, space is irrelevant. For example, each of the following syntactical statements is equivalent:\n4 * 5\n4*5\n4    *            5\nThat being said, well-written code includes space! Space in code makes it easier to read and debug, in the same way that including space in written prose helps us read and parse words, sentences, and paragraphs.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#computing-in-the-console",
    "href": "01-02-getting-started-with-r.html#computing-in-the-console",
    "title": "2¬† Getting Started with R",
    "section": "",
    "text": "&gt; 23 /\n+",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#script-files-recording-your-syntax",
    "href": "01-02-getting-started-with-r.html#script-files-recording-your-syntax",
    "title": "2¬† Getting Started with R",
    "section": "2.2 Script Files: Recording Your Syntax",
    "text": "2.2 Script Files: Recording Your Syntax\nA second method of computing in RStudio is to use a script file. Using a script file allows a recording of the syntax you use. This acts as a way of ‚Äúsaving‚Äù your work, and it also acts as a record of the analysis for your collaborators in the spirit of reproducible work. You can create a new script file by selecting File &gt; New File &gt; R Script from the RStudio menu bar. You can also obtain a new R script by clicking the New File icon (document with the plus-sign) on the tool bar and selecting R Script. (This should open the script file in a new RStudio pane!)\n\n\n\n\n\nLEFT: Create a new script file using RStudio‚Äôs File menu. RIGHT: Create a new script file by clicking on the New File icon in the toolbar.\n\n\n\n\nScript files should only include your R syntax and comments. Script files should NOT include:\n\nprompts (&gt;)\noutput\n\nComments, which are human-readable annotations or explanations of the syntax, are written using the hashtag (#). These can be placed on their own line in the script file, or can be placed at the end of a line with syntax. The comment continues until you hit the  key. Comments help other people understand your syntax and also act as a reminder for the future you of what your code actually does. Get is the habit of including comments in your syntax. Not only is it good coding practice, but it also will help you become familiar with and learn the R syntax as you describe the purpose of the syntax you are writing.\n\n\n\n\n\nExample script file with comments.\n\n\n\n\nScript files can be saved and opened the same as any other document. So, no more worrying about losing your work or objects that you created when you close your R session. Enter the computations you previously ran in the console into your script file. (Note: When you hit &lt;enter&gt; in the script file, the cursor moves to a new line, but doesn‚Äôt execute the computation like it did in the console.) Save the script file to your computer (it should have a .R file suffix).\n\n\n2.2.1 Executing Syntax from a Script File\nNot only does the script file record your syntax, but it can also act as the vehicle from which you run your R syntax. Syntax in the script file can be executed by highlighting it and pressing the Run button in the toolbar. You can run one line at a time, or highlight multiple lines and execute all of them sequentially.\n\n\n\n\n\nTo execute syntax from the script file, highlight the syntax you want to run and then click the Run button in the toolbar.\n\n\n\n\nWriting syntax directly in the script file and running it is a groovy workflow for using R. Writing syntax directly in the script file also saves you from having to copy-and-paste syntax you want to save from the console. In my own work, I use this workflow almost daily.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#functions-the-workhorse-of-r",
    "href": "01-02-getting-started-with-r.html#functions-the-workhorse-of-r",
    "title": "2¬† Getting Started with R",
    "section": "2.3 Functions: The Workhorse of R",
    "text": "2.3 Functions: The Workhorse of R\nAlmost all commands in R are built around the use of a function. Functions carry out operations on their inputs (called arguments) and produce an output (called a returned value).\n\n\n\n\n\nLEFT: Arguments are inputted into a function which returns an output. RIGHT: The value 25 is inputted into the square root function which returns the value of 5.\n\n\n\n\nThe syntax for using most functions in R follows a simple structure: The name of the function is followed by a pair of parentheses. Argument values (inputs) are specified inside the parentheses. In general,\n\nfunction_name(argument)\n\nBelow are several example of this structure for some common mathematical functions.\n\n#Square root\nsqrt(100)\n\n[1] 10\n\n#Absolute value\nabs(-23)\n\n[1] 23\n\n#Factorial\nfactorial(5)\n\n[1] 120\n\n\nFunctions can take multiple arguments (inputs). If there is more than one argument, the arguments are always separated by a comma.\n\nfunction_name(argument_1, argument_2, ...)\n\nFor example, the seq() function creates a sequence of values that have a particular start and end value.\n\nseq(1, 5)\n\n[1] 1 2 3 4 5\n\n\nNote that the order of the arguments matters! Reversing the order of the arguments inputted to the seq() function returns different output.\n\nseq(5, 1)\n\n[1] 5 4 3 2 1\n\n\nEach of the arguments actually has a name, and if those names are used to assign the values we are inputting to the function, then the order of the arguments is irrelevant.\n\n# Named arguments\nseq(from = 1, to = 5)\n\n[1] 1 2 3 4 5\n\n# Order no longer matters\nseq(to = 5, from = 1)\n\n[1] 1 2 3 4 5\n\n\nIt is a good habit to use named arguments when you are writing your syntax. It makes the code more readable and easier to adapt if you come back to it later. Sometimes when the initial argument of a function is well-established, that first argument is left unnamed, but all other arguments used are named. A good example of this is the use of the lm() function in which the initial formula= argument is typically unnamed, but other arguments (e.g., data=) are named.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#connecting-computations",
    "href": "01-02-getting-started-with-r.html#connecting-computations",
    "title": "2¬† Getting Started with R",
    "section": "2.4 Connecting Computations",
    "text": "2.4 Connecting Computations\nOne powerful aspect of computing is that the output from a function can be used as input into another function. This is akin to calculations you may have encountered in mathematics course like algebra. For example,\n\\[\n\\sqrt{\\log(100)}\n\\]\nIn carrying out this calculation, you would first compute the logarithm of 100 and then take the square root of that result. Using function notation, your algebra teacher might have written\n\\[\ng(~f(x)~)\n\\]\nwhere \\(f(x)\\) is the logarithm function and \\(g(x)\\) is the square root function. Regardless of how we express this,the idea is that the output of the logarithm function is used as input to the square root function. Using R, there are two primary ways to connect computations in this manner: chaining and assignment.\n\n\n2.4.1 Chaining\nChaining is a direct reflection of the functional notation \\(g(~f(x)~)\\) in that you embed one computation directly in another. For example, to find the absolute value of all the integers between \\(-5\\) and \\(-1\\), we can chain the abs() function and the seq() functions:\n\nabs( seq(from = -5, to = -1) )\n\n[1] 5 4 3 2 1\n\n\nNote here that the output/returned value is not a single value, but five values. The absolute value function was applied to each of the values in the sequence. Compare this to the result from the following chained computations:\n\nmean( seq(from = -5, to = -1) )\n\n[1] -3\n\n\nHere the mean function applied to the sequence of values returns a single value as output. When a function is applied to a set of multiple values (i.e., a vector), some functions will apply their computations separately on each element/value (element-wise computation returns multiple values), while others will apply the computation to the set of elements as a whole (vector-wise computation returns a single value). Most of the time it will be clear from the function name or description whether the output returns a single value or multiple values.\nWe can chain as many computations together as we would like. For example here we find the square root of the absolute value of all the integers between \\(-5\\) and \\(-1\\).\n\nsqrt( abs( seq(from = -5, to = -1) ) )\n\n[1] 2.236068 2.000000 1.732051 1.414214 1.000000\n\n\n\n\n\n2.4.2 Assignment\nWe can also connect computations through assignment. With assignment, we store the output of a computation by assigning it to a named object. We can then use that named object in another computation. For example, here we first store the integers between \\(-5\\) and \\(-1\\) in an object called chili. Then we find the absolute value of each value by using chili as the argument in the abs() function.\n\n# Assign the sequence to the object chili\nchili = seq(from = -5, to = -1) \n\n# Compute the absolute values\nabs(chili)\n\n[1] 5 4 3 2 1\n\n\nTo view the contents of an object, just print the name of the object. Below, after creating the object sadie, we view its contents.\n\n# Assign values to sadie\nsadie = rep(3, times = 5) \n\n# View contents of sadie\nsadie\n\n[1] 3 3 3 3 3\n\n\nPretty much any name can be used when you create an object, with some caveats: object names cannot begin with a digit nor include hyphens or spaces. Although they are legal object names, chili and sadie are not particularly good object names. Better object names would describe the contents of the object.\nIn my own workflow, I tend to use all lowercase letters in my object names and I use underscores for word breaks. For example,\n\nses, gpa, occupation\nact_math, mothers_educ\n\n\n\n\n2.4.3 Objects in the R Working Environment\nWe can continue to use the objects you created (e.g., chili and sadie) in our computations, so long as the objects remain in our R working environment.\n\n# Sum the pairwise elements of the two objects\nchili + sadie\n\n[1] -2 -1  0  1  2\n\n# Sum all the elements in chili\nsum(chili)\n\n[1] -15\n\n# Product of all the elements in sadie\nprod(sadie)\n\n[1] 243\n\n\nIn RStudio you can see which objects are in your working environment by examining the Environment pane.\n\n\n\n\n\nThe enivironment pane shows the objects in the R working environment. It also displays the object‚Äôs class and gives a preview of the the contents.\n\n\n\n\nNot only does this pane indicate the name of the objects in the working environment, but is also displays each object‚Äôs class. In this case we can tell that chili is an integer vector and sadie is a numeric vector.1 Moreover, we are told that each vector includes five elements, shown in the environment pane as [1:5]. Lastly, we are given a preview of each object‚Äôs contents. Since these vectors only contain five elements, we see all the values in the preview.\nYou can also use syntax to obtain a list of objects that are in your working environment using the ls() function with no arguments.\n\n# List the objects in working environment\nls()\n\n[1] \"chili\" \"sadie\"\n\n\nWhen an object name is re-used, the previous value of the object is lost.\n\n# Assign the values 1 to 10 in chili\nchili = seq(from = 1, to = 10)\n\nAfter assigning new values to chili, we can see the information in the environment pane has been updated to reflect the new contents of the object.\n\n\n\n\n\nThe object chili although still an integer vector, now includes 10 elements.\n\n\n\n\nAny computations carried out with chili will use the new object.\n\n# Sum all the elements in chili\nsum(chili)\n\n[1] 55\n\n\nIf you want the previous version of chili you need to re-create the object. If you close your R session all of the objects you created will be lost.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#installing-and-loading-r-packages",
    "href": "01-02-getting-started-with-r.html#installing-and-loading-r-packages",
    "title": "2¬† Getting Started with R",
    "section": "2.5 Installing and Loading R Packages",
    "text": "2.5 Installing and Loading R Packages\nEvery R function is housed in a package. To use the functions in a particular package, the package needs to be (1) installed, and (2) loaded into memory.\n\n\n\n\n\nPackages need to be installed and loaded.\n\n\n\n\nYou can see the packages (and which version of each package) are installed by examining the Packages tab in RStudio. Every package listed there has been installed. You will also be able to see the version number of the package that is installed. Some of those packages may be checked. These are the packages that are also loaded into memory.\n\n\n\n\n\nThe packages tab shows which packages are installed. The list of packages you have installed will likely be different. Checked packages are loaded into memory. In the packages seen here, only the base package is loaded into memory.\n\n\n\n\nTwenty-nine packages were included when you installed R on your computer. When you start an R session by opening RStudio, some of those packages are also loaded into memory.\n\n\n\n\n\nThe 29 packages installed as part of R. The base, datasets, graphics, grDevices, methods, stats, and utils packages are loaded into memory when you start an R session. The other 22 packages are installed but not loaded into memory.\n\n\n\n\n\n\n2.5.1 Loading Packages into Memory\nTo load a package that is installed, you use the library() function and include the name of the package you want to load in as the sole argument. For example, to load the {splines} package, use the following syntax:\n\n# Load splines package\nlibrary(splines)\n\nSome packages requires other packages (dependencies) to work. For example, the {lme4} package is dependent on the {Matrix} package. When you load packages that have dependencies, R will also load the dependencies (assuming you have them installed). When it does this, a message will be printed after you execute library(). For example, here is what happens when we load the {lme4} package.\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\n\n\nOnce the package is loaded, all of the functions, data sets, etc. in that package are available to you. Packages will need to be loaded every time you launch a new R session.\n\n\n\n2.5.1.1 Masked Objects\nSometimes you will get a message about objects being masked. This is not a problem. It is just informative and means that the package you just loaded has a function that has the exact same name as a previously loaded package. If you use that particular function, the most recently loaded package‚Äôs version of the function will be used. For example, after loading the {dplyr} library the following message is printed:\nAttaching package: ‚Äòdplyr‚Äô\n\nThe following objects are masked from ‚Äòpackage:stats‚Äô:\n\n    filter, lag\n\nThe following objects are masked from ‚Äòpackage:base‚Äô:\n\n    intersect, setdiff, setequal, union\nThis tells me that the {dplyr} package includes six functions that have the same name as functions included in other packages that have already been loaded into memory (two from the {stats} package and four from the {base} package.) Since {dplyr} was the most recently loaded package, if you were to use the filter() function, R would use {dplyr}‚Äôs filter() function rather than that from the {stats} package2.\n\n\n\n2.5.1.2 Error Loading a Package\nOnce in a while, when loading a package, you may get an error. Don‚Äôt panic. There are two errors that are common. The first error you may get indicates that the package did not get installed. For example, if the {ggplot2} package was not installed, trying to use the library() function to load that package would result in an error.\n\nlibrary(ggplot2)\n\nError in library(ggplot2) : there is no package called ‚Äòggplot2‚Äô\nSimply install the package and then re-try loading it.\nThe second error that you might run across when trying to load a package occurs when the installation did not include the package dependencies. For example,\n\nlibrary(odbc)\n\nError: package or namespace load failed for ‚Äòodbc‚Äô in loadNamespace(j &lt;- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\nthere is no package called ‚ÄòRcpp‚Äô\nAgain, don‚Äôt panic! Here the error message is saying that the {Rcpp} package is a dependency and it is not installed. To fix this, install the {Rcpp} package and then try again. (You may need to open a new R session first.) You may need to install more than one dependency, so just keep installing what is missing until it works.\n\n\n\n\n2.5.2 Adding Functionality: Installing Packages\nYou can also install other packages onto your R system. R, in fact, has a repository called CRAN3, that includes 16,000 different packages (as of July 2020). The easiest way to install a package from CRAN onto your computer is to use the Install button in the `Packages tab of RStudio.\nThis will open a pop-up window where you can type the CRAN package you want to install in a text box. Ensure that the ‚ÄúInstall dependencies‚Äù box is checked (this will also install any package dependencies), and then click ‚ÄúInstall‚Äù.\n\n\n\n\n\nPop-up window to install packages. Here we are installing the dplyr package. Note that the ‚ÄòInstall dependencies‚Äô box is checked.\n\n\n\n\nYou may be prompted to choose a nearest mirror. If so, choose a mirror location. If you are successful in installing the package, you will get a message like the following:\nInstalling package into ‚Äò/Users/zief0002/Library/R/4.0/library‚Äô\n(as ‚Äòlib‚Äô is unspecified)\ntrying URL 'https://cran.rstudio.com/bin/macosx/contrib/4.0/dplyr_1.0.0.tgz'\nContent type 'application/x-gzip' length 1209135 bytes (1.2 MB)\n==================================================\ndownloaded 1.2 MB\n\n\nThe downloaded binary packages are in\n    /var/folders/s3/sqlc9xw92w54166w86dgkd000000gr/T//Rtmps80Uf8/downloaded_packages\nThe message you get on Windows may be slightly different, but the key is that there is not an error. Furthermore, you should immediately be able to load the package using the library() function.\nAn equivalent manner of installing a package via syntax is to use the install.packages() function. For example, to install the {dplyr} package we could have used the following syntax:\n\ninstall.packages(\"dplyr\", dependencies = TRUE)\n\nNote that the name of the package is included in quotation marks (it is a character string). The argument dependencies=TRUE installs all package dependencies, similar to checking the ‚ÄúInstall dependencies‚Äù box in the pop-up menu.\n\n\n2.5.2.1 Installing Packages from GitHub\nCRAN is not the only place to get R packages. Many developers add packages to a website called GitHub. Packages hosted on GitHub can be installed using the install_github() function from the {remotes} package.\nFirst, you will need to install the {remotes} package from CRAN and then load it using the library() function. Then, you can use the install_github() function to actually install the package. This function is provided a character string that specifies the user name and GitHub repository for the package, separated by a slash. You can find this in the part of the URL that follows ‚Äúhttps://github.com/‚Äù in your web browser. For example, the URL for the {educate} package is: ‚Äúhttps://github.com/zief0002/educate‚Äù, so to install this we would use:\n\n# Load remotes package\nlibrary(remotes)\n\n# Install dplyr from GitHub\ninstall_github(\"zief0002/educate\")\n\nThe message I get when installing this is\nInstalling package into ‚Äò/Users/zief0002/Library/R/4.0/library‚Äô\n(as ‚Äòlib‚Äô is unspecified)\n* installing *source* package ‚Äòeducate‚Äô ...\n** using staged installation\n** R\n** inst\n** byte-compile and prepare package for lazy loading\n** help\n*** installing help indices\n*** copying figures\n** building package indices\n** installing vignettes\n** testing if installed package can be loaded from temporary location\n** testing if installed package can be loaded from final location\n** testing if installed package keeps a record of temporary installation path\n* DONE (educate)\nThe ‚ÄúDONE‚Äù message typically signified successful installation. Note that you may be prompted to update some packages. If you get this message, choose the option to update ‚ÄúALL‚Äù packages. As with packages installed from CRAN, if things worked you should be able to load the package you just installed using the library() function without any errors.\n\n\n\n\n2.5.3 Install Rtools/Command Line Tools\nYou may need to install some additional functionality to your system in order to get certain packages to install or load properly. On a Windows machine, you might need to install Rtools. Mac users might need to add the Command Line Tools. These tools also allow you to write and compile your own R packages. RStudio has well written instructions for adding these tools at: https://support.rstudio.com/hc/en-us/articles/200486498-Package-Development-Prerequisites.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#additional-resources",
    "href": "01-02-getting-started-with-r.html#additional-resources",
    "title": "2¬† Getting Started with R",
    "section": "2.6 Additional Resources",
    "text": "2.6 Additional Resources\nHere are some additional resources for getting started with R and RStudio.\n\nRStudio Cheatsheets: A set of printable cheatsheets for using some popular R packages.\nRStudio Keyboard Shortcuts: A set of keyboard shortcuts for working with RStudio. The information here is also available in the RStudio IDE under the Tools menu: Tools ‚Üí Keyboard Shortcuts Help.\nR Cookbook: This book is full of how-to recipes, each of which solves a specific problem. The recipe includes a quick introduction to the solution followed by a discussion that aims to unpack the solution and give you some insight into how it works.\nTeacups, Giraffes, and Statistics: Learn statistics & R coding through a series of modules that teach in an intuitive, playful, and approachable way",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#footnotes",
    "href": "01-02-getting-started-with-r.html#footnotes",
    "title": "2¬† Getting Started with R",
    "section": "",
    "text": "The difference between the two classes is technical and related to how R internally stores the information in the vector.‚Ü©Ô∏é\nIf you really wanted to use the filter() function from the {stats} package you could specify this in the syntax using the :: operator, stats::filter(). This operator also allows you to use a function without loading the package with the library() function.‚Ü©Ô∏é\n‚ÄúCRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R.‚Äù‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html",
    "href": "01-03-data-structures-in-r.html",
    "title": "3¬† Data Structures in R",
    "section": "",
    "text": "3.1 Vectors\nVectors (the single-column bookcases in our metaphor) are perhaps the most common data structure you will encounter in R. In fact, even the data frame is composed of vectors; each column is a vector. There are many ways to create a vector in R, in fact you have already been introduced to a couple of them: seq() and rep(). These are useful to create sequences of values and vectors with repeated values, respectively. But what if you wanted to create the vector of the Spice Girls‚Äô ages when the band was formed in 1994 (the values in the second column in the picture above)?\nTo create a vector of these ages, we can use the c() function to input each of the five ages. Within this function, each age is separated by a comma‚Äîeach input is a separate argument to the c() function. We will also assign this to an object called age.\n# Create age vector\nage = c(19, 20, 18, 22, 20)\n\n# View vector\nage\n\n[1] 19 20 18 22 20\nNote that once we assign create age it shows up in our global environment. In the technical language of R, each age is an element of the vector. All of the elements in the age vector are numeric values. This is the vector‚Äôs type.3 Lastly, there are five elements in the vector.\nOnce you have created a numeric vector, you can compute on it. For example in the syntax below we compute the mean age, the standard deviation of the ages, and count the elements in the vector.\n# Compute mean\nmean(age)\n\n[1] 19.8\n\n# Compute standard deviation\nsd(age)\n\n[1] 1.48324\n\n# Count elements\nlength(age)\n\n[1] 5",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#vectors",
    "href": "01-03-data-structures-in-r.html#vectors",
    "title": "3¬† Data Structures in R",
    "section": "",
    "text": "3.1.1 Logical Vectors\nAnother common vector type you will encounter is the logical vector. Each element in a logical vector is either TRUE or FALSE (all uppercase letters). You could use the c() function to create a logical vector. For example, to create the original_member vector we could use the following syntax:\n\n# Create logical vector\noriginal_member = c(TRUE, TRUE, FALSE, TRUE, FALSE)\n\n# View vector\noriginal_member\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE\n\n\nIt is more common to create logical vectors through computation using logical operators. For example we might ask which elements of the age object are greater than 20.\n\n# Which elements of age &gt; 20\nage &gt; 20\n\n[1] FALSE FALSE FALSE  TRUE FALSE\n\n\nThe result of using the logical operator &gt; is a logical vector. There are several logical operators in addition to &gt;:\n\n# greater than or equal to 20\nage &gt;= 20\n\n[1] FALSE  TRUE FALSE  TRUE  TRUE\n\n# less than 20\nage &lt; 20\n\n[1]  TRUE FALSE  TRUE FALSE FALSE\n\n# less than or equal to 20\nage &lt;= 20\n\n[1]  TRUE  TRUE  TRUE FALSE  TRUE\n\n# equal to 20\nage == 20\n\n[1] FALSE  TRUE FALSE FALSE  TRUE\n\n# not equal to 20\nage != 20\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\n\nNote that the logical operator for ‚Äúequal to‚Äù is two equals signs. This is because = (one equal sign) is what we use for assignment . If you wrote age=20 you would be assigning the value 20 to age, not asking whether the elements in age are equal to 20!\nLogical elements have numeric values associated with them, namely,\n\nFALSE = 0; and\nTRUE = 1.\n\nThis means we can apply computations to a logical vector. For example, we could count the number of Spice Girls that were original members by summing the logical values in the original_members object. (Since all FALSE values are 0, this amounts to counting the number of TRUE values.)\n\n# Count original members\nsum(original_member)\n\n[1] 3\n\n\nWe could also count the number of Spice Girls who are under the age of 20.\n\n# Count members with age &lt; 20\nsum(age &lt; 20)\n\n[1] 2\n\n\n\n\n\n3.1.2 Character Vectors\nA third type of vector you will work with is a character vector. Character vectors (a.k.a., strings, literals) are vectors in which each element is a string of characters delimited by quotation marks. For example, the Spice names column is a character vector. We can again create this vector using the c() function.\n\n# Create character vector\nspice = c(\"Scary\", \"Sporty\", \"Baby\", \"Ginger\", \"Posh\")\n\n# View vector\nspice\n\n[1] \"Scary\"  \"Sporty\" \"Baby\"   \"Ginger\" \"Posh\"  \n\n\nMany computations that worked on numeric vectors do not work on character vectors. These will often return an error or unexpected result. In the syntax below, for example, we are told that the mean() function expects a numeric or logical vector, and since what we used was not either of those, the result returned was NA.\n\n# Find mean name\nmean(spice)\n\nWarning in mean.default(spice): argument is not numeric or logical: returning\nNA\n\n\n[1] NA\n\n\nSome computations work the same way.\n\n# Count the number of elements\nlength(spice)\n\n[1] 5",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#data-frames",
    "href": "01-03-data-structures-in-r.html#data-frames",
    "title": "3¬† Data Structures in R",
    "section": "3.2 Data Frames",
    "text": "3.2 Data Frames\nData frames (the multi-column bookcases in our metaphor) are a more complex data structures than vectors. There are again, multiple ways to create a data frame in R. We will examine two methods for creating a data frame: using the data.frame() function and importing data from a spreadsheet or CSV file.\nTo create a data frame from scratch, using R, we can use the data.frame() function. Each argument to this function is a named vector that will correspond to a column within the data frame, and each argument (vector) is separated by commas. For example, to create the Spice Girls data frame from our example, we could use the following syntax:\n\n# Create data frame\nspice_girls = data.frame(\n  spice = c(\"Scary\", \"Sporty\", \"Baby\", \"Ginger\", \"Posh\"),\n  age = c(19, 20, 18, 22, 20),\n  original_member = c(TRUE, TRUE, FALSE, TRUE, FALSE),\n  solo_nominations = c(4, 26, 14, 13, 12),\n  real_name = c(\"Mel B\", \"Mel C\", \"Emma\", \"Geri\", \"Victoria\")\n)\n\n# View data frame\nspice_girls\n\n\n  \n\n\n\nNote that we also assigned the data frame to an object called spice_girls so we can compute on it. You will learn how to compute on data frames in the chapters Data Wrangling with dplyr and Visualizing Data with ggplot2.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#importing-data-from-a-csv-file",
    "href": "01-03-data-structures-in-r.html#importing-data-from-a-csv-file",
    "title": "3¬† Data Structures in R",
    "section": "3.3 Importing Data From a CSV File",
    "text": "3.3 Importing Data From a CSV File\nIn professional practice, you will often enter data into a spreadsheet and rather than typing it into R. When you save this work, many spreadsheet programs use a proprietary format for saving the information (e.g., Excel saves as a XLSX file; Google Sheets saves as a GSHEET file). These often include extraneous information (e.g., formatting) that is irrelevant to the raw data. While R includes libraries and functions that can import data in the XLSX and GSHEETS formats, it is generally easier to save or export your data to a CSV (comma separated value) file from within your spreadsheet program prior to importing it into R.\n\n\n\n\n\n\n\n\n\n\nHere are some tips for entering data into a spreadsheet:\n\nThe first row should be the variable names. Do not use spaces in variable names.\nCharacter strings should be entered without quotation marks in a spreadsheet.\nIf you have missing data, leave the cell blank.\n\nFor more tips on entering data, see Broman & Woo (2018).\n\nOnce your data are saved as a CSV file, it can be easily imported into R. To do so,\n\nClick the Import Dataset button under the Environment tab in RStudio and choose ‚ÄúFrom Text (readr)‚Äù.\nIf the CSV file is a file stored on your computer, click the Browse button and navigate to where you saved your CSV file, select the file, and click ‚ÄúOpen‚Äù. If the CSV file is hosted on the web, type the URL into the ‚ÄúFile/URL‚Äù text box and click ‚ÄúUpdate‚Äù.\n\n\n\n3.3.1 Importing the Spice Girls Data\nThe file spice-girls.csv is accessible at https://raw.githubusercontent.com/zief0002/modeling/main/data/spice-girls.csv.\n\nCopy and paste that URL into the ‚ÄúFile/URL‚Äù text box.\nClick the ‚ÄúUpdate‚Äù button.\n\nClicking ‚ÄúUpdate‚Äù will open a preview of your data. Check to be sure the variable names are correct and that the data looks like what you entered into your spreadsheet.\n\nChange the text in the name box to correspond to the object name you want to use in R.\nFinally, click the Import button to import your data.\n\nAfter importing the data you should see the object in your global environment.\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Importing Data Using a Script File\nEven though you used the Import button‚Äîa point-and-click feature in RStudio‚Äîto import the data, behind the scenes, syntax was generated that was actually used to import the data into R. When we selected ‚ÄúFrom Text (readr)‚Äù, the read_csv() function from the {readr} package was used to import the data. You can see the syntax generated in the Code Preview window after you selected your CSV file.\n\n\n\n\n\n\n\n\n\nIn the first line of syntax, the {readr} package is loaded using the library() function. The data is imported in the second line of syntax and assigned to an object, in this case spice_girls. The read_csv() function includes an unnamed argument providing the URL for the CSV file.4 The View() function in the third line of syntax simply opens the spice_girls object in a view tab in RStudio.\nIt is a good idea to copy the first two lines of syntax from the Code Preview window into your script file. It will be faster to import the data in the future by running it from a script file rather than trying to reproduce all the steps to import your data. The third line of syntax, using View(), is not essential to importing your data..\n\nSince there are better ways to actually ‚Äúsee‚Äù the contents of the data object (e.g., print()), you should not include the View() syntax line in your script file.\n\nBelow are the two lines I would include in the script file. I would also comment them.\n\n# Load readr library\nlibrary(readr)\n\n# Import data\nspice_girls &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/modeling/main/data/spice-girls.csv\")\n\n\nThe syntax &lt;- is another way to write the assignment operator. You can use either = or &lt;- for the assignment operator. Whichever you choose, be consistent!",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#validity-check-on-imported-data",
    "href": "01-03-data-structures-in-r.html#validity-check-on-imported-data",
    "title": "3¬† Data Structures in R",
    "section": "3.4 Validity Check on Imported Data",
    "text": "3.4 Validity Check on Imported Data\nOnce you import data, you should always perform a validity check to ensure that the entire dataset was imported and that things look OK. There are several functions that are useful for this examination. Three that I use regularly are print(), glimpse() and summary().\nThe print() function gives us a quick look at the data.\n\n# View data\nprint(spice_girls)\n\n# A tibble: 5 √ó 5\n  spice_name   age original_member solo_nominations real_name\n  &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;                      &lt;dbl&gt; &lt;chr&gt;    \n1 Scary         19 TRUE                           4 Mel B    \n2 Sporty        20 TRUE                          26 Mel C    \n3 Baby          18 FALSE                         14 Emma     \n4 Ginger        22 TRUE                          13 Geri     \n5 Posh          20 FALSE                         12 Victoria \n\n\nNote that from this output we can see that the read_csv() function actually imports the data as a tibble. Tibbles are essentially the same data structure as data frames. The only difference is that when you use print() (and some other functions) to examine the data object, what is printed to the screen is slightly different.5 For tibbles,\n\nThe number of rows and columns is displayed;\nThe first 10 rows are shown;\nOnly the columns that fit on screen are printed; and\nEach column type is reported\n\nHere the size of the data object is 5 x 5, which indicates that there are five rows (first value) and five columns (second value). We are also informed which columns are numeric, which are logical, and which are character.6\nThe summary() function computes summary statistics for each column in the data object. Different measures are computed depending on the column type. For character columns, only the length of the column is computed. The count of TRUE and FALSE values are computed for logical columns, and several measures are computed for numeric columns.\n\n# Compute summary measures for each column\nsummary(spice_girls)\n\n  spice_name             age       original_member solo_nominations\n Length:5           Min.   :18.0   Mode :logical   Min.   : 4.0    \n Class :character   1st Qu.:19.0   FALSE:2         1st Qu.:12.0    \n Mode  :character   Median :20.0   TRUE :3         Median :13.0    \n                    Mean   :19.8                   Mean   :13.8    \n                    3rd Qu.:20.0                   3rd Qu.:14.0    \n                    Max.   :22.0                   Max.   :26.0    \n  real_name        \n Length:5          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nThis is another good validity check to ensure that numeric columns have appropriate minimum and maximum values, etc. Here we see that the the age and solo_nominations columns have reasonable values. In practice you would undertake many more validity checks, but for now this is a good start.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#references",
    "href": "01-03-data-structures-in-r.html#references",
    "title": "3¬† Data Structures in R",
    "section": "References",
    "text": "References\n\n\n\n\nBroman, K. W., & Woo, K. H. (2018). Data organization in spreadsheets. The American Statistician, 72(1), 2‚Äì10. https://doi.org/10.1080/00031305.2017.1375989",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#footnotes",
    "href": "01-03-data-structures-in-r.html#footnotes",
    "title": "3¬† Data Structures in R",
    "section": "",
    "text": "Technically, a data frame can have a single column, but in practice most data frames you encounter will have many columns.‚Ü©Ô∏é\nIn this case, everything in the column would be turned into a character string.‚Ü©Ô∏é\nThe technical type is ‚Äúdouble‚Äù, which is commonly referred to as numeric.‚Ü©Ô∏é\nThis argument for the read_csv() function can also be a pathname to the location of the CSV file on your computer. If you are computing on a Mac, you may need to add ~/ to the beginning of this path name.‚Ü©Ô∏é\nFor data frames only the first six rows are displayed, all the columns are printed regardless of size, and column type is not reported.‚Ü©Ô∏é\nNote that just typing the name of the data frame also allows you to view the data. However, using print allows us more flexibility when the data set is larger.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html",
    "href": "01-04-data-wrangling-with-dplyr.html",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "",
    "text": "4.1 Piping: The Key to Using dplyr\nRecall that functions work by taking arguments as inputs and then producing an output. For example, the glimpse() function takes the comics data frame as its input.\n# View data\nglimpse(comics)\nWe could get the same result by using the pipe operator (|&gt;). This operator takes a DATA FRAME, or a tibble, (given immediately before the operator) and uses it as the FIRST argument in the function that comes immediately after the pipe operator.\n# The pipe operator makes comics the first argument of the glimpse() function\ncomics |&gt; glimpse()\n\nRows: 23,272\nColumns: 14\n$ character         &lt;chr&gt; \"14\", \"88\", \"99\", \"107\", \"'Spinner\", \"\\\"Thumper\\\" Mo‚Ä¶\n$ comic             &lt;chr&gt; \"Marvel\", \"Marvel\", \"Marvel\", \"Marvel\", \"Marvel\", \"M‚Ä¶\n$ reality           &lt;chr&gt; \"Earth-616\", \"Earth-616\", \"Earth-616\", \"Earth-616\", ‚Ä¶\n$ identity          &lt;chr&gt; \"Secret Identity\", \"Public Identity\", \"Secret Identi‚Ä¶\n$ alignment         &lt;chr&gt; \"Bad\", \"Bad\", \"Neutral\", \"Neutral\", \"Good\", \"Bad\", \"‚Ä¶\n$ eye_color         &lt;chr&gt; NA, \"Blue\", \"Blue\", \"Green\", NA, NA, NA, \"Blue\", NA,‚Ä¶\n$ hair_color        &lt;chr&gt; NA, \"Blond\", NA, NA, NA, \"Bald\", NA, \"White\", NA, \"B‚Ä¶\n$ sex               &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"M‚Ä¶\n$ lgbtq             &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"‚Ä¶\n$ lgbtq_note        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ alive             &lt;chr&gt; \"Living\", \"Living\", \"Living\", \"Living\", \"Living\", \"L‚Ä¶\n$ appearances       &lt;dbl&gt; 1, 3, 1, 1, NA, NA, 1, 1, 1, 1, 3, 1, 2, 1, 1, 10, N‚Ä¶\n$ first_appear_date &lt;chr&gt; \"1994, November 01\", \"1994, March 01\", \"1994, Novemb‚Ä¶\n$ first_appear_year &lt;dbl&gt; 1994, 1994, 1994, 1994, 2007, 1965, 1991, 2010, 2011‚Ä¶\nNote since the glimpse() function did NOT include any additional arguments, we do not include anything between the parentheses after we pipe. Here is another example that illustrate the use of the pipe operator.\n# Count number of rows in comics data frame\nnrow(comics)\n\n[1] 23272\n\n# Can be written using the pipe operator as...\ncomics |&gt; nrow()\n\n[1] 23272\nOne last example will show how we use the additional arguments in the function following the pipe operator. For example, say we wanted to use the print() function to print the tibble/data frame, and we wanted to show all of the columns. The print() function would include not only the name of the tibble we wanted to print, but also the argument width=Inf. Here is the syntax for this:\n# Print all columns of comics tibble\nprint(comics, width = Inf)\nUsing piping, the syntax would be:\n# Print all columns of comics tibble\ncomics |&gt; print(width = Inf)\n\n# A tibble: 23,272 √ó 14\n   character                  comic  reality   identity        alignment\n   &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;    \n 1 \"14\"                       Marvel Earth-616 Secret Identity Bad      \n 2 \"88\"                       Marvel Earth-616 Public Identity Bad      \n 3 \"99\"                       Marvel Earth-616 Secret Identity Neutral  \n 4 \"107\"                      Marvel Earth-616 Secret Identity Neutral  \n 5 \"'Spinner\"                 Marvel Earth-616 Secret Identity Good     \n 6 \"\\\"Thumper\\\" Morgan\"       Marvel Earth-616 Secret Identity Bad      \n 7 \"11-Ball\"                  Marvel Earth-616 Secret Identity Bad      \n 8 \"115 (Legion Personality)\" Marvel Earth-616 Secret Identity Neutral  \n 9 \"181 (Legion Personality)\" Marvel Earth-616 Secret Identity Neutral  \n10 \"1X\"                       Marvel Earth-616 Public Identity Good     \n   eye_color hair_color sex    lgbtq lgbtq_note alive  appearances\n   &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;\n 1 &lt;NA&gt;      &lt;NA&gt;       Female No    &lt;NA&gt;       Living           1\n 2 Blue      Blond      Male   No    &lt;NA&gt;       Living           3\n 3 Blue      &lt;NA&gt;       Male   No    &lt;NA&gt;       Living           1\n 4 Green     &lt;NA&gt;       Male   No    &lt;NA&gt;       Living           1\n 5 &lt;NA&gt;      &lt;NA&gt;       Male   No    &lt;NA&gt;       Living          NA\n 6 &lt;NA&gt;      Bald       Male   No    &lt;NA&gt;       Living          NA\n 7 &lt;NA&gt;      &lt;NA&gt;       Male   No    &lt;NA&gt;       Living           1\n 8 Blue      White      Female No    &lt;NA&gt;       Living           1\n 9 &lt;NA&gt;      &lt;NA&gt;       &lt;NA&gt;   No    &lt;NA&gt;       Living           1\n10 &lt;NA&gt;      Blond      Male   No    &lt;NA&gt;       Living           1\n   first_appear_date first_appear_year\n   &lt;chr&gt;                         &lt;dbl&gt;\n 1 1994, November 01              1994\n 2 1994, March 01                 1994\n 3 1994, November 01              1994\n 4 1994, November 01              1994\n 5 2022, November 07              2007\n 6 1965, February 01              1965\n 7 1991, July 01                  1991\n 8 2022, August 10                2010\n 9 2022, July 11                  2011\n10 1940, March 01                 1940\n# ‚Ñπ 23,262 more rows\nHere, comics will be inputted as the FIRST argument in the print() function, and any additional arguments are simply included in the print() function itself.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#piping-the-key-to-using-dplyr",
    "href": "01-04-data-wrangling-with-dplyr.html#piping-the-key-to-using-dplyr",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "",
    "text": "It is a good coding practice to use multiple lines when you are piping rather than putting all the syntax on a single line. When you do this, the pipe operator (|&gt;) needs to come at the end of the line. You can see this in the code below, where the pipe operator is placed at the end of the first line of syntax; not at the beginning of the second line of syntax. Include a line break after every pipe operator you use.\n\n# Print all columns of comics tibble\ncomics |&gt; \n  print(width = Inf)",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#common-dplyr-functions-for-data-wrangling",
    "href": "01-04-data-wrangling-with-dplyr.html#common-dplyr-functions-for-data-wrangling",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.2 Common dplyr Functions for Data Wrangling",
    "text": "4.2 Common dplyr Functions for Data Wrangling\nHere are some common operations that researchers use to prepare data for analysis (i.e., data preparation, data wrangling, data cleaning) and the corresponding {dplyr} functions.\n\n\n\nCommon data wrangling activities and the corresponding {dplyr} functions.\n\n\n\n\n\n\nData wrangling activity\ndplyr function\n\n\n\n\nSelect a subset of rows from a data frame.\nfilter()\n\n\nSelect a subset of columns from a data frame.\nselect()\n\n\nAdd new columns to a data frame.\nmutate()\n\n\nSort and re-order data in a data frame.\narrange()\n\n\nCompute summaries of columns in a data frame.\nsummarize()\n\n\nGroup the data to carry out computations for each group.\ngroup_by()",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#sorting-the-data-arranging",
    "href": "01-04-data-wrangling-with-dplyr.html#sorting-the-data-arranging",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.3 Sorting the Data: Arranging",
    "text": "4.3 Sorting the Data: Arranging\nTo answer our initial set of research questions related to early representation of LGBTQ characters in comics, it is useful to sort the data by both LGBTQ status and year of first appearance. The arrange() function sorts the data based on the values within one or more specified columns. The data is ordered based on the column name provided in the argument(s). The syntax below sorts the rows in the comics data frame from earliest to most recent year of first appearance.\n\n# Sort data from earliest to most recent year of first appearance\ncomics |&gt;\n  arrange(first_appear_year)\n\n\n  \n\n\n\nHere we see the earliest character in these data (Richard Occult) appeared in 1935. This, however, does not give us the first LBGTQ character. To determine this, we need to sort on LGBTQ status in addition to year of first appearance.\nProviding the arrange() function multiple arguments sort initially by the column name given in first argument, and then by the columns given in subsequent arguments. Here the data are sorted first by LGBTQ status (alphabetically since lgbtq is a character string) and then by year of first appearance.\n\n# Sort data by LGBTQ status and then from earliest to most recent year of first appearance\ncomics |&gt;\n  arrange(lgbtq, first_appear_year)\n\n\n  \n\n\n\nBecause No is alphabetically before Yes, the non-LGBTQ characters are printed first. Because only the first 10 rows of a tibble are printed (and all 10 are non-LGBTQ characters), we still can‚Äôt quite answer our research question. If you want to see all of the sorted data or operate on it further, you need to (a) explicitly tell R to print all of the rows, or (b) assign the output into an object which can be viewed and scrolled through by clicking on the object in the RStudio Environment pane.\nTo print all of the rows to the console, we can pipe the sorted data into the print() function, and include the argument N=Inf. Reminder: Best practice is to start a new line after each pipe operator!\n\n# Sort data by LGBTQ status and then from earliest to most recent year of first appearance\n# Print all the rows\ncomics |&gt;\n  arrange(lgbtq, first_appear_year) |&gt;\n  print(N = Inf)\n\n# A tibble: 23,272 √ó 14\n   character   comic reality identity alignment eye_color hair_color sex   lgbtq\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;\n 1 Richard Oc‚Ä¶ DC    New Ea‚Ä¶ Secret ‚Ä¶ &lt;NA&gt;      Grey      Black      Male  No   \n 2 Arthur Pen‚Ä¶ DC    New Ea‚Ä¶ Public ‚Ä¶ Good      Brown     Brown      Male  No   \n 3 Bedivere    DC    New Ea‚Ä¶ &lt;NA&gt;     &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;       Male  No   \n 4 Franklin D‚Ä¶ DC    New Ea‚Ä¶ Public ‚Ä¶ Good      &lt;NA&gt;      Grey       Male  No   \n 5 Gareth      DC    New Ea‚Ä¶ &lt;NA&gt;     &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;       Male  No   \n 6 Gawain      DC    New Ea‚Ä¶ Public ‚Ä¶ Good      &lt;NA&gt;      &lt;NA&gt;       Male  No   \n 7 Guinevere   DC    New Ea‚Ä¶ Public ‚Ä¶ Good      &lt;NA&gt;      Blond      Fema‚Ä¶ No   \n 8 Lady of th‚Ä¶ DC    New Ea‚Ä¶ &lt;NA&gt;     Good      Blue      Blue       Fema‚Ä¶ No   \n 9 Lancelot    DC    New Ea‚Ä¶ Public ‚Ä¶ Good      &lt;NA&gt;      &lt;NA&gt;       Male  No   \n10 Merlin      DC    New Ea‚Ä¶ Secret ‚Ä¶ Neutral   Black     White      Male  No   \n# ‚Ñπ 23,262 more rows\n# ‚Ñπ 5 more variables: lgbtq_note &lt;chr&gt;, alive &lt;chr&gt;, appearances &lt;dbl&gt;,\n#   first_appear_date &lt;chr&gt;, first_appear_year &lt;dbl&gt;\n\n\nAnother way to view the entire set of data is to assign the sorted data into an object and then click on that object in the environment pane.\n\n# Sort data by LGBTQ status and then from earliest to most recent year of first appearance\n# Assign to the object 'sorted_comics'\nsorted_comics = comics |&gt;\n  arrange(lgbtq, first_appear_year)\n\n\n\n\n\n\nClicking the sorted_comics data object in the Environment pane will display the data in the RStudio data viewer.\n\n\n\n\nBased on an examination of the sorted data, we find the first appearance of an LQBTQ character is Jack Casey in 1940.\n\n\n\n\n\n\n4.3.1 Sorting in Descending Order\nRather than scrolling through the data, we could also have sorted the data so that the characters with LGBTQ status of ‚ÄúYes‚Äù are printed first. To do this we want to sort the data initially (using thelgbtq column) in reverse alphabetical order (‚ÄúYes‚Äù followed by ‚ÄúNo‚Äù).\nUse the desc() function on a column name to sort the data in descending order. Here the data are sorted in descending order by LGBTQ status and then by year of first appearance (in ascending order).\n\n# Sort data by LGBTQ status and then from earliest to most recent year of first appearance\ncomics |&gt;\n  arrange(desc(lgbtq), first_appear_year)",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#obtain-a-subset-of-rows-filtering",
    "href": "01-04-data-wrangling-with-dplyr.html#obtain-a-subset-of-rows-filtering",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.4 Obtain a Subset of Rows: Filtering",
    "text": "4.4 Obtain a Subset of Rows: Filtering\nThere are many times in research applications that an educational scientist will need to select a subset of data cases. This type of application, for example, is quite common when we carry out demographic analyses (e.g., select the special education students, select students on free/reduced-price lunch). To select a subset of rows from a tibble or data frame, we will pipe the data frame we want to select rows from into the filter() function.\nThe argument(s) for the filter() function are logical expressions that will be used to select the rows. For example, suppose we wanted to select the LGBTQ characters (i.e., rows) from the comics data frame. We would need a logical expression that returns a TRUE value for all the LGBTQ characters. One such logical expression is: lgbtq==\"Yes\". Recall that a single equals sign (=) is the assignment operator and that to say ‚Äúis equal to‚Äù, we need to use two equals signs (==). Including this logical expression in the filter() function, the syntax for selecting the LQBTQ characters is then:\n\n# Select the LGBTQ characters\ncomics |&gt;\n  filter(lgbtq == \"Yes\")\n\n\n  \n\n\n\nNote that the output from this computation (data for the LGBTQ characters) is only printed to the screen. If you want to keep the filtered data or operate on it further, you need to assign the output into an object.\n\n# Select the LGBTQ characters\nlgbtq_characters = comics |&gt;\n  filter(lgbtq == \"Yes\")\n\n# Count the number of rows\nnrow(lgbtq_characters)\n\n[1] 155\n\n\nWe could have found the same result exclusively using piping; without the interim assignment.\n\n# Select the LGBTQ characters and count the rows\ncomics |&gt;\n  filter(lgbtq == \"Yes\") |&gt;\n  nrow()\n\n[1] 155\n\n\nThe first pipe operator uses the comics data frame in the filter() function to select the LGBTQ characters. This output (only the LGBTQ characters) is then used in the nrow() function to count the number of rows. It is akin to a constant pipeline of chaining functions together (i.e., nrow(filter(comics, lgbtq == \"Yes\"))); the output of a computation is used as the input into the next computation in the pipeline.\nBased on this result (and the results from the earlier glimpse() output), we can now answer our first research question: What percentage of comic characters identify as LQBTQ?\n\n# Compute percentage of LGBTQ characters\n155 / 23272\n\n[1] 0.006660364\n\n\nOnly 0.6% of comic characters identified as LGBTQ (at least as of 2014). This is well below 7.1%, the percentage of U.S. adults who self-identify as lesbian, gay, bisexual, transgender or something other than heterosexual according to a 2022 Gallup Poll. (This is even below the 2012 estimate of 3.5%.) This suggests that the LQBTQ population is likely underrepresented in comic culture.\n\n\n\n\n\n\n4.4.1 Filtering on Multiple Attributes\nYou can filter on multiple attributes by including more than one logical statement in the filter() function. For example, say we wanted to determine if the Pride Movement had an impact on LGBTQ representation in comics. The first Pride parade took place in March 1970, so we could look at the percentage of LGBTQ comic characters introduced prior to 1970 and compare it to the percentage of LGBTQ comic characters introduced in 1970 or later.\nThe syntax below counts the number of LGBTQ comic characters introduced prior to 1970. We also compute the total number of character introduced prior to 1970 to compute the correct percentage.\n\n# Count LGBTQ characters introduced prior to 1970\ncomics |&gt;\n  filter(lgbtq == \"Yes\", first_appear_date &lt; 1970) |&gt;\n  nrow()\n\n[1] 11\n\n# Count all characters introduced prior to 1970\ncomics |&gt;\n  filter(first_appear_date &lt; 1970) |&gt;\n  nrow()\n\n[1] 4002\n\n# Compute percentage\n11 / 4002\n\n[1] 0.002748626\n\n\nOf the 4002 characters introduced prior to 1970, 0.27% identified as LGBTQ.\nHere, when we included multiple logical expressions in the filter() function, separated by a comma, they were linked using the AND (&) operator. This means that both expressions have to evaluate as TRUE to be included. We could also have explicitly used the & operator to link the two statements.\n\ncomics |&gt;\n  filter(lgbtq == \"Yes\", sex == \"Female\")\n\n# Is equivalent to...\ncomics |&gt;\n  filter(lgbtq == \"Yes\" & sex == \"Female\")\n\n\n\n\n\n\nWe can also filter() using the OR (|) operator. This means that if EITHER logical expression included in the filter() function evaluates as TRUE, the row is included in the output. For example, say we wanted to count the number of comic characters who are either female or identify as LGBTQ. The syntax for this would be:\n\n# Count character who are LQBTQ or are female\ncomics |&gt;\n  filter(lgbtq == \"Yes\" | sex == \"Female\") |&gt;\n  nrow()\n\n[1] 5890",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#selecting-a-subset-of-columns",
    "href": "01-04-data-wrangling-with-dplyr.html#selecting-a-subset-of-columns",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.5 Selecting a Subset of Columns",
    "text": "4.5 Selecting a Subset of Columns\nSuppose a journalist at Lavender Magazine is writing a story about the representation of LGBTQ comic characters and has asked you to create a new dataset for their work that only includes the LGBTQ comic characters. Moreover, this new dataset should also only include the characters‚Äô name, year of first appearance, and the LGBTQ note. To complete this task, we need to select not only a subset of rows from the original data, but also a subset of the columns.\nTo select a subset of columns, we will use the select() function. The argument(s) for this function are the column names of the data frame that you want to select. For example, to select the character, first_appear_year, and lgbtq_note columns from the comics data frame we would use the following syntax:\n\n# Select a subset of columns\ncomics |&gt;\n  select(character, first_appear_year, lgbtq_note)\n\n\n  \n\n\n\nWe can combine this column selection with our filtering to select the LGBTQ characters. Note that since the filter() function uses the data in the lgbtq column, we need to apply the filter before we selecting the three columns we want. If we use select() prior to filtering, we will get an error since the column lgbtq was not included in the select() function.\n\n# This order produces and error\ncomics |&gt;\n  select(character, first_appear_year, lgbtq_note) |&gt;\n  filter(lgbtq == \"Yes\")\n\nError in `filter()`:\n‚Ñπ In argument: `lgbtq == \"Yes\"`.\nCaused by error:\n! object 'lgbtq' not found\n\n# This order gets us the data we want\ncomics |&gt;\n  filter(lgbtq == \"Yes\") |&gt;\n  select(character, first_appear_year, lgbtq_note)\n\n\n  \n\n\n\nLastly, in order to get this data to the journalist, we need to export the data from R to our computer. The {readr} package includes several functions that allow us to export data from R in a variety of formats. Here we will use the write_csv() function to export the data into a CSV file. This function necessitates that we provide the path and filename for where we want to save the exported CSV file. For example, to write a CSV file called lgbtq-comic-characters.csv to the desktop on a Mac we could use the following syntax:\n\n# Subset data and export it\ncomics |&gt;\n  filter(lgbtq == \"Yes\") |&gt;\n  select(character, first_appear_year, lgbtq_note) |&gt;\n  write_csv(\"/Users/username/Desktop/lgbtq-comic-characters.csv\")\n\nThe syntax to do this on a PC would be something like the following:\n\n# Subset data and export it\ncomics |&gt;\n  filter(lgbtq == \"Yes\") |&gt;\n  select(character, first_appear_year, lgbtq_note) |&gt;\n  write_csv(\"C:\\Users\\username\\Desktop\\lgbtq-comic-characters.csv\")\n\nIn both of the Mac and PC examples, the part of the pathname called username needs to be modified to be the user name for your computer. Typically this is the username you use to login to your computer.\n\n\n\n\n\n\n4.5.1 Helper Functions for select()\nThere are a number of helper functions you can use within the select() function. For example, starts_with(), ends_with(), and contains(). These let you quickly match larger blocks of columns that meet some criterion. The syntax below illustrates a couple of these functions. You can read about other helper functions and see examples here.\n\n# Select all the columns that have a column name that ends in 'r'\ncomics |&gt;\n  select(ends_with(\"r\"))\n\n\n  \n\n\n# Select all the columns that have a column name that contains an underscore\ncomics |&gt;\n  select(contains(\"_\"))\n\n\n  \n\n\n\n\n\n\n4.5.2 Renaming Columns\nYou can rename a column by using the rename() function. Here we select the character, eye_color, and hair_color columns from the comics data frame and then rename the eye_color and hair_color columns to eye and hair, respectively. Note that this works similar to assignment in that the new column name is to the left of the equal sign.\n\n# Select 3 columns and rename 2 of them\ncomics |&gt;\n  select(character, eye_color, hair_color) %&gt;%\n  rename(eye = eye_color, hair = hair_color)",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#create-new-columns-mutating",
    "href": "01-04-data-wrangling-with-dplyr.html#create-new-columns-mutating",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.6 Create New Columns: Mutating",
    "text": "4.6 Create New Columns: Mutating\nTo create new columns, we will use the mutate() function. Here we create a new column called num_years based on subtracting the year of the character‚Äôs first appearance from the current year (2022 as of this writing).\n\ncomics |&gt;\n  mutate(\n    num_years = 2022 - first_appear_year\n    )\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nIf you are running this in the console, the num_years column won‚Äôt be displayed because of the default printing options for tibbles; the new column is created, just not displayed. To view it, we can use the print() function with the argument width=Inf, which displays all columns in the tibble.\n\n# Add a new column and display all the columns\ncomics |&gt;\n  mutate(\n    num_years = 2022 - first_appear_year\n    ) |&gt;\n  print(width = Inf)\n\n\n\n\n4.6.1 Creating Multiple New Columns\nYou can create multiple new columns within the same mutate() function. Simply include each new column as an argument. Below we again create num_years, but we also additionally create centered_appearances which computes the difference between the number of appearances for each character and the mean number of appearances.\n\n# Add two new columns\ncomics |&gt;\n  mutate(\n    num_years = 2022 - first_appear_year,\n    centered_appearances = appearances - mean(appearances, na.rm = TRUE)\n    )\n\n\n  \n\n\n\nNote that the mean() function includes the optional argument na.rm=TRUE which allows the mean computation when there are NA values; it tells the mean() function to remove the NAs in the computation. (If you didn‚Äôt remove the NAs, the result of the computation would be an NA.)\n\nIf you want to continue to use the newly created columns, you need to assign the output into an object. If you do not assign the output into an object, the data with the new columns is printed to the screen and then the new columns are promptly ‚Äúforgotten‚Äù by R. If you are sure of your syntax, you can re-assign the data into the original object. Here we create the new columns and re-assign this into the comics object.\n\n# Add two new columns and re-assign to 'comics'\ncomics = comics |&gt;\n  mutate(\n    num_years = 2022 - first_appear_year,\n    centered_appearances = appearances - mean(appearances, na.rm = TRUE)\n    )",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#computing-summaries-of-data-in-a-column",
    "href": "01-04-data-wrangling-with-dplyr.html#computing-summaries-of-data-in-a-column",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.7 Computing Summaries of Data in a Column",
    "text": "4.7 Computing Summaries of Data in a Column\nThe summarize() function is used to compute summaries of data in a given column. Here we compute the mean number of appearances for all comic characters in the data.\n\ncomics |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE)\n    )\n\n\n  \n\n\n\n\nBecause the appearance column includes missing values (NAs), we need to include the argument na.rm=TRUE in the mean() function. Including this will compute the mean only using the cases that have values. If there are missing values and the argument is not included, the result of the mean computation will be NA.\n\nThe output from summarize() is a data frame with a single row and one or more columns, depending on how many summaries you computed. Here we computed a single summary so there is only one column. We also named the column M within the summarize() function.\nMultiple summaries can be computed by providing more than one argument to the summarize() function. The output is still a single row data frame, but now there will be multiple columns, one for each summary computation. Here we compute the mean number of appearances for all comic characters in the data and also the standard deviation.\n\ncomics |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE),\n    SD = sd(appearances, na.rm = TRUE)\n    )",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#computations-on-groups",
    "href": "01-04-data-wrangling-with-dplyr.html#computations-on-groups",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.8 Computations on Groups",
    "text": "4.8 Computations on Groups\nWhile we have leaned that, on average, comic characters appear about 20 times. And, that the variation is quite large (\\(SD=93.8\\)), telling us that there are characters who appear many more times (e.g., Spiderman, Susan Storm, Wonder Woman). Although a useful first step in an analysis, this alone does not answer our research question about how the average number of appearances for comic characters identifying as LQBTQ differ from those who don‚Äôt. To answer this, we need to compute these summary measures for LGBTQ and non-LGBTQ characters separately.\nThe group_by() function groups the data by a specified variable. By itself, this function essentially does nothing. But it is powerful when the grouped output is piped into other functions, such as summarize(). Here we use group_by(lgbtq) to compute the mean number of appearances and also the standard deviation for both LGBTQ and non-LGBTQ characters.\n\ncomics |&gt;\n  group_by(lgbtq) |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE),\n    SD = sd(appearances, na.rm = TRUE)\n    )\n\n\n  \n\n\n\nFrom this analysis we can see that characters that identify as LGBTQ appear, on average, about 75 times, while those that do not identify as LGBTQ appear only about 20 times. Both groups of characters have a large standard deviation implying that there is a lot of variation in the number of appearances for both groups.\nYou can also use group_by() with multiple attributes. Simply add additional column names in the group_by() function to create more conditional groups. For example to compute to compute the mean number of appearances and also the standard deviation for both LGBTQ and non-LGBTQ characters conditioned on comic company, we can use the following syntax.\n\ncomics |&gt;\n  group_by(lgbtq, comic) |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE),\n    SD = sd(appearances, na.rm = TRUE)\n    )\n\n\n  \n\n\n\nThis produces the summary measures for each of the combinations of the lgbtq and comic variables. So while we see that for both DC and Marvel, LGBTQ characters have more appearances, on average, than non-LGBTQ characters, this difference is more more pronounced for Marvel characters.\nIn one last analysis, we might also compute the sample size associated with these combinations.\n\ncomics |&gt;\n  group_by(lgbtq, comic) |&gt;\n  summarize(\n    M = mean(appearances, na.rm = TRUE),\n    SD = sd(appearances, na.rm = TRUE),\n    N = n()\n    )\n\n\n  \n\n\n\nThis added information reminds us that while the average number of appearances for LGBTQ characters is higher than for non-LGBTQ characters (for both DC and Marvel), overwhelming majority of comic characters are non-LGBTQ.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-04-data-wrangling-with-dplyr.html#additional-resources",
    "href": "01-04-data-wrangling-with-dplyr.html#additional-resources",
    "title": "4¬† Data Wrangling with dplyr",
    "section": "4.9 Additional Resources",
    "text": "4.9 Additional Resources\nHere are some additional resources for learning {dplyr}.\n\nData Transformation with dplyr Cheatsheet: A printable cheatsheet for using {dplyr}.\nData Wrangling Part 1: Basic to Advanced Ways to Select Columns\nData Wrangling Part 2: Transforming your columns into the right shape\nData Wrangling Part 3: Basic and more advanced ways to filter rows\nData Wrangling Part 4: Summarizing and slicing your data",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Wrangling with dplyr</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html",
    "href": "01-05-visualizing-with-ggplot2.html",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "",
    "text": "5.1 Some Background\nThe gg in {ggplot2} stands for grammar of graphics. The grammar of graphics (Wilkinson, 2005) is a formal system of expressive grammatical rules for creating perceivable graphs. The grammar of graphics includes things such as aesthetics, geometries, scales, facets, and guides. Hadley Wickham adopted this grammar into the initial {ggplot} package, which he then re-wrote and updated to create the {ggplot2} package. As you learn how to create plots using {ggplot2}, you will also begin to learn the grammar of graphics. Understanding this grammar will help you describe, and create almost any visualization you can imagine.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#understanding-the-basic-syntax",
    "href": "01-05-visualizing-with-ggplot2.html#understanding-the-basic-syntax",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.2 Understanding the Basic Syntax",
    "text": "5.2 Understanding the Basic Syntax\nPlots in {ggplot2} are built by layering different components. For example, consider the following syntax which creates a scatterplot using the income and CO2 emissions attributes:\n\nggplot(data = gapminder, aes(x = income, y = co2)) + \n  geom_point() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIn this syntax there are three layers used to create the plot:\n\na global layer,\na geometric layer, and\na theme layer.\n\nThe layers are literally summed together to form the plot. We will look at each of these layers in turn.\n\n\n5.2.1 The Global Layer\nThe first layer (referred to as the global layer) in every plot you create employs the function ggplot(). It contains a reference to the source data (data=) and any global aesthetic mappings (more about this later). The first layer only sets up the plot, it doesn‚Äôt actually plot anything.\n\nggplot(data = gapminder, aes(x = income, y = co2))\n\n\n\n\nThe background layer for the plot is drawn. The domain (x-values) and range (y-values) is based on data in the income and co2 attributes.\n\n\n\n\n\nThe data= argument indicates the source data frame.\nThe aes= argument sets the aesthetic mapping(s).\n\n\n\n\n5.2.2 Aesthetics and Aesthetic Mappings\nAesthetics define what we, as humans, perceive in a given plot; that is the visual properties of a plot. For example, the position of certain elements in the plot (where they are located), or the color or transparency of an element. These aesthetics can be fixed or variable. For example, consider the color of a set of points. If the color is fixed, it would be the same for all the points. If the color is variable, it might be red for some points and blue for other points. Often, this variability in the aesthetic is based on some attribute in our dataset (e.g., points representing Democrats are colored blue, while those representing Republicans are colored red).\nLinking an aesthetic to an attribute in the data, is referred to as an aesthetic mapping. That is because aesthetic mappings map visual properties in the plot (e.g., position, color) to the values in a particular attributes in the data. Aesthetic mappings are specified in an aes() function. In our earlier example syntax, there were two aesthetic mappings that were defined:\n\nIncome values from the data will be mapped to the x-position.\nCO2 values from the data will be mapped to the y-position.\n\nThese mappings were used to define the domain (x-values) and range (y-values) for the blank plot created by the ggplot() global layer.\n\nImportant\nAll aesthetic mappings need to be specified in an aes() function. Because aesthetic mappings use information in the attribute to apply the specified visual properties, the aesthetics (e.g., x=, y=, color=) need to be set to an attribute name in the data frame. For example, both income and co2 are attribute names in the gapminder data object.\n\n\n\n\n5.2.3 Adding Layers\nAfter starting with the global layer, we can modify our visualization by adding layers to the global layer. For example, the layer that includes the function geom_point() is being added to the global layer in the syntax below.\n\n#: fig-cap: Points are added on top of the plot's background layer.\nggplot(data = gapminder, aes(x = income, y = co2)) + \n  geom_point()\n\n\n\n\n\n\n\n\nGeometric layers (geom_*) are used to add things like points, lines, histograms, densities, etc. The geom_point() layer in our plot is actually drawing the points of the scatter plot. These layers draw on the aesthetic mappings defined in the global layer to know where to draw these geometric objects. For example, the data in the income and co2 variables define the x- and y-positions of the points, respectively.\nWhen layers are added they are ‚Äústacked‚Äù on top of previous layers. For example, consider the two sets of syntax below. Each will again create our scatterplot by adding a set of points based on the data in the global layer. Each will also draw a loess smoother (a sort of trend line). However, in the first set of syntax, the smoother is drawn on top of the points, and in the second set of syntax, the points are drawn on top of the loess smoother. (The argument alpha=1 sets the transparency of the smoother to be completely opaque.)\n\n# LEFT: Draw smoother on top of points\nggplot(data = gapminder, aes(x = income, y = co2)) + \n  geom_point() +\n  geom_smooth(alpha = 1)\n\n\n# RIGHT: Draw points on top of smoother\nggplot(data = gapminder, aes(x = income, y = co2)) + \n  geom_smooth(alpha = 1) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nLEFT: The smoother is drawn on top of the points. RIGHT: The points are drawn on top of the smoother.\n\n\n\n\n\n\n\nLEFT: The smoother is drawn on top of the points. RIGHT: The points are drawn on top of the smoother.\n\n\n\n\n\nA useful metaphor might be to imagine putting together a collage of many different photographs. Some parts of some of the photographs (especially those you put down first) might be covered up by photographs that you add later.\n\nProtip\nWhen you are creating plots, you might need to switch the order of some of the layers to get the visualization you want.\n\n\n\n\n5.2.4 Good Syntactic Habits\nAs we add multiple layers to build up our plot, it is a good habit to use multiple lines for the syntax. Generally we put one layer on each line.\n\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point()\n\nThe + sign needs to be at the end of the line (not at the beginning). If you are using a script file (which you should be), highlight ALL layers in the plot and click Run to create the plot.\n\nProtip\nIf you write your {ggplot2} syntax across multiple lines, it makes it not only easier to read, but also easier to try out different layers or features. For example, you can comment out lines to remove layers as you are building the plot without losing the syntax you wrote.\nYou can also debug syntax by highlighting all lines up to a given + sign and running the syntax. By subsequently highlighting and running additional lines of syntax, you can often figure out where any errors show up!",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#global-vs.-local-aesthetic-mappings",
    "href": "01-05-visualizing-with-ggplot2.html#global-vs.-local-aesthetic-mappings",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.3 Global vs.¬†Local Aesthetic Mappings",
    "text": "5.3 Global vs.¬†Local Aesthetic Mappings\nAs you learned earlier, we use the aes() function to set aesthetic mappings (i.e., linking attributes to aesthetics). Aesthetic mappings are often set globally (in the initial ggplot() layer). When we include aesthetic mappings in the global layer they are applied to all layers in the plot. For example, the syntax below maps data in the income attribute to the x-position, data from the co2 attribute to the y-position, and data from the region attribute to color for both the loess smoother and the points.\n\n# All aesthetic mappings are global\nggplot(data = gapminder, aes(x = income, y = co2, color = region)) +  \n  geom_smooth() +\n  geom_point()\n\n\n\n\nThe global aesthetic mappings of x- and y-positioning, as well as, color are applied to the smoother and point layers.\n\n\n\n\n\nNotice when we use non-positional aesthetic mappings (e.g., color) a legend, or guide in the grammar of graphics, will be automatically added to our plot for each aesthetic mapping.\n\nAesthetic mappings can also be set locally in a specific layer. Aesthetic mappings set in a specific layer only apply to that particular layer. Below, we continue to globally map data from the income attribute to the x-position, and data from the co2 attribute to the y-position. Both the smoother layer and point layer will utilize that. However, only the point layer will map data from the region attribute to color. Note that regardless of whether the aesthetic mapping is global or local, we still make this mapping inside an aes() function.\n\n# Aesthetic mappings for x- and y-position are global\n# Aesthetic mapping for color only applies to the points layer\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(aes(color = region))\n\n\n\n\nThe global aesthetic mappings of x- and y-positioning are applied to the smoother and point layers. The aesthetic mapping of color is only applied to the point layer.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#fixed-aesthetics",
    "href": "01-05-visualizing-with-ggplot2.html#fixed-aesthetics",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.4 Fixed Aesthetics",
    "text": "5.4 Fixed Aesthetics\nFixed aesthetics assign the exact same value for the visual property for all the observations; it is not based on the data. Fixed aesthetics do not go inside of the aes() function. (Remember: Inside of the aes() function the mapping has to be to an attribute name!) The following syntax uses the following aesthetics:\n\nGlobal aesthetic mapping: Data from the income attribute mapped to the x-position.\nGlobal aesthetic mapping: Data from the co2 attribute mapped to the y-position.\nFixed local aesthetic: All points are given a shape of 22 (filled square with a border). You can see all the shape options here.\nFixed local aesthetic: All points are given a size of 4 (slightly bigger). The default size is 3.\nLocal aesthetic mapping: Data from the region attribute mapped to fill for the points layer only. Because we are using a different shape we use fill= rather than color= to color the observations.\nFixed local aesthetic: All points are given a border color of black (for this shape border color is set using color=).\n\n\n# Aesthetic mappings for x- and y-position are global\n# Aesthetic mapping for fill only applies to the points layer\n# All points are the same shape, size, and border color\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(aes(fill = region), shape = 22, size = 4, color = \"black\")\n\n\n\n\nThe global aesthetic mappings of x- and y-positioning are applied to the smoother and point layers. The aesthetic mapping of color is only applied to the point layer. The point layer also includes several fixed aesthetics.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#faceting-separate-plots-for-subgroups",
    "href": "01-05-visualizing-with-ggplot2.html#faceting-separate-plots-for-subgroups",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.5 Faceting: Separate Plots for Subgroups",
    "text": "5.5 Faceting: Separate Plots for Subgroups\nFaceting creates a separate plot for different levels of a attribute. This is useful, for example, when you want a separate plot for different subgroups. To facet on a single attribute include the facet_wrap() layer. The wiggle, or tilde, (~) sets the attribute to facet on. In the following syntax, we create a separate plot for each region.\n\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  facet_wrap(~region)\n\n\n\n\nScatterplot of per person CO2 emissions versus income for 193 countries. This plot is shown for each of the four world regions.\n\n\n\n\nWe can format the output of the facetted plots by setting the number of rows (nrow=) or columns (ncol=). For example, the following syntax outputs all four subplots in a single row.\n\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  facet_wrap(~region, nrow = 1)\n\n\n\n\nScatterplot of per person CO2 emissions versus income for 193 countries. This plot is shown for each of the four world regions.\n\n\n\n\n\n\n5.5.1 Facetting on Multiple Variables\nTo facet on multiple attributes, use facet_grid() rather than facet_wrap(). The facet_grid() layer also uses the wiggle or tilde, but in this function we will include an attribute before the tilde and a second attribute after the tilde. This defines the layout of the plot grid, so that the attribute that comes prior to the tilde will be facetted into separate rows, and the attribute that comes after the tilde will be facetted into different columns (i.e., rows ~ columns). The syntax below facets on both world region (rows) and CO2 change (columns).\n\n# Facet: regions in rows; \nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  facet_grid(region ~ co2_change)\n\n\n\n\nScatterplot of per person CO2 emissions versus income for 193 countries. This plot is shown for each of the four world regions and whether or not CO2 emissions increased or decreased since 2007.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#working-with-the-axes",
    "href": "01-05-visualizing-with-ggplot2.html#working-with-the-axes",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.6 Working with the Axes",
    "text": "5.6 Working with the Axes\nMany of the functions and layers employed in {ggplot2} syntax is to fine-tune the plot and make it ready for publication. One place this happens is on the axes of the plot. Changing the labels, the limits, or even where breakpoints occur are all things you may want to adjust as you ready a plot for publication.\n\n\n5.6.1 Changing the Axis Label\nTwo commonly used layers are xlab() and ylab(). These layers are used to change the label on the x- and y-axes, respectively. Here we change the axis label on both the x- and y-axes to give more information about the attributes being plotted.\n\n# Change the labels on the x- and y-axis\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  xlab(\"Per-person income (in thousands of international dollars, fixed for 2017 prices)\") +\n  ylab(\"Per-person CO2 emissions (in metric tonnes)\")\n\n\n\n\n\n\n\n\n\n\n\n5.6.2 Changing the Axis Limits\nAnother set of commonly used layers are xlim() and ylim(). These layers are used to set the limits on the x-axis and y-axis, respectively. These functions take two values which set the limits on the particular axis. The first value provided is the minimum, and the second value given is the maximum. Here, for example, the x-limits in the plot will be 0 to 125, and the y-axis will be 0 to 50.\n\n# Change the limits on the x- and y-axis\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  xlab(\"Per-person income (in thousands of international dollars, fixed for 2017 prices)\") +\n  ylab(\"Per-person CO2 emissions (in metric tonnes)\") +\n  xlim(0, 125) +\n  ylim(0, 50)\n\n\n\n\n\n\n\n\n\n\n\n5.6.3 Fine-Tuning Axis Scales\nThe xlab(), ylab(), xlim() and ylim() functions we used are shortcuts to using scaling layers. The use of scaling layers allows much more fine-tuning and control of the axis scales. There are four different scaling functions you can use depending on which axis (x or y) you want to control and whether the variable plotted along that axis is continuous or discrete. The four functions are:\n\nscale_x_continuous(),\nscale_x_discrete(),\nscale_y_continuous(), and\nscale_y_discrete().\n\nFor example, in our plot, to fine-tune the x-axis we could use scale_x_continuous() since income is a continuous variable and we want to fine-tune the x-axis.\n\n# Fine-tune the x-axis\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point() +\n  scale_x_continuous(\n    name = \"Per-person income (in thousands of international dollars, fixed for 2017 prices)\",\n    limits = c(0, 125),\n    breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120)\n  ) +\n  ylab(\"Per-person CO2 emissions (in metric tonnes)\") +\n  ylim(0, 50)\n\n\n\n\nScale on the x-axis set to have a label, as well as, specific limits, and break lines.\n\n\n\n\nThe name= option labels the scale‚Äîit replaces xlab(). The limits= argument takes a vector of the minimum and maximum values‚Äîit replaces xlim(). The breaks= option adds break lines on the axis. There are several other options including labels= for labeling the break lines, etc.\n\n\n\n5.6.4 Customizing the Color and Fill\nScaling functions can also be used to fine-tune colors and fills. For these you need to specify the aesthetic, either color or fill, and also the palette you want to use. For example, scale_fill_manual() can be used to manually set the colors when the fill= aesthetic mapping is used, whereas scale_color_manual() can be used to manually set the colors when the color= aesthetic mapping is used.\nIn an earlier example, we used the fill= mapping to fill the points using the region attribute. Because of this we will use the layer scale_fill_manual() to change the fill colors. We use the values= argument to set the colors. Since the region attribute includes four values, we need to give the values= argument a vector of four different colors.\n\n# Specify fill colors using color names\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, aes(fill = region)) +\n  scale_fill_manual(values = c(\"skyblue\", \"plum\", \"orange\", \"chartreuse\"))\n\n\n\n\nColor palette set manually using named color values.\n\n\n\n\nHere, the alphabetic order of the values in the region variable correspond to the order of colors given in the values= argument of scale_color_manual(). In our examples:\n\nAfrica ‚Äì&gt; ‚Äúskyblue‚Äù\nAmericas ‚Äì&gt; ‚Äúplum‚Äù\nAsia ‚Äì&gt; ‚Äúorange‚Äù\nEurope ‚Äì&gt; ‚Äúchartreuse‚Äù\n\nThe color names used are built-in color names that R knows. There are 657 different named colors that you can use. To see them all, use the colors() function (with no arguments).\n\n\n5.6.4.1 Specifying Colors: RGB Color Model\nColors can also be defined using an RGB color model. This model uses a triplet of values to indicate the intensity of red (R), green (G), and blue (B) hues in the color. Each value in the triplet takes a value from 0 (none of that hue) to 255 (complete hue). For example, the color ‚Äúskyblue‚Äù is equivalent to the RGB value of (135, 206, 235), where the triplet values correspond to:\n\nRed: 135\nGreen: 206\nBlue: 235\n\nUsing the RGB color model, we can obtain 16,777,216 different colors! To specify a color using the RGB color model, we use the rgb() function. This function takes the arguments red=, green= and blue=. We also need to indicate the maximum color value1, in our case 255 using maxColorValue=. The syntax to re-create the colors from the previous plot using the RGB color model is shown below.\n\n# Specify fill colors using RGB color model\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    values = c(\n      rgb(red = 135, green = 206, blue = 235, maxColorValue = 255), #skyblue\n      rgb(red = 221, green = 160, blue = 221, maxColorValue = 255), #plum\n      rgb(red = 255, green = 165, blue = 0,   maxColorValue = 255), #orange\n      rgb(red = 127, green = 255, blue = 0,   maxColorValue = 255) #chartreuse\n    )\n  )\n\n\n\n\nColor palette set manually using RGB triplets.\n\n\n\n\n\n\n\n5.6.4.2 Specifying Colors: HEX\nColors can also be defined using hexadecimal (hex) notation. This notation takes the three RGB color model values (from 0‚Äì255) and converts each of those to a two-digit base-16 value. For example ‚Äúskyblue‚Äù, which in the RGB color model was (135, 206, 235) in hex is:\n\nRed: 135 (RGB) ‚Äì&gt; 87 (hex)\nGreen: 206 (RGB) ‚Äì&gt; CE (hex)\nBlue: 235 (RGB) ‚Äì&gt; EB (hex)\n\nThere are many websites that will convert between RGB values and hex, including Google. (Just type the following search string into Google: ‚Äúconvert 135, 206, 235 to hex‚Äù.) The hex notation for color is the six-digit value of the three concatenated two-digit color values. So skyblue is denoted:\n\nSkyblue: #87CEEB\n\nWhen we specify hex notation as a color in R, the six-digit color value is always preceeded by a hashtag (#). This is given as a character string instead of a color name. So to specify the colors in our plot using hex notation, the syntax is as follows.\n\n# Specify fill colors using hex notation\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"))\n\n\n\n\nColor palette set manually using hex notation.\n\n\n\n\n\nUsing lower-case letters in the hex notation would also work. Just remember to always include a hashtag when specifying hex.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#selecting-a-color-palette",
    "href": "01-05-visualizing-with-ggplot2.html#selecting-a-color-palette",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.7 Selecting a Color Palette",
    "text": "5.7 Selecting a Color Palette\nSelecting a color palette can be challenging. It should be aesthetically pleasing, but needs to convey the differences and nuances in the data that you are using color to display. In addition, roughly 8% of males and 0.5% of females have some form of color vision deficiency which will affect how they see and interpret the plot. Here are a few resources for thinking about color palettes:\n\nPicking a Colour Scale for Scientific Graphics\nColor Universal Design (CUD): How to Make Figures and Presentations that are Friendly to Colorblind People\nColor Palettes in R\n\nIf you are creating visualizzations for a particular organization, there may be a palette of official colors associated with their brand. For example, the University of Minnesota‚Äôs two official primary colors in hex notation (for electronic display) are:\n\n#ffcc33 (gold)\n#7a0019 (maroon)\n\nYou can see more on the University Relations Colors and Type page. They also have a palette of complementary colors available.\n\n\n5.7.1 Pre-Selected Color Palettes\nThere are several ‚Äúbuilt-in‚Äù palettes available for use in {ggplot2}.\n\n\n\n\n\n\n\n\nFill Scale\nColor Scale\nDescription\n\n\n\n\nscale_fill_hue()\nscale_color_hue()\nColors evenly spaced around the color wheel\n\n\nscale_fill_grey()\nscale_color_grey()\nGrey scale palette\n\n\nscale_fill_brewer()\nscale_color_brewer()\nColorBrewer palettes\n\n\n\nIf you do not specify the colors to use, the plots created in{ggplot2} will default to a palette that is evenly spaced around the color wheel. To use one of the other built-in palettes, we use the appropriate scale from the table above instead of the scale_fill_manual() or scale_color_manual() layer.\nFor example, to use a greyscale color palette, useful if you are printing in black-and-white, we can use the following syntax:\n\n# Specify greyscale for fill colors\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_grey()\n\n\n\n\nGreyscale color palette good for black-and-white printing.\n\n\n\n\nAnother set of built-in palettes are the Brewer palettes. These paleetes were chosen by Cynthia Brewer, a cartographer and artist, to be both colorblind friendly and aesthetically pleasing. Moreover, the palettes were designed to help humans make sense of the visualized data based on how we perceive the colors that are displayed. Martin Krzywinski has written a very readable introduction to the Brewer color palettes that I recommend.\nShe has palettes for three different types of data\n\nQualitative/Categorical: Colors do not have a perceived order\nSequential: Colors have a perceived order and perceived difference between successive colors is uniform\nDiverging: Two back-to-back sequential palettes starting from a common color (e.g., for Likert scale data)\n\n\n\n\n\n\n\n\n\n\nTo use one of Cynthia Brewer‚Äôs color palettes, we employ scale_color_brewer() or scale_fill_brewer(). Within these functions, we need to specify a palette using the palette= argument. The palette names can be found at https://colorbrewer2.org/. In our example, the region values constitute qualitative/categorical data, so we could choose any of the qualitative color palettes. To use the qualitative color palette called ‚ÄúSet1‚Äù we use:\n\n# Specify Brewer color palette (qualitative, Set 1)\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\nSet1 qualitative color palette from the Brewer color palette.\n\n\n\n\nFinally, we note that there are several packages that can extend the number of built-in color palettes. Some of my favorite extension packages include:\n\n{ggthemes} includes palettes used by FiveThirtyEight and Tableau [see here];\n{wesanderson} includes palettes based on Wes Anderson movies [see here]; and\n{nationalparkcolors} includes palettes based on National Park posters and images [see here; this needs to be installed from GitHub].\n\nEmil Hvitfeldt has also put together a package called {paletteer}, that includes a comprehensive collection of color palettes in R that can be called using a common interface [see here].\n\n\nCode\n# Load libraries\nlibrary(ggthemes)\n\n# FiveThirtyEight fill colors\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_fivethirtyeight()\n\n\n\n\n\nFiveThirtyEight color palette from the {ggthemes} package.\n\n\n\n\n\n\nCode\n# Load libraries\nlibrary(wesanderson)\n\n\n# BottleRocket2 fill colors\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(values = wes_palette(name = \"BottleRocket2\", n = 4))\n\n\n\n\n\nBottleRocket2 color palette from the {wesanderson} package.\n\n\n\n\n\n\nCode\n# Load libraries\nlibrary(nationalparkcolors)\n\n\n# Acadia fill colors\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(values = park_palette(\"Acadia\", n = 4))\n\n\n\n\n\nAcadia color palette from the {nationalparks} package.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#customizing-the-legendguide",
    "href": "01-05-visualizing-with-ggplot2.html#customizing-the-legendguide",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.8 Customizing the Legend/Guide",
    "text": "5.8 Customizing the Legend/Guide\nScaling functions can also be used to change the name and labels in the legend or guide. When we used the color scales, the guide included both the name of the attribute being plotted, and each value of the attribute along with its corresponding fill color. To change the , We can include the argument name= to edit the text of the attribute name in the guide. We can also use labels= to edit the text for each of the attribute vaslues. For example, below we change the text of the attribute in the guide to read ‚ÄúWorld Region‚Äù and the text of ‚ÄúAmericas‚Äù to instead read ‚ÄúThe Americas‚Äù. Note that because there are four attribute values, the labels= argument needs to have a vector with four values; we can‚Äôt only include the text we want to change.\n\n# Specify Brewer color palette (qualitative, Set 1)\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  )\n\n\n\n\nSet1 qualitative color palette from the Brewer color palette.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#themes-changing-the-look-of-your-plot",
    "href": "01-05-visualizing-with-ggplot2.html#themes-changing-the-look-of-your-plot",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.9 Themes: Changing the Look of Your Plot",
    "text": "5.9 Themes: Changing the Look of Your Plot\nThere are several ‚Äúbuilt-in‚Äù themes that you can use to change the look of your plot: theme_grey(), theme_minimal(), theme_linedraw(), theme_light(), theme_dark(), theme_minimal(), theme_classic(), theme_void(), and theme_test(). The default theme is theme_grey(). Here we use the layer theme_minimal() to modify the look of our plot. This theme uses a minimal black-and-white background (rather than grey).\n\n# Using the `theme_minimal()` layer to update the look of the plot\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  theme_minimal()\n\n\n\n\nUsing the theme_minimal() layer to update the look of the plot.\n\n\n\n\n\n\n5.9.1 The ggthemes Package\nThe {ggthemes} package includes 20 additional themes that you can use to style your plot (see here to view the different themes available). Here I use a theme similar to that from plots that appear in the Wall Street Journal.\n\n# Load library\nlibrary(ggthemes)\n\n# Using the `theme_wsj()` layer to update the look of the plot\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  theme_wsj()\n\n\n\n\nUsing the theme_wsj() layer from the {ggthemes} package to update the look of the plot to look like plots in the Wall Street Journal.\n\n\n\n\n\n\n\n5.9.2 Customizing a Theme\nThe theme() layer can be used to change every element in the plot (e.g., grid lines, font, color, etc.). See here for more detail. In the syntax below, we call theme_minimal() to get the minimal black-and-white them from before, and the use arguments in the theme() layer to change the font face and color on the axes labels.\n\n# Using the `theme_minimal()` layer to update the look of the plot\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  theme_minimal() +\n  theme(\n    axis.title.x = element_text(face = \"bold\", color = \"blue\"),\n    axis.title.y = element_text(face = \"italic\")\n  )\n\n\n\n\nYou can customize almost any part of the theme using the theme() layer. In this plot we changed the font face and color on the axes labels.\n\n\n\n\nThe theme() function can also be used to create your own {ggplot2} theme. This is useful if you always want your plots to look a certain way (e.g., to fit an organizations style guide) or are always using the same modifications to the theme in your plots. Below, I create a theme called theme_andy() that\n\n# Create theme_andy()\ntheme_andy = function() {\n  theme_minimal() +\n  theme(\n    # add border\n    panel.border = element_rect(colour = \"#7a0019\", fill = NA, linetype = 1),\n    # modify grid\n    panel.grid.major.x = element_line(color = \"#7a0019\", linetype = 1, size = 0.25),\n    panel.grid.minor.x = element_line(color = \"#ffb71e\"),\n    panel.grid.major.y = element_line(color = \"#7a0019\", linetype = 1, size = 0.25),\n    panel.grid.minor.y = element_line(color = \"#ffb71e\"),\n    # modify text, axis and color\n    axis.text = element_text(colour = \"#5b0013\", face = \"italic\", family = \"Times New Roman\"),\n    axis.title = element_text(colour = \"#5b0013\", family = \"Times New Roman\"),\n    axis.ticks = element_line(colour = \"#5b0013\"),\n    # legend at the bottom\n    legend.position = \"bottom\"\n  )\n}\n\n# Use theme_andy() to theme the plot\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  theme_andy()\n\n\n\n\nYou can also create your own theme to use with any plot.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#ggplot2-extension-packages",
    "href": "01-05-visualizing-with-ggplot2.html#ggplot2-extension-packages",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.10 {ggplot2} Extension Packages",
    "text": "5.10 {ggplot2} Extension Packages\nThere are several packages that extend the functionality of {ggplot2}. Many of these packages are listed at the ggplot2 Extensions page.\n\n\n\n\n\n\n\n\n\nOne useful extension package is the {scales} package. The functions and layers in this package are useful for transforming and labeling scales that are used to create your plot. For example, one of the functions in the {scales} package. label_number(), can be used to add a character prior to, or after all the numerical values labelled on an axis (very useful if the attribute being plotted is dollars). There is a nice web tutorial on using the {scales} package here.\nHere we add\n\n# Load library\nlibrary(scales)\n\n# Use the `{scales}` package to add $ in front of labels and k at the end on the x-axis\nggplot(data = gapminder, aes(x = income, y = co2)) +  \n  geom_smooth() +\n  geom_point(shape = 21, size = 4, aes(fill = region)) +\n  scale_fill_manual(\n    name = \"World Region\",\n    values = c(\"#87CEEB\", \"#DDA0DD\", \"#FFA500\", \"#7FFF00\"),\n    labels = c(\"Africa\", \"The Americas\", \"Asia\", \"Europe\")\n  ) +\n  scale_x_continuous(\n    name = \"Income (in international dollars, fixed for 2017 prices)\",\n    labels = label_number(prefix = \"$\", suffix = \"k\")\n  ) +\n  theme_minimal()\n\n\n\n\nThe {scales} package helps format labels on the axes. Here we have used it to add a dollar sign in front of labels on the x-axis.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#captions-and-figure-numbering",
    "href": "01-05-visualizing-with-ggplot2.html#captions-and-figure-numbering",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.11 Captions and Figure Numbering",
    "text": "5.11 Captions and Figure Numbering\n\nIt is easier to use a word-processor (e.g., MS Word) to add the figure title and caption than to try and get it formatted correctly using R. This is especially true when trying to mimic the APA format.\n\nHere is one workflow for saving plots, importing the saved plot into your word-processing application, and adding a figure number and caption.\n\nCreate your plot in R.\nExport it (Click the Export button above the plot in RStudio.\nSelect Save as Image...\nClick `Directory to indicate where you want to save the image\nGive the plot a name in the File name box\nChange the height and width values until you have a good aspect ratio for the plot. You can preview the image to see that it looks good.\nClick Save\nIn Word or Google Docs, import the image from where you saved it.\nResize the image to take up less space if you can. (It needs to be readable, but not too big.)\nAdd the figure number and caption using your word-processing document. :::",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#using-piping-with-ggplot2",
    "href": "01-05-visualizing-with-ggplot2.html#using-piping-with-ggplot2",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.12 Using Piping with {ggplot2}",
    "text": "5.12 Using Piping with {ggplot2}\nSince output from the piping operator produces a data frame, we can pipe the data into the ggplot() global layer rather than using the argument data=. For example:\n\n# Use piping to indicate the data\ngapminder |&gt;\n  ggplot(aes(x = income, y = co2)) +  \n    geom_smooth() +\n    geom_point() \n\nThis is useful if you are wrangling data and want to see a plot. Here for example we filter to obtain the African countries and create the plot using only those countries. Note that since we only have observations from one region, we can now change the fill= to a fixed aesthetic.\n\ngapminder |&gt;\n  filter(region == \"Africa\") |&gt;\n  ggplot(aes(x = income, y = co2)) +  \n    geom_smooth() +\n    geom_point(shape = 21, size = 4, fill = \"#87CEEB\") +\n    theme_minimal()\n\n\n\n\nUsing {dplyr} functions and piping to plot athe African countries.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#practice-practice-practice",
    "href": "01-05-visualizing-with-ggplot2.html#practice-practice-practice",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.13 Practice, Practice, Practice",
    "text": "5.13 Practice, Practice, Practice\nThe key to becoming a {ggplot2} ninja is to practice by creating visualizations. They don‚Äôt have to be fancy! Even by creating simple visualizations, you will hone your skills. As you become more confident try changing the color, or the labels, or really anything.\nIf you are unsure where to start, one practice method I have found helpful is to try and re-create a plot that someone else has already created. There are many datasets available online that people have created plots for. One source of these is the Tidy Tuesday Repository.\nThere are also several resources to help you get started and continue your gg_journey! Here are a few I have found helpful:\n\nData visualization with ggplot2 cheatsheet : A one-page (front and back) cheatsheet of ggplot2 syntax with pictures https://www.rstudio.com/resources/cheatsheets/\nCookbook for R: Web-based version of Winston Chang‚Äôs R Graphics Cookbook http://www.cookbook-r.com/Graphs/ (The UMN library has electronic access to the actual book. Just search for ‚ÄúR Graphics Cookbook‚Äù and log-in with your x500.)\nData Visualization: A Practical Introduction: Online book about data viz using ggplot2 https://socviz.co/\n\nHappy Plotting!!! üìà üéâ",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#additional-resources",
    "href": "01-05-visualizing-with-ggplot2.html#additional-resources",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "5.14 Additional Resources",
    "text": "5.14 Additional Resources\nHere are some additional resources for learning {ggplot2}.\n\nData Visualization with ggplot2 Cheatsheet: A printable cheatsheet for using {ggplot2}.\nCookbook for R: Graphs: This book is full of how-to recipes, each of which solves a specific problem using {ggplot2}. The recipe includes a quick introduction to the solution followed by a discussion that aims to unpack the solution and give you some insight into how it works.\nPlotting with ggplot: Part 1 [video]\nPlotting with ggplot: Part 2 [video]",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#references",
    "href": "01-05-visualizing-with-ggplot2.html#references",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "References",
    "text": "References\n\n\n\n\nWilkinson, L. (2005). The grammar of graphics (2nd ed.). Springer.",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "01-05-visualizing-with-ggplot2.html#footnotes",
    "href": "01-05-visualizing-with-ggplot2.html#footnotes",
    "title": "5¬† Visualizing Data with ggplot2",
    "section": "",
    "text": "Computer scientists often use a 0‚Äì1 scale of intensity rather than a 0‚Äì255. In that case, our color of ‚Äúskyblue‚Äù would have an RGB triplet of (0.5294118 0.8078431 0.9215686). Here the original RGB triplet values are divided by 255.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Statistical Computation",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Visualizing Data with ggplot2</span>"
    ]
  },
  {
    "objectID": "02-00-intro-to-regression.html",
    "href": "02-00-intro-to-regression.html",
    "title": "Introduction to Regression",
    "section": "",
    "text": "In this unit we will introduce the ideas of regression. You will learn about the plots and summaries we use to explore data in regression analyses. You will also learn how to describe the relationship between two quantitative variables using the simple regression model. You will also learn how the parameters for this model are estimated and how correlation and regression are related. Finally, you will learn about carrying out regression on standardized variables.",
    "crumbs": [
      "Introduction to Regression"
    ]
  },
  {
    "objectID": "02-01-data-exploration-for-regression.html",
    "href": "02-01-data-exploration-for-regression.html",
    "title": "6¬† Data Exploration for Regression",
    "section": "",
    "text": "6.1 Marginal Distribution of Income\nTo begin this exploration, we will examine the marginal distribution of employee incomes. We can plot a marginal distribution using functionality from the {ggplot2} package.\nggplot(data = city, aes(x = income)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Income (in thousands of dollars)\") +\n  ylab(\"Probability density\")\n\n\n\n\nDensity plot of employee incomes.\nThis plot suggests that the distribution of employee incomes is unimodal with a little bit of positive (right) skew. Most of the incomes are between roughly $50,000 and $70,000. The smallest income in the sample is about $25,000 and the largest income is over $80,000. This indicates there is a fair amount of variation in the data. A typical income looks to be about $55,000.\nTo further summarize the distribution, it is typical to compute and report summary statistics such as the mean and standard deviation. One way to compute these values is to use functions from the {dplyr} library.\ncity |&gt;\n  summarize(\n    M = mean(income),\n    SD = sd(income)\n    )\nDescribing this variable we might write,",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Data Exploration for Regression</span>"
    ]
  },
  {
    "objectID": "02-01-data-exploration-for-regression.html#marginal-distribution-of-income",
    "href": "02-01-data-exploration-for-regression.html#marginal-distribution-of-income",
    "title": "6¬† Data Exploration for Regression",
    "section": "",
    "text": "When describing the marginal distribution of a variable, you want to describe three features: the shape of the distribution, typical value(s) in the distribution (i.e., ‚Äúcenter‚Äù) and the variability in the distribution.\n\n\n\n\n\nThe marginal distribution of income is unimodal with a mean of approximately $53,700. There is variation in employees‚Äô salaries (SD = $14,500).",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Data Exploration for Regression</span>"
    ]
  },
  {
    "objectID": "02-01-data-exploration-for-regression.html#marginal-distribution-of-education-level",
    "href": "02-01-data-exploration-for-regression.html#marginal-distribution-of-education-level",
    "title": "6¬† Data Exploration for Regression",
    "section": "6.2 Marginal Distribution of Education Level",
    "text": "6.2 Marginal Distribution of Education Level\nWe will also examine the marginal distribution of the education level variable.\n\n# Plot\nggplot(data = city, aes(x = education)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Education level\") +\n  ylab(\"Probability density\")\n\n\n\n\nDensity plot of employee education levels.\n\n\n\n\n\n# Summary statistics\ncity |&gt;\n  summarize(\n    M = mean(education),\n    SD = sd(education)\n    )\n\n\n  \n\n\n\nAgain, we might write,\n\nThe marginal distribution of education is unimodal, and roughly symmetric with a mean of 16 years. There is variation in employees‚Äô level of education (SD = 4.4).",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Data Exploration for Regression</span>"
    ]
  },
  {
    "objectID": "02-01-data-exploration-for-regression.html#relationship-between-variables",
    "href": "02-01-data-exploration-for-regression.html#relationship-between-variables",
    "title": "6¬† Data Exploration for Regression",
    "section": "6.3 Relationship Between Variables",
    "text": "6.3 Relationship Between Variables\nAlthough examining the marginal distributions is an important first step, those descriptions do not help us directly answer our research question. To better understand any relationship between income and education level we need to explore how the distribution of income differs as a function of education. To do this, we will create a scatterplot of income versus education.\n\nggplot(data = city, aes(x = education, y = income)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Education (in years)\") +\n  ylab(\"Income (in U.S. dollars)\")\n\n\n\n\nScatterplot displaying the relationship between employee education levels and incomes.\n\n\n\n\nThe plot suggests a relationship (at least for these employees) between level of education and income. When describing the relationship we want to touch on four characteristics of the relationship:\n\nFunctional form of the relationship\nDirection\nStrength\nObservations that do not fit the trend (outliers)\n\n\n\n6.3.1 Functional Form of the Relationship\nA functional form refers to the algebraic (mathematical) description of the relationship between the two attributes included in the relationship. Common functional forms used in the social and educational sciences are linear, quadratic, exponential, and cyclical (e.g., sinusoidal). Figure¬†6.1 shows examples of these four functional forms.\n\n\n\n\n\n\n\n\nFigure¬†6.1: Four functional forms commonly used to describe relationships in the educational and social sciences.\n\n\n\n\n\nNote that the data in a scatterplot won‚Äôt follow these patterns perfectly, but you want to pick out the general form of the function. In our example, the relationship between education level and income seems linear.\n\n\n\n6.3.2 Direction/Trend\nOnce we pick the functional form, the next thing we want to do is identify the direction/trend of the relationship. The direction/trend describes the overall ‚Äúslope‚Äù of the data and can be positive, negative, or flat. Figure¬†6.2 shows examples of a positive, negative, and flat linear relationship.\n\n\n\n\n\n\n\n\nFigure¬†6.2: A positive, negative, and flat linear relationship.\n\n\n\n\n\nA positive relationship would imply that lower values of x are associated with lower values of y and higher values of x are associated with higher values of y. A negative relationship, on the other hand, would imply that lower values of x are associated with higher values of y and higher values of x are associated with lower values of y. A flat relationship implies there is no relationship between x and y since all values of x are associated with the same y value.\n\nWhen you describe what the direction/trend implies, be careful about the language you use. For example, we would not want to say ‚Äúwhen x goes up, y goes up‚Äù when describing a positive relationship. This is because that statement is not true for all of our cases. The trend describes the general pattern in the relationship, which does not apply to all cases. That is why we use the wording ‚Äúis associated with‚Äù, which to other researchers indicates the general pattern. Other ways to describe a positive relationship would be that:\n\nOn average, higher values of x correspond to higher values of y.\nObservations that have higher values of x tend to have higher values of y.\n\n\n\n\n\n6.3.3 Magnitude\nThe magnitude of the relationship constitutes a description of the magnitude of change in the y-values for a given change in the x-values. Is an increase in x associated with a small change in the y-values? A big change in the y-values?\nTo better understand this, consider the three linear relationships in Figure¬†6.3. All three relationships depicted have a positive relationship; higher values of x are associated with higher values of y. However, the magnitude of change in the y-values is quite different as we increase x in these plots.\n\n\n\n\n\n\n\n\nFigure¬†6.3: A steep, moderately steep, and shallow, positive linear relationship.\n\n\n\n\n\nIn the left-hand panel, the magnitude of the relationship is quite large. Not only are higher values of x are associated with higher values of y, but those y-values are a lot larger for higher values of x. We can see this in the high degree of steepness of the line.\nCompare that to the middle panel where, again, higher values of x are associated with higher values of y, but the magnitude of the change in the y-values is much smaller. That is, the line in the middle panel is less steep. Finally, in the right-hand panel, again, higher values of x are associated with higher values of y, but now the magnitude of change in the y-values is very small. Here, the slope of the line is very shallow.\n\n\n\n6.3.4 Strength\nThe strength of the relationship describes how well the data adhere to the functional form. For example a strong linear relationship would be one in which the observations lie close to the line. Figure¬†6.4 shows three positive linear relationships, one that has weak, one that is moderate, and one that is strong.\n\n\n\n\n\n\n\n\nFigure¬†6.4: A weak, moderate, and strong positive linear relationship.\n\n\n\n\n\nAs you describe the strength of a relationship, know that the qualifiers ‚Äòweak‚Äô, ‚Äòmoderate‚Äô, and ‚Äòstrong‚Äô are somewhat subjective. For now, use your best judgment.\n\nAfter positing the functional form, put that line or curve on the scatterplot in your mind. This will help you better consider and describe the strength of the relationship. In a later chapter, we will actually learn how to do this in R.\n\n\n\n6.3.5 Potential Outliers\nLastly, you also want to identify any observations that do not fit the trend. These are potential outliers. For example, the reddish, purple observation is Figure¬†6.5 would be a potential outlier.\n\n\n\n\n\n\n\n\nFigure¬†6.5: The reddish, purple observation does not fit the trend.\n\n\n\n\n\nRemember, we identify potential outliers because they have extreme values (either high or low) relative to the other observations in the data. In a scatterplot, there are now two dimensions that an observation can be extreme on:\n\nA potential outlier might have an extreme x-value.\nA potential outlier might have an extreme y-value.\nA potential outlier might have both an extreme x-value and an extreme y-value.\n\nWhen we identify potential outliers, we do so by referencing their coordinates in the scatterplot. For example, to describe the reddish, purple observation that is a potential outlier in Figure¬†6.5, we might say,\n\nThe observation with the coordinates (6, 17) is a potential outlier. This observation has a very large y-value relative to the other observations in the data.\n\n\n\n\n6.3.6 Back to the Example\nLet‚Äôs return to the scatterplot showing the relationship between education level and income and use what we have learned to describe that relationship using the context of the data.\n\nggplot(data = city, aes(x = education, y = income)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Education (in years)\") +\n  ylab(\"Income (in U.S. dollars)\")\n\n\n\n\nScatterplot displaying the relationship between employee education levels and incomes.\n\n\n\n\nThe scatterplot suggests that there is a positive, linear relationship between education level and income for the 32 employees in our sample. This suggests that employees that have higher education levels tend to also have higher incomes. The magnitude of the relationship seems large as the slope of the relationship seems quite steep, indicating that even small changes in education level are associated with a big change in income. This relationship seems moderately strong, with the data clustered somewhat close to the line that describes this relationship. Lastly, there do not seem to be any potential outliers or extreme observations in the data.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Data Exploration for Regression</span>"
    ]
  },
  {
    "objectID": "02-01-data-exploration-for-regression.html#plot-scale-and-human-perception",
    "href": "02-01-data-exploration-for-regression.html#plot-scale-and-human-perception",
    "title": "6¬† Data Exploration for Regression",
    "section": "6.4 Plot Scale and Human Perception",
    "text": "6.4 Plot Scale and Human Perception\nOne issue that arises when we describe the magnitude and strength of the relationship is that our guesstimate for both the magnitude of the effect and the strength of the relationship can be influenced by the x- and y-scale on our scatterplot. To illustrate this, Figure¬†6.6 shows a plot of the relationship between education level and income data with two different scales on the axes.\n\n\n\n\n\n\n\n\nFigure¬†6.6: The two plots show the exact same data plotted using different scales on the x- and y-axis. This difference in scales can influence how we perceive both the magnitude and the strength of the relationship.\n\n\n\n\n\nIn the right-hand graph of Figure¬†6.6, we may perceive a stronger relationship than in the left-hand graph. We would also perceive that the magnitude of the effect (i.e., the slope of the linear function) is larger, that is the line looks steeper. This is problematic as the strength of the relationship is exactly the same in both graphs as it is the same data that is plotted.\nBecause of this, we often compute and report a numerical summary measures to quantify both the strength and the magnitude of the relationship. These measures are useful as they are not impacted by the scale we use to plot the data. In the next chapter, you will learn how to quantify the magnitude of the effect and the strength of the linear relationship.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Data Exploration for Regression</span>"
    ]
  },
  {
    "objectID": "02-02-simple-regression-and-correlation.html",
    "href": "02-02-simple-regression-and-correlation.html",
    "title": "7¬† Simple Linear Regression and Correlation",
    "section": "",
    "text": "7.1 Statistical Model: Expressing the Relationship in a Mathematical Equation\nTo fit a regression model to the data, we need to use the functional form of the relationship to write a mathematical description (i.e., an equation) of how employees‚Äô education levels are related to their incomes. This description is referred to as the statistical model. Since the relationship‚Äôs functional form seems reasonably linear, we will use a linear model to describe the data. We can express this model mathematically as,\n\\[\n\\text{Income}_i = \\beta_0 + \\beta_1(\\text{Education Level}_i) + \\epsilon_i\n\\] In this equation,\nThe general form of the simple linear regression model is:\n\\[\nY_i = \\beta_0 + \\beta_1(X_i) + \\epsilon_i\n\\]\nIn this equation,\nThe linear statistical model (i.e., the regression model) can be separated into two components: a systematic (or fixed) component and a random (or stochastic) component.\n\\[\nY_i = \\underbrace{\\beta_0 + \\beta_1(X_i)}_{\\substack{\\text{Systematic} \\\\ \\text{(Fixed)}}} + \\underbrace{\\epsilon_i}_{\\substack{\\text{Random} \\\\ \\text{(Stochastic)}}}\n\\]",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Simple Linear Regression and Correlation</span>"
    ]
  },
  {
    "objectID": "02-02-simple-regression-and-correlation.html#statistical-model-expressing-the-relationship-in-a-mathematical-equation",
    "href": "02-02-simple-regression-and-correlation.html#statistical-model-expressing-the-relationship-in-a-mathematical-equation",
    "title": "7¬† Simple Linear Regression and Correlation",
    "section": "",
    "text": "\\(\\text{Income}_i\\) is an employee‚Äôs income; it has an i subscript because it can vary across employees.\n\\(\\beta_0\\) is the intercept of the line that best fits the data; it does not vary across employees, so it has no i subscript.\n\\(\\beta_1\\) is the slope of the line that best fits the data; it does not vary across employees, so again there is no i subscript.\n\\(\\text{Education Level}_i\\) is the education level for an employee; it has an i subscript because it can vary across employees.\n\\(\\epsilon_i\\) is the error term; it has an i subscript because it can vary across employees.\n\n\n\n\n\n\\(Y_i\\) is the outcome/response value.\n\\(\\beta_0\\) is the intercept of the line that best fits the data.\n\\(\\beta_1\\) is the slope of the line that best fits the data.\n\\(X_i\\) is the predictor value.\n\\(\\epsilon_i\\) is the error term.\n\n\n\n\n\n7.1.1 Systematic Part of the Statistical Model\nThe systematic (fixed) part of the equation gives the mean value of Y given a particular X-value. The mean of Y given a particular X-value is referred to as a conditional mean of Y. The notation for the conditional mean of Y given a particular X value is \\(\\mu_{Y \\vert X_i}\\). We express the systematic part of the linear regression model mathematically as,\n\\[\n\\mu_{Y \\vert X_i} = \\beta_0 + \\beta_1(X_i)\n\\]\nIn our example, the systematic part of the model would produce the mean income for employees who have a particular education level. For example the mean income for all employees with an 8th-grade level of education, or the the mean income for all employees with a 10th-grade level of education.\nNote that the systematic part of the equation does not include the error term. The error term is a part of the random component of the model. Statisticians also use \\(\\hat{Y_i}\\) to indicate the conditional mean of Y at a particular X. Thus, the systematic part of the linear regression model can also be written as,\n\\[\n\\hat{Y_i} = \\beta_0 + \\beta_1(X_i)\n\\]\nThe terms \\(\\beta_0\\) and \\(\\beta_1\\) in the systematic part of the model are referred to as the regression parameters. One of the primary goals of a regression analysis is to estimate the values of the regression parameters (i.e., the intercept and slope terms). Thus the systematic part of the regression model is a description, in mathematical form, of how the conditional mean Y is related to X. The equation here indicates that the conditional mean of Y (\\(\\hat{Y_i}\\)) is a linear function of X. This implies that the conditional mean value of Y differs by a constant amount for a constant difference in X.\nFor example, the difference between the mean income for those employees who have 10 years of education and those that have 11 years of education is the same as the difference between the mean income for those employees who have 17 years of education and those that have 18 years of education. Or, the difference between the mean income for those employees who have 4 years of education and those that have 8 years of education is the same as the difference between the mean income for those employees who have 20 years of education and those that have 24 years of education.\n\n\n\n7.1.2 Visual Representation of the Regression Model\nTo help better understand the model, consider the following plot:\n\n\n\n\n\nPlot displaying conditional distribution of Y at several X values. The OLS fitted regression line (dotted) is also shown. The red points show the mean value of Y for each conditional distribution.\n\n\n\n\nAt each value of X there is a distribution of Y. For example, there would be a distribution of incomes for the employees with an education level of 10 years (in the population). There would be another distribution of incomes for the employees with an education level of 11 years (in the population). And so on. These are the conditional distributions of Y.\nEach conditional distribution of Y has a mean; the conditional mean or \\(\\hat{Y_i}\\). These conditional means can be connected using a line. This is what it means to be able to express the conditional mean of Y as a linear function of X, or to say that the relationship between X and Y is linear.\n\n\n\n7.1.3 Random Part of the Statistical Model\nFrom the visual representation of the model, we can see that there is a distribution of Y-values at each X-value; this is represented by the normal distributions in the picture. In our example, there are many employees who have the same education level, but have different incomes. The error term in the statistical model accounts for this variation in Y for those cases that have the same X-value. Mathematically we can understand this by re-writing the statistical model, substituting \\(\\mu_{Y \\vert X_i}\\) into the systematic part of the model.\n\\[\n\\begin{split}\nY_i &= \\beta_0 + \\beta_1(X_i) + \\epsilon_i \\\\\nY_i &= \\mu_{Y \\vert X_i} + \\epsilon_i\n\\end{split}\n\\]\nThis equation implies that each observed Y-value is the sum of the conditional mean value of Y (which is based on the X-value) and some residual (or error) term. Re-arranging the terms, we can mathematically express the residual term as,\n\\[\n\\epsilon_i = Y_i - \\mu_{Y \\vert X_i}\n\\]\nOr, using the \\(\\hat{Y_i}\\) notation,\n\\[\n\\epsilon_i = Y_i - \\hat{Y_i}\n\\]\nTo compute an observation‚Äôs residual, we compute the difference between the observation‚Äôs Y-value and its conditional mean value. When the observed value of Y is larger than the conditional mean value of Y the residual term will be positive (underprediction). If the observed value of Y is smaller than the conditional mean value of Y the residual term will be negative (overprediction).\nTo further understand the residual term, consider the plot below. This figure shows the relationship between education and income we plotted earlier, and also includes the regression line.\n\n\n\n\n\nScatterplot displaying the relationship between employee education levels and incomes. The OLS fitted regression line is also displayed.\n\n\n\n\nConsider the three employees that have an education level of 10 years. The conditional mean income for these three employees is approximately $37,800. This is denoted by the blue point. Remember, the conditional means are on the regression line. The error (residual) term allows for a discrepancy between the conditional mean of Y and the observed Y. In other words, none of these three employees have an actual income of $37,800. The residual represents the difference between the employee‚Äôs observed income and the conditional mean income based on their education level.\nGraphically, the residual is represented by the vertical distance between the line and a given point on the scatterplot. Some of those points are above the line (they have a positive residual) and some are below the line (they have a negative residual). Also note that for some observations the error term is smaller than for others.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Simple Linear Regression and Correlation</span>"
    ]
  },
  {
    "objectID": "02-02-simple-regression-and-correlation.html#estimating-parameters-in-the-regression-model",
    "href": "02-02-simple-regression-and-correlation.html#estimating-parameters-in-the-regression-model",
    "title": "7¬† Simple Linear Regression and Correlation",
    "section": "7.2 Estimating Parameters in the Regression Model",
    "text": "7.2 Estimating Parameters in the Regression Model\nThe regression model describes the relationship between Y-values and X-values in the population. Every term in the model denoted using a Greek letter is an unknown parameter in this model. In the model we have written there are three unknown parameters denoted in the model: the intercept term (\\(\\beta_0\\)), the slope term (\\(\\beta_1\\)), and the residual term (\\(\\epsilon_i\\)).1\nIn most statistical analyses, you will use a sample of data (not the entire population) to estimate the parameter values. Because a sample is only a subset of the population, the values we obtain for the parameters are imperfect estimates. To denote that the parameters are sample-based estimates, we add a hat to each parameter we are estimating. For example, estimates of the parameter estimates of \\(\\hat\\beta_0\\) and \\(\\hat\\beta_1\\) (referred to as regression coefficients) are typically reported in a regression analysis and should include hats.\nApplied researchers and statisticians tend to focus their analysis on the systematic (fixed) part of the model, and are thus often most interested in the values of the regression coefficients. After fitting the model to data, the estimated conditional means can be expressed mathematically as:\n\\[\n\\hat\\mu_{Y \\vert X_i} = \\hat\\beta_0 + \\hat\\beta_1(X_i)\n\\]\nOr, using the notation \\(\\hat{Y}_i\\) rather than \\(\\hat\\mu_{Y \\vert X_i}\\), as:\n\\[\n\\hat{Y_i} = \\hat\\beta_0 + \\hat\\beta_1(X_i)\n\\]\nWe use the hats when we are indicating sample-based estimates of these values, so hats should be used when you are reporting the values obtained after using a sample of data to obtain the values.2 The two estimated parameters of interest here (\\(\\hat\\beta_0\\) and \\(\\hat\\beta_1\\)) are referred to as the estimated regression coefficients, and this equation is often referred to as the fitted regression equation, or simply the fitted equation.\n\n\n7.2.1 Estimating Residuals\nNote that we can also use the estimated regression coefficients to obtain estimates for the residuals, often referred to as the observed residuals. Here we make use of the earlier idea that the residual term was the difference between the observed value of Y and the conditional mean of Y for a given X-value. Mathematically,\n\\[\n\\epsilon_i = Y_i - \\mu_{Y \\vert X_i}\n\\]\nOnce we use data to obtain estimates for the intercept and slope (\\(\\hat\\beta_0\\) and \\(\\hat\\beta_1\\)) we can substitute those into the fitted equation and obtain an estimate for the conditional mean (\\(\\hat{\\mu}_{Y \\vert X_i}\\)). This value can then be used to obtain an estimate for the residual.\n\\[\n\\hat\\epsilon_i = Y_i - \\hat{\\mu}_{Y \\vert X_i}\n\\]\nOr, using the ‚ÄúY-hat‚Äù notation,\n\\[\n\\hat\\epsilon_i = Y_i - \\hat{Y_i}\n\\]\nRemember, the hat on the residual indicates it is an estimate based on values obtained from the data!",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Simple Linear Regression and Correlation</span>"
    ]
  },
  {
    "objectID": "02-02-simple-regression-and-correlation.html#fitting-a-regression-model-to-data-using-r",
    "href": "02-02-simple-regression-and-correlation.html#fitting-a-regression-model-to-data-using-r",
    "title": "7¬† Simple Linear Regression and Correlation",
    "section": "7.3 Fitting a Regression Model to Data Using R",
    "text": "7.3 Fitting a Regression Model to Data Using R\nTo fit the regression model to data using R, we will use the lm() function. The syntax for this function looks like this:\n\nlm(outcome ~ 1 + predictor, data = dataframe)\n\nwhere outcome is the name of the outcome/response variable, predictor is the name of the predictor variable, and dataframe is the name of the data frame. (The 1 on the right side of the tilde tells R to include the intercept in its computation.) When we fit a regression model in R, we will also assign the output to a new object in R. Below, we fit the model using education level to predict income. Here the output is assigned to an object called lm.a. We can print the regression parameter estimates by typing the lm() object name and hitting enter.\n\n# Fit regression model\nlm.a = lm(income ~ 1 + education, data = city)\n\n# Print regression coefficients\nlm.a\n\n\nCall:\nlm(formula = income ~ 1 + education, data = city)\n\nCoefficients:\n(Intercept)    education  \n     11.321        2.651  \n\n\nHere the parameter estimates (or regression coefficients) are:\n\n\\(\\hat{\\beta}_0 = 11.321\\)\n\\(\\hat{\\beta}_1 = 2.651\\)\n\nRemember that these are estimates and need the hats. The systematic part of the fitted regression model (or fitted equation) is:\n\\[\n\\hat{\\mathrm{Income}_i} = 11.321 + 2.651(\\mathrm{Education~Level}_i)\n\\]\n\n\n7.3.1 Intercept Interpretation\nThe estimate for the intercept was 11.321. Graphically, this value indicates the value where the line passes through the Y-axis (i.e., Y-intercept). As such, it gives the \\(\\hat{Y}_i\\) or predicted value when \\(X=0\\). Algebraically we get the same thing if we substitute 0 in for \\(X_i\\) in the fitted regression equation.\n\\[\n\\begin{split}\n\\hat{Y}_i &= \\hat{\\beta}_0 + \\hat{\\beta}_1(0) \\\\\n\\hat{Y}_i &= \\hat{\\beta}_0\n\\end{split}\n\\]\nTo interpret this value, remember that \\(\\hat{Y}_i\\) is a conditional mean. In this case, it represents the model predicted mean income for all employees that have an education level of 0 years. Graphically this looks like the following.\n\n\n\n\n\n\n\n\nFigure¬†7.1: Plot displaying conditional distribution of Y at \\(X=0\\). The OLS fitted regression line (dotted) is also shown. The red points show the mean value of Y for this conditional distribution‚Äîwhich corresponds to the intercept value of the regression line.\n\n\n\n\n\nInterpreting the intercept coefficient from our example,\n\nThe model predicted mean income for all employees that have an education level of 0 years is $11,321.\n\n\nWhen interpreting the intercept, beware of extrapolation. Extrapolation is making a prediction outside of the range of the data used to fit the model. For example, in our interpretation, we are making a prediction of the mean income for emplyees that have an education level of 0 years. The smallest education level in our data is 8 years. Because 0 is outside the range of our data, this prediction is an extrapolation. The problem with extrapolation is that we don‚Äôt know if the relationship continues to be linear outside the range of our data. If it isn‚Äôt linear, then the prtediction we make will be quite errant.\n\n\n\n\n7.3.2 Slope Interpretation\nRecall from algebra that the slope of a line describes the change in Y versus the change in X. In regression, the slope describes the predicted change in \\(\\hat{Y}\\) for a one-unit difference in X. In our example,\n\\[\n\\hat{\\beta}_1 = \\frac{\\Delta\\hat{Y}}{\\Delta X} = \\frac{2.651}{1}\n\\]\nAgain, because \\(\\hat{Y}\\) is a conditional mean, the slope represents the difference in predicted mean incomes for each one-year difference in education level. Graphically,\n\n\n\n\n\nPlot displaying conditional distribution of Y at \\(X=0\\) and \\(X=1\\). The OLS fitted regression line (dotted) is also shown. The red points show the mean value of Y for these conditional distributions‚Äîthe relative change which corresponds to the slope value of the regression line.\n\n\n\n\nInterpreting the slope coefficient in our example,\n\nEach one-year difference in education level is associated with a model predicted difference of $2,651 in mean income.\n\nTo better understand this, consider the mean income for city employees with three different education levels. The first set of employees have an education level of 10 years. The second set has an education level of 11 years, and the third set has an education level of 12 years. Now let‚Äôs compute each set of employees‚Äô mean income using the estimated regression coefficients.\n\\[\n\\begin{split}\n\\mathbf{Education=10:~}\\hat{\\mathrm{Income}} &= 11.321 + 2.651(10) \\\\\n&= 37.831\n\\end{split}\n\\]\n\\[\n\\begin{split}\n\\mathbf{Education=11:~}\\hat{\\mathrm{Income}} &= 11.321 + 2.651(11) \\\\\n&= 40.482\n\\end{split}\n\\]\n\\[\n\\begin{split}\n\\mathbf{Education=12:~}\\hat{\\mathrm{Income}} &= 11.321 + 2.651(12) \\\\\n&= 43.133\n\\end{split}\n\\]\nEach set of employees‚Äô education levels differ by one year (10 to 11 to 12). The difference in predicted mean incomes for these employees differs by 2.651 thousand dollars.\n\n\n\n7.3.3 Estimating Residuals\nConsider the 25th case in the data frame.\n\ncity |&gt;\n  filter(row_number() == 25)\n\n\n  \n\n\n\nThis employee (Employee 25) has an education level of 20 years (\\(X_{25}=20\\)). Her income is 54.672 thousand dollars (\\(Y_{25}=54.672\\)). Using the fitted regression equation, we can compute the model predicted mean income for employees with 20 years of education as,\n\n# Y_hat = b0 + b1 * X\n11.321 + 2.651 * 20\n\n[1] 64.341\n\n\n\\[\n\\hat{Y}_{25} = 64.341\n\\]\nWe could also report this using the conditional mean notation,\n\\[\n\\hat\\mu_{Y \\vert X=20} = 64.341\n\\]\nNow we can use the estimated conditional mean to also compute Employee 25‚Äôs residual.\n\n# e = Y - Y_hat\n54.672 - 64.341\n\n[1] -9.669\n\n\nUsing mathematical notation,\n\\[\n\\hat\\epsilon_{25} = -9.669\n\\]\nThe negative residual, \\(\\hat\\epsilon_{25} = -9.669\\), suggests that this employee earns $9,669 less than the average predicted income for employees with 20 years of education. We can also represent these values graphically.\n\n\n\n\n\nPlot displaying the OLS fitted regression line (blue) between employee education levels and incomes. The 25th employee‚Äôs observed data (black dot) is plotted, and a visual representation of the employee‚Äôs residual (red line) is also displayed.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Simple Linear Regression and Correlation</span>"
    ]
  },
  {
    "objectID": "02-02-simple-regression-and-correlation.html#correlation-quantifying-the-strength-of-the-relationship",
    "href": "02-02-simple-regression-and-correlation.html#correlation-quantifying-the-strength-of-the-relationship",
    "title": "7¬† Simple Linear Regression and Correlation",
    "section": "7.4 Correlation: Quantifying the Strength of the Relationship",
    "text": "7.4 Correlation: Quantifying the Strength of the Relationship\nThe correlation coefficient is a numerical summary of the strength of a linear relationship. To compute the correlation coefficient, we use the correlate() function from the {corrr} package. We can use the dplyr-type syntax to select the variables we want correlations between, and then pipe that into the correlate() function.\nFor example, to compute the correlation coefficient between education levels and incomes, we use the following syntax:\n\ncity |&gt;\n  select(income, education) |&gt;\n  correlate()\n\n\n  \n\n\n\n\nThe order of attributes in the select() function is irrelevant. However, typically the response (or outcome) variable is the first variable provided in the select() function, followed by the predictor.\n\nThe correlation between education level and income is 0.795. Mathematically we use the lower-case letter ‚Äúr‚Äù to indicate a correlation. In our example,\n\\[\nr_{\\text{Education Level, Income}} = 0.795\n\\]\nAs we interpret the value of a correlation coefficient, keep in mind the following properties:\n\nCorrelation has no units, it is just a value.\nCorrelation coefficients always fall between \\(-1\\) and \\(+1\\), that is \\(-1 \\leq r \\leq +1\\).\nThe sign of the correlation coefficient (positive or negative) indicates the direction of the relationship.\n\nThe size of the correlation coefficient gives us an indication of the strength of the relationship. Here are some guidelines to help you think about the strength of the relationship:\n\nA value of 0 would indicate no relationship.\nValues around \\(-0.2\\) or \\(+0.2\\) might indicate a weak linear relationship.\nValues around \\(-0.5\\) or \\(+0.5\\) might indicate a moderate linear relationship.\nValues around \\(-0.8\\) or \\(+0.8\\) might indicate a strong linear relationship.\nValues of \\(-1\\) or \\(+1\\) indicate a perfect linear relationship (super-duper strong).\n\n\nThese guidelines may or may not be useful. You really have to know the substantive literature in your discipline to know for sure what values indicate a strong or weak relationship. For example, in the educational sciences most of the relationships we see with educational outcomes (e.g., GPA, test scores) have correlation values that are less than 0.4. So \\(r \\approx 0.5\\) would often be considered a strong relationship.\n\nReturning to our example, the correlation coefficient of 0.795 indicates a strong linear relationship between education level and incomes. The positive value of the correlation coefficient also indicates that the relationship between education level and income is positive. That is, employess with higher education levels also tend to have higher incomes.\n\n\n7.4.1 Correlation Only Measures a Linear Relationship\nIt is important to keep in mind that the correlation coefficient is only useful as a measure of the strength of the relationship when the relationship between variables is linear. Here is an example where the correlation coefficient would be misleading about the strength of the relationship.\n\n\n\n\n\n\n\n\nFigure¬†7.2: Hours of daylight versus day of the year for \\(n=75\\) days in Minneapolis.\n\n\n\n\n\nHere there is a perfect relationship between day of the year and hours of daylight. If you fitted a nonlinear model here, your ‚Äúline‚Äù would match the data exactly (no residual error!). But the correlation coefficient does not reflect that. The correlation coefficient would suggest that the relationship between day of the year and hours of daylight is weak (\\(r=-0.34\\)).\nAnother situation in which correlation can mislead is when you have subpopulations in your data. Here is an example of that.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.3: Salary versus neuroticism (0 = not at all neurotic; 7= very neurotic) as measured by the Big Five personality survey for \\(n=1000\\) employees from a Fortune 500 company.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.4: Salary versus neuroticism (0 = not at all neurotic; 7= very neurotic) as measured by the Big Five personality survey for \\(n=1000\\) employees from a Fortune 500 company. The data are colored by education level.\n\n\n\n\n\n\n\nIf we treat these data as one population (an assumption for using the correlation) the relationship between neurotocism and salary is positive; employees who are more neurotic tend to have higher salaries, on average. However, if we account for education level, the relationship between neurotocism and salary is negative for each of the education levels; once we account for education level, employees who are more neurotic tend to have lower salaries, on average. This reversal of the direction of the relationship once we account for other variables is quite common (so common it has a name, Simpson‚Äôs Paradox) and makes it difficult to be sure about the ‚Äútrue‚Äù relationship between variables in observational data.\n\nYou should always create a scatterplot to examine the relationship graphically before computing a correlation coefficient to numerically summarize it.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Simple Linear Regression and Correlation</span>"
    ]
  },
  {
    "objectID": "02-02-simple-regression-and-correlation.html#answering-the-research-question",
    "href": "02-02-simple-regression-and-correlation.html#answering-the-research-question",
    "title": "7¬† Simple Linear Regression and Correlation",
    "section": "7.5 Answering the Research Question",
    "text": "7.5 Answering the Research Question\nRemember that this whole analysis was driven because we wanted to answer a question, namely whether education level is related to income for the Riverview employees. The results from the regression analysis allow us to answer this question.\n\nTo answer the question of whether education level is related to income, a linear regression model was fitted to the data using ordinary least squares estimation. The results of this analysis suggested that education level is positively related to income for the 32 employees (\\(\\hat\\beta_1 = 2.65\\)). Each year of education is associated with a $2,651 difference in income, on average. Additionally, the evidence suggests that this relationship is quite strong (\\(r=0.795\\)).\n\nHere the regression analysis provides a quantitative summary of the relationship between education level and income. It provides us with information about the direction of the relationship (positive) and the magnitude of that relationship. The correlation coefficient adds to this description by helping quantify the strength of the relationship.\nAlthough these metrics can give us a description of the relationship, it is only for the sample of data you looked at (i.e., for these 32 employees). To make further statements about whether there is a relationship between education level and income in a broader population (e.g., all Riverview employees, or all California residents), we need more information, namely whether the sample is representative of the larger population and also statistical information about the amount of sampling error we have. (We will cover sampling error in Chapter 5.)",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Simple Linear Regression and Correlation</span>"
    ]
  },
  {
    "objectID": "02-02-simple-regression-and-correlation.html#optional-effect-of-the-predictor-calculus-edition",
    "href": "02-02-simple-regression-and-correlation.html#optional-effect-of-the-predictor-calculus-edition",
    "title": "7¬† Simple Linear Regression and Correlation",
    "section": "Optional: Effect of the Predictor (Calculus Edition)",
    "text": "Optional: Effect of the Predictor (Calculus Edition)\nThe slope is often referred to as the effect of the predictor, and mathematically indicates the rate-of-change in the outcome as the predictor changes. How much does the outcome change for a one-unit change in the predictor? The way that mathematicians measure the rate-of-change is by computing the derivative of a function. In a simple regression, we would compute the derivative of the fitted equation:\n\\[\n\\textrm{rate-of-change} = \\frac{\\partial}{\\partial x} \\quad \\hat{\\beta}_0 + \\hat{\\beta}_1(x)\n\\]\nIn our example,\n\\[\n\\begin{split}\n\\textrm{rate-of-change} &=\\frac{\\partial}{\\partial \\text{education}} \\quad 11.32 + 2.65(\\text{education}) \\\\[2ex]\n&= 2.65\n\\end{split}\n\\]\nIn a linear function, the rate-of-change is the slope of the line.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Simple Linear Regression and Correlation</span>"
    ]
  },
  {
    "objectID": "02-02-simple-regression-and-correlation.html#footnotes",
    "href": "02-02-simple-regression-and-correlation.html#footnotes",
    "title": "7¬† Simple Linear Regression and Correlation",
    "section": "",
    "text": "Technically there are many unknown residuals, one for each case, but the assumptions we put on the linear model make it so that we only care about the variance of the residuals, hence a single unknown.‚Ü©Ô∏é\nSometimes people use Roman letters when referring to sample estimates rather than hatting the Greek letters. For example, the sample-based equation might be denoted: \\(\\hat{Y}_i = b_0 + b_1(X_i) + e_i\\).‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Simple Linear Regression and Correlation</span>"
    ]
  },
  {
    "objectID": "02-03-ols-estimation.html",
    "href": "02-03-ols-estimation.html",
    "title": "8¬† Ordinary Least Squares (OLS) Estimation",
    "section": "",
    "text": "8.1 Ordinary Least Squares Estimation\nHow does R determine the coefficient values of \\(\\hat{\\beta}_0=11.321\\) and \\(\\hat{\\beta}_1=2.651\\)? These values are estimated from the data using a method called Ordinary Least Squares (OLS). To understand how OLS works, consider the following toy data set of five observations:\nTable¬†8.1: Toy data set with predictor (X) and outcome (Y) for five observations.\n\n\n\n\n\n  \n  \n\n\n\nXi\nYi\n\n\n\n\n30\n63\n\n\n10\n44\n\n\n30\n40\n\n\n50\n68\n\n\n20\n25\nWhich of the following two models fits these data better?\nWe could plot the data and both lines and try to determine which seems to fit better.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Ordinary Least Squares (OLS) Estimation</span>"
    ]
  },
  {
    "objectID": "02-03-ols-estimation.html#ordinary-least-squares-estimation",
    "href": "02-03-ols-estimation.html#ordinary-least-squares-estimation",
    "title": "8¬† Ordinary Least Squares (OLS) Estimation",
    "section": "",
    "text": "Model A: \\(~~\\hat{Y_i} = 28 + 0.8(X_i)\\)\nModel B: \\(~~\\hat{Y_i} = 20 + 1(X_i)\\)\n\n\n\n\n\n\n\n\n\n\n\n\nScatterplot of the observed toy data and the OLS fitted regression line for Model A.\n\n\n\n\n\n\n\n\n\nScatterplot of the observed toy data and the OLS fitted regression line for Model B.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Ordinary Least Squares (OLS) Estimation</span>"
    ]
  },
  {
    "objectID": "02-03-ols-estimation.html#datamodel-fit",
    "href": "02-03-ols-estimation.html#datamodel-fit",
    "title": "8¬† Ordinary Least Squares (OLS) Estimation",
    "section": "8.2 Data‚ÄìModel Fit",
    "text": "8.2 Data‚ÄìModel Fit\nIn this case, the lines are similar and it is difficult to make a determination of which fits the data better by eyeballing the two plots. Instead of guessing which model fits better, we can actually quantify the fit for the data by computing the residuals (errors) for each model and then comparing both sets of residuals; larger errors indicate a worse fitting model (i.e., more misfit to the data).\nRemember, to compute the residuals, we will first need to compute the predicted value (\\(\\hat{Y}_i\\)) for each of the five observations for both models.\n\n\n\nTable¬†8.2: Observed values, predicted values and residuals for Model A.\n\n\n\n\n  \n  \n\n\n\nXi\nYi\nYÃÇi\nŒµÃÇi\n\n\n\n\n30\n63\n52\n11\n\n\n10\n44\n36\n8\n\n\n30\n40\n52\n-12\n\n\n50\n68\n68\n0\n\n\n20\n25\n44\n-19\n\n\n\n\n\n\n\n\n\n\n\n\nTable¬†8.3: Observed values, predicted values and residuals for Model B.\n\n\n\n\n  \n  \n\n\n\nXi\nYi\nYÃÇi\nŒµÃÇi\n\n\n\n\n30\n63\n50\n13\n\n\n10\n44\n30\n14\n\n\n30\n40\n50\n-10\n\n\n50\n68\n70\n-2\n\n\n20\n25\n40\n-15\n\n\n\n\n\n\n\n\n\nEyeballing the numeric values of the residuals is also problematic. The size of the residuals is similar for both Models. Also, the eyeballing method would be impractical for larger datasets. So, we have to further quantify the model fit (or misfit). The way we do that in practice is to consider the total amount of error across all the observations. Unfortunately, we cannot just sum the residuals to get the total because some of our residuals are negative and some are positive. To alleviate this problem, we first square the residuals, then we sum them.\n\\[\n\\begin{split}\n\\mathrm{Total~Error} &= \\sum\\hat{\\epsilon}_i^2 \\\\\n&= \\sum \\left( Y_i - \\hat{Y}_i\\right)^2\n\\end{split}\n\\]\nThis is called a sum of squared residuals or sum of squared error (SSE; good name, isn‚Äôt it). Computing the squared residuals for Model A and Model B we get:\n\n\n\nTable¬†8.4: Observed values, predicted values, residuals, and squared residuals for Model A.\n\n\n\n\n  \n  \n\n\n\nXi\nYi\nYÃÇi\nŒµÃÇi\nŒµÃÇi2\n\n\n\n\n30\n63\n52\n11\n121\n\n\n10\n44\n36\n8\n64\n\n\n30\n40\n52\n-12\n144\n\n\n50\n68\n68\n0\n0\n\n\n20\n25\n44\n-19\n361\n\n\n\n\n\n\n\n\n\n\n\n\nTable¬†8.5: Observed values, predicted values, residuals, and squared residuals for Model B.\n\n\n\n\n  \n  \n\n\n\nXi\nYi\nYÃÇi\nŒµÃÇi\nŒµÃÇi2\n\n\n\n\n30\n63\n50\n13\n169\n\n\n10\n44\n30\n14\n196\n\n\n30\n40\n50\n-10\n100\n\n\n50\n68\n70\n-2\n4\n\n\n20\n25\n40\n-15\n225\n\n\n\n\n\n\n\n\n\nSumming these squared values for each model we obtain:\n\nModel A: SSE = 690\nModel B: SSE = 694\n\nOnce we have quantified the model misfit, we can choose the model that has the least amount of error. Since Model A has a lower SSE than Model B, we would conclude that Model A is the better fitting model to the data.\n\n\n8.2.1 Visualizing the SSE\nTo further understand the sum of squared error, we can examine a visual representation of the SSE for Model A. Recall that visually, the residual is the vertical distance between an observation and the fitted value (which lie on the fitted line). The residual indicates how different these two quantities are on the Y-metric. In the formula we squared each of the residuals. Visually, this is equivalent to producing the area of a square that has a side length equal to the absolute value of the residual.\n\n\n\n\n\n\n\n\n\nThis plot visually displays the residual values as line segments with negative residuals shown as dashed lines.\n\n\n\n\n\n\n\n\n\nThis plot visually displays the squared residuals as the area of a square with side length equal to the absolute value of the residual.\n\n\n\n\n\n\n\nFigure¬†8.1: Scatterplot of the observed toy data and the OLS fitted regression line for Model A.\n\n\n\nThe SSE is simply the total area encompassed by all of the squares. Note that the observation that is directly on the line has a residual of 0 and thus does not contribute a quantity to the SSE. If you computed the SSE for a line with different intercept or slope values, the SSE will be different. The plot below shows what this might look like for the flat line produced by \\(~~\\hat{Y_i} = 50\\).\n\n\n\n\n\nScatterplot of the observed toy data and the fitted flat line with Y-intercept of 50. The plot visually shows the squared residuals as the area of a square with side length equal to the absolute value of the residual.\n\n\n\n\nPowell & Lehe (2015) created an interactive website to help understand how the SSE is impacted by changing the intercept or slope of a line. You can also see how individual observations impact the SSE value.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Ordinary Least Squares (OLS) Estimation</span>"
    ]
  },
  {
    "objectID": "02-03-ols-estimation.html#best-fitting-model",
    "href": "02-03-ols-estimation.html#best-fitting-model",
    "title": "8¬† Ordinary Least Squares (OLS) Estimation",
    "section": "8.3 ‚ÄúBest‚Äù Fitting Model",
    "text": "8.3 ‚ÄúBest‚Äù Fitting Model\nIn the vocabulary of statistical estimation, the process we just used to adopt Model A over Model B was composed of two parts:\n\nQuantification of Model Fit: We quantify how well (or not well) the estimated model fits the data; and\nOptimization: We find the ‚Äúbest‚Äù model based on that quantification. (This boils down to finding the model that produces the biggest or smallest measure of model fit.)\n\nIn our example we used the SSE as the quantification of model fit, and then we optimized by selecting the model with the lower SSE. When we use lm() to fit a regression analysis to the data, R needs to consider not just two models like we did in our example, but all potential models (i.e., any intercept and slope). The model coefficients that lm() returns are the ‚Äúbest‚Äù in that no other values for intercept or slope would produce a lower SSE. The model returned has the lowest SSE possible thus least squares. For our toy dataset, the model that produces the smallest residuals is\n\\[\n\\hat{Y}_i = 28.682 + 8.614(X_i)\n\\]\nThis model gives the following predicted values and residuals:\n\n\n\nTable¬†8.6: Observed values, predicted values, residuals, and squared residuals for the ‚Äòbest‚Äô fitting model.\n\n\n\n\n  \n  \n\n\n\nXi\nYi\nYÃÇi\nŒµÃÇi\nŒµÃÇi2\n\n\n\n\n30\n63\n49.61364\n13.386364\n179.1947\n\n\n10\n44\n33.47727\n10.522727\n110.7278\n\n\n30\n40\n49.61364\n-9.613636\n92.4220\n\n\n50\n68\n65.75000\n2.250000\n5.0625\n\n\n20\n25\n41.54545\n-16.545455\n273.7521\n\n\n\n\n\n\n\n\n\nThe SSE is 661.16. This is the smallest SSE possible for a linear model. Any other value for the slope or intercept would result in a higher SSE.\n\n\n8.3.1 Mathematical Optimization\nFinding the intercept and slope that give the lowest SSE is referred to as an optimization problem in the field of mathematics. Optimization is such an important (and sometimes difficult) problem that there have been several mathematical and computational optimization methods that have been developed over the years. You can read more about mathematical optimization on Wikipedia if you are interested.\nOne common mathematical method to find the minimum SSE involves calculus. We would write the SSE as a function of\\(\\beta_0\\) and \\(\\beta_1\\), compute the partial derivatives (w.r.t. each of the coefficients), set these equal to zero, and solve to find the values of the coefficients.  The lm() function actually uses an optimization method called QR decomposition to obtain the regression coefficients. The actual mechanics and computation of these methods are beyond the scope of this course. We will just trust that the lm() function is doing things correctly in this course.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Ordinary Least Squares (OLS) Estimation</span>"
    ]
  },
  {
    "objectID": "02-03-ols-estimation.html#computing-the-sse-for-the-model-fitted-to-the-riverview-data",
    "href": "02-03-ols-estimation.html#computing-the-sse-for-the-model-fitted-to-the-riverview-data",
    "title": "8¬† Ordinary Least Squares (OLS) Estimation",
    "section": "8.4 Computing the SSE for the Model Fitted to the Riverview Data",
    "text": "8.4 Computing the SSE for the Model Fitted to the Riverview Data\nSince the regression model is based on the lowest SSE, it is often useful to compute and report the model‚Äôs SSE. We can use R to compute the SSE by carrying out the computations underlying the formula for SSE. Recall that the SSE is\n\\[\n\\mathrm{SSE} = \\sum \\left( Y_i - \\hat{Y}_i\\right)^2\n\\]\nWe need to compute the:\n\nPredicted values (\\(\\hat{Y}_i\\));\nResiduals (\\(e_i\\));\nSquared residuals (\\(e_i^2\\)); and finally,\nSum of the squared residuals (\\(\\sum e_i^2\\)).\n\nFrom the Riverview data set we have the observed X (education level) and Y (income) values, and from the fitted lm() we have the intercept and slope estimates for the ‚Äòbest‚Äô fitting regression model.\n\n# Compute the SSE\ncity |&gt;\n  mutate(\n    y_hat = 11.321 + 2.651 * education,  # Step 1: Compute the predicted values of Y\n    errors = income - y_hat,             # Step 2: Compute the residuals\n    sq_errors = errors ^ 2               # Step 3: Compute the squared residuals\n  ) |&gt;\n  summarize(\n    SSE = sum(sq_errors)                 # Step 4: Compute the sum of the squared residuals\n  )\n\n\n  \n\n\n\nThe SSE gives us information about the variation in Y (the outcome variable) that is left over (residual) after we fit the regression model. Since the regression model is a function of X, the SSE tells us about the variation in Y that is left over after we remove the variation associated with, or accounted for by X. In our example it tells us about the residual variation in incomes after we account for employee education level.\n\nIn practice, we often report the SSE, but we do not interpret the actual value. The value of the SSE is more useful when comparing models that have been fitted using the same outcome. When researchers are considering different models, the SSEs from these models are compared to determine which model produces the least amount of misfit to the data (similar to what we did earlier).",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Ordinary Least Squares (OLS) Estimation</span>"
    ]
  },
  {
    "objectID": "02-03-ols-estimation.html#references",
    "href": "02-03-ols-estimation.html#references",
    "title": "8¬† Ordinary Least Squares (OLS) Estimation",
    "section": "8.5 References",
    "text": "8.5 References\n\n\n\n\nPowell, V., & Lehe, L. (2015). Ordinary least squares regression: Explained visually. Explained Visually: A Setosa Project. https://setosa.io/ev/ordinary-least-squares-regression/",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Ordinary Least Squares (OLS) Estimation</span>"
    ]
  },
  {
    "objectID": "02-04-anova-decomposition.html",
    "href": "02-04-anova-decomposition.html",
    "title": "9¬† ANOVA Decomposition and \\(R^2\\)",
    "section": "",
    "text": "9.0.1 Evaluating the Impact of a Predictor Using SSE\nConsider again the general equation for the statistical model that includes a single predictor,\n\\[\nY_i = \\beta_0 + \\beta_1(X_i) + \\epsilon_i\n\\]\nOne way that statisticians evaluate a predictor is to compare a model that includes that predictor to the same model that does not include that predictor. For example, comparing the following two models allows us to evaluate the impact of \\(X_i\\).\n\\[\n\\begin{split}\nY_i &= \\beta_0 + \\beta_1(X_i) + \\epsilon_i \\\\\nY_i &= \\beta_0 + \\epsilon_i\n\\end{split}\n\\]\nThe second model, without the effect of X, is referred to as the intercept-only model. This model implies that the value of Y is not a function of X. In our example it suggests that the mean income is not conditional on education level. The fitted equation,\n\\[\n\\hat{Y}_i = \\hat{\\beta}_0\n\\]\nindicates that the predicted Y would be the same (constant) regardless of what X is. In our example, this would be equivalent to saying that the mean income is the same, regardless of employee education level.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>ANOVA Decomposition and $R^2$</span>"
    ]
  },
  {
    "objectID": "02-04-anova-decomposition.html#anova-decomposition-partitioning-variation-into-sum-of-squares",
    "href": "02-04-anova-decomposition.html#anova-decomposition-partitioning-variation-into-sum-of-squares",
    "title": "9¬† ANOVA Decomposition and \\(R^2\\)",
    "section": "9.1 ANOVA Decomposition: Partitioning Variation into Sum of Squares",
    "text": "9.1 ANOVA Decomposition: Partitioning Variation into Sum of Squares\nUsing the SSE terms we can partition the total variation in Y (the SSE value from the intercept-only model) into two parts: (1) the part that is explained by the model, and (2) the part that remains unexplained. The unexplained variation is just the SSE from the regression model that includes X; remember it is residual variation. Here is the partitioning of the variation in income.\n\\[\n\\underbrace{6566}_{\\substack{\\text{Total} \\\\ \\text{Variation}}} = \\underbrace{4148}_{\\substack{\\text{Explained} \\\\ \\text{Variation}}} + \\underbrace{2418}_{\\substack{\\text{Unexplained} \\\\ \\text{Variation}}}\n\\]\nEach of these three terms is a sum of squares (SS). The first is referred to as the total sum of squares, as it represents the total amount of variation in Y. The second term is commmonly called the model sum of squares (i.e., regression sum of squares), as it represents the variation explained by the model. The last term is the error sum of squares (i.e., residual sum of squares) as it represents the left-over variation that is unexplained by the model.\nMore generally,\n\\[\n\\mathrm{SS_{\\mathrm{Total}}} = \\mathrm{SS_{\\mathrm{Model}}} + \\mathrm{SS_{\\mathrm{Error}}}\n\\]\nFigure¬†9.1 illustrates this partitioning in a visual manner.\n\n\n\n\n\n\n\n\nFigure¬†9.1: A visual depiction of the ANOVA decomposition. The total variation as measured by the sum of squares is partitioned into that which is explained by the model (i.e., explained by education level) and that which is not (i.e., unexplained).\n\n\n\n\n\nAnother visualization of the partitioning of the sums of squares is shown in Figure¬†9.2. This visualization shows the decomposition via a tree diagram.\n\n\n\n\n\n\n\n\nFigure¬†9.2: Another visual depiction of the ANOVA decomposition.\n\n\n\n\n\n\nThe visualizations of the ANOVA decomposition are primarily pedagogical in nature to help you understand the partitioning. In practice, we generally only report the numeric values of the sums of squares (or a metric such as \\(R^2\\)) and do not create a visualization of this decomposition.\n\n\n\n9.1.1 Variation Accounted For by the Model\nIt is often convenient to express these values as proportions of the total variation. To do this we can divide each term in the partitioning by the total sum of squares.\n\\[\n\\frac{\\mathrm{SS_{\\mathrm{Total}}}}{\\mathrm{SS_{\\mathrm{Total}}}} = \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}} + \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\n\\]\nUsing the values from our example,\n\\[\n\\begin{split}\n\\frac{6566}{6566} &= \\frac{4148}{6566} + \\frac{2418}{6566} \\\\[2ex]\n1 &= 0.632 + 0.368\n\\end{split}\n\\]\nThe first term on the right-hand side of the equation, \\(\\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\\), is 0.632. This is the PRE value we computed earlier. Since the \\(\\mathrm{SS_{\\mathrm{Model}}}\\) represents the model-explained variation, many researchers interpret this value as the percentage of variation explained or accounted for by the model. They might say,\n\nThe model accounts for 63.2% of the variation in incomes.\n\nSince the only predictor in the model is education level, an alternative interpretation of this value is,\n\nDifferences in education level account for 63.2% of the variation in incomes.\n\nBetter models explain more variation in the outcome. They also have small errors. Aside from conceptually making some sense, this is also shown in the mathematics of the partitioning of variation.\n\\[\n1 = \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}} + \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\n\\]\nSince the denominator is the same on both terms, and the sum of the two terms must be one, this implies that the smaller the amount of error, the smaller the last term (proportion of unexplained variation ) must be and the larger the first term (the proportion of explained variation) has to be.\n\n\n\n9.1.2 R-Squared\nAnother way to think about measuring the quality of a model is that ‚Äògood‚Äô models should reproduce the observed outcomes, after all they explain variation in the outcome. How well do the fitted (predicted) values from our model match wih the outcome values? To find out, we can compute the correlation between the model fitted values and the observed outcome values. To compute a correlation, we will use the correlate() function from the {corrr} package.\n\n# Create fitted values and correlate them with the outcome\ncity |&gt;\n  mutate(\n    y_hat = 11.321 + 2.651*education\n  ) |&gt;\n  select(y_hat, income) |&gt;\n  correlate()\n\n\n  \n\n\n\nThe correlation between the observed and fitted values is 0.795. This is a high correlation indicating that the model fitted values and the observed values are similar. Recall that \\(r =0.795\\) was the same correlation we computed between the education and outcome variables.\n\n# Compute correlation b/w education and income\ncity |&gt;\n  select(income, education) |&gt;\n  correlate()\n\n\n  \n\n\n\nNow square this value. (When we square)\n\\[\nr_{x,y}^2 = 0.795^2 = 0.632\n\\]\nAgain we get the PRE value! All four ways of expressing this metric of model quality are equivalent:\n\\[\n\\frac{\\mathrm{SSE}_{\\mathrm{Intercept\\mbox{-}Only}} - \\mathrm{SSE}_{\\mathrm{Predictor\\mbox{-}Model}}}{\\mathrm{SSE}_{\\mathrm{Intercept\\mbox{-}Only}}} = \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}} = r_{x,y}^2 = r_{y,\\hat{y}}^2\n\\]\nAlthough these indices seem to measure different aspects of model quality‚Äîreduction in error variation, model explained variation, alignment between predictor and outcome, and alignment of the model fitted and observed values‚Äîwith OLS fitted linear models, these values are all equal. This will not necessarily be true when we estimate model parameters using a different estimation method (e.g., maximum likelihood). Most of the time this value will be reported in applied research as \\(R^2\\), but as you can see, there are many interpretations of this value under the OLS framework.\n\nSometimes \\(R^2\\) is referred to as the Coefficient of Determination.\n\n\n\n\n9.1.3 Back to Partitioning\nUsing the fact that \\(R^2 = \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\\), we can substitute this into the partitioning equation from earlier.\n\\[\n\\begin{split}\n\\frac{\\mathrm{SS_{\\mathrm{Total}}}}{\\mathrm{SS_{\\mathrm{Total}}}} &= \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}} + \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}} \\\\[2ex]\n1 &= R^2 + \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}} \\\\[2ex]\n1 - R^2 &= \\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\n\\end{split}\n\\]\nThis suggests that the last term in the partitioning, \\(\\frac{\\mathrm{SS_{\\mathrm{Error}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\\) is simply the difference between 1 and \\(R^2\\). In our example,\n\\[\n\\begin{split}\nR^2 &= 0.632, \\quad \\text{and} \\\\[2ex]\n1 - R^2 &= 0.368\n\\end{split}\n\\]\nRemember that one interpretation of \\(R^2\\) is that 63.2% of the variation in incomes was explained by the model. Alternatively, 36.8% of the variation in income is not explained by the model; it is residual variation. If the unexplained variation is too large, it suggests to an applied analyst that she could include additional predictors in the model. We will explore this in future chapters.\n\n\\(R^2\\) is one measure of the effect size of a model that educational scientists often report. As such, it is often viewed as a quantification of the quality of the model, with larger \\(R^2\\) values indicating higher quality models. But, be careful! Understanding whether \\(R^2\\) is large or small is based on the domain science. For example in some areas of educational research, an \\(R^2\\) of 0.4 might indicate a really great model, whereas the same \\(R^2\\) of 0.4 in some areas of biological research might be quite small and indicate a poor model.\nMoreover, even if \\(R^2\\) is large in the domain, it does not indicate that the model is a ‚Äúgood‚Äù model. In order to evaluate that, we have to study the model‚Äôs residuals. We will learn more about that when we learn about the regression model‚Äôs distributional assumptions.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>ANOVA Decomposition and $R^2$</span>"
    ]
  },
  {
    "objectID": "02-05-standardized-regression.html",
    "href": "02-05-standardized-regression.html",
    "title": "10¬† Standardized Regression",
    "section": "",
    "text": "10.1 Correlation‚Äôs Relationship to Regression\nThe correlation coefficient and the slope of the regression line are directly related to one another. Mathematically, the estimated slope of the simple regression line can be computed as:\n\\[\n\\hat\\beta_1 = r_{xy} \\times \\frac{s_y}{s_x}\n\\]\nwhere, \\(s_x\\) and \\(s_y\\) are the standard deviations for the variables x (predictor) and y (outcome), respectively, and \\(r_{xy}\\) is the correlation between x and y. If we are carrying out a regression analysis, there must be variation in both x and y, which implies that both \\(s_x\\) and \\(s_y\\) are greater than 0. This in turn implies that the ratio of the standard deviations (the second term on the right-hand side of the equation) is also a positive number. This means the sign of the slope is completely dependent on the sign of the correlation coefficient. If \\(r_{xy}&gt;0\\) then \\(\\hat\\beta_1&gt;0\\). If \\(r_{xy}&lt;0\\) then \\(\\hat\\beta_1&lt;0\\).\nThe magnitude of the regression slope (sometimes referred to as the effect of x on y) is impacted by three factors: (1) the magnitude of the correlation between x and y; (2) the amount of variation in y; and (3) the amount of variation in x. In general, there is a larger effect of x on y when:",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Standardized Regression</span>"
    ]
  },
  {
    "objectID": "02-05-standardized-regression.html#correlations-relationship-to-regression",
    "href": "02-05-standardized-regression.html#correlations-relationship-to-regression",
    "title": "10¬† Standardized Regression",
    "section": "",
    "text": "There is a stronger relationship (higher correlation; positive or negative) between x and y;\nThere is more variation in the outcome; or\nThere is less variation in the predictor.\n\n\n\n10.1.1 Checking the Formula on Our Data\nLet‚Äôs use the summary measures from the Riverview data to confirm the formula for the slope.\n\\[\n\\begin{split}\n\\hat\\beta_1 &= r_{xy} \\times \\frac{s_y}{s_x} \\\\[2ex]\n&= 0.795 \\times \\frac{14.55}{4.36} \\\\[2ex]\n&= 2.65\n\\end{split}\n\\] This is the same value for the slope that we got from the lm() output.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Standardized Regression</span>"
    ]
  },
  {
    "objectID": "02-05-standardized-regression.html#standardized-regression",
    "href": "02-05-standardized-regression.html#standardized-regression",
    "title": "10¬† Standardized Regression",
    "section": "10.2 Standardized Regression",
    "text": "10.2 Standardized Regression\nIn standardized regression, the correlation plays a more obvious role. Standardized regression is simply regression performed on the standardized variables (z-scores) rather than on the unstandardized variables. To carry out a standardized regression:\n\nStandardize the outcome and predictor(s) by turning all the observations into z-scores\nFit a model by regressing \\(z_y\\) on \\(z_x\\)\n\nHere we will perform a standardized regression on the Riverview data.\n\n\n10.2.1 Step 1: Standardizing the Variables\nRemember that a z-score is computed as:\n\\[\nz_x = \\frac{x - \\bar{x}}{s_x}\n\\]\nThat is we subtract the mean from our observation and then divide by the standard deviation. When we standardize a variable, we are going to turn each of the original observations into a z-score.\n\nA standardized variable will always have a mean of 0 and a standard deviation of 1. Subtracting the mean from each observation (this process is called mean centering) we are making the mean of the newly transformed observations 0 ‚Äî we re-centered the distribution so. Then, by dividing by the standard deviation (called scaling) we are changing the SD of the transformed observations to be 1. Anytime you add/subtract a value from each observation in a variable, you will shift the mean of that distribution. Anytime you multiply/divide each observation in a variable by some number, you change the SD.\n\n\n# Standardize the outcome and predictor\ncity = city |&gt;\n  mutate(\n    z_income = (income - mean(income)) / sd(income),\n    z_education = (education - mean(education)) / sd(education),\n  )\n\n# View updated data\nhead(city)\n\n\n  \n\n\n\n\n# Marginal distribution of the standardized incomes\nggplot(data = city, aes(x = z_income)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Standardized incomes\") +\n  ylab(\"Probability density\")\n\n# Marginal distribution of the standardized education levels\nggplot(data = city, aes(x = z_education)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Standardized education level\") +\n  ylab(\"Probability density\")\n\n\n\n\nDensity plot of the standardized employee incomes and standardized education levels.\n\n\n\n\n\n\n\nDensity plot of the standardized employee incomes and standardized education levels.\n\n\n\n\n\n# Compute summaries\ncity |&gt;\n  summarize(\n    M_y = mean(z_income),\n    SD_y = sd(z_income),\n    M_x = mean(z_education),\n    SD_x = sd(z_education)\n  )\n\n\n  \n\n\n\nNote that the shapes of the distributions for the standardized variables are identical to the shapes of the distributions of the unstandardized variables. Unless the distribution of a variable is normal to begin with, computing z-scores DOES NOT make the standardized distribution normal. The means for both standardized variables are 0 (because of rounding in the computation they are not exactly 0, but quite close) and the standard deviations are both 1. We can also compute the correlation between the standardized variables:\n\n# Compute correlation\ncity |&gt;\n  select(z_income, z_education) |&gt;\n  correlate()\n\n\n  \n\n\n\nThe correlation (\\(r=0.795\\)) between the standardized variables is exactly the same as the correlation between the unstandardized variables. Centering and scaling does not impact the relationship between variables! That means in regression analysis, it is irrelevant whether we perform the analysis on the unstandardized variables or whether we center or scale those variables. The choice of centering and scaling has more to do with making the interpretation of the results more relevant.\n\n\n\n10.2.2 Step 2: Fit a Regression Model Using the Standardized Variables\nNow that we have standardized the variables being used in the regression, we can fit a model by regressing \\(z_y\\) (the standardized outcome) on \\(z_x\\) (the standardized predictor).\n\n# Fit standardized regression\nlm.z = lm(z_income ~ 1 + z_education, data = city)\nlm.z\n\n\nCall:\nlm(formula = z_income ~ 1 + z_education, data = city)\n\nCoefficients:\n(Intercept)  z_education  \n -7.883e-17    7.948e-01  \n\n\nThe fitted regression equation is:\n\\[\n\\hat{z}_{\\mathrm{Income}_i} = 0 + 0.795(z_{\\mathrm{Education}_i})\n\\]\nThe intercept in a standardized regression is always 0.1 Notice that the slope of the standardized regression is the correlation between the predictor and outcome.\n\n\n10.2.3 Your Turn\nUse the formula for the slope to understand why the slope from a standardized regression will always be equal to the value of the correlation coefficient.\n\nIf we interpret these coefficients:\n\nThe predicted mean standardized income for all employees who have a standardized education level of 0 is 0.\nEach one-unit difference in the standardized education level is associated with a 0.795-unit difference in standardized income, on average.\n\nRemember that standardized variables have a mean equal to 0 and a standard deviation equal to 1. Using that, these interpretations can be revised to:\n\nThe mean income for all employees who have the mean level of education is predicted to be the mean income.\nEach one-standard deviation difference in education level is associated with a 0.795-standard deviation difference in income, on average.\n\nHere is a scatterplot of the standardized variables along with the fitted standardized regression line. This will help you visually see the results of the standardized regression analysis.\n\nggplot(data = city, aes(x = z_education, y = z_income)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Standardized education level\") +\n  ylab(\"Standardized income\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_abline(intercept = 0, slope = 0.795)\n\n\n\n\nPlot of the standardized income versus the standardized education level for the Riverview employees. The mean values are also displayed (dashed lines) along with the fitted regression line (solid line).\n\n\n\n\nUsing standardized regression results allows us to talk about the effect of x on y in a standard metric (standard deviation difference). This can be quite helpful when the unstandardized metric is less meaningful. This is also why some researchers refer to correlation as an effect, even though the value of \\(R^2\\) is more useful in summarizing the usefulness of the model. Standardized regression also makes the intercept interpretable, since the mean value of x is not extrapolated.\n\nThe choice to standardize, center, or scale the outcome or predictors only impacts the interpretations of the intercept and slope, it does not change the underlying relationships between the variables in the model. When it is helpful to have these different interpretations, then transfom the variables. Otherwise, don‚Äôt worry about it.\n\n\n\n10.2.4 A Slick Property of the Regression Line\nNotice from the previous scatterplot of the standardized regression results that the standardized regression line goes through the point \\((0,0)\\). Since the variables are standardized, this is the point \\((\\bar{x}, \\bar{y})\\). The regression line will always go through the point \\((\\bar{x}, \\bar{y})\\) even if the variables are unstandardized. This is an important property of the regression line.\nWe can show this property mathematically by predicting \\(y\\) when \\(x\\) is at its mean. The predicted value when \\(x=\\bar{x}\\) is then\n\\[\n\\hat{Y}_i = \\hat\\beta_0 + \\hat\\beta_1(\\bar{x})\n\\]\nUsing a common formula for the regression intercept,\n\\[\n\\hat\\beta_0 = \\bar{y} - \\hat\\beta_1(\\bar{x}),\n\\]\nand substituting this into the prediction equation:\n\\[\n\\begin{split}\n\\hat{Y}_i &= \\hat\\beta_0 + \\hat\\beta_1(\\bar{x}) \\\\\n&= \\bar{y} - \\hat\\beta_1(\\bar{x}) + \\hat\\beta_1(\\bar{x}) \\\\\n&= \\bar{y}\n\\end{split}\n\\]\nThis implies that \\((\\bar{x}, \\bar{y})\\) is always on the regression line and that the predicted value of y for x-values at the mean is always the mean of y.\n\n\n\n10.2.5 Variance Accounted For in a Standardized Regression\nThe \\(R^2\\) value for the standardized and unstandardized regression models are identical. That is because the correlation between x and y and that between \\(z_x\\) and \\(z_y\\) are identical (see below). Thus the squared correlation will also be the same, in this case \\(R^2 = 0.795^2 = 0.632\\).\nWe can also compute \\(R^2\\) as the proportion reduction in error variation (PRE) from the intercept-only model. To do so we again compute the sum of squared error (SSE) for the standardized models (intercept-only and intercept-slope) and determine how much variation was explained by including the standardized education level as a predictor.\nRemember that the intercept-only model is referred to as the marginal mean model‚Äîit predicts the marginal mean of y regardless of the value of x. Since the variables are standardized, the marginal mean of y is 0. Thus the equation for the intercept-only model when the variables are standardized is:\n\\[\n\\hat{z}_{\\mathrm{Income}} = 0\n\\]\nYou could also fit the intercept-only model to obtain this result, lm(z_income ~ 1, data = city). We can now compute the SSE based on the intercept-only model.\n\n# Compute the SSE for the standardized intercept-only model\ncity |&gt;\n  mutate(\n    y_hat = 0,\n    errors = z_income - y_hat,\n    sq_errors = errors ^ 2\n  ) |&gt;\n  summarize(\n    SSE = sum(sq_errors)\n  )\n\n\n  \n\n\n\nWe also compute the SSE for the standardized model that includes the standardized predictor of time spent on homework.\n\n# Compute the SSE for the standardized slope-intercept model\ncity |&gt;\n  mutate(\n    y_hat = 0 + 0.795 * z_education,\n    errors = z_income - y_hat,\n    sq_errors = errors ^ 2\n  ) |&gt;\n  summarize(\n    SSE = sum(sq_errors)\n  )\n\n\n  \n\n\n\nThe proportion reduction in SSE is:\n\\[\n\\text{PRE} =  \\frac{31 - 11.4}{31} = 0.632\n\\]\nWe can say that differences in education level explains 63.2% of the variation in employee incomes, and that 36.8% of the varition in income remains unexplained. Note that if we compute the SSEs for the unstandardized models, they will be different than the SSEs for the standardized models (after all, they are in a different metric), but they will be in the same proportion, which produces the same value as the \\(R^2\\) value.",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Standardized Regression</span>"
    ]
  },
  {
    "objectID": "02-05-standardized-regression.html#footnotes",
    "href": "02-05-standardized-regression.html#footnotes",
    "title": "10¬† Standardized Regression",
    "section": "",
    "text": "R or other statistical software might round this to a very small number. The intercept should always be reported as zero, or dropped from the fitted equation.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Regression",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Standardized Regression</span>"
    ]
  },
  {
    "objectID": "03-00-regression-inference.html",
    "href": "03-00-regression-inference.html",
    "title": "Regression Inference",
    "section": "",
    "text": "In this unit you will learn how to carry out statistical inference on the regression parameters. You will be introduced to how we quantify uncertainty in the estimates we make for the regression model. You will also learn about the hypothesis tests that are commonly used in regression analyses, including t-tests to evaluate hypotheses about coefficients, and F-tests to evaluate hypotheses about the broader model. You will also learn about how we can use our estimates of uncertainty to produce interval estimates for our regression coefficients. Finally you will learn how to evaluate the distributional assumptions that underlie the simple regression model.",
    "crumbs": [
      "Regression Inference"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html",
    "href": "03-01-coefficient-level-inference.html",
    "title": "11¬† Coefficient-Level Inference",
    "section": "",
    "text": "11.1 Data Exploration\nWe begin by looking at the marginal distributions of both time spent on homework and GPA. We will also examine summary statistics of these variables. Finally, we also examine a scatterplot of GPA versus time spent on homework.\n# Summary statistics\nkeith |&gt;\n  summarize(\n    M_gpa  = mean(gpa),\n    SD_gpa = sd(gpa),\n    M_hw   = mean(homework),\n    SD_hw  = sd(homework)\n    )\n\n\n  \n\n\n# Compute correlation\nkeith |&gt;\n  select(gpa, homework) |&gt;\n  correlate()\nWe might describe the results of this analysis as follows:\nWe could also present this information in a table. This table could be extended to include additional variables (which we will do in later chapters). We include the mean and standard deviations in the same table as the correlations by placing them on the main diagonal.\nTable¬†11.1: Correlations between 8th-Grade students‚Äô GPA and weekly time spent on homework. Means and standard deviations (in parentheses) are displayed on the main diagonal.\n\n\n\n\n\n  \n  \n\n\n\n\n1.\n2.\n\n\n\n\n1. GPA\n80.47 (7.62)\n\n\n\n2. Time spent on homework\n.33\n5.09 (2.06)\nWe will also fitted a model by regressing GPA on time spent on homework and storing those results in an object called lm.a.\n# Fit regression model\nlm.a = lm(gpa ~ 1 + homework, data = keith)\n\n# View output\nlm.a\n\n\nCall:\nlm(formula = gpa ~ 1 + homework, data = keith)\n\nCoefficients:\n(Intercept)     homework  \n     74.290        1.214\nThe fitted equation is:\n\\[\n\\hat{\\mathrm{GPA}_i} = 74.29 + 1.21(\\mathrm{Time~spent~on~homework}_i),\n\\]\nSummarizing this,",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#data-exploration",
    "href": "03-01-coefficient-level-inference.html#data-exploration",
    "title": "11¬† Coefficient-Level Inference",
    "section": "",
    "text": "Code\n# Marginal distribution of GPA\nggplot(data = keith, aes(x = gpa)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"GPA (on a 100-pt. scale)\") +\n  ylab(\"Probability density\") +\n  ggtitle(\"Outcome: GPA\")\n# Marginal distribution of homework\nggplot(data = keith, aes(x = homework)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Time spent on homework per week (in hours)\") +\n  ylab(\"Probability density\")  +\n  ggtitle(\"Predictor: Homework\")\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†11.1: Density plots of the marginal distribution of GPA.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†11.2: Density plots of the marginal distribution of time spent on homework.\n\n\n\n\n\n\n\n\n\nCode\n# Scatterplot of GPA versus homework\nggplot( data = keith, aes(x = homework, y = gpa) ) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Time spent on homework per week (in hours)\") +\n  ylab(\"GPA (on a 100-pt. scale)\")\n\n\n\n\n\n\n\n\nFigure¬†11.3: Scatterplot showing the relationship between GPA and time spent on homework.\n\n\n\n\n\n\n\n\n\nThe marginal distributions of GPA and time spent on homework are both unimodal. The average amount of time these 8th-grade students spend on homework each week is 5.09 hours (SD = 2.06). These 8th-grade students have a mean GPA of 80.47 (SD = 7.62) on a 100-pt scale. There is a moderate, positive, linear relationship between time spent on homework and GPA for these students. This suggests that 8th-grade students who spend less time on homework tend to have lower GPAs, on average, than students who spend more time on homework.\n\n\n\n\n\n\n\n\n\n\nThis model estimated mean GPA for all 8th-grade students who spend 0 hours a week on homework is 74.29. Each additional hour 8th-grade students spend per week on homework is associated with a difference in GPA of 1.21, on average. Differences in time spent on homework explains 10.7% of the variation in students‚Äô GPAs. All this suggests that time spent on homework is related to GPA for the \\(n=100\\) 8th-graders in the sample.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#statistical-inference",
    "href": "03-01-coefficient-level-inference.html#statistical-inference",
    "title": "11¬† Coefficient-Level Inference",
    "section": "11.2 Statistical Inference",
    "text": "11.2 Statistical Inference\nWhat if we want to understand the relationship between time spent on homework and GPA for a larger population of 8th-grade students, say all of them in the district? The problem is that if we had drawn a different sample of \\(n=100\\) 8th-grade students, all the regression estimates (\\(\\hat\\beta_0, \\hat\\beta_1,\\) and \\(R^2\\)) would be different than the ones we obtained from our sample. This makes it difficult to say, for example, how the conditional mean GPA differs for students with differing amounts of time spent on homework. In our observed sample, \\(\\hat\\beta_1\\) was 1.21. But, had we sampled different students, we might have found that \\(\\hat\\beta_1\\) was 2.03. And a different random sample of employees we might have produced a \\(\\hat\\beta_1\\) of 0.96.\nThis variation in the estimates arises because of the random nature of the sampling. One of the key findings in statistical theory is that the amount of variation in estimates under random sampling is completely predictable‚Äî this variation is called sampling error. Being able to quantify the sampling error allows us to provide a more informative answer to the research question. For example, it turns out that based on the quantification of sampling error in our example, we believe that the actual \\(\\beta_1\\) is between 0.51 and 1.92.\nStatistical inference allows us to learn from incomplete or imperfect data Gelman & Hill (2007). In many studies, the primary interest is to learn about one or more characteristics about a population. These characteristics must be estimated from sample data. This is the situation in our example, where we have only a sample of 8th-grade students and we want to understand the relationship between time spent on homework and GPA for ALL 8th-grade students in the district.\nIn the example, the variation in estimates arises because of sampling variation. It is also possible to have variation because of imperfect measurement. This is called measurement error. Despite these being very different sources of variation, in practice they are often combined (e.g., we measure imperfectly and we want to make generalizations).\nRegardless of the sources of variation, the goals in most regression analyses are two-fold:\n\nEstimate the parameters from the observed data; and\nSummarize the amount of uncertainty (e.g., quantify the sampling error) in those estimates.\n\nThe first goal we addressed in the Simple Linear Regression‚ÄîDescription chapter. It is the second goal that we will explore in this chapter.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#quantification-of-uncertainty",
    "href": "03-01-coefficient-level-inference.html#quantification-of-uncertainty",
    "title": "11¬† Coefficient-Level Inference",
    "section": "11.3 Quantification of Uncertainty",
    "text": "11.3 Quantification of Uncertainty\nBefore we talk about estimating uncertainty in regression, let me bring you back in time to your Stat I course. In that course, you probably spent a lot of time talking about sampling variation for the mean. The idea went something like this: Imagine you have a population that is infinitely large. The observations in this population follow some probability distribution. (This distribution is typically unknown in practice, but for now, let‚Äôs pretend we know what that distribution is.) For our purposes, let‚Äôs assume the population is normally distributed with a mean of \\(\\mu\\) and a standard deviation of \\(\\sigma\\).\nSample n observations from that population. Based on the n sampled observations, find the mean. We will call this \\(\\hat\\mu_1\\) since it is an estimate for the population mean (the subscript just says it is the first sample). In all likelihood, \\(\\hat\\mu_1\\) is not the exact same value as \\(\\mu\\). It varies from the population mean because of sampling error.\nNow, sample another n observations from the population. Again, find the mean. We will call this estimate \\(\\hat\\mu_2\\). Again, it probably varies from \\(\\mu\\), and may be different than \\(\\hat\\mu_1\\) as well. Continue to repeat this process: randomly sample n observations from the population; and find the mean.\n\n\n\n\n\n\n\n\nFigure¬†11.4: Thought experiment for sampling samples of size n from the population to obtain the sampling distribution of the mean.\n\n\n\n\n\nThe distribution of the sample means, it turns out, is quite predictable using statistical theory. Theory predicts that the distribution of the sample means will be normally distributed. It also predicts that the mean, or expected value, of all the sample means will be equal to the population mean, \\(\\mu\\). Finally, theory predicts that the standard deviation of this distribution, called the standard error, will be equal to the population standard deviation divided by the square root of the sample size. Mathematically, we would write all this as,\n\\[\n\\hat\\mu_n\\sim\\mathcal{N}\\left(\\mu, \\dfrac{\\sigma}{\\sqrt{n}}\\right).\n\\]\nThe important thing is not that you memorize this result, but that you understand that the process of randomly sampling from a known population can lead to predictable results in the distribution of statistical summaries (e.g., the distribution of sample means). The other crucial thing is that there the sampling variation can be quantified. The standard error is the quantification of that sampling error. In this case, it gives a numerical answer to the question of how variable the sample mean will be because of random sampling.\n\nWhen we report information about theoretical distributions, we parameterize the distribution by reporting all the necessary parameter values that are needed to reproduce it. For example to parameterize a normal distribution we need to report not only that it is normal, but also the mean and standard deviation. Notice that these two parameters specifically define the center (mean) and variability (standard deviation) of the distribution. In addition to the shape (normal) these give a perfect description of the distribution. Mathematically, we write that description as:\n\\[\n\\sim\\mathcal{N}\\left(\\text{Mean}, ~\\text{SD}\\right)\n\\]\n\n\n\n11.3.1 Quantification of Uncertainty in Regression\nWe can extend these ideas to regression. Now the thought experiment goes something like this: Imagine you have a population that is infinitely large. The observations in this population have two attributes, call them X and Y. The relationship between these two attributes can be expressed via a regression equation as: \\(\\hat{Y}=\\beta_0 + \\beta_1(X)\\). Randomly sample n observations from the population. This time, rather than computing a mean, regress the sample Y values on the sample X values. Since the sample regression coefficients are estimates of the population parameters, we will write this as: \\(\\hat{Y}=\\hat{\\beta}_{0,1} + \\hat{\\beta}_{1,1}(X)\\). Repeat the process. This time the regression equation is: \\(\\hat{Y}=\\hat{\\beta}_{0,2} + \\hat{\\beta}_{1,2}(X)\\). Continue this process an infinite number of times.\n\n\n\n\n\n\n\n\nFigure¬†11.5: Thought experiment for sampling samples of size n from the population to obtain the sampling distribution of the regression coefficients.\n\n\n\n\n\nStatistical theory again predicts the characteristics of the two distributions, that of \\(\\hat{\\beta}_0\\) and that of \\(\\hat{\\beta}_1\\). The distribution of \\(\\hat{\\beta}_0\\) can be expressed as,\n\\[\n\\hat\\beta_0\\sim\\mathcal{N}\\left(\\beta_0,~ \\sigma_\\epsilon\\sqrt{\\dfrac{1}{n} + \\dfrac{\\mu_X^2}{\\sum(X_i-\\mu_X)^2}}\\right).\n\\]\nSimilarly, the distribution of \\(\\hat{\\beta}_1\\) can be expressed as,\n\\[\n\\hat\\beta_1\\sim\\mathcal{N}\\left(\\beta_1,~ \\dfrac{\\sigma_\\epsilon}{\\sigma_x\\sqrt{n-1}}\\right).\n\\]\nAgain, don‚Äôt panic over the formulae. What is important is that theory allows us to quantify the variation in both \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) that is due to sampling error. In practice, our statistical software will give us the numerical estimates of the two standard errors.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#hypothesis-testing",
    "href": "03-01-coefficient-level-inference.html#hypothesis-testing",
    "title": "11¬† Coefficient-Level Inference",
    "section": "11.4 Hypothesis Testing",
    "text": "11.4 Hypothesis Testing\nSome research questions point to examining whether the value of some regression parameter differs from a specific value. For example, it may be of interest whether a particular population model (e.g., one where \\(\\beta_1=0\\)) could produce the sample result of a particular \\(\\hat\\beta_1\\). To test something like this, we state the value we want to test in a statement called a null hypothesis. For example,\n\\[\nH_0: \\beta_1 = 0\n\\]\nThe hypothesis is a statement about the population. Here we hypothesize \\(\\beta_1=0\\). It would seem logical that one could just examine the estimate of the parameter from the observed sample to answer this question, but we also have to account for sampling uncertainty. The key is to quantify the sampling variation, and then see if the sample result is unlikely given the stated hypothesis.\nOne question of interest may be: Is there evidence that the average GPA differs for different amounts of time spent on homework? In our example, we have a \\(\\hat\\beta_1=1.21\\). This is sample evidence, but does 1.21 differ from 0 more than we would expect because of random sampling? If it doesn‚Äôt, we cannot really say that the average GPA differs for different amounts of time spent on homework. To test this, we make an assumption that there is no relationship between time spent on homework and GPA, in other words, the slope of the line under this assumption would be 0. The thought experiment underlying this would be to randomly sample n observations from the population where \\(\\beta_1 =0\\). Regress the sample Y values on the sample X values and obtain the sample slope.\n\n\n\n\n\n\n\n\nFigure¬†11.6: Thought experiment for sampling samples of size n from the population where there is no effect of X (\\(\\beta_1=0\\)) to obtain the sampling distribution of the slopes.\n\n\n\n\n\nTheory would suggest that the distribution of \\(\\hat{\\beta}_1\\), assuming the null hypothesis is true, can be expressed as,\n\\[\n\\hat\\beta_1\\sim\\mathcal{N}\\left(0,~ \\dfrac{\\sigma_\\epsilon}{\\sigma_x\\sqrt{n-1}}\\right).\n\\]\nNote that the only thing that changed is that the mean of the sampling distribution is now 0, reflecting the null hypothesis being true. The key is to determine the standard error (quantify the uncertainty) for the distribution of sample slopes.\n\n11.4.1 Obtaining SEs for the Regression Coefficients\nTo obtain the estimated standard errors for the regression coefficients, we will use the tidy() function from the {broom} package to display the fitted regression output. We provide the fitted regression object as the input to this function.\n\n# Display the coefficient-level output\ntidy(lm.a)\n\n\n  \n\n\n\nIn the displayed output, we now obtain the estimates for the standard errors in addition to the coefficient estimates. We can use these values to quantify the amount of uncertainty due to sampling error. For example, the distribution for the slope has a standard error of 0.35. So now, the the distribution of \\(\\hat{\\beta}_1\\), assuming the null hypothesis is true, can be expressed as,\n\\[\n\\hat\\beta_1\\sim\\mathcal{N}\\left(0,~ 0.35\\right)\n\\]\nOne way to envision this is as a distribution.\n\n\n\n\n\n\n\n\nFigure¬†11.7: Sampling distribution of the slope coefficient under the hypothesis that \\(\\beta_1=0\\). The distribution is approximately normal with a mean of 0 and a standard error of 0.35.\n\n\n\n\n\nBefore we talk about how to use this sampling distribution to conduct our hypothesis test, we need to introduce one wrinkle into the procedure.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#estimating-variation-from-sample-data-no-longer-normal",
    "href": "03-01-coefficient-level-inference.html#estimating-variation-from-sample-data-no-longer-normal",
    "title": "11¬† Coefficient-Level Inference",
    "section": "11.5 Estimating Variation from Sample Data: No Longer Normal",
    "text": "11.5 Estimating Variation from Sample Data: No Longer Normal\nIn theory, the sampling distributions for the two regression coefficients were both normally distributed. This is the case when we know the variation parameters in the population. For example, for the sampling distribution of the slope to be normally distributed, we would need to know \\(\\sigma_\\epsilon\\) and \\(\\sigma_x\\).\nIn practice these values are typically unknown and are estimated from the sample data. Anytime we are estimating things we introduce additional uncertainty. In this case, the uncertainty affects the shape of the sampling distribution.\n\n\n\n\n\n\n\n\nFigure¬†11.8: Comparison of two distributions. The normal distribution (solid, blue) and one with additional uncertainty (dashed, orange).\n\n\n\n\n\nCompare the normal distribution (solid, blue) to the distribution with additional uncertainty (dashed, orange). From the figure you can see that the additional uncertainty slightly changed the shape of the distribution from normal.\n\nIt is still symmetric and unimodal (like the normal distribution).\nThe additional uncertainty makes more extreme values more likely than they are in the normal distribution.\nThe additional uncertainty makes values in the middle less likely than they are in the normal distribution.\n\nIt is important to note that the amount of uncertainty affects how closely the shape of the distribution matches the normal distribution. And, that the sample size directly affects the amount of uncertainty we have. All things being equal, we have less uncertainty when we have larger samples. The following figure illustrates this idea.\n\n\n\n\n\n\n\n\nFigure¬†11.9: The normal distribution (solid, blue), a distribution with estimates based on a larger sample size (dashed, orange), and one based on a smaller sample size (dotted, green).\n\n\n\n\n\n\n\n11.5.1 The t-Distribution\nAs pointed out, the distributions with uncertainty introduced from using a sample of data are not normally distributed. Thus, it doesn‚Äôt make sense to use a normal distribution as a model for describing the sampling variation. Instead, we will a t-distribution; a family of distributions that have several advantageous properties:\n\nThey are unimodal and symmetric.\nThey have more variation (uncertainty) than the normal distribution resulting in a distribution that has thicker tails and is shorter in the middle than a normal distribution.\nHow thick the tails are and how short the middle of the distribution is, is related to the sample size.\n\nSpecifically, the t-distribution is unimodal and symmetric with a mean of 0. The variance of the distribution (which also specifies the exact shape), is\n\\[\n\\mathrm{Var} = \\frac{\\mathit{df}}{\\mathit{df} - 2}\n\\]\nfor \\(\\mathit{df}&gt;2\\) where df is referred to as the degrees of freedom.\n\nTo parameterize a t-distribution, we need to report the degrees-of-freedom which dictate the variation. Since the mean of a t-distribution is always 0, it isn‚Äôt necessary to report the center. So by knowing a distribution is t-distributed and also knowing it df, we again have a perfect description of the distribution. Mathematically, we could write:\n\\[\n\\sim t(\\mathit{df})\n\\]\n\n\n\n\n11.5.2 Back to the Hypothesis Test\nRecall that we are interested in testing the following hypothesis,\n\\[\nH_0: \\beta_1 = 0\n\\]\nTo test this we compute the number of standard errors that our observed slope (\\(\\hat\\beta_1=1.21\\)) is from the hypothesized value of zero (stated in the null hypothesis). Since we already obtained the standard error for the slope (\\(SE=0.354\\)), we just use some straight-forward algebra to compute this:\n\\[\n\\frac{1.21 - 0}{0.354} = 3.42\n\\]\nInterpreting this, we can say,\n\nThe observed slope of 1.21 is 3.42 standard errors from the expected value of 0.\n\nThis value is referred to as the observed t-value. (It is similar to a z-value in the way it is computed; it is standardizing the distance from the observed slope to the hypothesized value of zero. But, since we had to estimate the SE using the data, we introduced additional uncertainty; hence a t-value.)\nWe can evaluate this t-value within the appropriate t-distribution. For regression coefficients, the t-distribution we will use for evaluation has degrees of freedom that are a function of the sample size and the number of coefficients being estimated in the regression model, namely,\n\\[\n\\mathit{df} = n - (\\textrm{number of coefficients}).\n\\]\nIn our example the sample size (n) is 100, and the number of coefficients being estimated in the regression model is two (\\(\\hat\\beta_0\\) and \\(\\hat\\beta_1\\)). Thus,\n\\[\n\\mathit{df} = 100 - 2 = 98\n\\]\nBased on this, we will evaluate our observed t-value of 3.42 using a t-distribution with 98 degrees of freedom. Using this distribution, we can compute the probability of obtaining a t-value (under random sampling) at least as extreme as the one in the data under the assumed model. This is equivalent to finding the area under the probability curve for the t-distribution that is greater than or equal to 3.42.1 This is called the p-value.\n\n\n\n\n\n\n\n\nFigure¬†11.10: Plot of the probability curve for the t(98) distribution. The shaded area under the curve represents the p-value for a two-tailed test evaluating whether the population slope is zero using an observed t-value of 73.42.\n\n\n\n\n\nThe p-value is computed for us and displayed in the tidy() output, along with the t-value (provided in the statistic column). In our example, \\(p=0.000885\\). (Note that the p-value might be printed in scientific notation. For example, it may be printed as 8.85e-04, which is equivalent to \\(8.85 \\times 10^{-4}\\).) To interpret this we would say,\n\nThe probability of observing a t-value of 3.42, or a t-value that is more extreme, under the assumption that \\(\\beta_1=0\\) is 0.000885.\n\nThis is equivalent to saying:\n\nThe probability of observing a sample slope of 1.21, or a slope that is more extreme, under the assumption that \\(\\beta_1=0\\) is 0.000885.\n\nThis is quite unlikely, and indicates that the empirical data are inconsistent with the hypothesis that \\(\\beta_1=0\\). As such, it serves as evidence against the hypothesized model. In other words, it is likely that \\(\\beta_1\\neq0\\).\n\n\n\n11.5.3 Testing the Intercept\nThe hypothesis being tested for the intercept is \\(H_0:\\beta_0=0\\). The tidy() output also provides information about this test:\n\n# Coefficient-level output\ntidy(lm.a)\n\n\n  \n\n\n\nThe results indicate that the observed intercept of 74.28 is 38.26 standard errors from the hypothesized value of 0;\n\\[\nt = \\frac{74.28 - 0}{1.94} = 38.26\n\\]\nAssuming the null hypothesis that \\(\\beta_0=0\\) is true, the probability of observing a sample intercept of 74.28 or one that is more extreme, is \\(1.01 \\times 10^{-60}\\). (Any p-value less than .001 is typically reported as \\(p&lt;.001\\).) This is evidence against the hypothesized model. Because of this, we would say the empirical data are inconsistent with the hypothesis that \\(\\beta_0=0\\); it is unlikely that the intercept in the population is zero.\n\nHow small does our p-value have to be for the empirical data are inconsistent with the null hypothesis? That is something that is decided by the researcher prior to doing any data analysis. Typically in the social and educational sciences we say that for the empirical data are inconsistent with the null hypothesis the p-value needs to be less than 0.05. The value we choose is referred to as the alpha value (\\(\\alpha = .05\\)).",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#statistical-significance-an-outdated-idea-for-research",
    "href": "03-01-coefficient-level-inference.html#statistical-significance-an-outdated-idea-for-research",
    "title": "11¬† Coefficient-Level Inference",
    "section": "11.6 ‚ÄòStatistical Significance‚Äô: An Outdated Idea for Research",
    "text": "11.6 ‚ÄòStatistical Significance‚Äô: An Outdated Idea for Research\nYou may have read papers or taken statistics courses that emphasized the language ‚Äústatistically significant‚Äù. This adjective was typically used when the empirical evidence was inconsistent with a hypothesized model (when the p-value was less than or equal to the specified alpha level), and the researcher subsequently ‚Äúrejected the null hypothesis‚Äù. In the social sciences this occurred when the p-value was less than .05.\nIn 2019, the American Statistical Association put out a special issue in one of their premier journals, stating,\n\n‚Ä¶it is time to stop using the term ‚Äòstatistically significant‚Äô entirely. Nor should variants such as ‚Äòsignificantly different,‚Äô ‚Äòp &lt; 0.05,‚Äô and ‚Äònonsignificant‚Äô survive, whether expressed in words, by asterisks in a table, or in some other way. Regardless of whether it was ever useful, a declaration of ‚Äòstatistical significance‚Äô has today become meaningless. (Wasserstein & Schirm, 2019, p. 2)\n\nThey went on to say,\n\n‚Ä¶no p-value can reveal the plausibility, presence, truth, or importance of an association or effect. Therefore, a label of statistical significance does not mean or imply that an association or effect is highly probable, real, true, or important. Nor does a label of statistical nonsignificance lead to the association or effect being improbable, absent, false, or unimportant. (Wasserstein & Schirm, 2019, p. 2)\n\nThis is not to say that p-values should not be reported; they should. But rather that we should not arbitrarily dichotomize a continuous measure into two categories whose labels are at best meaningless and at worst misleading. The goal of scientific inference (which is much broader than statistical inference for a single study) is replicability and empirically generalizable results and findings. And, as Hubbard et al. (2019) point out, declaring findings as ‚Äòsignificant‚Äô or ‚Äònot significant‚Äô works in direct opposition to the broader culmination of knowledge and evidence in a field.\nInstead, we want to begin to see the p-value as a measure of incompatibility between the empirical data and a very specific model, one in which a certain set of assumptions are true. Both the empirical data (which are unique to the specific study) and the model‚Äôs set of assumptions often make the p-value unique to the specific study carried out and less useful in the broader goal of scientific inference. As such we need to come to view the p-value for what it is, one measure of evidence, for one very particular model, in one very localized study. As Ron Wasserstein reminds us,\n\nSmall p-values are like a right-swipe in Tinder. It means you have an interest. It doesn‚Äôt mean you‚Äôre ready to book the wedding venue.\n\n\n\n\n\n\n\n\n\n\n\n\n11.6.1 What Language Should We Use Instead of ‚ÄúSignificance‚Äù?\nThe word ‚Äúsignificant‚Äù in the phrases ‚Äústatistically significant‚Äù and ‚Äúsignificantly different‚Äù conveys the finding as important. As Wasserstein & Schirm (2019) remind us, findings are not important just because the have a small p-value, nor are findings with a large p-value unimportant. Instead, what a small p-value indicates is that statistically you can differentiate between your data‚Äôs summary measure and what you are testing that against after accounting for some level of uncertainty. For example in testing whether the slope is different from 0 (\\(H_0: \\beta_1 = 0\\)), if you obtain a small p-value it means that you have statistically detected a difference between your observed slope and 0 after accounting for uncertainty at a particular \\(\\alpha\\) level.\nBecause of this, one suggestion in writing about the results is to use the words ‚Äústatistically discernible‚Äù rather than ‚Äústatistically significant‚Äù. For example, in writing up results from our example:\n\nThe hypothesis test suggests that the effect of homework (\\(B = 1.21\\)) is statistically discernible from 0 (\\(p=0.000885\\)).\n\n\nWhen reporting p-values for the social sciences, we typically round to three decimal places. So our p-value of 0.000885 would be rounded to 0.000. However, since the p-value is not actually 0, we would instead report this as \\(p &lt; .001\\).",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#confidence-intervals",
    "href": "03-01-coefficient-level-inference.html#confidence-intervals",
    "title": "11¬† Coefficient-Level Inference",
    "section": "11.7 Confidence Intervals",
    "text": "11.7 Confidence Intervals\nRather than test whether the data are consistent with a particular parameter value (e.g., is \\(\\beta_1=0\\)), you could provide a range of parameter values that the data are consistent with. This range of compatible parameter values is referred to as a confidence interval or a compatibility interval; typically abbreviated CI. To compute a confidence interval we use:\n\\[\n\\text{CI} = \\text{Estimate} \\pm t^*(\\text{SE})\n\\]\nwhere the estimate is the observed value from the data, SE is the estimate of the standard error, and \\(t^*\\) is a multiplier that depends on the t-distribution and the confidence level. In the social and educational sciences, it is typical to have a multiplier around two.2 The plus/minus means you do the calculation using minus and then re-do it using plus; resulting in two different values. So, to compute the CI for our slope estimate:\n\\[\n\\begin{split}\n&\\text{CI} = 1.21 \\pm 2(0.35) \\\\[2ex]\n&1.21 - 2(0.35) = 0.51\\\\\n&1.21 + 2(0.35) = 1.91\n\\end{split}\n\\]\nThe two values form the endpoints of our confidence interval, so our \\(\\text{CI} = \\big[0.51, 1.91\\big]\\). The CI accounts for the uncertainty due to sampling variation by providing a range of values for the slope that are compatible with the observed data. Interpreting this, we might say,\n\nFor all 8th-graders in the district, each one-hour difference in time spent on homework per week is associated with a difference in overall GPA between 0.51 and 1.91, on average.\n\nWe can use the conf.int=TRUE argument in the tidy() function to obtain these limits directly. By default this will compute a 95% CI. This can be changed using the conf.level= argument.3\n\n# Include CIs in the coefficient-level output\ntidy(lm.a, conf.int = TRUE, conf.level = 0.95)\n\n\n  \n\n\n\nWe could similarly express the uncertainty in the intercept via a CI as,\n\\[\n\\text{CI for }\\beta_0 = \\left[70.4,~78.1\\right]\n\\]\nInterpreting this, we might say,\n\nThe average GPA for all 8th-grade students in the district who spend zero hopurs per week on homework is between 70.4 and 78.1.\n\n\nWhen reporting results from hypothesis tests, in addition to the p-value, always include either the standard error or the confidence interval in reporting your results. This allows readers to see how different from 0 the observed result is after accounting for uncertainty. This allows them to judge the scientific importance using their domain knowledge. For example,\n\nThe hypothesis test suggests that the effect of homework (\\(B = 1.21\\)) is statistically discernible from 0 (\\(p&lt;0.001\\)). The 95% CI suggests that the effect of homework for 8th-graders is likely between 0.51 and 1.91, indicating that each 1-hour of homework is associated with a difference of between 0.51 and 1.91 GPA points.\n\n\n\n\n11.7.1 Confidence Intervals as Compatibility Intervals\nOne way of interpreting this interval is that every value in the interval is a parameter value that is reasonably compatible with the empirical data. For example, in considering the CI for the slope parameter, population slope \\((\\beta_1)\\) values between 0.51 and 1.92 are all reasonably compatible with the empirical data (with the caveat that, again, all the assumptions used to create the interval are satisfied). As applied researchers, we should describe the practical implications of all values inside the interval, especially the observed effect (or point estimate) and the limits.\nFor us this means describing the practical implications of the true slope being 1.21, as low as 0.51, and as high as 1.92. Are these meaningful differences in GPA (measure on a 100-pt.¬†scale)? Given that the SD for GPA was 7.62, a one-hour difference in time spent on homework is associated with at most a 0.25 SD difference in GPA or as little as a 0.07 SD difference in GPA. This is not a large difference, however whether it is meaningful depends on previous research about GPA.4\nConfidence intervals help us keep an open-mind about uncertainty, after all they suggest several values that are compatible with the empirical data. However, they can also be misleading. Amrhein et al. (2019) point out four key points fo us to remember as we use CIs:\n\nJust because the interval gives the values most compatible with the data, given the assumptions, it does not mean values outside it are incompatible; they are just less compatible.\nNot all values inside are equally compatible with the data, given the assumptions. The point estimate is the most compatible, and values near it are more compatible than those near the limits.\nLike the 0.05 alpha threshold from which it came, the default 95% used to compute intervals is itself an arbitrary convention.\nLast, and most important of all, be humble: compatibility assessments hinge on the correctness of the statistical assumptions used to compute the interval. In practice, these assumptions are at best subject to considerable uncertainty.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#references",
    "href": "03-01-coefficient-level-inference.html#references",
    "title": "11¬† Coefficient-Level Inference",
    "section": "11.8 References",
    "text": "11.8 References\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmrhein, V., Greenland, S., & McShane, B. (2019). Retire statistical significance. Nature, 567, 305‚Äì307.\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge University Press.\n\n\nHubbard, R., Haig, B. D., & Parsa, R. A. (2019). The limited role of formal statistical inference in scientific inference. The American Statistician, 73, 91‚Äì98. https://doi.org/10.1080/00031305.2018.1464947\n\n\nWasserstein, R., & Schirm, A. (2019). Moving to a world beyond \\(p &lt; .05\\). Keynote presentation at the United States Conference on Teaching Statistics.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-01-coefficient-level-inference.html#footnotes",
    "href": "03-01-coefficient-level-inference.html#footnotes",
    "title": "11¬† Coefficient-Level Inference",
    "section": "",
    "text": "We actually compute the area under the probability curve that is greater than or equal to 3.42 AND that is less than or equal to \\(-3.42\\).‚Ü©Ô∏é\nA multiplier around two is associated with a 95% CI. A 99% CI would use a multiplier around 3.‚Ü©Ô∏é\nThe actual limits from the 95% CI are computed using a multiplier that is slightly different than two; thus the discrepancy between our off-the-cuff computation earlier and the result from tidy(). Using a multiplier of two is often close enough for practical purposes, especially when the sample size is large.‚Ü©Ô∏é\nIt turns out this is quite a complicated question and the effects of homework depend on a variety of student factors, including age, culture, household income, etc. Many studies have also found a non-linear effect of homework, indicating there may be an optimum amount for some groups of students.‚Ü©Ô∏é",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Coefficient-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-02-model-level-inference.html",
    "href": "03-02-model-level-inference.html",
    "title": "12¬† Model-Level Inference",
    "section": "",
    "text": "12.1 Model-Level Inference\nIn the previous chapter, we looked at how to carry out statistical tests of hypotheses and quantify the uncertainty associated with the coefficients in the simple regression model. Sometimes you are interested in the model as a whole, rather than the individual parameters. For example, you may be interested in whether a set of predictors together explains variation in the outcome. (This is more relevant when we have multiple predictors!) Model-level information is displayed using the glance() output from the {broom} package. Below we fit a model by regressing GPA on time spent on homework, store those results in an object called lm.a, and then print the model-level output.\n# Fit regression model\nlm.a = lm(gpa ~ 1 + homework, data = keith)\n\n# Model-level output\nglance(lm.a)\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.107        0.0981  7.24      11.8 0.000885     1  -339.  684.  691.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    5136.          98   100\nThe r.squared column indicates the proportion of variation in the outcome explained by differences in the predictor in the sample. Here, differences in time spent on homework explains 10.7% of the variation in students‚Äô GPAs for the 100 students in the sample. The inferential question at the model-level is: Does the model explain variation in the outcome, in the population? This can formally be expressed in a statistical hypothesis as,\n\\[\nH_0: \\rho^2 = 0\n\\]\nTo test this, we need to be able to obtain the sampling distribution of \\(R^2\\) to estimate the uncertainty in the sample estimate. The thought experiment for this goes something like this: Imagine you have a population that is infinitely large. The observations in this population have two attributes, call them X and Y. There is NO relationship between these two attributes; \\(\\rho^2 = 0\\). Randomly sample n observations from the population. Fit the regression and compute the \\(R^2\\) value. Repeat the process an infinite number of times.\nFigure¬†12.1: Thought experiment for sampling samples of size n from the population to obtain the sampling distribution of R-squared.\nBelow is a density plot of the sampling distribution for \\(R^2\\) based on 1,000 random samples of size 32 drawn from a population where \\(\\rho^2=0\\). (Not an infinite number of draws, but large enough that we should have an idea of what the distribution might look like.)\nFigure¬†12.2: Sampling distribution based on 1000 simple random samples of size 32 drawn from a population where \\(\\rho^2=0\\).\nMost of the \\(R^2\\) values are near 0, although there is some variability that is due to sampling error. This sampling distribution is right-skewed. (WHY???) This means that we cannot use a t-distribution to model this distribution‚Äîremember the t-distribution is symmetric around zero. It turns out that this sampling distribution is better modeled using an F-distribution.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Model-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-02-model-level-inference.html#model-level-inference",
    "href": "03-02-model-level-inference.html#model-level-inference",
    "title": "12¬† Model-Level Inference",
    "section": "",
    "text": "12.1.1 The F-Distribution\nIn theoretical statistics, the F-distribution is the ratio of two chi-squared statistics,\n\\[\nF = \\frac{\\chi^2_1 / \\mathit{df}_1}{\\chi^2_2 / \\mathit{df}_2}\n\\]\nwhere \\(\\mathit{df}_1\\) and \\(\\mathit{df}_2\\) are the degrees of freedom associated with each of the chi-squared statistics, respectively. For our purposes, we don‚Äôt need to pay much attention to this other than to the fact that an F-distribution is defined using TWO parameters: \\(\\mathit{df}_1\\) and \\(\\mathit{df}_2\\). Knowing these two values completely parameterize the F-distribution (they give the shape, expected value, and variation).\nIn regression analysis, the F-distribution associated with model-level inference is based on the following degrees of freedom:\n\\[\n\\begin{split}\n\\mathit{df}_1 &= p \\\\\n\\mathit{df}_2 &= \\mathit{df}_{\\mathrm{Total}}-p\n\\end{split}\n\\]\nwhere p is the number of predictors used in the model and \\(\\mathrm{Total}\\) is the total degrees of freedom in the data used in the regression model (\\(\\mathrm{Total}=n-1\\)). In our example, \\(\\mathit{df}_1=1\\) and \\(\\mathit{df}_2=99-1=98\\). Using these values, we have defined the \\(F(1,98)\\)-distribution.\nThe F-distribution is the sampling distribution of F-values (not \\(R^2\\)-values). But, it turns out that we can easily convert an \\(R^2\\)-value to an F-value using,\n\\[\nF = \\frac{R^2}{1 - R^2} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1}\n\\]\nIn our example,\n\\[\n\\begin{split}\nF &= \\frac{0.107}{1 - 0.107} \\times \\frac{98}{1} \\\\[1em]\n&= 0.1198 \\times 98 \\\\[1em]\n&= 11.74\n\\end{split}\n\\]\nThus, our observed F-value is: \\(F(1,98)=11.74\\). To evaluate this under the null hypothesis, we find the area under the \\(F(1,98)\\) density curve that corresponds to F-values at least as extreme as our observed F-value of 11.74.\n\n\n\n\n\n\n\n\nFigure¬†12.3: Plot of the probability curve for the F(1,98) distribution. The shaded area under the curve represents the p-value for a test evaluating whether the population rho-squared is zero using an observed F-value of 11.74.\n\n\n\n\n\nThis area (which is one-sided in the F-distribution) corresponds to the p-value. In our case this p-value is 0.000885. The probability of observing an F-value at least as extreme as we the one we observed (\\(F=11.74\\)) under the assumption that the null hypothesis is true is 0.000885. This suggests that the empirical data are inconsistent with the hypothesis that \\(\\rho^2=0\\), and it is unlikely that the model explains no variation in students‚Äô GPAs.\n\n\n\n12.1.2 Using the F-distribution in Practice\nIn practice, all of this information is provided in the output of the glance() function.\n\nglance(lm.a)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.107        0.0981  7.24      11.8 0.000885     1  -339.  684.  691.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    5136.          98   100\n\n\nThe observed F-value is given in the statistic column and the associated degrees of freedom are provided in the df and df.residual columns. Lastly, the p-value is given in the p.value column. When we report results from an F-test, we need to report the values for both degrees of freedom, the F-value, and the p-value.\n\nThe model-level test suggested that the empirical data are not consistent with the null hypothesis that the model explains no variation in GPAs; \\(F(1,98)=11.8\\), \\(p&lt;0.001\\).\n\n\n\n\n12.1.3 ANOVA Decomposition\nWe can also get the model-level inferential information from the anova() output. This gives us the ANOVA decomposition for the model.\n\n# Obtain ANOVA decomposition\nanova(lm.a)\n\n\n  \n\n\n\nNote that the two df values for the model-level F-statistic correspond to the df in each row of the ANOVA table. The first df (in this case, 1) is the model degrees-of-freedom, and the second df (in this case, 98) is the residual degrees-of-freedom. Note the p-value is the same as that from the glance() function.\nThis ANOVA decomposition also breaks out the sum of squared values into the variation explained by the model (616.5) and that which is unexplained by the model (residual variation; 5136.4). Summing these two values will give the total amount of variation which can be used to compute \\(R^2\\); \\(R^2 = \\mathrm{SS}_{\\mathrm{Model}}/\\mathrm{SS}_{\\mathrm{Total}}\\).\nThis decomposition also gives us another way to consider the F-statistic. Recall that the F-statistic had a direct relationship to \\(R^2\\)\n\\[\nF = \\frac{R^2}{1 - R^2} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1}\n\\]\nSince \\(R^2 = \\mathrm{SS}_{\\mathrm{Model}}/\\mathrm{SS}_{\\mathrm{Total}}\\) we can rewrite this as:\n\\[\nF = \\frac{\\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}}{1 - \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1}\n\\]\nUsing algebra,\n\\[\n\\begin{split}\nF &= \\frac{\\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}}{\\frac{\\mathrm{SS}_{\\mathrm{Total}}}{\\mathrm{SS}_{\\mathrm{Total}}} - \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1} \\\\[2ex]\n&= \\frac{\\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}}{\\frac{\\mathrm{SS}_{\\mathrm{Total}} - \\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1} \\\\[2ex]\n&= \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Total}} - \\mathrm{SS}_{\\mathrm{Model}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1} \\\\[2ex]\n&= \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Error}}} \\times \\frac{\\mathit{df}_2}{\\mathit{df}_1} \\\\[2ex]\n\\end{split}\n\\]\nThis expression of the F-statistic helps us see that the F-statistic is proportional to the ratio of the explained and unexplained variation. So long as the degrees of freedom remain the same, if the model explains more variation, the numerator of the F-statistic gets larger and the denominator will be smaller. Thus, larger F-values are associated with more explained variation by the model. We could also have seen this in the earlier expression of the F-statistic using \\(R^2\\).\n\n\n\n12.1.4 The F-Statistic as the Ratio of Two Variance Estimates\nIn statistical theory, a sum of squares divided by a degrees of freedom is referred to as a mean squared value‚Äîthe average amount of variation per degree of freedom. Since \\(\\mathit{df}_1\\) is the model degrees of freedom and \\(\\mathit{df}_2\\) is the residual (or error) degrees of freedom we could also express the F-statistic as:\n\\[\n\\begin{split}\nF &= \\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathrm{SS}_{\\mathrm{Error}}} \\times \\frac{\\mathit{df}_{\\mathrm{Error}}}{\\mathit{df}_{\\mathrm{Model}}} \\\\[2ex]\n&= \\frac{\\frac{\\mathrm{SS}_{\\mathrm{Model}}}{\\mathit{df}_{\\mathrm{Model}}}}{\\frac{\\mathrm{SS}_{\\mathrm{Error}}}{\\mathit{df}_{\\mathrm{Error}}}} \\\\[2ex]\n&= \\frac{\\mathrm{MS}_{\\mathrm{Model}}}{\\mathrm{MS}_{\\mathrm{Error}}}\n\\end{split}\n\\]\nThus the F-value is the ratio of the average variation explained by the model and the average variation that remains unexplained. In our example\n\\[\n\\begin{split}\n\\mathrm{MS}_{\\mathrm{Model}} &= \\frac{616.5}{1} = 616.5 \\\\[2ex]\n\\mathrm{MS}_{\\mathrm{Error}} &= \\frac{5136.4}{98} = 52.41 \\\\\n\\end{split}\n\\]\nThese values are also printed in the anova() output.\n\n# Obtain ANOVA decomposition\nanova(lm.a)\n\n\n  \n\n\n\n\\[\nF = \\frac{616.5}{52.41} = 11.76\n\\]\nThe observed F-value of 11.76 indicates that the average explained variation is 11.76 times that of the average unexplained variation. There is an awful lot more explained variation than unexplained variation, on average. Another name for a mean squared value is a variance estimate. A variance estimate is literally the average amount of variation (in the squared metric) per degree of freedom. For example, go back to the introductory statistics formula for using sample data to estimate a variance:\n\\[\n\\hat\\sigma^2_Y = \\frac{\\sum(Y_i - \\bar{Y})^2}{n-1}\n\\]\nThis numerator is a sum of squares; namely the \\(\\mathrm{SS}_{\\mathrm{Total}}\\). The denominator is the total degrees of freedom. We could have also referred to this as a mean square\n\\[\n\\begin{split}\n\\hat\\sigma^2_Y &= \\frac{\\mathrm{SS}_{\\mathrm{Total}}}{\\mathit{df}_{\\mathrm{Total}}} \\\\[2ex]\n&= \\mathrm{MS}_{\\mathrm{Total}}\n\\end{split}\n\\]\nNote that the \\(\\mathrm{MS}_{\\mathrm{Total}}\\) is not printed in the anova() output. However, it can be computed from the values that are printed. The \\(\\mathrm{SS}_{\\mathrm{Total}}\\) is just the sum of the printed sum of squares, and likewise the \\[\\mathit{df}_{\\mathrm{Total}}\\] is the sum of the df values.\n\\[\n\\begin{split}\n\\mathrm{SS}_{\\mathrm{Total}} &= 616.5 + 5136.4 = 5752.9 \\\\[2ex]\n\\mathit{df}_{\\mathrm{Total}} &= 1 + 98 = 99\n\\end{split}\n\\]\nThen the \\(\\mathrm{MS}_{\\mathrm{Total}}\\) is the ratio of these values,\n\\[\n\\mathrm{MS}_{\\mathrm{Total}} = \\frac{5752.9}{99} = 58.11\n\\]\nSince this is an estimate of the outcome variable‚Äôs variance, we could also have computed the sample variance of the outcome variable, gpa, using the var() function.\n\n# Compute variance for outcome\nkeith |&gt;\n  summarize(V_gpa = var(gpa))\n\n\n  \n\n\n\nThe total mean square, or variance estimate, is also the mean square estimate of the residuals from the intercept-only model.\n\n# Fit intercept-only model\nlm.0 = lm(gpa ~ 1, data = keith)\n\n# ANOVA decomposition\nanova(lm.0)\n\n\n  \n\n\n\nRemember the sum of squared residuals is \\((Y_i - \\hat{Y_i})^2\\), but in the intercept-only model \\(\\hat{Y_i}\\) is the marginal mean, i.e., \\(\\hat{Y_i} = \\bar{Y}\\). This is the numerator of the sample variance estimate and is why the mean square error from the intercept-only model and the sample variance for GPA are equivalent!\n\n\n\n12.1.5 Relationship Between Coefficient-Level and Model-Level Inference\nLastly, we point out that in simple regression models (models with only one predictor), the results of the model-level inference (i.e., the p-value) are exactly the same as that for the coefficient-level inference for the slope.\n\n# Model-level inference\nglance(lm.a)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.107        0.0981  7.24      11.8 0.000885     1  -339.  684.  691.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    5136.          98   100\n\n\n\n# Coefficient-level inference\ntidy(lm.a)\n\n\n  \n\n\n\nThat is because the model is composed of a single predictor, so asking whether the model accounts for variation in GPA is the same as asking whether GPA is different, on average, for students who spend a one-hour difference in time on homework. Once we have multiple predictors in the model, the model-level results and predictor-level results will not be the same.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Model-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-02-model-level-inference.html#confidence-envelope-for-the-model",
    "href": "03-02-model-level-inference.html#confidence-envelope-for-the-model",
    "title": "12¬† Model-Level Inference",
    "section": "12.2 Confidence Envelope for the Model",
    "text": "12.2 Confidence Envelope for the Model\nRe-consider our thought experiment. Again, imagine you have a population that is infinitely large. The observations in this population have two attributes, call them X and Y. The relationship between these two attributes can be expressed via a regression equation as: \\(\\hat{Y}=\\beta_0 + \\beta_1(X)\\). Randomly sample n observations from the population, and compute the fitted regression equation, this time plotting the line (rather than only paying attention to the numerical estimates of the slope or intercept). Continue sampling from this population, each time drawing the fitted regression equation.\n\n\n\n\n\n\n\n\nFigure¬†12.4: Thought experiment for sampling samples of size n from the population to obtain the fitted regression line.\n\n\n\n\n\nNow, imagine superimposing all of these lines on the same plot.\n\n\n\n\n\n\n\n\nFigure¬†12.5: Plot showing the fitted regression lines for many, many random samples of size n.\n\n\n\n\n\nExamining where the sampled lines fall gives a visual interpretation of the uncertainty in the model. This two-dimensional display of uncertainty is referred to as a confidence envelope. In practice we estimate the uncertainty from the sample data and plot it around the fitted line from the sample.\nFor simple regression models, we can plot this directly by including the geom_smooth() layer in our plot. This adds a smoother to the plot. To add the fitted simple regression line, we use the argument method=\"lm\". This will add the fitted regression line and confidence envelope to the plot based on fitting a linear model to the variables included in the x= and y= arguments in the aesthetic mapping defined in aes().1 The color of the fitted line and of the confidence envelope can be set using color= and fill= respectively.\n\n# Create plot\nggplot(data = keith, aes(x = homework, y = gpa)) +\n  geom_smooth(method = \"lm\", color = \"#c62f4b\", fill = \"#696969\") +\n  xlab(\"Time spent on homework\") +\n  ylab(\"GPA (on a 100-pt. scale)\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure¬†12.6: GPA plotted as a function of time spent on homework. The OLS regression line (raspberry) and confidence envelope (grey shaded area) are also displayed.\n\n\n\n\n\nNote that we want to indicate the confidence envelope or make reference to the uncertainty in the figure caption. We pointed out that the confidence envelope indicates uncertainty by displaying the sampling variation associated with the location of the fitted regression line.\nWe can also use this plot to make inferences about the mean Y-value conditioned on X. For example, using the fitted regression equation, the model predicts that the mean GPA for students who spend 6 hours each week on homework is 81.6. Graphically this is the point on the fitted regression line associated with \\(X=6\\).\nHowever, we also now understand that there is uncertainty associated with estimates obtained from sample data. How much uncertainty is there in that estimate of 81.6? We can use the bounds of the confidence envelope at \\(X=6\\) to answer this question. The lower bound of the confidence envelope at \\(X=6\\) is approximately 80 and the upper bound is approximately 83. This tells, based on the sample data, we think the mean GPA for students who spend 6 hours each week on homework is between 80 and 83. Graphically, we can see these values in the plot.\n\n\n\n\n\n\n\n\nFigure¬†12.7: GPA plotted as a function of time spent on homework. The OLS regression line (raspberry) and confidence envelope (grey shaded area) are also displayed. The fitted value at X=6 is displayed as a point and the uncertainty in the estimate is displayed as an error bar.\n\n\n\n\n\nThis uncertainty estimate is technically a 95% confidence interval for the mean GPA for students who spend 6 hours each week on homework. As such, a more formal interpretation is:\n\nWith 95% confidence, the mean GPA for students who spend 6 hours each week on homework is between 80 and 83.\n\nNotice that there is more uncertainty for the mean GPA for some values of X than for others. This is because of the amount of information at each X. We have more information in the data around the mean X-value and less information at extreme X-values. That implies that we have more certainty in the estimates we make for the mean GPA for students who spend around 5 hours of homework each week than we do in students who only spend 1 hour a week or those who spend 11 hours a week on homework.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Model-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-02-model-level-inference.html#footnotes",
    "href": "03-02-model-level-inference.html#footnotes",
    "title": "12¬† Model-Level Inference",
    "section": "",
    "text": "The confidence envelope can be omitted by using the argument se=FALSE.‚Ü©Ô∏é",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Model-Level Inference</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html",
    "href": "03-03-model-assumptions.html",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "",
    "text": "13.1 Four Distributional Assumptions Needed for Validity of Regression Results\nThe validity of the statistical inferences (e.g., p-values, confidence intervals) rely on a set of distributional assumptions that we need to make about the errors in the population. Recall that the simple regression model (in the population) is expressed as:\n\\[\nY_i = \\beta_0 + \\beta_1(X_i) + \\epsilon_i\n\\]\nThe assumptions we make about the errors (\\(\\epsilon_i\\) values) in the regression model are:\nYou can remember these assumptions using the mnemonic LINE. To better understand these assumptions, imagine that we had the population of X- and Y-values in which all the distributional assumptions were valid. Now imagine we plotted the ordered pairs, \\((x_i,y_i)\\), and we also regressed the Y-values on the X-values and plotted this regression line as well. A visual depiction of this is shown in Figure¬†21.9.\nFigure¬†13.1: A visual depiction of X- and Y-values and regression line from a population in which the distributional assumptions are valid.\nIn Figure¬†21.9, the normal distributions depicted are the distribution of Y-values at each value of X, or what we refer to as the conditional distributions of Y. Although only three conditional distributions are shown in Figure 1, there is a conditional distribution for EVERY value of X.\nAlthough the distributional assumptions are about the model‚Äôs errors, we can also apply the assumptions to the conditional Y-values since they are linear transformations of the error terms. This allows us to use Figure¬†21.9 to expand upon each of the distributional assumptions listed earlier.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#four-distributional-assumptions-needed-for-validity-of-regression-results",
    "href": "03-03-model-assumptions.html#four-distributional-assumptions-needed-for-validity-of-regression-results",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "",
    "text": "[L]inearity\n[I]ndependence\n[N]ormality\n[E]qual variances (i.e., Homoskedasticity)\n\n\n\n\n\n\nLinearity: The linearity assumption implies that the MEAN values of \\(Y\\) from all the conditional distributions all fall on the same line. If this is the case, we would say that the conditional mean \\(Y\\)-values are linear.\nIndependence: This is not shown in the figure. The assumption is that each \\(Y\\)-value in a particular conditional distribution is independent from every other \\(Y\\)-value in that same distribution.\nNormality: This assumption indicates that every one of the conditional distributions of \\(Y\\)-values is normally distributed.\nEqual variances: This assumption says that the variance (or standard deviation) of all of the conditional distributions is exactly the same.\n\n\n\n13.1.1 Distributional Assumptions are Really About the Residuals\nStating these distributional assumptions in terms of the conditional distributions of Y was useful in helping us visualize them within a typical representation of the regression model through the relationship between X- and Y-values. Technically, however, all the distributional assumptions are about the conditional distributions of the residuals.1 Think about how we compute the residuals:\n\\[\n\\epsilon_i = Y_i - \\hat{Y}_i\n\\] In Figure¬†21.9, the \\(\\hat{Y}_i\\) value is the \\(Y\\)-value that corresponds to the point on the line. Within each conditional distribution of Y, the \\(\\hat{Y}_i\\) is constant; in other words all of the observations with the same X-value will have the same \\(\\hat{Y}_i\\)-value. That means within a conditional distribution, to compute the residual values, we are subtracting a constant:\n\\[\n\\epsilon_i = Y_i - C\n\\]\nRemember, subtracting a constant from each value in a distribution shifts the center of the distribution. Pick any conditional distribution from Figure 1, which is a normal distribution centered at the \\(\\hat{Y}_i\\) value. Now subtract the \\(\\hat{Y}_i\\)-value from each Y-value. This will re-center the normal distribution at 0. Thus, the conditional distribution of residuals is normally distributed, has a mean of 0, and has the same variance (or standard deviation) as the conditional distribution of Y-values. If we transform every Y-value in the population, from Figure¬†21.9, to a residual value, and re-plot them, the visual depiction now looks like this.\n\n\n\n\n\n\n\n\nFigure¬†13.2: A visual depiction of the simple regression model‚Äôs assumptions about the residuals.\n\n\n\n\n\nSo if we restate the assumptions in terms of the residuals and the conditional distributions of the residuals,\n\nLinearity: The MEAN value of each of the conditional distributions of the residuals is 0.\nIndependence: Again, this is not shown in the figure. The assumption is that each residual value in a particular conditional distribution is independent from every other residual value in that same distribution.\nNormality: This assumption indicates that each of the conditional distributions of residuals is normally distributed.\nEqual variance: The variance (or standard deviation) of all of the conditional distributions of residuals is exactly the same.\n\nThese assumptions can also be expressed mathematically as,\n\\[\n\\epsilon_{i|X} \\overset{\\mathrm{i.i.d~}}{\\sim} \\mathcal{N}\\left(0, \\sigma^2\\right)\n\\]\nThe ‚Äúi.i.d‚Äù stands for independent and identically distributed. The mathematical expression says the residuals conditioned on X (having the same X-value) are independent and identically normally distributed with a mean of 0 and some variance (\\(\\sigma^2\\)).",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#evaluating-the-distributional-assumptions",
    "href": "03-03-model-assumptions.html#evaluating-the-distributional-assumptions",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "13.2 Evaluating the Distributional Assumptions",
    "text": "13.2 Evaluating the Distributional Assumptions\nBefore beginning to evaluate the distributional assumptions using our empirical data, it is important to point out that the assumptions are about the residuals in the population. Because in most analyses, we only have a sample of data, we can never really evaluate whether these assumptions are true. We can only offer a guess as to whether they are tenable given the data we see. The strongest argument for justifying any of the distributional assumptions is a theoretical argument based on existing literature in the discipline.\n\n\n13.2.1 Linearity\nThe linearity assumption is critical in specifying the structural part of the model. Fitting a linear model when the TRUE relationship between X and Y is non-linear may be quite problematic. Coefficients may be wrong. Predictions may also be wrong, especially at the extreme values for X. More importantly, mis-specified models lead to misinformed understandings of the world.\n\n\n\n\n\n\n\n\nFigure¬†13.3: The left-hand plot shows observations simulated from a nonlinear model. The right-hand plot shows the same data and the results of fitting a linear model to non-linear data. Using the linear fitted model to make predictions would be quite misleading, especially at extreme values of X.\n\n\n\n\n\nIn the left-hand plot of Figure¬†13.3, when the correct nonlinear model is fitted to the data, the conditional Y-values are scattered above and below the line at each X-value. In the right-hand plot of Figure¬†13.3, when a linear model was fitted to data generated from a non-linear function, the data tend to either be consistently above, or below the line, depending on the X-value. This type of systematic deviation would be evidence that the linearity assumption is not tenable. When evaluating this assumption, we want to see data in the scatterplot that is ‚Äúequally‚Äù above and below the fitted regression line at each value of X.\nSince the linearity assumption also means that the average residual is 0, if we are evaluating this assumption by looking at a plot of the residuals, we would want to see residuals above (positive) and below (negative) 0. Figure 4 shows scatterplots of the residuals versus the X-values from the two fitted lines. In the left-hand plot, when the residuals are based on the true model, we see that the residuals are scattered above and below 0 at each value of X. In the right-hand plot, in which the residuals were computed based on a mis-specified linear model, we again see that the residuals are clustered above, or below 0, depending on the value of X.\n\n\n\n\n\n\n\n\nFigure¬†13.4: The left-hand plot shows the residuals from the true nonlinear model versus the X-values. The right-hand plot shows the residuals from the mis-specified linear model versus the X-values. A reference line at \\(Y=0\\) has also been added to the plot to aid interpretation.\n\n\n\n\n\n\n\n\n13.2.2 Independence\nThe definition of independence relies on formal mathematics. Loosely speaking a set of observations is independent if knowing that one observation is above (or below) the mean value in a conditional distribution conveys no information about whether any other observation in the same conditional distribution is above (or below) its mean value. If observations are not independent, we say they are dependent or correlated.\nIndependence is not an assumption we can check graphically. To evaluate this assumption we need to know something about how the data were collected or assigned to values of X. Using random chance in the design of the study, to either select observations (random sampling) or assign them to levels of the predictor (random assignment) will guarantee independence of the observations. Outside of this, independence is often difficult to guarantee, and often has to be a logical argument.\nThere are a few times that we can ascertain that the independence assumption would be violated. These instances often result from aspects of the data collection process. One such instance common to social science research is when the observations (i.e., cases, subjects) are collected within a physical or spatial proximity to one another. For example, this is typically the case when a researcher gathers a convenience sample based on location, such as sampling students from the same school. Another violation of independence occurs when observations are collected over time (longitudinally), especially when the observations are repeated measures from the same subjects.\nOne last violation of independence occurs when the observation level used to assign cases to the different predictor values (e.g., treatment or control) does not correspond to the observation level used in the analysis. For example, in educational studies whole classrooms are often assigned to treatment or control. That means that the cases used in the analysis, in order to satisfy the independence assumption, would need to be at the classroom level (e.g., the cases would need to be classroom means), not individual students. This can be deleterious for the sample size.\nIf the independence assumption is violated, almost every value you get in the tidy() and glance() output‚Äîthe standard errors, t-values, F-values, p-values, and residual standard errors (RMSE)‚Äîare wrong. If you suspect that the independence assumption is violated, then you will need to use a method (not OLS regression) that accommodates non-independence.2\n\n\n\n13.2.3 Normality and Equal Variances\nThe assumption about normality is about the conditional distribution of errors at each value of X. This assumption is less critical than the assumptions of linearity and independence. It is only problematic for the OLS regression results if there are egregious violations of normality. In general, if the violations of these assumptions are only minor, the results of the OLS regression are still valid; we would say the results from an OLS regression are robust to violations of normality. Even if the violations are bad, there are many transformations of the data that can alleviate this problem.3\nNormal distributions are symmetric with the density of observations close to the mean. This means that in the scatterplot of the residuals versus the X-values, we want to see symmetry around 0 at each X-value and that most of the residuals are ‚Äúclose‚Äù to 0 (‚ÄúClose‚Äù is hard to define as it depends on the standard deviation, remember that 68% of the residuals should be within one standard deviation, 95% within two standard deviations, etc.)\n\n\n\n\n\n\n\n\nFigure¬†13.5: The left-hand plot shows conditional distributions of normally distributed residuals. The right-hand plot shows conditional distributions that are not normally distributed. The line \\(Y=0\\) has also been included to aid interpretation.\n\n\n\n\n\nThe residuals in the left-hand plot of Figure 4 are symmetric around 0 for each X-value. The bulk of the residuals at each X-value is near 0 and they become less dense the further from 0 they are, for both the positive and negative residual values. This is the pattern we want to see in empirical residuals. The residuals in the right-hand plot of Figure 4, are not symmetric around 0. They are also more dense in the negative values and then become less dense for higher positive values. This is evidence that the normality assumption is violated.\nIn the examples given in Figure 4, the number of observations and the shape of the conditional distributions make deviations from normality easier to spot. Evaluating the normality assumption in empirical data, which are often composed of fewer observations, is much more of a challenge. Moreover, evaluating the shape of distributions in a scatterplot is not an easy task.\nResearchers often evaluate the normality assumption by examining the shape of the marginal distribution of the residuals. Figure 5 shows density plots of the marginal distributions for the same two sets of residuals plotted in Figure 4.\n\n\n\n\n\n\n\n\nFigure¬†13.6: The left-hand plot shows conditional distributions of normally distributed residuals. The right-hand plot shows conditional distributions that are not normally distributed. The line \\(Y=0\\) has also been included to aid interpretation.\n\n\n\n\n\nThe marginal distribution in the right-hand plot clearly shows deviation from normality and we could safely say that the normality assumption is violated. We may be tempted to say that the marginal distribution in the left-hand plot also violates the assumption of normality as the density plot does not look normal. This would be a mistake. Remember that the assumptions are about the residuals in the population; the sample residuals may deviate from normality simply because of sampling error. Moreover, this looks like a minor violation of the normality assumption and is probably not an issue for the regression results.\n\n\n13.2.4 Equal Variances\nSimilar to the assumption about normality, the assumption of equal variances (homoskedasticity) is less critical than the assumptions of linearity and independence, and only egregious violations of the assumption is problematic for the validity of the regression results.4\n\n\n\n\n\n\n\n\nFigure¬†13.7: The left-hand plot shows conditional distributions of normally distributed residuals with equal variances. The center plot shows conditional distributions that are not normally distributed but still have equal variances. The right-hand plot shows conditional distributions that are normally distributed but have unequal variances. The line \\(Y=0\\) has also been included in all plots to aid interpretation.\n\n\n\n\n\nWhen evaluating the assumption of equal variances, we want to see that the range of residual values at each X-value is roughly the same. For the left-hand and center plots in Figure 6, the range of residual values is roughly the same at each X-value, so we can conclude that the equal variances assumption is tenable. In the right-hand plot, the residuals show a pattern of variances that seems to be increasing for larger X-values. That is, the range of the residual values at smaller X-values is smaller than the range of the residual values at larger X-values. This is a violation of the equal variances assumption.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#empirically-evaluating-the-distributional-assumptions",
    "href": "03-03-model-assumptions.html#empirically-evaluating-the-distributional-assumptions",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "13.3 Empirically Evaluating the Distributional Assumptions",
    "text": "13.3 Empirically Evaluating the Distributional Assumptions\nWe can use the residuals computed from the empirical data to evaluate the distributional assumptions of linearity, normality, and equal variances. (The assumption of independence is difficult to evaluate using the data, and is better left to a logical argument that refers to the study design.) Recall that the assumptions are about the residuals. To compute the residuals, we will use the augment() function from the {broom} package. We will also write those results into an object, aug_a, so we can compute on it later.\n\n# Load library\nlibrary(broom)\n\n# Augment the model to get residuals\naug_a = augment(lm.a)\n\n# View augmented data\naug_a\n\n\n\n# A tibble: 100 √ó 8\n     gpa homework .fitted .resid   .hat .sigma   .cooksd .std.resid\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1    78        2    76.7  1.28  0.0328   7.28 0.000550      0.180 \n 2    79        6    81.6 -2.57  0.0120   7.27 0.000776     -0.358 \n 3    79        1    75.5  3.50  0.0500   7.27 0.00646       0.495 \n 4    89        5    80.4  8.64  0.0100   7.22 0.00728       1.20  \n 5    82        3    77.9  4.07  0.0204   7.26 0.00336       0.568 \n 6    77        4    79.1 -2.15  0.0128   7.27 0.000579     -0.298 \n 7    88        5    80.4  7.64  0.0100   7.23 0.00569       1.06  \n 8    70        3    77.9 -7.93  0.0204   7.23 0.0128       -1.11  \n 9    86        5    80.4  5.64  0.0100   7.25 0.00310       0.783 \n10    80        5    80.4 -0.361 0.0100   7.28 0.0000127    -0.0501\n# ‚Ñπ 90 more rows\n\n\nThe cases in the augmented data frame are in the same order as the cases in the keith data frame. For example, the first case had a GPA of 78 and spent 2 hours a week on homework. The augmented data also includes several other useful measures for evaluating regression models. For now, we will focus on the .fitted column and the .resid column. Those columns contain the fitted values (\\(\\hat{Y_i}\\)) and the residuals for each case based on the model fitted in lm.a.\nWe will examine two residual plots to help us evaluate the tenability of the assumptions: (1) a density plot of the marginal distribution of residuals, and (2) a scatterplot of the residuals versus the X-values. The density plot will allow us to evaluate the normality assumption, and the scatterplot will allow us to evaluate the linearity and equal variances assumption. As we make these evaluations, remember that we do not have the entire population of residuals (we obtained our residuals by fitting a regression to a sample of data), so we do not expect that our residuals will actually meet the assumptions perfectly (remember, sampling error). Examining the sample residuals, is however, a reasonable way to evaluate the tenability of assumptions in practice. We just have to keep in mind that the sample residuals may deviate a bit from these assumptions.\n\n# Density plot of the residuals\np1 = ggplot(data = aug_a, aes(x = .resid)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Residual\") +\n  ylab(\"Probability density\")\n\n# Scatterplot of the residuals versus X\np2 = ggplot(data = aug_a, aes(x = homework, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  theme_bw() +\n  xlab(\"Time spent on homework (in hours)\") +\n  ylab(\"Residual\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†13.8: LEFT: Density plot of the marginal distribution of residuals from the fitted regression model. RIGHT: Scatterplot of the residuals versus time spent on homework. The \\(Y=0\\) line has been included as a reference for interpretation.\n\n\n\n\n\nThe marginal distribution of residuals looks symmetric and bell-shaped. Based on this plot, the normality assumption seems tenable (or at least there is a negligable violation of the assumption). The scatterplot of residuals versus time spent on homework shows random scatter around the line \\(Y=0\\). This suggests that the average residual is roughly 0 at each X-value, and that the linearity assumption seems tenable. The range of the residuals at each X-value seems similar indicating that the assumption of equal variances is also tenable. Lastly, since the observations were randomly sampled (see data codebook) we believe the independence assumption is satisfied.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#standardized-residuals",
    "href": "03-03-model-assumptions.html#standardized-residuals",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "13.4 Standardized Residuals",
    "text": "13.4 Standardized Residuals\nOften researchers standardize the residuals before performing the assumption checking. Using standardized residuals rather than unstandardized (raw) residuals does not change any of the previous findings. In fact, since standardizing is a linear transformation, the scatterplot and density plot look identical whether you use the unstandardized residuals or the standardized residuals. The only thing that changes is the scale on the residual axis of the plots.\nTo standardize a residual, we subtract the mean of its conditional distribution and divide by the standard deviation. The distributional assumptions stated that the mean of each conditional distribution of the residuals is 0 and the standard deviation is the same, although unknown, namely \\(\\sigma_{\\epsilon}\\). Mathematically, we standardize using:\n\\[\nz_{\\epsilon} = \\frac{\\epsilon - 0}{\\mathrm{\\sigma}_{\\epsilon}}\n\\]\nUnfortunately, we do not know what the value for \\(\\sigma_{\\epsilon}\\), so we need to estimate it from the data. This adds uncertainty to the calculation of the standardized residual in the same way estimating the standard error in a normal distribution adds uncertainty and makes the distribution t-distributed. As such, we write the formula for the standardized residuals using a t rather than z and compute it as:\n\\[\nt_{\\epsilon} = \\frac{\\epsilon - 0}{\\mathrm{\\hat\\sigma}_{\\epsilon}}\n\\]\nSince the t-distribution is also referred to as Student‚Äôs distribution, standardized residuals are also sometimes referred to as studentized residuals.5 What standardizing does for us is to put the residuals on a scale that uses the standard error. This allows us to judge whether particular residuals that look extreme (either highly positive or negative) are actually extreme or not. The standardized residuals are given in the augmented output in the .std.resid column.\n\n# Density plot of the residuals\np1 = ggplot(data = aug_a, aes(x = .std.resid)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n# Scatterplot of the residuals versus X\np2 = ggplot(data = aug_a, aes(x = homework, y = .std.resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  theme_bw() +\n  xlab(\"Time spent on homework (in hours)\") +\n  ylab(\"Standardized residual\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†13.9: LEFT: Density plot of the marginal distribution of standardized residuals from the fitted regression model. RIGHT: Scatterplot of the standardized residuals versus time spent on homework. The \\(Y=0\\) line has been included as a reference for interpretation.\n\n\n\n\n\nThe only thing that has changed between these plots and the previous plots of the unstandardized residuals is the scale on the y-axis. However, now we can identify observations with extreme residuals, because we can make use of the fact that most of the residuals (~95%) should fall within two standard errors from the mean of 0. There are four students who have residuals of more than two standard errors. Given that we have \\(N=100\\) observations, it is not surprising to see four observations more extreme than two standard errors; remember we expect to see 5% just by random chance. If observations have really extreme residuals (e.g., \\(|t_{\\epsilon}|&gt;3.5\\)), it is often worth a second look since these extreme observations are interesting and may point to something going on in the data.\nWe can also filter() the augmented data to find these observations and to determine the exact value of the standardized residuals. Recall that the vertical line (|) means ‚ÄúOR‚Äù.\n\n# Identify extreme observations\naug_a |&gt; \n  filter(.std.resid &lt;= -2 | .std.resid &gt;= 2)",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#using-the-fitted-values-rather-than-x-in-the-scatterplot",
    "href": "03-03-model-assumptions.html#using-the-fitted-values-rather-than-x-in-the-scatterplot",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "13.5 Using the Fitted Values Rather than X in the Scatterplot",
    "text": "13.5 Using the Fitted Values Rather than X in the Scatterplot\nIn practice, when we evaluate the assumptions, we often use the fitted values (the \\(\\hat{Y}_i\\) values) rather than the X-values when we create the scatterplot. To do this, we use x=.fitted in the aes() function of ggplot() (Recall that the fitted values are stored in the .fitted column of the augmented output.)\n\n# Scatterplot of the residuals versus the fitted values\nggplot(data = aug_a, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  theme_bw() +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n\n\n\n\n\n\nFigure¬†13.10: Scatterplot of the standardized residuals versus the fitted values. The \\(Y=0\\) line has been included as a reference for interpretation.\n\n\n\n\n\nNotice that other than the scale on the x-axis, this plot is identical to the previous scatterplot of the standardized residuals versus time spent on homework. (This will always be true for simple regression models.) That is because the fitted values are just linear combinations of the X-values. Since the scale is not relevant for evaluating the assumptions, we come to the same conclusions about the assumptions using this plot as we did previously:\n\nThe linearity assumption seems tenable: The average residual is roughly 0 at each fitted value.\nThe assumption of equal variances is also tenable: The range of the residuals at each fitted value seems similar.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#advanced-plotting-accounting-for-sampling-uncertainty-in-the-density-plot",
    "href": "03-03-model-assumptions.html#advanced-plotting-accounting-for-sampling-uncertainty-in-the-density-plot",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "13.6 Advanced Plotting: Accounting for Sampling Uncertainty in the Density Plot",
    "text": "13.6 Advanced Plotting: Accounting for Sampling Uncertainty in the Density Plot\nSo far, when we have evaluated the normality assumption we have relied on our intuition (and experience) about whether the density plot of the marginal distribution of residuals was close to (or at least close enough to) normal. One thing we could do to help with this evaluation is to include a reference line showing normality as a basis of comparison. For example, here we again plot the marginal distribution of the standardized residuals from the fitted multiple regression. But this time, we also include the normal reference density.\n\n# Density plot of the standardized residuals\nggplot(data = aug_a, aes(x = .std.resid)) +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = \"black\", linetype = \"dashed\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n\n\n\n\n\n\nFigure¬†13.11: Density plot of the marginal distribution of standardized residuals from the fitted regression model (raspberry, solid line). The density for a ~N(0,1) distribution (black, dashed line) has been included as a comparative reference.\n\n\n\n\n\nThe stat_function() layer uses the dnorm() function to plot the normal density. Since this is for the standardized residuals, we assume a mean of 0 and a standard deviation of 1 for this normal distribution. These parameters are included in the args=list() argument. The density of the standardized residuals is close to that for the normal distribution, although it is not perfect (e.g., flatter peak than normal). The big question is whether this deviation is more than we would expect because of sampling error?\nTo answer this question, we need to be able to visualize the deviation from a perfectly normal distribution that is due to sampling error.\n\n\n\n\n\n\n\n\nFigure¬†13.12: The density for a ~N(0,1) distribution (black, dashed line) and the sampling uncertainty associated with that normal distribution (blue shaded area).\n\n\n\n\n\nIn this plot, the black, dashed line corresponds to where the density curve would lie if the distribution was normally distributed. The blue shaded area is the confidence envelope for the normal distribution. In other words, it shows the area we would expect a density curve to lie in if it came from the normal distribution.\nTo create this confidence envelope, we will use the stat_density_confidence() layer from the {educate} package (see below for instructions on how to install the {educate} package). We provide this layer the argument model=\"normal\".\n\n# Load library\nlibrary(educate)\n\n# Density plot of the standardized residuals\nggplot(data = aug_a, aes(x = .std.resid)) +\n  stat_density_confidence(model = \"normal\") +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n\n\n\n\n\n\nFigure¬†13.13: Density plot of the marginal distribution of standardized residuals from the fitted regression model (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area).\n\n\n\n\n\nThe raspberry line depicting the density of the marginal distribution of standardized residuals lies completely within the blue area. This suggests that the deviation we saw earlier from the normal distribution is consistent with just being sampling error. Thus we conclude that the normality assumption is tenable.\n\n13.6.1 Installing the educate Package\nThe {educate} package is not available on CRAN, thus you cannot install it using the Install button in RStudio. To install this package, we need to use the install_github() function from the {remotes} package.\n\nUse the Install button in RStudio to install the {remotes} package.\nOnce the {remotes} package has successfully installed, use the following syntax to install the {educate} package:\n\n\nremotes::install_github(\"zief0002/educate\")",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#advanced-plotting-loess-smooth-to-help-evaluate-linearity",
    "href": "03-03-model-assumptions.html#advanced-plotting-loess-smooth-to-help-evaluate-linearity",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "13.7 Advanced Plotting: Loess Smooth to Help Evaluate Linearity",
    "text": "13.7 Advanced Plotting: Loess Smooth to Help Evaluate Linearity\nIn the scatterplot of the standardized residuals versus the fitted values, if the assumption of ‚Äúlinearity‚Äù is tenable, we would expect that the average value of the residual at a given fitted value would be 0‚Äîwithin sampling error. Because the fitted values and the residuals (or standardized residuals) are independent a fitted regression line in this plot would be at \\(Y=0\\). We can use the geom_smooth() function with the argument method=\"lm\" to include this line The argument se=TRUE in this function will also add the confidence envelope.\n\nggplot(data = aug_a, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) + #ADD Line and confidence envelope\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n\n\n\n\n\n\nFigure¬†13.14: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework to predict GPA. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption.‚Äù\n\n\n\n\n\nThe confidence envelope shows us how much variation we might expect from the line \\(Y=0\\) because of sampling error.\nThe second thing we want to add to the plot is the loess smoother. This smoother helps us visualize the mean pattern in the actual data. To do this we will add a second geom_smooth() function with the arguments method=\"loess\" and se=TRUE. This will include the loess smoother without a confidence envelope around it.\n\nggplot(data = aug_a, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) + #ADD Line and confidence envelope\n  geom_smooth(method = \"loess\", se = FALSE) + #ADD loess smoother\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n\n\n\n\n\n\nFigure¬†13.15: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework to predict GPA. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption. The loess line (blue) and uncertainty bands (grey shaded area) are also displayed.\n\n\n\n\n\nWe can then evaluate if the loess smoother is encompassed inside the confidence envelope of what is expected if the assumption that the average residual is equal to 0 is actually met. In Figure¬†13.15 the plot suggests the assumption of ‚Äúlinearity‚Äù might be violated. Although the loess smoother is mostly inside the confidence envelope, there does seem to be some minor deviation around fitted values of 81.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#advanced-plotting-identify-observations-with-extreme-residuals",
    "href": "03-03-model-assumptions.html#advanced-plotting-identify-observations-with-extreme-residuals",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "13.8 Advanced Plotting: Identify Observations with Extreme Residuals",
    "text": "13.8 Advanced Plotting: Identify Observations with Extreme Residuals\nIt can be useful to identify particular observations in the residual plots directly. This can be useful as you explore the plots, and also to create plots for publications in which you wish to highlight particular cases. Rather than plotting points (geom_point()) for each observation, we can plot text for each observation using geom_text(). For example, you might imagine writing the name of each student in place of their point on the scatterplot. To do this, we need to:\n\nCreate an ID variable in the augmented data.\nUse geom_text() rather than geom_point() in the ggplot syntax. In the geom_text() function we will set label= to the newly created ID variable, and since it is a variable in the data set, we will put that in an aes() function.\n\nSince the original data set does not include an ID variable (e.g., names), we will use the row number from the original data as the ID. In other words the student in the first row will have an ID of 1, the student in the second row will have an ID of 2, etc.\n\n# Create ID variable in the augmented data\naug_a = aug_a |&gt; \n  mutate(id = row.names(keith))\n\n# View new data\nhead(aug_a)\n\n\n\n\n\n\n\n\nFigure¬†13.16: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework to predict GPA. The values plotted indicate the students‚Äô row numbers in the data. Horizontal lines at \\(Y={-2, 0, +2}\\) are included to aid interpretation.\n\n\n\n# Plot the id variable as text rather than points in the scatterplot\nggplot(data = aug_a, aes(x = .fitted, y = .std.resid)) +\n  geom_text(aes(label = id), size = 4) +\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  geom_hline(yintercept = -2, linetype = \"dotted\") +\n  geom_hline(yintercept = 2, linetype = \"dotted\") +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residuals\")\n\n\n\n\n\n\n\nFigure¬†13.17: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework to predict GPA. The values plotted indicate the students‚Äô row numbers in the data. Horizontal lines at \\(Y={-2, 0, +2}\\) are included to aid interpretation.\n\n\n\n\n\nWe can also plot points for some students and ID label for other students. For example, suppose we wanted to give the ID number for only those students with a standardized residual that was less than \\(-2\\) or greater than 2, and plot a point otherwise. To do this, we would create the ID variable in the augmented data (which we have already done), then split the data frame into two data frames: one for those students with extreme residuals and one for those that have a non-extreme residual. Then we will call geom_point() for those in the non-extreme data set, and geom_text() for those in the extreme set. We do this by including a data= argument in one of those functions to reference a different data frame.\n\n# Create different data sets for the extreme and non-extreme observations\nextreme = aug_a |&gt; \n  filter(.std.resid &lt;= -2 | .std.resid &gt;= 2)\n\nnonextreme = aug_a |&gt; \n  filter(.std.resid &gt; -2 & .std.resid &lt; 2)\n\n# Plot using text for the extreme observations and points for the non-extreme\nggplot(data = extreme, aes(x = .fitted, y = .std.resid)) +\n  geom_text(aes(label = id), size = 4, color = \"red\") +\n  geom_point(data = nonextreme) +\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n\n\n\n\n\n\nFigure¬†13.18: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework to predict GPA. Students with standardized residuals more than two standard errors from 0 are identified by their row number. A horizontal line at \\(Y=0\\) is included to aid interpretation.",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "03-03-model-assumptions.html#footnotes",
    "href": "03-03-model-assumptions.html#footnotes",
    "title": "13¬† Assumptions Underlying the Regression Model",
    "section": "",
    "text": "This is true for other statistical models as well (e.g., ANOVA, t-test).‚Ü©Ô∏é\nWe cover some of these methods in EPsy 8252.‚Ü©Ô∏é\nWe will cover some of those transformations in EPsy 8252.‚Ü©Ô∏é\nAgain, there are many transformations of the data that can alleviate this problem.‚Ü©Ô∏é\nTechnically they are internally studentized residuals.‚Ü©Ô∏é",
    "crumbs": [
      "Regression Inference",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Assumptions Underlying the Regression Model</span>"
    ]
  },
  {
    "objectID": "04-00-multiple-regression.html",
    "href": "04-00-multiple-regression.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "In this unit you will learn about using multiple regression model to describe and infer about the relationship between a quantitative outcome and multiple predictor variables. You will also learn about statistical control and how we can use statistical control to make stronger claims about predictor effects. Finally you will learn how to evaluate the distributional assumptions that underlie the multiple regression model.",
    "crumbs": [
      "Multiple Regression"
    ]
  },
  {
    "objectID": "04-01-intro-to-multiple-regression.html",
    "href": "04-01-intro-to-multiple-regression.html",
    "title": "14¬† Introduction to Multiple Regression",
    "section": "",
    "text": "14.1 Observational Data and Alternative Explanations\nIn the previous chapters, we fitted a model regressing students‚Äô GPA on time spent on homework. Recall that the goal of the analysis was to understand the relationship between time spent on homework and GPA and, in particular, to estimate the effect of time spent on homework on students‚Äô GPA. The results from the analyses we undertook are presented here:\nWhile it seems we have an answer to our research question, unfortunately because of the nature of the data our answer might be quite wrong. To understand this, we need to dive into the differences between observational and experimental data and why experimental data is the key to obtaining ‚Äútrue‚Äù estimates of effects.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Introduction to Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-01-intro-to-multiple-regression.html#observational-data-and-alternative-explanations",
    "href": "04-01-intro-to-multiple-regression.html#observational-data-and-alternative-explanations",
    "title": "14¬† Introduction to Multiple Regression",
    "section": "",
    "text": "The \\(R^2\\) value of 0.107 suggests that 10.7% of the variation in students‚Äô GPAs is explainrd by differences in time spent on homework. Although small, this amount of explained variation is statistically discernible from 0; \\(F(1,98)=11.8\\), \\(p&lt;0.001\\). The effect of time spent on homework (\\(B=1.21\\), \\(p&lt;.001\\)) suggests that each additional hour spent on homework is associated with a 1.21-grade point difference in GPA, on average. These analyses suggest that time spent on homework seems to have a small, positive effect on GPA.\n\n\n\n\n14.1.1 Experimental or Observational Data\nExperimental data are data that have been collected from a study in which the researcher randomly assigned cases/participants in their sample to different levels of the predictor. In an introductory statistics class you probably encountered this in the context of a predictor with only two levels (e.g., treatment and control). In those situations the goal was to determine the effect of the treatment on some outcome.\nWe can also think about random assignment with predictors that have more than two levels. For example, if you were studying the effect of the amount of tutoring on some educational outcome you might have several levels of the predictor: 30 min of tutoring, 45 min of tutoring, 60 min of tutoring, 75 min of tutoring, 90 min of tutoring, etc. The data here can also be experimental so long as the participants in the study were randomly assigned to the different levels of tutoring.\n\nThe key question to determine whether the data are experimental is: were cases/participants randomly assigned to different levels of the predictor?\n\nLet‚Äôs ask that question about our homework/GPA data‚Ä¶were students randomly assigned to spend different amount of time on homework? The answer is no. Students were not randomly assigned to different levels of the predictor. They self select how much time they spend on homework. Because of this, these data are not experimental in nature. We instead refer to these data as observational in nature. Observational data are any data in which cases/participants were not randomly assigned to levels of the predictor. Most data collected or used in the social and educational sciences are observational in nature!\n\n\n\n14.1.2 Confounding and Observational Data\nThe nature of the data has a direct impact on our conclusions about the effect of the predictor. When the data are observational, any conclusions about effects are not as strong as those conclusions we could draw if the data were experimental. This is because the conclusions we draw about effects from observational data may be impacted/biased by confounding. Confounding occurs when some variable influences both the assignment of cases/participants to the predictor levels and also influences the outcome. For example, we know that in education, student outcomes are typically influenced by parent education level‚Äîthat is it influences the outcome. Parent education level might also impact how much time a student spends on homework. Students whose parents have a higher education level might spend more time on homework than students whose parents have a lower education level. (Again, this is ‚Äúon average‚Äù. There may be individual students whose parents have a lower education level that spend a lo of time on homework.) In this scenario, parent education level is a confounder; it influences both the predictor (amount of time spent on homework) and the outcome (GPA).\nWe can depict some of these ideas in a path diagram. A path diagram visualizes the different variables under study and the effects of those variables. Variables are depicted as rectangles1 and effects are depicted as single-headed arrows. For example, the following path diagram shows the two variables time spent on homework and GPA. Note that the arrow representing the effect of time spent on homework on GPA originates from the predictor rectangle and points toward the outcome. This shows that the effect is on the outcome.\n\n\n\n\n\n\n\n\n\nRecall that our potential confounder (parent education) has an effect on both the predictor and the outcome. The path diagram showing this is depicted as:\n\n\n\n\n\n\n\n\n\nThe big issue with confounders is that they can impact the effect of your focal predictor on the outcome. In our case, the true effect of time spent on homework on GPA may not really be small and positive. Maybe it is actually large and positive. Or maybe time spent on homework actually has no effect on GPA. Or worse, maybe it actually has a negative effect on GPA! We just don‚Äôt know. To make matters worse, there may be other confounders that we haven‚Äôt even thought about. These will also have a potential impact on the effect of our focal variable on the outcome.\nWith experimental studies, since participants are assigned randomly by the researcher, there is theoretically no such thing as a confounder. This is because other predictors (e.g., parent education) cannot influence the level of predictor sicne it is a random mechanism that is determining the level of the predictor. The path diagram if this were experimental data would look like this:\n\n\n\n\n\n\n\n\n\nNote that there is no longer an arrow going from parent education to time spent on homework since parent education cannot influence time spent on homework if students were being randomly assigned to levels of homework. That is, students whose parents have a higher education level are just as likely to be assigned to low levels of time on homework as high levels of time on homework. Because parent education is no longer influencing the level on the time spent on homework predictor it is not a confounder.\nMore importantly, with experimental data whatever the effect of time spent on homework was on GPA in the simple two rectangle model, it is theoretically the same, regardless of any other predictor that might be influencing the outcome. That is, even if parent education influences students‚Äô GPA, the effect of time spent on homework would not change the original effect, it would remain a small, positive effect. Whereas, with observational data, we just don‚Äôt know whether nor how the effect will change.2\n\n\n\n\n\n\n\n\n\n\nDrawing out a path diagram helps you document the effects you are evaluating. It can also help you identify confounders when you have observational data.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Introduction to Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-01-intro-to-multiple-regression.html#multiple-regression-the-key-to-evaluating-observational-data",
    "href": "04-01-intro-to-multiple-regression.html#multiple-regression-the-key-to-evaluating-observational-data",
    "title": "14¬† Introduction to Multiple Regression",
    "section": "14.2 Multiple Regression: The Key to Evaluating Observational Data",
    "text": "14.2 Multiple Regression: The Key to Evaluating Observational Data\nTo understand whether or how the effect of time spent on homework on GPA is impacted by the confounder of parent education, we can include parent education level as an additional predictor in the model (along with time spent on homework). By looking at the resulting effect of time spent on homework on GPA we get a better understanding of what the true effect is.\n\nWhile multiple regression is helpful for dealing with confounders in observational data, we can use multiple regression to quantify effects for any type of data, including experimental data.\n\n\n\n14.2.1 Examining the Parent Education Level Predictor\nBefore we begin modeling, it behooves us to explore the parent education level predictor. Below we examine the marginal distribution of parent education for the 100 students in the sample.\n\n# Examine the marginal distribution\nggplot(data = keith, aes(x = parent_ed)) +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Parent education level\") +\n  ylab(\"Probability density\")\n\n\n\n\n\n\n\nFigure¬†14.1: Density plot of the marginal distribution of parent education level.\n\n\n\n\n\nWe also compute numerical summaries of the distribution.\n\n# Compute mean and standard deviation\nkeith |&gt;\n  summarize(\n    M = mean(parent_ed),\n    SD = sd(parent_ed)\n    )\n\n\n  \n\n\n\n\nParent education level is somewhat right skewed with a typical education level of roughly 14 years (some college). There is quite a lot of variation in parent education level (SD=1.93), with most employees having between 12 and 16 years of formal education.\n\nAfter we examine the marginal distribution, we should examine the relationships among all of the three variables we are considering in the analysis. Typically researchers will examine the scatterplot between each predictor and the outcome (to evaluate the functional forms of the relationships with the outcome) and also examine the correlation matrix. Since we have already looked at the scatterplot between time spent on homework and GPA, we focus here on the relationship between parent education level and GPA.\n\n# Relationship between parent education level and GPA\nggplot(data = keith, aes(x = parent_ed, y = gpa)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Parent education level\") +\n  ylab(\"GPA\")\n\n\n\n\n\n\n\nFigure¬†14.2: Scatterplot showing the relationship between parent education level and GPA.\n\n\n\n\n\nThe correlation matrix between all three variables is also examined. When we select the variables to use, again we start with the outcome followed by our focal predictor. Then any other predictors are included.\n\n# Correlation matrix\nkeith |&gt;\n  select(gpa, homework, parent_ed) |&gt;\n  correlate()\n\n\n  \n\n\n\n\nThe relationship between parent education level and GPA seems linear and positive (\\(r=0.29\\)). This suggests that students whose parents have higher education levels also tend to have higher GPAs. Time spent on homework and parent education level are also modestly correlated (\\(r=0.28\\)), indicating that students whose parents have higher education levels also tend to spend more time on homework.\n\nNote here that parent education level seems to be related to the predictor and the outcome. This suggests that it may be a confounder. (In an experimental study, the correlation between parent education level and time spent on homework would be close to 0.) Sometimes people show the correlations on a path diagram. Correlations are shown as double-headed arrows rather than single-headed arrows.\n\n\n\n\n\n\n\n\n\nThe relationships observed in this correlation matrix are consistent with the issues we were concerned about earlier, namely that the positive effect of time spent on homework on GPA may be due to the fact that students who spend more time on homework are the students whose parents have higher education levels. And, the positive relationship between parent education level and GPA is clouding the ‚Äúreal‚Äù underlying relationship between time spent on homework and GPA.\n\n\n\n14.2.2 Simple Regression Model: Parent Education Level as a Predictor of GPA\nIt is also instructive to fit and examine the results from the simple regression model using parent education level as a predictor of variation in GPA.\n\nlm.b = lm(gpa ~ 1 + parent_ed, data = keith)\n\n# Model-level results\nglance(lm.b)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0866        0.0772  7.32      9.29 0.00297     1  -340.  686.  694.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    5255.          98   100\n\n\n\n# Coefficient-level results\ntidy(lm.b)\n\n\n  \n\n\n\nThe fitted equation,\n\\[\n\\hat{\\mathrm{GPA}_i} = 64.20 + 1.16(\\mathrm{Parent~Education~Level}_i)\n\\]\n\nThese analyses suggest that differences in parent education level explain 8.7% of the variation in GPA. The effect of parent education level on GPA is \\(B=1.16\\) indicating that the estimated mean GPA for students whose parent education level differs by one year varies by 1.16 grade points. We also find that this effect is statistically discernible from 0 (\\(p=.003\\)).\n\n\n\n\n14.2.3 Multiple Regression Model: Parent Education Level and Time Spent on Homework as a Predictors of GPA\nOur research question is focused on examining the relationship between time spent on homework and GPA, which as we learned, may be confounded by parent education level.\nWhat we need to know in order to determine the effect of time spent on homework on GPA is: After we account for any distributional differences in parent eduation level across levels of time spent on homework is there is still a relationship between time spent on homework and GPA. To answer this question, we will fit a model that includes both predictors. To fit the multiple regression model, we will just add (literally) additional predictors to the right-hand side of the lm() formula.\n\n# Fit multiple regression model\nlm.c = lm(gpa ~ 1 + parent_ed + homework, data = keith)\n\n\n\n14.2.3.1 Model-Level Results\nTo interpret multiple regression results, begin with the model-level information.\n\n# Model-level results\nglance(lm.c)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.152         0.135  7.09      8.70 0.000336     2  -336.  681.  691.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    4878.          97   100\n\n\nIn a multiple regression model there are multiple predictors that are being used to explain variation in the outcome variable. We can begin by examining the \\(R^2\\) value from the output. Interpreting this value, we say:\n\nDifferences in time spent on homework AND parent education level explain 15.2% of the variation in GPA, in the sample.\n\nThe model-level test allows us to evaluate whether, together, these predictors explain variation in the outcome or whether any explained variation in the sample is attributable to sampling error. The formal model-level null hypothesis that tests this can be written mathematically as,\n\\[\nH_0:\\rho^2 = 0.\n\\]\nThis is a test of whether all the predictors together explain variation in the outcome variable. The results of this test, \\(F(2,97)=8.70\\), \\(p=.003\\), suggest that the empirical evidence is inconsistent with the null hypothesis; it is likely that together time spent on homework AND parent education level do explain variation in the population.\nEquivalently, we can also write the model null hypothesis as a function of the predictor effects, namely,\n\\[\nH_0:\\beta_{\\mathrm{Time~on~HW}} = \\beta_{\\mathrm{Parent~Education~Level}} = 0.\n\\]\nIn plain English, this is akin to stating that there is NO EFFECT for every predictor included in the model. If the empirical data are inconsistent with this null hypothesis, it suggests that AT LEAST ONE of the predictor effects is likely not zero.\nAlthough the two expressions of the model-level null hypothesis look quite different, they are answering the same question, namely whether the model predicts more variation in GPA than is attributable to sampling variation. Based on the results of the model-level hypothesis test we believe there is: (1) an effect of time spent on homework on GPA, (2) an effect of parent education level on GPA, OR (3) there is an effect of both predictors on GPA. The model-level results, however, do not allow us to determine which of the predictors has an effect on the outcome variable. For that we need to evaluate the coefficient-level results.\n\n\n\n14.2.3.2 Coefficient-Level Results\nNow we turn to the coefficient-level results produced in the tidy() output.\n\n# Coefficient-level results\ntidy(lm.c)\n\n\n  \n\n\n\nFirst we will write the fitted multiple regression equation,\n\\[\n\\hat{\\mathrm{GPA}_i} = 63.20 + 0.87(\\mathrm{Parent~Education~Level}_i) + 0.99(\\mathrm{Time~on~HW}_i)\n\\]\nThe slopes (of which there are now more than one) are referred to as partial regression slopes or partial effects. They represent the effect of the predictor AFTER accounting for the effects of the other predictors included in the model. For example,\n\n\nThe partial effect of parent education level is 0.87. This indicates that a one year difference in parent education level is associated with a 0.87 grade-point difference in GPA (on average), after accounting for differences in time spent on homework.\nThe partial effect of time spent on homework is 0.99. This indicates that a one hour difference in time spent on homework is associated with a 0.99 grade-point difference in GPA (on average), after accounting for differences in parent education level.\n\n\n\nThe language ‚Äúafter accounting for‚Äù is not ubiquitous in interpreting partial regression coefficients. Some researchers instead use ‚Äúcontrolling for‚Äù, ‚Äúholding constant‚Äù, or ‚Äúpartialling out the effects of‚Äù. For example, the time spent on homework effect could also be interpreted these ways:\n\nA one hour difference in time spent on homework is associated with a 0.99 grade-point difference in GPA (on average), after controlling for differences in parent education level.\nA one hour difference in time spent on homework is associated with a 0.99 grade-point difference in GPA (on average), after holding the effect of parent education level constant.\nA one hour difference in time spent on homework is associated with a 0.99 grade-point difference in GPA (on average), after partialling out the effect of parent education level.\n\n\nLastly, we can also interpret the intercept:\n\nThe average GPA for all students whose parent education level is 0 years AND who spend 0 hours on homework a week is estimated to be 63.2.\n\nThis is the predicted average Y value when ALL the predictors have a value of 0. As such, it is often an extrapolated prediction and is not of interest to most applied researchers. For example, in our data, parent education level ranges from 10 to 20 years and time spent on homework ranges from 1 to 11 years. We have no data that has a zero value for either predictor, let alone for both. This makes prediction of the average Y value tenuous at these X values.\n\n\n\n14.2.3.3 Coefficient-Level Inference\nAt the coefficient-level, the hypotheses being tested are about each individual predictor. The mathematical expression of the hypothesis is\n\\[\nH_0: \\beta_k = 0.\n\\]\nIn plain English, the statistical null hypothesis states: After accounting for ALL the other predictors included in the model, there is NO EFFECT of X on Y. These hypotheses are evaluated using a t-test. For example, consider the test associated with the parent education level coefficient.\n\\[\nH_0: \\beta_{\\mathrm{Parent~Education~Level}} = 0\n\\]\nThis is akin to stating there is NO EFFECT of parent education level on GPA after accounting for differences in the amount of time spent on homework. The empirical evidence is inconsistent with this hypothesis, \\(t(97)=2.27\\), \\(p=.026\\), suggesting that there is likely an effect of parent education level on GPA after controlling for differences in the amount of time spent on homework. (Note that the df for the t-test for all of the coefficient tests is equivalent to the error, or denominator, df for the model-level F-test. This can be found in the glance() output.)\nThe test for the focal predictor, time spent on homework is evaluating the null hypothesis that there is NO EFFECT of the amount of time spent on homework on GPA after accounting for differences in parent education level: \\(H_0: \\beta_{\\mathrm{Time~on~HW}} = 0\\). The empirical evidence is also inconsistent with this hypothesis, \\(t(97)=2.74\\), \\(p=.007\\), suggesting that there is likely an effect of the amount of time spent on homework on GPA after controlling for differences in parent education level.\nBased on these results, both predictors seem to have an effect on GPA.\n\nIt is important to note that unlike in simple regression models, the p-value at the model-level for multiple regression models is different from any of the coefficient-level p-values. In our example the p-value from the model-level F-test was 0.0003, while those for the coefficient-level t-tests were 0.026 and 0.007 respectively. This is because when we include more than one predictor in a model, the hypotheses being tested at the model- and coefficient-levels are different. The model-level test is a simultaneous test of all the predictor effects, while the coefficient-level tests are testing the added effect of a particular predictor after we control for all other predictors in the model.\n\n\n\n\n14.2.3.4 Updating the Path Model\nWe can now include the coefficients from the fitted multiple regression model to update our path diagram.\n\n\n\n\n\n\n\n\nFigure¬†14.3: Path diagram for the multiple regression model. Path values are unstandardized coefficients.\n\n\n\n\n\nOne thing you will note is that the updated path diagram no longer includes the arrow from parent education level to GPA. That is because it is no longer relevant to us. We were concerned about that path because it indicated that parent education level might be a confounding variable which would impact the effect we were interested in, namely that for the effect of time spent on homework. By including parent education level in the regression model along with time spent on homework, we obtain an estimate of the effect of time spent on homework that accounts for the confounding. Because of that, the path from parent education level to GPA can be omitted.3\nBy comparing the effect of time spent on homework on GPA from the simple and the multiple regression model, we have a more accurate understanding of the effect.\n\n\n\n\n\n\n\n\nFigure¬†14.4: Path diagram for the simple and multiple regression model. Path values are unstandardized coefficients.\n\n\n\n\n\nIn the simple regression model the effect of time spent on homework on GPA was 1.21, indicating that each one hour difference in the amount of time spent on homework was associated with a 1.21 grade-point difference in GPA on average. After we account for parent education level, the effect of time spent on homework on GPA is 0.99. This implies that some of the inital effect is really attributable to parent level of education (it is a confounder). The diminished value better reflects the actual effect of time spent on homework on GPA.4",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Introduction to Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-01-intro-to-multiple-regression.html#multiple-regression-statistical-model",
    "href": "04-01-intro-to-multiple-regression.html#multiple-regression-statistical-model",
    "title": "14¬† Introduction to Multiple Regression",
    "section": "14.3 Multiple Regression: Statistical Model",
    "text": "14.3 Multiple Regression: Statistical Model\nThe multiple regression model posits that each case‚Äôs outcome (Y) is a function of two or more predictors (\\(X_1\\), \\(X_2\\), , \\(X_k\\)) and some amount of error. Mathematically it can be written as\n\\[\nY_i = \\beta_0 + \\beta_1(X1_{i}) + \\beta_2(X2_{i}) + \\ldots + \\beta_k(Xk_{i}) + \\epsilon_i\n\\]\nAs with simple regression we are interested in estimating the values for each of the regression coefficients, namely, \\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\), ‚Ä¶, \\(\\beta_k\\). To do this, we again employ least squares estimation to minimize the sum of the squared error terms.\nSince we have more than one X term in the fitted equation, the structural part of the model no longer mathematically defines a line. For example, the fitted equation from earlier,\n\\[\n\\hat{Y_i} = 63.20 + 0.87(X1_i) + 0.99(X2_i),\n\\]\nmathematically defines a regression plane. (Note we have three dimensions: Y, \\(X1\\), and \\(X2\\). If we add predictors, we have four or more dimensions and the equation would describe a hyperplane.)\nThe data and regression plane defined by the parent education level, time spent on homework, and GPA for the keith data is shown below. The regression plane is tilted up in both the education level direction (corresponding to a positive partial slope of education) and in the seniority level direction (corresponding to a positive partial slope of seniority). The blue points are above the plane (employees with a positive residual) and the yellow points are below the plane (employees with a negative residual).\n\n\n\n\n\n\n\n\nFigure¬†14.5: Three-dimensional scatterplot showing the relationship between parent education level, time spent on homework, and GPA. The fitted regression plane is also shown. Blue observations have a positive residual and pink observations have a negative residual.\n\n\n\n\n\n\n\n14.3.1 Residuals\nGraphically, the residuals from this model are the vertical distance between the observed points and the regression plane. Mathematically, they can be computed in the same manner as they were in the simple regression model, namely:\n\\[\n\\hat{\\epsilon_i} = Y_i - \\hat{Y_i}\n\\]\nFor example, consider the first observation in the keith data. This student has the following values:\n\nGPA = 78\nParent education level = 13\nTime spent on homework = 2\n\nTo compute this students fitted value we use:\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_1} &= 63.20 + 0.87(13) + 0.99(2) \\\\[2ex]\n&= 76.49\n\\end{split}\n\\]\nThe residual for this observation is then:\n\\[\n\\begin{split}\n\\hat{\\epsilon_1} &= 78 - 76.49 \\\\[2ex]\n&= 1.51\n\\end{split}\n\\]\nGiven this student‚Äôs parent education level and the amount of time they spend on homework, their GPA is above average by 1.51 grade-points. This is depicted in Figure¬†14.6.\n\n\n\n\n\n\n\n\nFigure¬†14.6: Three-dimensional scatterplot showing the relationship between parent education level, time spent on homework, and GPA. The fitted regression plane is also shown. Blue observations have a positive residual and pink observations have a negative residual. Observation 1 is shown in orange and its residual depicted as a blue vertical line extending to the regression plane.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Introduction to Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-01-intro-to-multiple-regression.html#order-of-predictors-in-the-lm-function",
    "href": "04-01-intro-to-multiple-regression.html#order-of-predictors-in-the-lm-function",
    "title": "14¬† Introduction to Multiple Regression",
    "section": "14.4 Order of Predictors in the lm() Function",
    "text": "14.4 Order of Predictors in the lm() Function\nIn our lm(), we fitted the multiple regression model by first including parent education level, and then including time spent on homework.\n\n# Fit multiple regression model\nlm.c = lm(gpa ~ 1 + parent_ed + homework, data = keith)\n\nLet‚Äôs re-fit our multiple regression model, but this time we will include time spent on homework first and parent education level second.\n\n# Fit multiple regression model\nlm.d = lm(gpa ~ 1 + homework + parent_ed, data = keith)\n\nDoes the order of the predictors change the estimates we get in the model- and coefficient-level output?\n\n# Model-level results\nglance(lm.d)\n\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.152         0.135  7.09      8.70 0.000336     2  -336.  681.  691.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    4878.          97   100\n\n\n\n# Coefficient-level output\ntidy(lm.d)\n\n\n  \n\n\n\nBoth the model-level and coefficient-level output is identical regardless of the order that the predictors are entered into the lm() function.\n\nWhile this means you don‚Äôt have to stress about the order you enter predictors in the model, conventionally if you have a focal predictor that is entered into the model last. That is why we included parent education level prior to time spent on homework in the lm() initially.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Introduction to Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-01-intro-to-multiple-regression.html#footnotes",
    "href": "04-01-intro-to-multiple-regression.html#footnotes",
    "title": "14¬† Introduction to Multiple Regression",
    "section": "",
    "text": "Sometimes variables are represented as circles in a path diagram. These typically represent latent variables.‚Ü©Ô∏é\nWhen the effect of a predictor remains consistent regardless of other things that might influence the outcome, we call that predictor a ‚Äúcause‚Äù. Because this is the case in experimental data, sometimes people will say that experimental data allows for cause-and-effect type inferences.‚Ü©Ô∏é\nDepending on the analyses undertaken sometimes researchers keep the path and also include a path coefficient as well. This can help them compute indirect effects. This is beyond the scope of this class, but you can learn more in EPSY 8264.‚Ü©Ô∏é\nWhile this is a more accurate representation of the effect, the reality is that both estimates are pretty close to 1. Moreover, on the 100-point scale which GPA is measured on, there is really no practical difference between an effect of 1.21 and 0.99. So, while parent education level is attributable for some of the initial effect, it isn‚Äôt a lot.‚Ü©Ô∏é",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Introduction to Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-02-more-multiple-regression.html",
    "href": "04-02-more-multiple-regression.html",
    "title": "15¬† Multiple Regression: ANOVA Decomposition",
    "section": "",
    "text": "15.1 ANOVA Decomposition\nOne goal in fitting any regression is to quantify the amount of variation in the outcome that the model explains. As with the simple regression, the way we do this is via an ANOVA decomposition, computing the different sums of squares (total, model, error). The decomposition of the variation into these three parts is governed by the equation:\n\\[\n\\mathrm{SS_{\\mathrm{Total}}} = \\mathrm{SS_{\\mathrm{Model}}} + \\mathrm{SS_{\\mathrm{Error}}}\n\\]\nPrior to this the way we obtained this was to compute sum of squared errors for two different models‚Äîthe model in question (SSE), and the intercept-only model (SST). Then by comparing these two SSEs we could quantify the amount of variation explained by the model (SSM). These values could also be used to compute the model‚Äôs \\(R^2\\) value:\n\\[\nR^2 = \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}}\n\\]\nRather than fit the intercept-only model like we have in the past, we are going to instead use the anova() function to carry out the ANOVA decomposition. To illustrate this function, we will first carry out the ANOVA decomposition on a simple regression model.\n# ANOVA decomposition\nanova(lm.a)\nThe Sum Sq column provides the sum of squares values. In this output we have the sum of squares explained by homework (616.5) and the residual (error) sum of squares (5136.4). Since this is a simple regression model the model only encompasses the time spent on homework predictor, so the model sum of squares is 616.5. That is, in this model:\nThe anova() output doesn‚Äôt provide the total sum of squares, but we can use out decomposition equation to compute it by summing the model and residual sum of squares:\n\\[\n\\begin{split}\n\\mathrm{SS_{\\mathrm{Total}}} &= 616.5 + 5136.4 \\\\[2ex]\n&= 5752.9\n\\end{split}\n\\]\nA visualization of this partitioning is shown in Figure¬†15.1\nFigure¬†15.1: Partitioning of variation associated with the simple regression model using time spent on homework to predict variation in GPA.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Multiple Regression: ANOVA Decomposition</span>"
    ]
  },
  {
    "objectID": "04-02-more-multiple-regression.html#anova-decomposition",
    "href": "04-02-more-multiple-regression.html#anova-decomposition",
    "title": "15¬† Multiple Regression: ANOVA Decomposition",
    "section": "",
    "text": "SSM = 616.5\nSSE = 5136.4\n\n\n\n\n\n\n\n15.1.1 ANOVA Decomposition for Multiple Regression Model\nWe will no carry out an ANOVA decomposition on our multiple regression model.\n\n# ANOVA decomposition\nanova(lm.c)\n\n\n  \n\n\n\nBecause the multiple regression model has an additional predictor (parent education level), the output of the anova() function has an additional row. It splits the explained variation (i.e., the SS Model) into that which is explained by the parent education predictor and that which is explained by the time spent on homework predictor. Since the model includes both of these predictors, to compute the SS Model, we need to sum these two sum of squares terms.\n\\[\n\\begin{split}\n\\mathrm{SS_{\\mathrm{Model}}} &= \\mathrm{SS_{\\mathrm{Parent~Education~Level}}} + \\mathrm{SS_{\\mathrm{HW}}} \\\\[2ex]\n&= 497.9 + 376.8 \\\\[2ex]\n&= 874.7\n\\end{split}\n\\] Then, to compute the SS Total we can use:\n\\[\n\\begin{split}\n\\mathrm{SS_{\\mathrm{Total}}} &= \\mathrm{SS_{\\mathrm{Model}}} + \\mathrm{SS_{\\mathrm{Error}}} \\\\[2ex]\n&= 874.7 + 4878.2 \\\\[2ex]\n&= 5752.9\n\\end{split}\n\\] Notice that the SS Total is the same as in the simple regression model! This is because the outcome is still GPA and the total variation in the GPA values has not changed; it is still 5752.9. We could also use the SS Model and SS Total values to compuyte the model \\(R^2\\).\n\\[\n\\begin{split}\nR^2 &= \\frac{\\mathrm{SS_{\\mathrm{Model}}}}{\\mathrm{SS_{\\mathrm{Total}}}} \\\\[2ex]\n&= \\frac{874.7}{5752.9} \\\\[2ex]\n&= 0.152\n\\end{split}\n\\] This is the same \\(R^2\\) value produced in the glance() output.\n\nNote that the output from anova() also partitions the df among the predictor terms and the residuals. Each predictor has 1 df associated with it, which gives the model 2 df. The residuals have 97 df associated with them. The model and residual df are the df used in the F-test and given in the glance() output, namely 2 and 97. The total df in the data are \\(2+97 = 99\\), which is \\(n-1\\). Lastly, we point out that the residual df value from the anova() output (97) is the df associated with the t-tests for the coefficient-level tests (presented earlier).",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Multiple Regression: ANOVA Decomposition</span>"
    ]
  },
  {
    "objectID": "04-02-more-multiple-regression.html#order-in-the-lm-mattterskind-of",
    "href": "04-02-more-multiple-regression.html#order-in-the-lm-mattterskind-of",
    "title": "15¬† Multiple Regression: ANOVA Decomposition",
    "section": "15.2 Order in the lm() Mattters‚Ä¶Kind Of",
    "text": "15.2 Order in the lm() Mattters‚Ä¶Kind Of\nLet‚Äôs re-fit our multiple regression model, but this time we will include time spent on homework first and parent education level second.\n\nlm.d = lm(gpa ~ 1 + homework + parent_ed, data = keith)\n\nNow let‚Äôs examine the results from the ANOVA decomposition.\n\n# ANOVA decomposition\nanova(lm.d)\n\n\n  \n\n\n\nIn this decomposition time spent on homework has a SS value of 616.5 and parent education level has a SS value of 258.2. This is quite different than the SS we obtained from the model where parent education level was put in the model before time spent on homework. The residual SS are the same as in the previous model‚Äôs decomposition (4878.2). Let‚Äôs compute the Model SS using these new values.\n\\[\n\\begin{split}\n\\mathrm{SS_{\\mathrm{Model}}} &= \\mathrm{SS_{\\mathrm{Parent~Education~Level}}} + \\mathrm{SS_{\\mathrm{HW}}} \\\\[2ex]\n&= 258.2 + 616.5 \\\\[2ex]\n&= 874.7\n\\end{split}\n\\] The Model SS is the same regardless of order of the predictors in lm(). This implies that our model \\(R^2\\) value will also be the same regardless of order of order of the predictors in lm().\n\n\n15.2.1 Danger: Using the ANOVA Decomposition at the Individual Predictor Level\nThe fact that the SS values change depending on the order you put the the predictors in the lm() function implies that it is difficult to come up with a quantification for the amount of variation that an individual predictor explains in a multiple regression model. For example, say we wanted to compute the explained variation for time spent on homework on GPA (our focal predictor). If we use the ANOVA decomposition from Model C, we would say it explains 376.8 of the total 5752.9, and we could compute its \\(R^2\\) value as:\n\\[\n\\begin{split}\nR^2_{\\mathrm{HW}} &= \\frac{\\mathrm{SS_{\\mathrm{HW}}}}{\\mathrm{SS_{\\mathrm{Total}}}} \\\\[2ex]\n&= \\frac{376.8}{5752.9} \\\\[2ex]\n&= 0.065\n\\end{split}\n\\]\nIf, however, we use the ANOVA decomposition from Model D, we would say it explains 616.5 of the total 5752.9, and we could compute its \\(R^2\\) value as:\n\\[\n\\begin{split}\nR^2_{\\mathrm{HW}} &= \\frac{616.5}{5752.9} \\\\[2ex]\n&= 0.107\n\\end{split}\n\\] This is almost double the explained percentage as in Model C! Moreover, which one of these is ‚Äúcorrect‚Äù depends on what you are trying to answer by getting this percentage, and it may be that neither is correct. In general it is advisable to only use the ANOVA decomposition to compute sum of squares for the Model, Residuals, and Total, and not use it to compute SS for individual predictors.\n\nMost of the time researchers who undertake this are trying to determine which predictor is more important. In general it is not a good idea to use an ANOVA decomposition to evaluate this. Instead, look at the coefficients to assess importance. Is parent education level or time spent on homework more important? Each 1-unit difference in parent education level is associated with a 0.87-grade point difference while a 1-unit difference in time spent on homework is associated with a 0.99-grade point difference. It seems time spent on homework has a larger effect than parent education level.1",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Multiple Regression: ANOVA Decomposition</span>"
    ]
  },
  {
    "objectID": "04-02-more-multiple-regression.html#footnotes",
    "href": "04-02-more-multiple-regression.html#footnotes",
    "title": "15¬† Multiple Regression: ANOVA Decomposition",
    "section": "",
    "text": "If you are worried about the difference in metric‚Äîyears versus hours‚Äîyou can fit a standardized regression which puts both predictors on the same metric. In this example the homework coefficient from the standardized regression (0.27) is still larger than that for parent education level (0.22) indicating time spent on homework has a larger effect on GPA than parent education level.‚Ü©Ô∏é",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Multiple Regression: ANOVA Decomposition</span>"
    ]
  },
  {
    "objectID": "04-03-understanding-statistical-control.html",
    "href": "04-03-understanding-statistical-control.html",
    "title": "16¬† Understanding Statistical Control",
    "section": "",
    "text": "16.1 Presenting Results from Regression Analysis\nIt is common to present results from regression analyses in a table. You can rea more in the section Presenting Results from Many Fitted Regression Models here. ?tbl-parented shows the results from fitting the simple and multiple regression models to examine the effect of time spent on homework on student GPA.\nThe results from Model 1 are consistent with time spent on homework having a positive association with GPA (\\(p&lt;.001\\)). Each one hour difference in time spent on homework is associated with a 1.21-point difference in GPA, on average. This positive association is seen, even after controlling for parent education level (see Model 2; \\(p=.026\\)), although the effect is somewhat smaller, with each one hour difference in time spent on homework is associated with a 0.99-point difference in GPA, on average.\nThese results argue against the alternative explanation that it is really parent education level that is explaining both time spent on homework and students‚Äô GPAs. The results from the multiple regression model argue that after we account for the fact that parent education is related to both those variables, there is still a positive, albeit smaller, relationship between time spent on homework and students‚Äô GPAs. To understand why we can rule out this alternative explanation of the relationship, we need to understand the idea of statistical control.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Understanding Statistical Control</span>"
    ]
  },
  {
    "objectID": "04-03-understanding-statistical-control.html#presenting-results-from-regression-analysis",
    "href": "04-03-understanding-statistical-control.html#presenting-results-from-regression-analysis",
    "title": "16¬† Understanding Statistical Control",
    "section": "",
    "text": "Unstandardized coefficients (standard errors) for a taxonomy of OLS regression models fitted to explore the effect of time spent on homework on GPA. All models were fitted with n=100 observations.\n\n\n\n\nPredictor\n\n\nModel 1\n\n\nModel 2\n\n\n\n\n\n\nTime spent on homework\n\n\n1.21(0.35)\n\n\n0.99(0.36)\n\n\n\n\nParent education level\n\n\n\n\n0.87(0.38)\n\n\n\n\nConstant\n\n\n74.3(1.94)\n\n\n63.2(5.24)\n\n\n\n\n\n\n\n\nR2\n\n\n0.107\n\n\n0.152\n\n\n\n\nRMSE\n\n\n7.24\n\n\n7.09",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Understanding Statistical Control</span>"
    ]
  },
  {
    "objectID": "04-03-understanding-statistical-control.html#understanding-statistical-control-via-predicted-values",
    "href": "04-03-understanding-statistical-control.html#understanding-statistical-control-via-predicted-values",
    "title": "16¬† Understanding Statistical Control",
    "section": "16.2 Understanding Statistical Control via Predicted Values",
    "text": "16.2 Understanding Statistical Control via Predicted Values\nThe fitted equation for Model 2 is,\n\\[\n\\hat{\\mathrm{GPA}_i} = 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{Parent~Education}_i)\n\\]\nLet‚Äôs predict the average GPA for students who spend differing amounts of time on homework,\n\nTime spent on homework = 1 hour\nTime spent on homework = 2 hours\nTime spent on homework = 3 hours\n\nLet‚Äôs also assume that these student all have parent education level of 12 years.\n\n\n\n\nTable¬†16.1: Predicted average GPA for students who spend 1, 2, and 3 hours a week on homework with parent education level of 12 years.\n\n\n\n\n\n  \n  \n\n\n\nHomework\nParent Education\nModel Predicted GPA\n\n\n\n\n1\n12\n63.22 + 0.99(1) + 0.87(12) = 74.65\n\n\n2\n12\n63.22 + 0.99(2) + 0.87(12) = 75.64\n\n\n3\n12\n63.22 + 0.99(3) + 0.87(12) = 76.63\n\n\n\n\n\n\n\n\n\n\n\nIn this example, the value of parent_ed is ‚Äúconstant‚Äù across the three types of students. Time spent on homework differs by one-hour between each subsequent type of student. The difference in model predicted average GPA between these students is 0.99. When we hold level of parent education constant, the predicted difference in average GPA between students who spend an additional hour on homework is 0.99.\nWhat if we had chosen a parent education level of 13 years instead?\n\n\n\n\nTable¬†16.2: Predicted average GPA for students who spend 1, 2, and 3 hours a week on homework with parent education level of 13 years.\n\n\n\n\n\n  \n  \n\n\n\nHomework\nParent Education\nModel Predicted GPA\n\n\n\n\n1\n13\n63.22 + 0.99(1) + 0.87(13) = 75.52\n\n\n2\n13\n63.22 + 0.99(2) + 0.87(13) = 76.51\n\n\n3\n13\n63.22 + 0.99(3) + 0.87(13) = 77.50\n\n\n\n\n\n\n\n\n\n\n\nThe model predicted average GPAS are higher for these students because they have a higher parent education level. But, again, when we hold parent education level constant, the predicted difference in average GPA between students who spend an additional hour on homework is 0.99. Moreover, this difference in average GPAs for any one hour difference in time spent on homework will be 0.99, regardless of the value we pick for parent level of education.\nBy fixing the value of parent level of education to a particular value (holding it constant) we can ‚Äúfairly‚Äù compare the average predicted GPA for different values of time spent on homework. This allows us to evaluate the association between time spent on homework and GPA without worrying that the GPAs we are comparing have different values for parent level of education. By holding parent level of education constant, we remove it as a potentially confounding explanation of the relationship between time spent on homework and students‚Äô GPAs.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Understanding Statistical Control</span>"
    ]
  },
  {
    "objectID": "04-03-understanding-statistical-control.html#understanding-statistical-control-via-the-fitted-model",
    "href": "04-03-understanding-statistical-control.html#understanding-statistical-control-via-the-fitted-model",
    "title": "16¬† Understanding Statistical Control",
    "section": "16.3 Understanding Statistical Control via the Fitted Model",
    "text": "16.3 Understanding Statistical Control via the Fitted Model\nLet us return to the fitted equation for Model 2,\n\\[\n\\hat{\\mathrm{GPA}_i} = 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{Parent~Education}_i)\n\\]\nBut this time, instead of computing predicted values, let‚Äôs focus on the fitted equation for students with a specified parent education level, say 12 years. We can substitute this value into the fitted equation and reduce the result.\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{12}) \\\\[2ex]\n&= 63.22 + 0.99(\\mathrm{Homework}_i) + 10.44 \\\\[2ex]\n&= 73.66 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nBy substituting in a constant value for parent education level, we can write the model so that GPA is a function of time spent on homework. Interpreting the coefficients,\n\nStudents with a parent education level of 12 years and who spend 0 hours a week on homework are predicted to have a mean GPA of 73.66.\nFor students with a parent education level of 12 years, each additional hour spent on homework is associated with a 0.99-pt difference in GPA, on average.\n\nWhat about the students whose parent education level is 13? Substituting this value into the fitted equation and reducing the result, we get,\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{13}) \\\\[2ex]\n&= 63.22 + 0.99(\\mathrm{Homework}_i) + 11.31 \\\\[2ex]\n&= 74.53 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nInterpreting these coefficients,\n\nStudents with a parent education level of 13 years and who spend 0 hours a week on homework are predicted to have a mean GPA of 74.53.\nFor students with a parent education level of 13 years, each additional hour spent on homework is associated with a 0.99-pt difference in GPA, on average.\n\nThe key here is that the slope for these two sets of students is the same. The relationship between time spent on homework and GPA is exactly the same regardless of parent education level.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Understanding Statistical Control</span>"
    ]
  },
  {
    "objectID": "04-03-understanding-statistical-control.html#understanding-statistical-control-via-the-plot-of-the-fitted-model",
    "href": "04-03-understanding-statistical-control.html#understanding-statistical-control-via-the-plot-of-the-fitted-model",
    "title": "16¬† Understanding Statistical Control",
    "section": "16.4 Understanding Statistical Control via the Plot of the Fitted Model",
    "text": "16.4 Understanding Statistical Control via the Plot of the Fitted Model\nTo create a plot that helps us interpret the results of a multiple regression analysis, we pick fixed values for all but one of the predictors and substitute those into the fitted equation. We can then rewrite the equation and use geom_abline() to draw the fitted line. Below I illustrate this by choosing three fixed values for parent level of education (namely 8, 12, and 16) and rewriting the three equations.\nParent education level = 8\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{8}) \\\\[2ex]\n&= 70.18 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nParent education level = 12\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{12}) \\\\[2ex]\n&= 73.66 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nParent education level = 16\n\\[\n\\begin{split}\n\\hat{\\mathrm{GPA}_i} &= 63.22 + 0.99(\\mathrm{Homework}_i) + 0.87(\\mathrm{16}) \\\\[2ex]\n&= 77.14 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nNow I will create a plot of the outcome versus the predictor we left as a variable in the three equations (time spent on homework) and use geom_abline() to include the line for each of the three rewritten equations. Note that since I have three different equations (one for each of the three parent education levels), I will need to include three layers of geom_abline() in the plot syntax.\n\nggplot(data = keith, aes(x = homework, y = gpa)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Time spent on homework\") +\n  ylab(\"Model predicted GPA\") +\n  geom_abline(intercept = 70.18, slope = 0.99, color = \"#003f5c\", linetype = \"dotdash\") +\n  geom_abline(intercept = 73.66, slope = 0.99, color = \"#f26419\", linetype = \"solid\") +\n  geom_abline(intercept = 77.14, slope = 0.99, color = \"#b40f20\", linetype = \"dashed\") \n\n\n\n\n\n\n\nFigure¬†16.1: Model predicted GPA as a function of time spent on homework for students with a parent education level of 8 years (blue, dot-dashed line), 12 years (orange, solid line), and 16 years (red, dashed line).\n\n\n\n\n\nFrom the plot we can see the effect of time spent on homework in the slopes of the fitted lines. Regardless of the level of parent education (8, 12, or 16), the slope of the line is 0.99, which means the three lines are parallel. The intercepts of these three lines vary reflecting the different level of parent education.\nWe can interpret the effect of parent level of education by fixing time spent on homework to a particular value on the same plot. For example, by fixing time spent on homework to 6, we see that the average GPA varies for the three levels of parent education displayed in the plot.\n\nggplot(data = keith, aes(x = homework, y = gpa)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Time spent on homework\") +\n  ylab(\"Model predicted GPA\") +\n  geom_abline(intercept = 70.18, slope = 0.99, color = \"#003f5c\", linetype = \"dotdash\") +\n  geom_abline(intercept = 73.66, slope = 0.99, color = \"#f26419\", linetype = \"solid\") +\n  geom_abline(intercept = 77.14, slope = 0.99, color = \"#b40f20\", linetype = \"dashed\") +\n  geom_point(x = 6, y = 76.11908, color = \"#003f5c\", size = 2) +\n  geom_point(x = 6, y = 79.60157, color = \"#f26419\", size = 2) +\n  geom_point(x = 6, y = 83.08407, color = \"#b40f20\", size = 2)\n\n\n\n\n\n\n\nFigure¬†16.2: Model predicted GPA as a function of time spent on homework for students with a parent education level of 8 years (blue, dot-dashed line), 12 years (orange, solid line), and 16 years (red, dashed line). The model predicted GPAs for students who spend six hours a week on homework are also displayed.\n\n\n\n\n\nHow much do the model predicted GPAs vary for these three parent education levels?\n\n\n\n\nTable¬†16.3: Predicted GPA for students who spend six hours a week on homework with 8, 12, and 16 years of parent education.\n\n\n\n\n\n  \n  \n\n\n\nHomework\nParent Education\nModel Predicted GPA\n\n\n\n\n6\n8\n76.12\n\n\n6\n12\n79.60\n\n\n6\n16\n83.08\n\n\n\n\n\n\n\n\n\n\n\nThe difference between each of these subsequent model predicted GPA values is 3.48. This is constant because we chose parent education levels that differ by the same amount, in this case each value of parent education differs by four years.\n\n\n16.4.1 Effect of Parent Education Level\nWhat if we would have chosen parent education levels that differed by one year rather than by four years?\n\n\n\n\nTable¬†16.4: Predicted GPA for students who spend six hours a week on homework with with parent education of 8, 9, and 10 years\n\n\n\n\n\n  \n  \n\n\n\nHomework\nParent Education\nModel Predicted GPA\n\n\n\n\n6\n8\n76.12\n\n\n6\n9\n76.99\n\n\n6\n10\n77.86\n\n\n\n\n\n\n\n\n\n\n\nNow a one-year difference in parent education level is associated with a 0.87-point difference in predicted GPA, holding time spent on homework constant. We could also have calculated this directly from the earlier result. Since a four-year difference in parent education is associated with a 3.48-point difference in predicted GPA, a one-year difference in parent education is associated with a \\(3.48 / 4=0.87\\)-point difference in predicted GPA. This algebra works since the relationship is constant (i.e., linear).",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Understanding Statistical Control</span>"
    ]
  },
  {
    "objectID": "04-03-understanding-statistical-control.html#triptych-plots-displaying-the-results-from-a-multiple-regression-model",
    "href": "04-03-understanding-statistical-control.html#triptych-plots-displaying-the-results-from-a-multiple-regression-model",
    "title": "16¬† Understanding Statistical Control",
    "section": "16.5 Triptych Plots: Displaying the Results from a Multiple Regression Model",
    "text": "16.5 Triptych Plots: Displaying the Results from a Multiple Regression Model\nRemember, to create a plot that helps us interpret the results of a multiple regression analysis, we pick fixed values for all but one of the predictors and substitute those into the fitted equation. We can then rewrite the equation and use geom_abline() to draw the fitted lines. We illustrated this earlier by choosing three fixed values for parent level of education (namely 8, 12, and 16) and rewriting the three equations:\n\\[\n\\begin{split}\n\\mathbf{Parent~Education=8:} \\quad\\hat{\\mathrm{GPA}_i} &= 70.18 + 0.99(\\mathrm{Homework}_i) \\\\[2ex]\n\\mathbf{Parent~Education=12:} \\quad\\hat{\\mathrm{GPA}_i} &= 73.66 + 0.99(\\mathrm{Homework}_i) \\\\[2ex]\n\\mathbf{Parent~Education=16:} \\quad\\hat{\\mathrm{GPA}_i} &= 77.14 + 0.99(\\mathrm{Homework}_i)\n\\end{split}\n\\]\nThe plot we created earlier put all three fitted lines on the same plot. An alternative plot is to show each line in a different plot, and to place these plots side-by-side in a ‚Äútriptych‚Äù. (I borrow this terminology from McElreath (2016) who coined this in his Statistical Rethinking book.) To do this we save each plot into an object and then use functionality from the patchwork package to put the plots side-by-side.\n\n# Load package\nlibrary(patchwork)\n\n# Create plot 1\np1 = ggplot(data = keith, aes(x = homework, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 70.18, slope = 0.99) +\n      theme_bw() +\n      xlab(\"Time spent on homework\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Parent Education = 8 Years\")\n\n# Create plot 2\np2 = ggplot(data = keith, aes(x = homework, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 73.66, slope = 0.99) +\n      theme_bw() +\n      xlab(\"Time spent on homework\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Parent Education = 12 Years\")\n\n# Create plot 3\np3 = ggplot(data = keith, aes(x = homework, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 77.14, slope = 0.99) +\n      theme_bw() +\n      xlab(\"Time spent on homework\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Parent Education = 16 Years\")\n\n# Put plots side-by-side\np1 | p2 | p3\n\n\n\n\n\n\n\nFigure¬†16.3: Model predicted GPA as a function of time spent on homework for students with a parent education level of 8, 12, and 16 years.\n\n\n\n\n\n\n\n16.5.1 Emphasis on the Effect of Parent Level of Education\nWith two (or more) effects in the model we have more than one potential way to display the fitted results. In general, we will display one predictor through the slope of the line plotted (same as we did with only one predictor), and EVERY OTHER predictor will be shown through one or more lines. In the previous plots, below, we have displayed the effect of time spent on homework (on the x-axis) through the slope of the lines, and the effect of parent level of education through the vertical distance between the three different lines.\nIn general, the partial effect seen via the slope of the line is more cognitively apparent than the vertical distance between different lines. Thus whichever effect you want to emphasize should be placed on the x-axis; or left as a variable when you algebraically simplify the fitted regression equation.\nFor example, what if we wanted to emphasize parent level of education? In that case, we would choose fixed values for time spent on homework, substitute these into the fitted equation, and simplify. Here we choose fixed values for time spent on homework of 2, 5, and 10 hours. Rewriting the three equations:\n\\[\n\\begin{split}\n\\mathbf{Homework=2:}  \\quad\\hat{\\mathrm{GPA}_i} &= 65.18 + 0.87(\\mathrm{Parent~Education}_i) \\\\[2ex]\n\\mathbf{Homework=5:} \\quad\\hat{\\mathrm{GPA}_i} &= 68.14 + 0.87(\\mathrm{Parent~Education}_i) \\\\[2ex]\n\\mathbf{Homework=10:} \\quad\\hat{\\mathrm{GPA}_i} &= 73.08 + 0.87(\\mathrm{Parent~Education}_i)\n\\end{split}\n\\]\nThen we create the triptych plot showing the resulting equations:\n\n# Create plot 1\np4 = ggplot(data = keith, aes(x = parent_ed, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 65.18, slope = 0.87) +\n      theme_bw() +\n      xlab(\"Parent education (in years)\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Time Spent on Homework = 2 Hours\")\n\n# Create plot 2\np5 = ggplot(data = keith, aes(x = parent_ed, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 68.14, slope = 0.87) +\n      theme_bw() +\n      xlab(\"Parent education (in years)\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Time Spent on Homework = 5 Hours\")\n\n# Create plot 3\np6 = ggplot(data = keith, aes(x = parent_ed, y = gpa)) +\n      geom_point(alpha = 0) +\n      geom_abline(intercept = 73.08, slope = 0.87) +\n      theme_bw() +\n      xlab(\"Parent education (in years)\") +\n      ylab(\"Model predicted GPA\") +\n      ggtitle(\"Time Spent on Homework = 10 Hours\")\n\n# Put plots side-by-side\np4 | p5 |p6\n\n\n\n\n\n\n\nFigure¬†16.4: Model predicted GPA as a function of parent education level for students who spend 2 hours, 5 hours, and 10 hours a week on homework.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Understanding Statistical Control</span>"
    ]
  },
  {
    "objectID": "04-03-understanding-statistical-control.html#only-displaying-a-single-effect",
    "href": "04-03-understanding-statistical-control.html#only-displaying-a-single-effect",
    "title": "16¬† Understanding Statistical Control",
    "section": "16.6 Only Displaying a Single Effect",
    "text": "16.6 Only Displaying a Single Effect\nSometimes you only want to show the effect of a single predictor from the model. For example, in educational studies we often control for SES and mother‚Äôs level of education when we fit the model, but we don‚Äôt want to display those effects in our plot. There is no rule that just because you included an effect in the fitted model that you are obligated to display it.\nAny effect that you do not want to display graphically can be fixed to a single value, typically the mean value. Fixing the effect to a single value will produce only one line. For example, here we set the parent education value to its mean value of 14.03 years. After substituting this value into the fitted equation, this results in,\n\\[\n\\hat{\\mathrm{GPA}_i} = 75.43 + 0.99(\\mathrm{Homework}_i)\n\\]\nPlotting this we get a single line which displays the effect of time spent on homework on GPA. Even though the effect of parent education is not displayed, it is still included as the intercept value of the plotted line is based on fixing this effect to its mean.\n\nggplot(data = keith, aes(x = homework, y = gpa)) +\n geom_point(alpha = 0) +\n geom_abline(intercept = 75.43, slope = 0.99) +\n theme_bw() +\n xlab(\"Time spent on homework\") +\n ylab(\"Model predicted GPA\")\n\n\n\n\n\n\n\nFigure¬†16.5: Model predicted GPA as a function of time spent on homework for students with an average parent education level (14.03 years).",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Understanding Statistical Control</span>"
    ]
  },
  {
    "objectID": "04-03-understanding-statistical-control.html#references",
    "href": "04-03-understanding-statistical-control.html#references",
    "title": "16¬† Understanding Statistical Control",
    "section": "References",
    "text": "References\n\n\n\n\nMcElreath, R. (2016). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Understanding Statistical Control</span>"
    ]
  },
  {
    "objectID": "04-04-assumptions.html",
    "href": "04-04-assumptions.html",
    "title": "17¬† Assumptions: Multiple Regression",
    "section": "",
    "text": "17.1 Distributional Assumptions for the Multiple Regression Model\nThese are the same four assumptions that we evaluate for multiple regression models. To help you see these assumptions, remember that the model for a multiple regression (with two predictors) is a plane that is fitted using observations composed of ordered triples, \\((X_1,X_2,Y)\\). Figure 8 visually shows the multiple regression model‚Äôs assumptions on a plane.\nFigure¬†17.1: A visual depiction of the multiple regression model‚Äôs assumptions.\nNow the conditional distributions that we put the assumptions on are the residuals (or Y-values) at each combination of (\\(X_1\\), \\(X_2\\)). The assumptions for the multiple regression model are similar to those for the simple model, namely,\nTo evaluate these assumptions, we will create the exact same plots we created to evaluate the assumptions in the simple regression model, with one twist. Rather than creating the scatterplot by plotting the standardized residuals versus the X-value, we will plot them against the FITTED values (i.e., the \\(\\hat{Y}_i\\) values). The fitted values from a multiple regression represent the weighted combination of both predictors, and thus give us the appropriate conditioning when we examine the distributions. (Remember, we want to consider the distribution of residuals at each (\\(X_1\\), \\(X_2\\)) combination.)\nAs an example, we will regress student GPAs on both time spent on homework and parent education levels.\n# Augment the model to obtain the fitted values and residuals\naug_c = augment(lm.c)\nhead(aug_c)\n\n\n\n\n\n\n\n\nFigure¬†17.2: LEFT: Density plot of the marginal distribution of standardized residuals from the fitted regression model (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area). RIGHT: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption. The loess line (blue) and uncertainty bands (grey shaded area) are also displayed. The \\(Y=0\\), \\(Y=-2\\) and \\(Y=2\\) lines have been included as a references for interpretation.\n\n\n\n# Density plot of the standardized residuals\np1 = ggplot(data = aug_c, aes(x = .std.resid)) +\n  stat_density_confidence(model = \"normal\") +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n# Plot the standardized residuals versus the fitted values\np2 = ggplot(data = aug_c, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\", linewidth = 0.5) + #ADD y=0 line and confidence envelope\n  geom_smooth(method = \"loess\", se = FALSE) + #ADD loess smoother\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  geom_hline(yintercept = c(-2, 2), linetype = \"dashed\") +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†17.3: LEFT: Density plot of the marginal distribution of standardized residuals from the fitted regression model (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area). RIGHT: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption. The loess line (blue) and uncertainty bands (grey shaded area) are also displayed. The \\(Y=0\\), \\(Y=-2\\) and \\(Y=2\\) lines have been included as a references for interpretation.\nThe density plot of the marginal distributio,n of standardized residuals is unimodal and roughly symmetric (raspberry line). While this shows slight deviation from normality the raspberry line depicting the density of the marginal distribution of standardized residuals lies completely within the blue area (where we would expect a density curve to lie in if it came from the normal distribution). This suggests that the deviation from the normal distribution in the sample data is consistent with just being sampling error. Thus we conclude that the normality assumption seems tenable.\nThe scatterplot shows random scatter around the \\(Y=0\\) line which indicates that the mean residual value is close to 0 (linearity) for all fitted values. Since the loess smoother is encompassed inside the confidence envelope (again, what where we expect the loess smoother to be if the assumption that the average residual is equal to 0 is actually met), the assumption of ‚Äúlinearity‚Äù also seems tenable.\nThe range of the standardized residuals at each fitted value also seems roughly the same indicating that the equal variances assumption seems tenable as well.\nLastly, since the observations were randomly sampled we believe the independence assumption is satisfied.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Assumptions: Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-04-assumptions.html#distributional-assumptions-for-the-multiple-regression-model",
    "href": "04-04-assumptions.html#distributional-assumptions-for-the-multiple-regression-model",
    "title": "17¬† Assumptions: Multiple Regression",
    "section": "",
    "text": "Linearity: Notice from the visual that the MEAN values of each combination (\\(X_1\\), \\(X_2\\)) are linear in both the \\(X_1\\) and the \\(X_2\\) directions. This implies that the mean of each of the conditional distributions of residuals is zero at (\\(X_1\\), \\(X_2\\)).\nIndependence: Again, this is not shown in the figure. The assumption is that each residual value in a particular conditional distribution is independent from every other residual value in that same distribution.\nNormality: This assumption indicates that each of the conditional distributions of residuals is normally distributed.\nHomoskedasticity: The variance (or standard deviation) of all of the conditional distributions of residuals is exactly the same.\n\n\n\n\n\n\n\n\n\nIf any of the assumptions (aside from the independence assumption) do not seem reasonably satisfied, you can re-plot the residual plots based on the different simple regression models. (In this case we would look at the residuals versus time spent on homework and then the residuals versus parent education). This might help you identify if one, or both. of the predictors is the cause of the problem.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Assumptions: Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-04-assumptions.html#identifying-extreme-cases",
    "href": "04-04-assumptions.html#identifying-extreme-cases",
    "title": "17¬† Assumptions: Multiple Regression",
    "section": "17.2 Identifying Extreme Cases",
    "text": "17.2 Identifying Extreme Cases\nOne potential reason that assumptions are violated occurs when there are cases with extreme residuals in the data; what we might call regression ouliers. The reference lines in the scatterplot at \\(Y=-2\\) and \\(Y=+2\\) help us identify these observations. (For large sample sizes these reference lines can be placed at \\(Y=-3\\) and \\(Y=3\\).) There are a few observations that have residuals that are more than two standard errors from the mean. This indicates students that have relatively high (positive residual) or low (negative residual) GPAs given the time they spend each week on homework and their parent education level. To be able to identify those cases in the data (for possible removal) we will label those cases with their row number.\n\n# Create ID variable in the augmented data\naug_c = aug_c |&gt; \n  mutate(id = row.names(keith))\n\n# View new data\nhead(aug_c)\n\n\n\n\n\n\n\n\nFigure¬†17.4: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. Students with standardized residuals more than two standard errors from 0 are identified by their row number. A horizontal lines at \\(Y=0\\), \\(Y=-2\\), and \\(Y=+2\\) are included to aid interpretation.\n\n\n\n# Create different data sets for the extreme and non-extreme observations\nextreme = aug_c |&gt; \n  filter(.std.resid &lt;= -2 | .std.resid &gt;= 2)\n\nnonextreme = aug_c |&gt; \n  filter(.std.resid &gt; -2 & .std.resid &lt; 2)\n\n# Plot using text for the extreme observations and points for the non-extreme\nggplot(data = extreme, aes(x = .fitted, y = .std.resid)) +\n  geom_text(aes(label = id), size = 4, color = \"#c62f4b\") +\n  geom_point(data = nonextreme) +\n  theme_bw() +\n  geom_hline(yintercept = 0) +\n  geom_hline(yintercept = c(-2, 2), linetype = \"dashed\") +\n  xlab(\"Fitted values\") +\n  ylab(\"Standardized residual\")\n\n\n\n\n\n\n\nFigure¬†17.5: Scatterplot of the standardized residuals versus the fitted values from a regression model using time spent on homework and parent education level to predict GPA. Students with standardized residuals more than two standard errors from 0 are identified by their row number. A horizontal lines at \\(Y=0\\), \\(Y=-2\\), and \\(Y=+2\\) are included to aid interpretation.\n\n\n\n\n\nObservation 34 has the most extreme residual with a standardized residual value of around three standard error lower than we would expect. This student is really underperforming given their parent education level and the amount of time they spend on homework.\n\nAs a data analyst, because the assumptions were all reasonably satisfied, there is no need to remove any of the observations. But, as an educational practioner this student is ‚Äúinteresting‚Äù. If we had additional data or knew the participants, you could explore this student more to understand why their GPA is so low given where we would expect them to be. This could also be helpful in identifying students for potential interventions or testing.",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Assumptions: Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-04-assumptions.html#regression-model-revisited",
    "href": "04-04-assumptions.html#regression-model-revisited",
    "title": "17¬† Assumptions: Multiple Regression",
    "section": "17.3 Regression Model Revisited",
    "text": "17.3 Regression Model Revisited\nTo this point, we have been writing the regression model as a mathematical expression of the relationship between some outcome (\\(Y\\)) and a set of predictors (\\(X_1,X_2,\\ldots,X_k\\)), namely as,\n\\[\nY_i = \\beta_0 + \\beta_1(X_{1i}) + \\beta_2(X_{2i}) + \\ldots + \\beta_k(X_{ki}) + \\epsilon_i\n\\]\nThis is partially correct. A statistical model needs to represent the data generating process, which also embodies the set of underlying distributional assumptions. This implies that when we write out the regression model, it should include the mathematical relationship and the underlying distributional assumptions.\n\\[\n\\begin{gathered}\nY_i = \\beta_0 + \\beta_1(X_{1i}) + \\beta_2(X_{2i}) + \\ldots + \\beta_k(X_{ki}) + \\epsilon_i \\\\[2ex]\n\\mathrm{where}~\\quad\\epsilon_{i} \\overset{\\mathrm{i.i.d~}}{\\sim}  \\mathcal{N}\\left(0, \\sigma^2\\right)\n\\end{gathered}\n\\]\nTo read the distribution part of this expression, we say: the errors are independent and identically normally distributed with some variance.1\n\nWhen we report regression results, we want to report parameter estimates for the data generating model. Notice that aside from the coefficient estimates, another parameter in the model (now that we have added the assumptions) is \\(\\sigma^2\\). This is the estimate of the error variance (i.e., \\(\\sigma^2_{\\epsilon}\\)). That means we should report the estimate for this parameter, or for the square root of this parameter. This is why we report the sigma value (or RMSE) from the glance() output for our models. This is the estimate for \\(\\sigma_{\\epsilon}\\).",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Assumptions: Multiple Regression</span>"
    ]
  },
  {
    "objectID": "04-04-assumptions.html#footnotes",
    "href": "04-04-assumptions.html#footnotes",
    "title": "17¬† Assumptions: Multiple Regression",
    "section": "",
    "text": "\\(\\overset{\\mathrm{i.i.d~}}{\\sim}\\) = independent and identically distributed; \\(\\mathcal{N}\\) indicates a normal distribution‚Ü©Ô∏é",
    "crumbs": [
      "Multiple Regression",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Assumptions: Multiple Regression</span>"
    ]
  },
  {
    "objectID": "05-00-categorical-predictors.html",
    "href": "05-00-categorical-predictors.html",
    "title": "Categorical Predictors",
    "section": "",
    "text": "In this unit you will learn how we can use categorical predictors in the regression model to answer questions related to group differences. You will learn how to encode categorical predictors using numbers, and why dummy coding is often used for this process. You will also learn about methods to adjust p-values when to avoid false discoveries when you are comparing more than two groups.",
    "crumbs": [
      "Categorical Predictors"
    ]
  },
  {
    "objectID": "05-01-dichotomous-predictors.html",
    "href": "05-01-dichotomous-predictors.html",
    "title": "18¬† Dichotomous Categorical Predictors",
    "section": "",
    "text": "18.1 Data Exploration\nTo begin, as always, we will plot the marginal distributions of graduation rates (grad) and educational sector (sector). Since educational sector is a categorical variable, rather than creating a density plot of the marginal distribution, we will create a bar plot. We will also create a scatterplot of graduation rates versus educational sector.\n# Density plot of graduation rates\np1 = ggplot(data = mn, aes(x = grad)) +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Six-year graduation rate\") +\n  ylab(\"Probability density\")\n\n# Bar plot of education sector\np2 = ggplot(data = mn, aes(x = sector)) +\n  geom_bar(fill = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Educational sector\") +\n  ylab(\"Frequency\")\n\n# Scatterplot\np3 = ggplot(data = mn, aes(x = sector, y = grad)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Educational sector\") +\n  ylab(\"Six-year graduation rate\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\nFigure¬†18.1: LEFT: Density plot of six-year graduation rates. CENTER: Bar plot of education sector. RIGHT: Scatterplot of the six-year graduation rate versus educational sector.\nWe will also compute the means, standard deviations, and sample sizes for private and public schools.\n# Compute summary measures\nmn |&gt; \n  group_by(sector) |&gt;\n  summarize(\n    M = mean(grad),\n    SD = sd(grad),\n    N = length(grad)\n  )\nTable¬†18.1: Mean (M), standard deviation (SD), and sample size (N) of the six-year graduation rates for 33 Minnesota colleges and universities conditioned on educational sector.\n\n\n\n\n  \n  \n\n\n\nSector\nM\nSD\nN\n\n\n\n\nPrivate\n65.27\n17.58\n23\n\n\nPublic\n51.03\n9.16\n10\nWe note a couple differences in the distribution of graduation rates between public and private schools. First, the mean graduation rates are different. Private schools have a graduation rate that is, on average, 14.2 percentage points higher than public schools. There is also more variation in private schools‚Äô graduation rates than in public schools‚Äô graduation rates. Lastly, we note that the sample sizes are not equal. There are 13 more private schools than there are public schools in the data set.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Dichotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-01-dichotomous-predictors.html#indicator-variables",
    "href": "05-01-dichotomous-predictors.html#indicator-variables",
    "title": "18¬† Dichotomous Categorical Predictors",
    "section": "18.2 Indicator Variables",
    "text": "18.2 Indicator Variables\nBefore we can compute correlations or fit a regression model, we need to convert educational sector into a numeric variable. In this numeric variable, we will assign the public schools one value, and the private schools another value. The numbers are just stand-ins for the category. As such, they are referred to as indicator variables, since the numerical values only indicate a category.\nFor example, here we will code public schools as 5 and private schools as 10. To create this new indicator variable, we mutate() a new column (called indicator) onto our mn data frame that takes the value of 5 if sector is Public and 10 if sector is Private. Here we use the if_else() function to carry out this logic.\n\n# Create indicator variable\nmn = mn |&gt;\n  mutate(\n    indicator = if_else(sector == \"Public\", 5, 10)\n  )\n\n# View data frame\nmn\n\n\n  \n\n\n\nNow, we can then use this new indicator variable in correlation and regression analyses.\n\n# Correlation\nmn |&gt;\n  select(grad, indicator) |&gt;\n  correlate() |&gt;\n  fashion(decimals = 3)\n\n\n  \n\n\n\nThe correlation between educational sector and graduation rate is small and positive, indicating that institutions with higher graduation rates tend to have higher values on the indicator variable. Since there are only two values mapped to the sector variable, this implies that institutions with higher graduation rates tend to be private institutions.\n\n# Fit regression model\nlm.a = lm(grad ~ 1 + indicator, data = mn)\n\n# Model-level output\nglance(lm.a) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.158         0.130  15.6      5.80  0.0222     1  -136.  279.  283.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    7552.          31    33\n\n# Coefficient-level output\ntidy(lm.a)\n\n\n  \n\n\n\n\nChaining the glance() output in the print() function allows us to include the argument width=Inf. This argument prints ALL the columns from the glance() output instead of truncating the output. This hack can also be used to print all of the columns from a data frame that gets truncated as well.\n\nDifferences in these indicator values (i.e., educational sector) explain 15.75% of the variation in graduation rates. This is statistically reliable, \\(F(1, 31) = 5.80\\), \\(p=0.022\\). Interpreting the coefficients,\n\nThe average graduation rate for schools coded as 0 on the indicator variable is 36.8% (\\(t(31)=3.54\\), \\(p = 0.001\\)). Since the mapping we used (5 and 10) did not include 0, the intercept and inferential information related to the intercept are meaningless.\nInstitutions that have coding values that are one-unit differences have, on average, a graduation rate that is 2.85 percentage points different (\\(t(31)=2.41\\), \\(p=0.022\\)). The slope information in its current form is also meaningless. But, since the model is linear, we can translate the slope information to be more meaningful. In our mapping, the difference between public and private schools was a 5-point difference. We can use this to compute the difference in graduation rates between these two sectors,\n\n\\[\n\\mathrm{Difference} = 5 \\times 2.85 = 14.3\n\\]\nWe could also have substituted the mapped values of 5 and 10 into the fitted regression equation to obtain the same result. Substituting the indicator values into the fitted equation, we find the predicted average graduation rates for public and private schools:\n\\[\n\\begin{split}\n\\mathbf{Private:~}\\hat{\\mathrm{Graduation~Rate}_i} &= 36.8 + 2.85(10) = 65.3 \\\\[2ex]\n\\mathbf{Public:~}\\hat{\\mathrm{Graduation~Rate}_i} &= 36.8 + 2.85(5) = 51 \\\\[2ex]\n\\end{split}\n\\]\nThe difference in these average graduation rates comes out to 14.3. The p-value associated with the slope coefficient suggests that this difference (or any difference between different values of X computed from the model) is more than we expect because of chance, so we conclude that there is a difference between the average graduation rates of public and private schools. What if we would have used different values in the indicator variable. Let‚Äôs try this mapping:\n\\[\n\\mathrm{Indicator}_2 = \\begin{cases}\n2 \\quad \\mathrm{for~Public}\\\\\n7 \\quad \\mathrm{for~Private}\n\\end{cases}\n\\]\n\n# Create indicator variable\nmn = mn |&gt;\n  mutate(\n    indicator_2 = if_else(sector == \"Public\", 2, 7)\n  )\n\n# View data frame\nmn\n\n\n  \n\n\n\nUsing this second indicator to compute correlations and in the regression model, we find:\n\n# Correlation\nmn |&gt;\n  select(grad, indicator_2) |&gt;\n  correlate() |&gt;\n  fashion(decimals = 3)\n\n\n  \n\n\n# Fit regression model\nlm.b = lm(grad ~ 1 + indicator_2, data = mn)\n\n# Model-level output\nglance(lm.b) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.158         0.130  15.6      5.80  0.0222     1  -136.  279.  283.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    7552.          31    33\n\n# Coefficient-level output\ntidy(lm.b)\n\n\n  \n\n\n\nThe correlation between educational sector and graduation rate and the model-level output is exactly the same. Institutions with higher graduation rates tend to have higher values on the indicator variable (private institutions). Differences in these indicator values (i.e., educational sector) explain 15.75% of the variation in graduation rates. This is statistically reliable, \\(F(1, 31) = 5.80\\), \\(p=0.022\\).\nIn the coefficient-level output, the slope output is the same as when we used the values of 5 and 10 (\\(\\hat\\beta_1=2.85\\), \\(t(31)=2.41\\), \\(p=0.022\\)). Institutions that have coding values that are one-unit differences have, on average, a graduation rate that is 2.85 percentage points different (\\(t(31)=2.41\\), \\(p=0.022\\)). Substituting the indicator values into the fitted equation, we find the predicted average graduation rates for public and private schools:\n\\[\n\\begin{split}\n\\mathbf{Private:~}\\hat{\\mathrm{Graduation~Rate}_i} &= 45.3 + 2.85(7) = 65.25 \\\\[2ex]\n\\mathbf{Public:~}\\hat{\\mathrm{Graduation~Rate}_i} &= 45.3 + 2.85(2) = 51 \\\\[2ex]\n\\end{split}\n\\]\nThe intercept coefficient, and subsequently inferential output, are different. This is because in our second indicator variable, the code of 0 is in a different location relative to the values of 2 and 7 than it was when we used 5 and 10. In reality, it doesn‚Äôt matter because 0 is not a legitimate mapping in either indicator variable (remember the values represent categories!).\n\n\n18.2.1 Dummy Coding\nSince regardless of the values we choose for the indicator variable, we get similar results we can make use of the interpretational value of the intercept and slope to help select our mapped values. For example, since the intercept is the average Y-value for an X-value of 0, we should choose one of our mapped values to be 0. Also, since the slope gives us a difference in the average Y-value for a one-unit difference in X, we can choose our other value to correspond to a mapping that is one-unit higher than 0, namely 1. Our mapping is then,\n\\[\n\\mathrm{Indicator} = \\begin{cases}\n0 \\quad \\mathrm{for~Public}\\\\\n1 \\quad \\mathrm{for~Private}\n\\end{cases}\n\\]\n\n# Create indicator variable\nmn = mn |&gt;\n  mutate(\n    private = if_else(sector == \"Private\", 1, 0)\n  )\n\n# View data frame\nmn\n\n\n  \n\n\n\nUsing a 0, and 1 coding for an indicator variable is referred to as dummy coding. Conventionally, we name an indicator variable that employs dummy coding with the category that is mapped to 1. In the syntax, private schools are mapped to 1, and hence the indicator variable is named private. The category mapped to 0 is known as the reference category, or reference group. Here public schools are the reference group.\nUsing the dummy coded indicator to compute correlations and fit the regression model, we find:\n\n# Correlation\nmn |&gt;\n  select(grad, private) |&gt;\n  correlate() |&gt;\n  fashion(decimals = 3)\n\n\n  \n\n\n# Fit regression model\nlm.c = lm(grad ~ 1 + private, data = mn)\n\n# Model-level output\nglance(lm.c) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.158         0.130  15.6      5.80  0.0222     1  -136.  279.  283.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    7552.          31    33\n\n# Coefficient-level output\ntidy(lm.c)\n\n\n  \n\n\n\nThe correlation between educational sector and graduation rate and the model-level output is exactly the same. Institutions with higher graduation rates tend to have higher values on the indicator variable (private institutions). Differences in these indicator values (i.e., educational sector) explain 15.75% of the variation in graduation rates. This is statistically reliable, \\(F(1, 31) = 5.80\\), \\(p=0.022\\).\nThe fitted equation is:\n\\[\n\\hat{\\mathrm{Graduation~Rate}_i} = 51 + 14.2(\\mathrm{Private_i})\n\\]\nInterpreting the coefficients,\n\nThe average graduation rate for schools coded as 0 on the indicator variable is 51%.\nEach one-unit difference on the indicator variable has, on average, a graduation rate that is 14.2 percentage points different.\n\nSince 0 represented the private schools the intercept is the average graduation rate for public schools. In general, when using dummy coding, the intercept will be the average Y-value for the reference group. The inferential test, \\(H_0:\\beta_0=0\\), tests whether the average Y-value for the reference group is 0. (Sometimes this is relevant and other times it is not, depending whether this is of substantive interest.) In our example, we find that the empirical data is not consistent with the average graduation rate for public schools being 0%; \\(t(31)=10.34\\), \\(p &lt; 0.001\\).\nThe slope coefficient now represents the difference in average graduation rates between public and private schools as their dummy codes were one-unit apart. In general, when using dummy coding, the slope gives the difference between the category labeled 1 and the reference group. The test of the parameter, \\(H_0:\\beta_1=0\\), is a direct test of whether the difference in average graduation rates is different than 0; or that public and private schools have the same graduation rate. Here we find that the empirical data is not consistent with the average graduation rates between public and private schools being the same; \\(t(31)=2.41\\), \\(p=0.022\\).\nPutting these contextual queues around the interpretations, we interpret the coefficients as:\n\nThe average graduation rate for public schools is 51%.\nPrivate schools have a graduation rate that is 14.2 percentage points, on average, higher than public schools.\n\n\n\n\n18.2.2 Making Private Schools the Reference Group\nWhat happens if we had coded the predictor so that private schools were the reference group (coded as 0), and public schools were coded as 1?\n\n# Create indicator variable\nmn = mn |&gt;\n  mutate(\n    public = if_else(sector == \"Public\", 1, 0)\n  )\n\n# View data frame\nmn\n\n\n  \n\n\n\nUsing the dummy coded indicator to compute correlations and fit the regression model, we find:\n\n# Correlation\nmn |&gt;\n  select(grad, public) |&gt;\n  correlate() |&gt;\n  fashion(decimals = 3)\n\n\n  \n\n\n# Fit regression model\nlm.d = lm(grad ~ 1 + public, data = mn)\n\n# Model-level output\nglance(lm.d) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.158         0.130  15.6      5.80  0.0222     1  -136.  279.  283.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    7552.          31    33\n\n# Coefficient-level output\ntidy(lm.d)\n\n\n  \n\n\n\nThe correlations and model-level output are exactly the same, except that the sign on the correlation is now negative since we switched the order of the coding so that private schools were mapped to a lower value (0) and public school were mapped to a higher value (1). The fitted equation is:\n\\[\n\\hat{\\mathrm{Graduation~Rate}_i} = 65.3 - 14.2(\\mathrm{Public_i})\n\\]\nInterpreting the coefficients,\n\nThe average graduation rate for private schools is 65.3%.\nPublic schools have a graduation rate that is 14.2 percentage points, on average, lower than private schools.\n\nThe inferential test for the intercept now examines whether the average graduation rate for private schools (reference group) is different than 0%. The test for slope is still evaluating whether there is a difference between the average graduation rates between private and public schools. Although the coefficient has the opposite sign, the p-value is still identical.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Dichotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-01-dichotomous-predictors.html#assumption-checking",
    "href": "05-01-dichotomous-predictors.html#assumption-checking",
    "title": "18¬† Dichotomous Categorical Predictors",
    "section": "18.3 Assumption Checking",
    "text": "18.3 Assumption Checking\nLike any other regression model, we need to examine whether or not the model‚Äôs assumptions are tenable. We look at (1) the marginal distribution of the standardized residuals, and (2) the scatterplot of the standardized residuals versus the model‚Äôs fitted values. The only difference is that with only categorical predictors in the model, we do not have to worry about the linearity assumption. Since there is no ordinal quality to the predictor space, the average residual will always be zero when there are only categorical predictors in the model. (Once we add any quantitative covariates we will again have to evaluate this assumption.)\n\n# Obtain the fitted values and residuals\naug_d = augment(lm.d)\n\n# View augmented data frame\nhead(aug_d)\n\n\n\n\n\n\n\n\nFigure¬†18.2: LEFT: Density plot of the marginal distribution of standardized residuals from a regression model using educational sector to predict variation in six-year graduation rates (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area). RIGHT: Scatterplot of the standardized residuals versus the fitted values from the same model. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption and the expected uncertainty (grey shaded area). The empirical loess smoother (blue) is also displayed.\n\n\n\n# Density plot of the marginal standardized residuals\np1 = ggplot(data = aug_d, aes(x = .std.resid)) +\n  stat_density_confidence(model =\"normal\") +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n# Scatterplot of the standardized residuals versus the fitted values\np2 = ggplot(data = aug_d, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  theme_bw() +\n  xlab(\"Fitted value\") +\n  ylab(\"Standardized residual\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†18.3: LEFT: Density plot of the marginal distribution of standardized residuals from a regression model using educational sector to predict variation in six-year graduation rates (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area). RIGHT: Scatterplot of the standardized residuals versus the fitted values from the same model. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption and the expected uncertainty (grey shaded area). The empirical loess smoother (blue) is also displayed.\n\n\n\n\n\nFrom the scatterplot, we see that there is some question about the tenability of the equal variances assumption. The variation in the private schools‚Äô residuals seems greater than the variation in the public schools‚Äô residuals. (This was foreshadowed earlier when we examined the standard deviations of the two distributions.) This difference in variation, however, might be due to the extreme private school that has a residual that is less than \\(-2\\). Additionally, this assumption violation might not be a problem once we add other predictors to the model. So, for now, we will move on, but will re-check this assumption after fitting additional models.\nThe marginal distribution of the residuals does not show evidence of mis-fit with the normality assumption. Since the predictor has only two levels, we could actually examine the distribution of residuals for each sector. Here we do so as a pedagogical example, but note that once other non-categorical predictors are included, this can no longer be done. To examine the conditional distributions, we will filter the augmented data by sector and then plot each sector‚Äôs residuals separately.\n\n# Get private schools\naug_private = aug_d |&gt; \n  filter(public == 0)\n\n# Get public schools\naug_public = aug_d |&gt; \n  filter(public == 1)\n\n# Density plot of the private schools' standardized residuals\np1 = ggplot(data = aug_private, aes(x = .std.resid)) +\n  stat_density_confidence(model = \"normal\") +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n# Density plot of the public schools' standardized residuals\np2 = ggplot(data = aug_public, aes(x = .std.resid)) +\n  stat_density_confidence(model = \"normal\") +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†18.4: Density plot of the standardized residuals from the regression model using educational sector to predict variation in six-year graduation rates for private (LEFT) and public (RIGHT) colleges and universities (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area) for both sets of schools.\n\n\n\n\n\nThe normality assumption seems tenable since neither conditional distribution of residuals seem to indicate more mis-fit to normality than would be expected from sampling error. Lastly, we wonder if the independence assumption is tenable. It might seem reasonable that there is some dependence among graduation rates given that multiple schools may be related to one another (e.g., University of Minnesota‚ÄìTwin Cities and Duluth). Dependence also arises because of spatial proximity. Since schools are located in particular geographic areas within Minnesota, this might also be a problem.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Dichotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-01-dichotomous-predictors.html#including-other-predictors",
    "href": "05-01-dichotomous-predictors.html#including-other-predictors",
    "title": "18¬† Dichotomous Categorical Predictors",
    "section": "18.4 Including Other Predictors",
    "text": "18.4 Including Other Predictors\nBased on the results from fitting the simple regression model, there seems to be differences between the average graduation rate between public and private institutions. It may, however, be that the private schools are just more selective and this selectivity is the cause of the differences in graduation rates. To examine this, we will include the median SAT score (sat) as a covariate into our model. So now, the regression model will include both the public dummy coded predictor and the sat predictors in an effort to explain variation in graduation rates.\nPrior to fitting the regression model, we will examine the correlation matrix.\n\nmn |&gt;\n  select(grad, private, sat) |&gt;\n  correlate() |&gt;\n  fashion(decimals = 3)\n\n\n  \n\n\n\nFrom the correlation matrix we see:\n\nPrivate institutions tend to have higher graduation rates than public institutions (\\(r = 0.397\\)).\nInstitutions with higher median SAT scores tend to have higher graduation rates (\\(r=0.889\\)).\nPrivate institutions tend to have higher median SAT scores than public institutions (\\(r = 0.194\\)).\n\nFitting the regression model\n\nlm.e = lm(grad ~ 1 + sat + private, data = mn)\n\n# Model-level output\nglance(lm.e) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.843         0.832  6.86      80.3 9.05e-13     2  -109.  226.  232.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    1411.          30    33\n\n\nDifferences in educational sector and median SAT score explain 84.26% of the variation in graduation rates. This is statistically reliable, \\(F(2, 30) = 80.27\\), \\(p&lt;0.001\\).\n\n# Coefficient-level output\ntidy(lm.e)\n\n\n  \n\n\n\nThe fitted equation is:\n\\[\n\\hat{\\mathrm{Graduation~Rate}_i} = -84.4 + 0.13(\\mathrm{SAT}_i) + 8.4(\\mathrm{Private_i})\n\\]\nInterpreting the coefficients,\n\nThe average graduation rate for private schools that have a median SAT score of 0 is \\(-84.4\\)%. (extrapolation)\nA ten-point difference in median SAT score is associated with a 1.3 percentage point difference in graduation rate, controlling for differences in educational sector. (Here we interpret using a factor of 10.)\nPrivate schools, on average, have a graduation rate that is 8.4 percentage points higher than public schools (reference group), controlling for differences in median SAT scores.\n\nBased on our research question, the focal predictor in this model is the coefficient and test associated with private. The \\(t\\)-test associated with the partial slope for private suggests that the controlled difference in means between private and public schools is likely not 0 (\\(p=0.004\\)) given the empirical evidence. Thus, even after controlling for differences in institution selectivity, we believe there is still a difference in private and public schools‚Äô graduation rates, on average.\n\n\n18.4.1 Analysis of Covariance (ANCOVA)\nOur research question in the controlled model, fundamentally, is: Is there a difference on Y between group A and group B, after controlling for covariate Z? We can make the question more complex by having more than two groups (say group A, group B, and group C), or by controlling for multiple covariates. But, the primary question is whether there are group differences on some outcome after controlling for one or more covariates.\nIn the social sciences, the methodology used to analyze group differences when controlling for other predictors is referred to as analysis of covariance, or ANCOVA. ANCOVA models can be analyzed using a framework that focuses on partitioning variation (ANOVA) or using regression as a framework. Both ultimately give the same results (p-values, etc.). In this course we will focus using the regression framework to analyze this type of data.\n\n\n\n18.4.2 Adjusted Means\nSince the focus of the analysis is to answer whether there is a difference in graduation rates between private and public schools, we should provide some measure of how different the graduation rates are. Initially, we provided the mean graduation rates for public and private schools, along with the difference in these two means. These are referred to as the unconditional means and the unconditional mean difference, respectively. They are unconditional because they are the model predicted means (\\(\\hat{Y_i}\\)-values) from the model that does not include any covariates.\nAfter fitting our controlled model, we should provide new adjusted means and an adjusted mean difference based on the predicted mean graduation rates from the model that controls for median SAT scores. Typically, the adjusted means are computed based on substituting in the mean value for all covariates, and then computing the predicted value for all groups. Here we show those computations for our analysis.\n\n# Compute mean SAT\nmn |&gt;\n  summarize(M = mean(sat))\n\n\n  \n\n\n# Compute adjusted mean for private schools\n-84.4 + 0.127*1101.2 + 8.4*1\n\n[1] 63.8524\n\n# Compute adjusted mean for public schools\n-84.4 + 0.127*1101.2 + 8.4*0\n\n[1] 55.4524\n\n# Compute adjusted mean difference\n63.9 - 55.5\n\n[1] 8.4\n\n\nNote that the adjusted mean difference is the value of the partial regression coefficient for private from the ANCOVA model. These values are typically presented in a table along with the unadjusted values.\n\n\n\nTable¬†18.2: Unadjusted and adjusted mean six-year graduation rates for private and public colleges and universities in Minnesota.\n\n\n\n\n  \n  \n\n\n\n\nUnadjusted Mean\nAdjusted Mean1\n\n\n\n\nPrivate institution\n65.3\n63.9\n\n\nPublic institution\n51.0\n55.5\n\n\nDifference\n14.3\n8.4\n\n\n\n1 The model controlled for median SAT scores.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Dichotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-01-dichotomous-predictors.html#one-last-model",
    "href": "05-01-dichotomous-predictors.html#one-last-model",
    "title": "18¬† Dichotomous Categorical Predictors",
    "section": "18.5 One Last Model",
    "text": "18.5 One Last Model\nNow we will include the private dummy coded predictor, the sat predictor, and the tuition predictor in a model to explain variation in graduation rates. Our focus again will be on whether or not there are mean differences in graduation rates between public and private schools, but this time after controlling for differences in median SAT scores and tuition.\nAgain, prior to fitting the regression model, we will examine the correlation matrix.\n\nmn |&gt;\n  select(grad, private, sat, tuition) |&gt;\n  correlate() |&gt;\n  fashion(decimals = 3)\n\n\n  \n\n\n\nFrom the correlation matrix we see:\n\nPrivate institutions tend to have higher graduation rates than public institutions (\\(r = 0.397\\)).\nInstitutions with higher median SAT scores tend to have higher graduation rates (\\(r=0.889\\)).\nInstitutions with higher tuition costs tend to have higher graduation rates (\\(r=0.755\\)).\nPrivate institutions tend to have higher median SAT scores than public institutions (\\(r = 0.194\\)).\nPrivate institutions tend to have higher tuition costs than public institutions (\\(r = 0.773\\)).\nInstitutions with higher tuition costs tend to have higher median SAT scores (\\(r=0.613\\)).\n\nFitting the regression model:\n\nlm.f = lm(grad ~ 1 + sat + tuition + private, data = mn)\n\n# Model-level info\nglance(lm.f) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.861         0.846  6.56      59.7 1.59e-12     3  -107.  224.  231.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1    1249.          29    33\n\n\nDifferences in median SAT scores, tuition rates, and educational sector explain 86.07% of the variation in graduation rates. This is statistically reliable, \\(F(3, 29) = 59.73\\), \\(p&lt;0.001\\).\n\n# Coefficient-level info\ntidy(lm.f)\n\n\n  \n\n\n\nThe fitted equation is:\n\\[\n\\hat{\\mathrm{Graduation~Rate}_i} = -68.9 + 0.10(\\mathrm{Median~SAT}_i) + 0.47(\\mathrm{Tuition~Rate}_i) + 0.65(\\mathrm{Private}_i)\n\\]\nHere we will not interpret all of the coefficients, but instead focus on only the private coefficient, as that is germain to our research question.\n\nPrivate schools, on average, have a graduation rate that is 0.64 percentage points higher than public schools, controlling for differences in median SAT scores and tuition.\n\nThe t-test associated with the partial slope coefficient for private suggests that 0 is a possible value for the controlled difference in means between private and public schools (\\(p=0.892\\)). Given the empirical evidence, after controlling for differences in median SAT score and tuition rates, it is uncertain that there is a difference in average graduation rates between private and public schools.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Dichotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-01-dichotomous-predictors.html#assumption-checking-for-the-final-model",
    "href": "05-01-dichotomous-predictors.html#assumption-checking-for-the-final-model",
    "title": "18¬† Dichotomous Categorical Predictors",
    "section": "18.6 Assumption Checking for the Final Model",
    "text": "18.6 Assumption Checking for the Final Model\nIt is important to check the assumptions of any adopted model. Since we have added non-categorical covariates into the model we need to evaluate all four major assumptions (LINE).\n\n# Obtain the fitted values and residuals\naug_f = augment(lm.f)\n\n# View augmented data frame\nhead(aug_f)\n\n\n\n\n\n\n\n\nFigure¬†18.5: LEFT: Density plot of the marginal distribution of standardized residuals from a regression model using median SAT score, tuition rates, and educational sector to predict variation in six-year graduation rates (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area). RIGHT: Scatterplot of the standardized residuals versus the fitted values from the same model. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption and the expected uncertainty (grey shaded area). The empirical loess smoother (blue) is also displayed.\n\n\n\n# Density plot of the marginal standardized residuals\np1 = ggplot(data = aug_f, aes(x = .std.resid)) +\n  stat_density_confidence(model =\"normal\") +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"Standardized residual\") +\n  ylab(\"Probability density\")\n\n# Scatterplot of the standardized residuals versus the fitted values\np2 = ggplot(data = aug_f, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  theme_bw() +\n  xlab(\"Fitted value\") +\n  ylab(\"Standardized residual\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†18.6: LEFT: Density plot of the marginal distribution of standardized residuals from a regression model using median SAT score, tuition rates, and educational sector to predict variation in six-year graduation rates (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area). RIGHT: Scatterplot of the standardized residuals versus the fitted values from the same model. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption and the expected uncertainty (grey shaded area). The empirical loess smoother (blue) is also displayed.\n\n\n\n\n\nThe marginal distribution of the residuals shows minor evidence of misfit with the normality assumption. The equal variances assumption looks tenable from this set of plots. However, the scatterplot of the standardized residuals versus the fitted values suggests problems with the tenability of the linearity assumption‚Äîat low fitted values more of the residuals are negative than we would expect (over-estimation); at moderate fitted values the residuals tend to be positive (under-estimation); and at high fitted values the residuals tend to the negative again (over-estimation). For now we will ignore this (although in practice this is a BIG problem).",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Dichotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-01-dichotomous-predictors.html#presenting-results",
    "href": "05-01-dichotomous-predictors.html#presenting-results",
    "title": "18¬† Dichotomous Categorical Predictors",
    "section": "18.7 Presenting Results",
    "text": "18.7 Presenting Results\nBelow we present pertinent results from the three models that we fitted.\n\n\nUnstandardized coefficients (standard errors) for a taxonomy of OLS regression models to explain variation in six-year graduation rates for colleges and universities in Minnesota. All models were fitted with n=33 observations.\n\n\n\n\n\n\nModel A\n\n\nModel B\n\n\nModel C\n\n\n\n\n\n\nMedian SAT score\n\n\n\n\n0.127(0.011)\n\n\n0.104(0.016)\n\n\n\n\nTuition\n\n\n\n\n\n\n0.470(0.242)\n\n\n\n\nEducational Sector\n\n\n14.235(5.912)\n\n\n8.378(2.648)\n\n\n0.647(4.716)\n\n\n\n\nConstant\n\n\n51.030(4.936)\n\n\n-84.435(12.054)\n\n\n-68.944(14.017)\n\n\n\n\nR2\n\n\n0.158\n\n\n0.843\n\n\n0.861\n\n\n\n\nRMSE\n\n\n15.608\n\n\n6.859\n\n\n6.562\n\n\n\n\nNote: Educational sector was dummy coded so that 0 = Private institutions; 1 = Public institutions.\n\n\n\n\n\nNotice that when presenting results we referred to the three models as Model A, B, and C, despite the fact that these were named lm.c, lm.e, and lm.f. You need to make decisions about what you present and your naming structure in the final manuscript doesn‚Äôt need to reflect the names used in your analysis. By using A, B, and C, it makes it easier for the reader!\n\n\n\n18.7.1 Data Narrative\nThe presentation of the models helps us build an evidence-based narrative about the differences in graduation rates between public and private schools. In the unconditional model, the evidence suggests that private schools have a higher graduation rate than public schools. Once we control for median SAT score, this difference in graduation rates persists, but at a much lesser magnitude. Finally, after controlling for differences in SAT scores and tuition, we find no statistically reliable differences between the two educational sectors.\nThis narrative suggests that the initial differences we saw in graduation rates between the two sectors is really just a function of differences in SAT scores and tuition, and not really a public/private school difference. As with many non-experimental results, the answer to the question about group differences change as we control for different covariates. It may be, that once we control for other covariates, the narrative might change yet again. This is an important lesson, and one that cannot be emphasized enough‚Äîthe magnitude and statistical importance of predictors change when the model is changed.\n\n\n\n18.7.2 Adjusted Means: Revisited\nWe should also present our table of unadjusted adn adjusted means. To compute the adjusted means for Model C, we will substitute in the mean value for median SAT score and tuition to deterine the predicted value for public nd private institutions. Here we show those computations for our analysis.\n\n# Mean median SAT value = 1101.2\n# Compute mean tuition\nmn |&gt;\n  summarize(M = mean(tuition))\n\n\n  \n\n\n# Compute adjusted mean for private schools\n-68.94 + 0.104*1101.2 + 0.470*32.3 + 0.647*1\n\n[1] 61.4128\n\n# Compute adjusted mean for public schools\n-68.94 + 0.104*1101.2 + 0.470*32.3 + 0.647*0\n\n[1] 60.7658\n\n# Compute adjusted mean difference\n61.4128 - 60.7658\n\n[1] 0.647\n\n\nThe updated table is presented below.\n\n\n\nTable¬†18.3: Unadjusted and adjusted mean six-year graduation rates for private and public colleges and universities in Minnesota.\n\n\n\n\n  \n  \n\n\n\n\nModel A&lt;br /&gt;(Unadjusted Mean)\nModel B&lt;br /&gt;(Adjusted Mean)1\nModel C&lt;br /&gt;(Adjusted Mean)2\n\n\n\n\nPrivate institution\n65.3\n63.9\n61.4\n\n\nPublic institution\n51.0\n55.5\n60.8\n\n\nDifference\n14.3\n8.4\n0.6\n\n\n\n1 The model controlled for median SAT scores.\n\n\n2 The model controlled for median SAT scores and tuition rate.\n\n\n\n\n\n\n\n\n\n\n\n\n\n18.7.3 Plots to Display Model Results\nWe may want to consider creating a plot to accompany the data narrative. Within this plot, we would want to focus on the public‚Äìprivate institution difference (i.e., effect of educational sector) and how that effect changes as we control for educational covariates.\nOne potential plot is a tripych, with each panel plotting the model predicted graduation rates for each model, respectively. For Models B and C we could plot the predicted graduation rates as a function of median SAT scores, and have different lines for public and private institutions. However, for Model A we couldn‚Äôt show this as that model didn‚Äôt include median SAT score.\nOne solution is to plot the unadjusted (Model A) and adjusted (Models B and C) mean values. This is essentially a graphical depiction of the information in Table¬†18.3. Below is the syntax to create this\n\n# Create plot data\nplot_data = data.frame(\n  pred_grad = c(65.3, 51.0, 63.9, 55.5, 61.4, 60.8),\n  sector = c(\"Private\", \"Public\", \"Private\", \"Public\", \"Private\", \"Public\"),\n  model = c(\"Model A\", \"Model A\", \"Model B\", \"Model B\", \"Model C\", \"Model C\")\n)\n\nggplot(data = plot_data, aes(x = model, y = pred_grad)) +\n  geom_point(aes(color = sector), size = 4) +\n  theme_bw() +\n  xlab(\"\") +\n  ylab(\"Predicted graduation rate\") +\n  scale_color_manual(\n    name = \"Sector\",\n    values = c(\"#56b4e9\", \"#e69f00\")\n  )\n\n\n\n\n\n\n\nFigure¬†18.7: Predicted mean graduation rate for public (orange) and private (blue) institutions in Minnesota. In Models B and C, the means are adjusted for median SAT score (Model B) and median SAT score and tuition rate (Model C), respectively.\n\n\n\n\n\nAn alternative plot would show the difference in means for each model. One advantage of this is that you could also display the uncertainty for these differences by plotting the CIs. Remember that the differences in mean graduation rate is simply the public (or private) coefficient from each model. Here we re-obtain the coefficient-level output for each model and also display the CIs (output not shown).\n\n# Coefficient-level output for each model with CIs\ntidy(lm.c, conf.int = TRUE)\ntidy(lm.e, conf.int = TRUE)\ntidy(lm.f, conf.int = TRUE)\n\nNow we create a data frame of the private coefficient information and create a plot of the difference in means for the three models.\n\n# Create plot data\nplot_data = data.frame(\n  pred_diff = c(14.2, 8.38, 0.647),\n  low_ci = c(2.18, 2.97, -9.00),\n  high_ci = c(26.3, 13.8, 10.3),\n  model = c(\"Model A\", \"Model B\", \"Model C\"),\n  sig = c(\"Yes\", \"Yes\", \"No\")\n)\n\nggplot(data = plot_data, aes(x = model, y = pred_diff, color = sig)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_errorbar(aes(ymin = low_ci, ymax = high_ci)) + #Create CIs\n  geom_point(size = 4) + #Add observed difference\n  theme_bw() +\n  xlab(\"\") +\n  ylab(\"Predicted difference in graduation rate\") +\n  scale_color_manual(\n    values = c(\"#777777\", \"#cc79a7\")\n  ) +\n  guides(color = \"none\")\n\n\n\n\n\n\n\nFigure¬†18.8: Predicted difference in mean graduation rate between private and public institutions in Minnesota. Model A is the uncontrolled model while Model B controlls for median SAT score and Model C controld for both median SAT score and tuition rate. The line \\(Y=0\\) indicates no difference. Differences that are statistically discernible from 0 are colored pink.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Dichotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html",
    "href": "05-02-polychotomous-predictors.html",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "",
    "text": "19.1 Data Exploration\nTo begin, as always, we will plot the marginal distributions of news knowledge (knowledge) and new source (news_source).\n# Density plot of news knowledge\np1 = ggplot(data = pew, aes(x = knowledge)) +\n  stat_density(geom = \"line\", color = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"News knowledge\") +\n  ylab(\"Probability density\")\n\n# Bar plot of news source\np2 = ggplot(data = pew, aes(x = news_source)) +\n  geom_bar(fill = \"#c62f4b\") +\n  theme_bw() +\n  xlab(\"News source\") +\n  ylab(\"Frequency\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†19.1: LEFT: Density plot of news knowledge. RIGHT: Bar plot of news source.\nThe distribution of new knowledge is slightly left-skewed with the majority of respondents scoring around 50-75. The distribution of news source indicates that the sample is quite unbalanced among the different news sourcess.1 The majority of the people in the sample do not watch/listen to any of the three news sources or get their news from a conservative source.\nWhat does the distribution of news knowledge look like once we condition on news source? We will explore this by creating a scatterplot of news knowledge versus news source. We will also use the geom_density_ridges() layer from the {ggridges} package to create conditional density plots of news knowledge. It is easier to compare the shape of distributions using conditional density plots. We will also compute the summary measures of news knowledge conditioned on news source.\n# Scatterplot\np1 = ggplot(data = pew, aes(x = news_source, y = knowledge)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"News source\") +\n  ylab(\"News knowledge\")\n\n# News knowledge conditioned on news source\np2 = ggplot(data = pew, aes(x = knowledge, y = news_source)) +\n  geom_density_ridges() +\n  theme_bw() +\n  ylab(\"News source\") +\n  xlab(\"News knowledge\")\n\n# Layout plots\np1 | p2\n\n# Compute summary statistics\npew |&gt;\n  group_by(news_source) |&gt;\n  summarize(\n    M  = mean(knowledge),\n    SD = sd(knowledge),\n    N = n()\n  ) |&gt;\n  arrange(desc(M))\n\n\n\n\n\n\n\n\nFigure¬†19.2: LEFT: Scatterplot of the news knowledge versus news source. RIGHT: Density plots of news knowledge conditioned on news source.\n\n\n\n\n\n\n\n\n\n\nFigure¬†19.3: LEFT: Scatterplot of the news knowledge versus news source. RIGHT: Density plots of news knowledge conditioned on news source.\nAfter conditioning on news source, the data suggest that there are differences in the Americans‚Äô knowledge about current affairs based on their source of news. In the sample, those who get their news from liberal and comedy sources have the highest news knowledge scores, on average. Not surprisingly, those who do not get heir news from any of the sources have the lowest news knoledge scores, on average. Also, those who get their news from liberal or comedy sources tend to score higher (on average) than thos who get their news from conservative sources.\nThere is, however, a great deal of variation in all the distributions‚Äîthe SDs range between 16 and 23. This variation makes it difficult to be certain about the trends/differences we saw between the groups without carrying out any inferential analyses (e.g., CIs or hypothesis tests).",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html#does-news-source-predict-variation-in-americans-news-knowledge",
    "href": "05-02-polychotomous-predictors.html#does-news-source-predict-variation-in-americans-news-knowledge",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "19.2 Does News Source Predict Variation in American‚Äôs News Knowledge?",
    "text": "19.2 Does News Source Predict Variation in American‚Äôs News Knowledge?\nTo examine whether the sample differences we observed in news knowledge is more than we would expect because of chance, we can fit a regression model using news source to predict variation in news knowledge. Before fitting this model, however, we need to create a set of dummy variables; one for EACH category of the news_source variable. For our analysis, we will need to create EIGHT dummy variables: The mapping for these eight indicators are:\n\\[\n\\begin{split}\n\\mathtt{none} &= \\begin{cases}\n1 \\quad \\mathrm{for~None}\\\\\n0 \\quad \\mathrm{Otherwise}\n\\end{cases} \\\\[2ex]\n\\mathtt{con} &= \\begin{cases}\n1 \\quad \\mathrm{for~Conservative}\\\\\n0 \\quad \\mathrm{Otherwise}\n\\end{cases} \\\\[2ex]\n\\mathtt{com} &= \\begin{cases}\n1 \\quad \\mathrm{for~Comedy}\\\\\n0 \\quad \\mathrm{Otherwise}\n\\end{cases} \\\\[2ex]\n\\mathtt{lib} &= \\begin{cases}\n1 \\quad \\mathrm{for~Liberal}\\\\\n0 \\quad \\mathrm{Otherwise}\n\\end{cases} \\\\[2ex]\n\\mathtt{con\\_com} &= \\begin{cases}\n1 \\quad \\mathrm{for~Conservative\\_Comedy}\\\\\n0 \\quad \\mathrm{Otherwise}\n\\end{cases} \\\\[2ex]\n\\mathtt{con\\_lib} &= \\begin{cases}\n1 \\quad \\mathrm{for~Conservative\\_Liberal}\\\\\n0 \\quad \\mathrm{Otherwise}\n\\end{cases} \\\\[2ex]\n\\mathtt{lib\\_com} &= \\begin{cases}\n1 \\quad \\mathrm{for~Liberal\\_Comedy}\\\\\n0 \\quad \\mathrm{Otherwise}\n\\end{cases} \\\\[2ex]\n\\mathtt{all} &= \\begin{cases}\n1 \\quad \\mathrm{for~All}\\\\\n0 \\quad \\mathrm{Otherwise}\n\\end{cases} \\\\[2ex]\n\\end{split}\n\\]\nBelow we write the syntax to create all eight dummy variables and save the new columns in the pew data frame.2\n\n# Create all eight dummy variables\npew = pew |&gt;\n  mutate(\n    none    = if_else(news_source == \"None\", 1, 0),\n    con     = if_else(news_source == \"Conservative\", 1, 0),\n    com     = if_else(news_source == \"Comedy\", 1, 0),\n    lib     = if_else(news_source == \"Liberal\", 1, 0),\n    con_com = if_else(news_source == \"Conservative_Comedy\", 1, 0),\n    con_lib = if_else(news_source == \"Conservative_Liberal\", 1, 0),\n    lib_com = if_else(news_source == \"Liberal_Comedy\", 1, 0),\n    all     = if_else(news_source == \"All\", 1, 0),\n    )\n\n# Examine data\npew |&gt;\n  print(width = Inf)\n\n# A tibble: 1,502 √ó 17\n      id knowledge news_source   news ideology engagement   age education female\n   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; \n 1     1        50 Conservative    63     39.3       79.5  44.4        14 Yes   \n 2     2        32 All             59     35.6       69.2  67.9         9 Yes   \n 3     3        45 None            49     75.7       61    45.7        12 Yes   \n 4     4        26 None            22     23.5       66.8  39.3        15 Yes   \n 5     5        79 None            54     69.5       80.8  59.5        15 No    \n 6     6        31 Conservative    65     18         99.6  43.8        12 Yes   \n 7     7        22 Conservative    63     33.2       37.4  29.6        10 No    \n 8     8        93 Conservative    50     29.7       88.6  29.6        16 No    \n 9     9        23 None            12     52.5       82.4  45.1        12 Yes   \n10    10        41 Liberal         16     14         87.3  18.7        11 No    \n    none   con   com   lib con_com con_lib lib_com   all\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1     0     1     0     0       0       0       0     0\n 2     0     0     0     0       0       0       0     1\n 3     1     0     0     0       0       0       0     0\n 4     1     0     0     0       0       0       0     0\n 5     1     0     0     0       0       0       0     0\n 6     0     1     0     0       0       0       0     0\n 7     0     1     0     0       0       0       0     0\n 8     0     1     0     0       0       0       0     0\n 9     1     0     0     0       0       0       0     0\n10     0     0     0     1       0       0       0     0\n# ‚Ñπ 1,492 more rows\n\n\nIf you do not know the actual names of the categories (or you want to check capitalization, etc.) use the unique() function to obtain the unique category names.\n\n# Get the categories\npew |&gt;\n  select(news_source) |&gt;\n  unique()\n\n\n  \n\n\n\nIt turns out that all eight categories of the predictor are completely identified using any seven of the eight indicator variables. For example, consider the news source for the sample of six people below.\n\n\n\nTable¬†19.1: News source and values on seven of the eight dummy-coded indicator variables for a sample of six people.\n\n\n\n\n  \n  \n\n\n\nNews Source\nall\ncon\ncom\nlib\ncon_com\ncon_lib\nlib_com\n\n\n\n\nLiberal\n0\n0\n0\n1\n0\n0\n0\n\n\nNone\n0\n0\n0\n0\n0\n0\n0\n\n\nConservative\n0\n1\n0\n0\n0\n0\n0\n\n\nLiberal\n0\n0\n0\n1\n0\n0\n0\n\n\nConservative_Liberal\n0\n0\n0\n0\n0\n1\n0\n\n\nNone\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n\nBy using any seven of the indicators, we can identify the news source for everyone in the sample. For example, in the data shown in Table¬†19.1, we used all of the indicators except for none. For Americans whose news source is ‚ÄúNone‚Äù, they would have a 0 for all of the seven indicators used. In other words, we don‚Äôt need the information in the none indicator to identify people whose news source is ‚ÄúNone‚Äù, so long as we have the other seven indicators.\nTo examine the effect of news source, we will fit the regression using any seven of the eight dummy-coded indicator variables you created. The indicator you leave out of the model will correspond to the reference category. For example, in the model fitted below, we include all the predictors except none as predictors in the model. As such, people whose news source is ‚ÄúNone‚Äù is our reference group.\n\nUltimately we will need to fit several models, so I often name my regression objects using the reference group. For example, in the model where ‚ÄúNone‚Äù is the reference group, I will name my regression object lm.none.\n\n\n# News source = None is reference group\nlm.none = lm(knowledge ~ 1 + all + con + com + lib + con_com + con_lib +\n                      lib_com, data = pew)\n\n# Model-level info\nglance(lm.none) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     0.103        0.0988  21.8      24.5 9.11e-32     7 -6754. 13526. 13574.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1  707719.        1494  1502\n\n\nAt the model-level, differences in news source explain 10.3% of the variation in American‚Äôs news knowledge. This is statistically discernible from 0 (i.e., the empirical data are not consistent with the hypothesis that news source does not explain any variation in Americans‚Äô news knowledge, \\(F(7,1494)=24.50\\), \\(p &lt; .001\\).\nIn other words, the data suggest there is an effect of news source on news knowledge. Recall that an effect of a categorical predictor means that there are differences in the average value of the outcome between different levels of the predictor. In our example, there are differences in the average news knowledge based on news source. The key question in exploratory research is then: Which news sources show differences in the average news knowledge? In order to answer this, we need to look at the coefficient-level output.\n\n# Coefficient-level info\ntidy(lm.none)\n\n\n  \n\n\n\nThe fitted regression equation is\n\\[\n\\begin{split}\n\\hat{\\mathrm{Knowledge}_i} = &48.7 + 16.9(\\mathrm{All}_i) + 7.8(\\mathrm{Con}_i) + 15.0(\\mathrm{Com}_i) + 16.9(\\mathrm{Lib}_i) + \\\\\n&11.9(\\mathrm{Con\\_Com}_i) + 10.8(\\mathrm{Con\\_Lib}_i) + 28.1(\\mathrm{Lib\\_Con}_i)\n\\end{split}\n\\]\nRecall from the previous chapter, the intercept coefficient is the average Y-value for the reference group. Each partial slope is the difference in average Y-value between the reference group and the group represented by the dummy variable. In our example,\n\nThe average news knowledge score for Americans who have no news source is 48.7.\nAmericans who get their news from all three sources (conservative, comedy, and liberal) have a news knowledge score that is 16.9 points higher, on average, than Americans who have no news source.\nAmericans who get their news from a conservative source have a news knowledge score that is 7.8 points higher, on average, than Americans who have no news source.\nAmericans who get their news from a comedy source have a news knowledge score that is 15 points higher, on average, than Americans who have no news source.\nAmericans who get their news from a liberal source have a news knowledge score that is 16.9 points higher, on average, than Americans who have no news source.\nAmericans who get their news from conservative and comedy sources have a news knowledge score that is 11.9 points higher, on average, than Americans who have no news source.\nAmericans who get their news from conservative and liberal sources have a news knowledge score that is 10.8 points higher, on average, than Americans who have no news source.\nAmericans who get their news from liberal and comedy sources have a news knowledge score that is 28.1 points higher, on average, than Americans who have no news source.\n\nThe statistical hypothesis associated with each of the parameters in the model are:\n\n\\(H_0:\\beta_0 = 0\\)\n\\(H_0:\\beta_{\\mathrm{All}} = 0\\)\n\\(H_0:\\beta_{\\mathrm{Con}} = 0\\)\n\\(H_0:\\beta_{\\mathrm{Com}} = 0\\)\n\\(H_0:\\beta_{\\mathrm{Lib}} = 0\\)\n\\(H_0:\\beta_{\\mathrm{Con\\_Com}} = 0\\)\n\\(H_0:\\beta_{\\mathrm{Con\\_Lib}} = 0\\)\n\\(H_0:\\beta_{\\mathrm{Lib\\_Com}} = 0\\)\n\nThese relate to the following scientific hypotheses, respectively:\n\nThe average news knowledge score for Americans who have no news source (reference group) is 0.\nThe average news knowledge score for Americans who get their news from all three sources (conservative, comedy, and liberal) is not different than the average news knowledge score for Americans who have no news source.\nThe average news knowledge score for Americans who get their news from conservative sources is not different than the average news knowledge score for Americans who have no news source.\nThe average news knowledge score for Americans who get their news from comedy sources is not different than the average news knowledge score for Americans who have no news source.\nThe average news knowledge score for Americans who get their news from liberal sources is not different than the average news knowledge score for Americans who have no news source.\nThe average news knowledge score for Americans who get their news from conservative and comedy sources is not different than the average news knowledge score for Americans who have no news source.\nThe average news knowledge score for Americans who get their news from conservative and liberal sources is not different than the average news knowledge score for Americans who have no news source.\nThe average news knowledge score for Americans who get their news from liberal and comedy sources is not different than the average news knowledge score for Americans who have no news source.\n\nBecause the scientific hypotheses are really about comparisons of conditional means, the statistical hypotheses can also be written to reflect this as:\n\n\\(H_0:\\mu_{\\mathrm{None}} = 0\\)\n\\(H_0:\\mu_{\\mathrm{All}} = \\mu_{\\mathrm{None}}\\) or equivalently \\(H_0:\\mu_{\\mathrm{All}} - \\mu_{\\mathrm{None}} = 0\\)\n\\(H_0:\\mu_{\\mathrm{Con}} = \\mu_{\\mathrm{None}}\\) or equivalently \\(H_0:\\mu_{\\mathrm{Con}} - \\mu_{\\mathrm{None}} = 0\\)\n\\(H_0:\\mu_{\\mathrm{Com}} = \\mu_{\\mathrm{None}}\\) or equivalently \\(H_0:\\mu_{\\mathrm{Com}} - \\mu_{\\mathrm{None}} = 0\\)\n\\(H_0:\\mu_{\\mathrm{Lib}} = \\mu_{\\mathrm{None}}\\) or equivalently \\(H_0:\\mu_{\\mathrm{Lib}} - \\mu_{\\mathrm{None}} = 0\\)\n\\(H_0:\\mu_{\\mathrm{Con\\_Com}} = \\mu_{\\mathrm{None}}\\) or equivalently \\(H_0:\\mu_{\\mathrm{Con\\_Com}} - \\mu_{\\mathrm{None}} = 0\\)\n\\(H_0:\\mu_{\\mathrm{Con\\_Lib}} = \\mu_{\\mathrm{None}}\\) or equivalently \\(H_0:\\mu_{\\mathrm{Con\\_Lib}} - \\mu_{\\mathrm{None}} = 0\\)\n\\(H_0:\\mu_{\\mathrm{Lib\\_Com}} = \\mu_{\\mathrm{None}}\\) or equivalently \\(H_0:\\mu_{\\mathrm{Lib\\_Com}} - \\mu_{\\mathrm{None}} = 0\\)\n\nwhere \\(\\mu_j\\) represents the average news knowledge for Americans who get their news from source j (e.g., \\(\\mu_{\\mathrm{Con}}\\) indicates the average news knowledge score for Americans who get their news from conservative sources).\nIt is evaluation of the hypotheses associated with the partial slopes in the model that allow us to answer our question about which news sources show differences in the average news knowledge. The p-values associated with the partial slope coefficients indicate whether the observed differences in news scores (relative to the reference group) are simply due to sampling error, or whether there is a statistically discernible difference in the news knowledge between the groups. Based on the p-values, all seven groups have an average news knowledge score that is statistically discernible than the average news knowledge score for Americans who have no news source. Moreover, based on the positive coefficients, we can assume that those scores are higher than the average news knowledge score for Americans who have no news source.\n\n\n19.2.1 Alternative Expression of the Model-Level Null Hypothesis\nRecall that one expression of the null hypothesis associated with the model-level test in multiple regression is that all the partial slopes are zero. In general,\n\\[\nH_0: \\beta_1 = \\beta_2 = \\ldots = \\beta_k = 0\n\\]\nWhen we use multiple dummy-coded indicator variables to represent a categorical predictor, each partial slope represents the mean difference between two groups, and the effect of that categorical predictor is composed of ALL sets of differences between two groups (pairwise differences). In our example,there are 28 pairwise differences! (Think of all the ways we can compare two of the eight different groups.)\n\nAll sources vs.¬†conservative sources\nAll sources vs.¬†comedy sources\nAll sources vs.¬†liberal sources\nAll sources vs.¬†conservative/comedy sources\nAll sources vs.¬†conservative/liberal sources\nAll sources vs.¬†liberal/comedy sources\nAll sources vs.¬†no sources\nConservative sources vs.¬†comedy sources\nConservative sources vs.¬†liberal sources\nConservative sources vs.¬†conservative/comedy sources\nConservative sources vs.¬†conservative/liberal sources\nConservative sources vs.¬†liberal/comedy sources\nConservative sources vs.¬†no sources\nComedy sources vs.¬†liberal sources\nComedy sources vs.¬†conservative/comedy sources\nComedy sources vs.¬†conservative/liberal sources\nComedy sources vs.¬†liberal/comedy sources\nComedy sources vs.¬†no sources\nLiberal sources vs.¬†conservative/comedy sources\nLiberal sources vs.¬†conservative/liberal sources\nLiberal sources vs.¬†liberal/comedy sources\nLiberal sources vs.¬†no sources\nConservative/comedy sources sources vs.¬†conservative/liberal sources\nConservative/comedy sources sources vs.¬†liberal/comedy sources\nConservative/comedy sources sources vs.¬†no sources\nConservative/liberal sources sources vs.¬†liberal/comedy sources\nConservative/liberal sources sources vs.¬†no sources\nLiberal/comedy sources sources vs.¬†no sources\n\nThe model-level null hypothesis can be expressed as:\n\\[\n\\begin{split}\nH_0: &\\bigg(\\mu_{\\mathrm{All}} - \\mu_{\\mathrm{Con}}\\bigg) = \\bigg(\\mu_{\\mathrm{All}} - \\mu_{\\mathrm{Com}}\\bigg) =\\\\ &\\bigg(\\mu_{\\mathrm{All}} - \\mu_{\\mathrm{Lib}}\\bigg) = \\ldots = \\bigg(\\mu_{\\mathrm{Lib\\_Com}} - \\mu_{\\mathrm{None}}\\bigg) = 0\n\\end{split}\n\\]\nThe test at the model-level is considering all 28 pairwise differences simultaneously. If the model-level test is statistically discernible from 0, any one (or more than one) of the 28 differences may not be zero.\nIn our example, we found that the model-level test had a small p-value, so at least one of the 28 comparisons would have results that are statistically discernible from 0.\nNote that in our coefficient-level output, we found that 7 of the potential comparisons (those that compare to the ‚ÄúNone‚Äù group) yielded results that were statistically discernible from zero. That is, based on those results we believe:\n\n\\(\\mu_{\\mathrm{All}} - \\mu_{\\mathrm{None}} \\neq 0\\)\n\\(\\mu_{\\mathrm{Con}} - \\mu_{\\mathrm{None}} \\neq 0\\)\n\\(\\mu_{\\mathrm{Com}} - \\mu_{\\mathrm{None}} \\neq 0\\)\n\\(\\mu_{\\mathrm{Lib}} - \\mu_{\\mathrm{None}} \\neq 0\\)\n\\(\\mu_{\\mathrm{Con\\_Com}} - \\mu_{\\mathrm{None}} \\neq 0\\)\n\\(\\mu_{\\mathrm{Con\\_Lib}} - \\mu_{\\mathrm{None}} \\neq 0\\)\n\\(\\mu_{\\mathrm{Lib\\_Com}} - \\mu_{\\mathrm{None}} \\neq 0\\)\n\nUnfortunately, the coefficient-level output from the regression we fitted, does not give us any information about the other 21 comparisons. In order to get information about the other pairwise comparisons, we need to fit additional regression models using a different reference group.\n\nWhen you have more than two levels in your categorical predictor in order to examine ALL potential coefficient-level differences, you will need to fit many regression models using different reference groups.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html#pairwise-comparisons-for-americans-who-get-their-news-from-conservative-sources",
    "href": "05-02-polychotomous-predictors.html#pairwise-comparisons-for-americans-who-get-their-news-from-conservative-sources",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "19.3 Pairwise Comparisons for Americans who get their News from Conservative Sources",
    "text": "19.3 Pairwise Comparisons for Americans who get their News from Conservative Sources\nConsider the pairwise comparisons between Americans who get their News from conservative sources and those who get their news from other sources. There are 7 such comparisons. We already evaluated one of those, namely the comparison between Americans who get their News from conservative sources and those who have no news source. To evaluate the other 6 differences, we need to fit a model in which con is the reference group. By doing this, the partial slopes will indicate the difference in average news knowledge between Americans who get their news each of the other sources and those who get their news from conservative sources. Below, we fit this model (using con as the reference group) to predict variation in news knowledge.\n\n# Conservative news sources is reference group\nlm.con = lm(knowledge ~ 1 + all + com + lib + con_com + con_lib +\n                      lib_com + none, data = pew)\n\n# Model-level info\nglance(lm.con) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     0.103        0.0988  21.8      24.5 9.11e-32     7 -6754. 13526. 13574.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1  707719.        1494  1502\n\n\nNote that the model-level output for this fitted model is exactly the same as that for the model in which none was the reference group. That is because at the model-level, this model is testing the exact same hypothesis as the previous model (to examine whether the 28 sets of pairwise differences explain variation in news knowledge). The results suggest that at least one of the pairwise differences is statistically discernible from 0; that is there are differences in the average amount of news knowledge between at least two of the groups.\n\n# Coefficient-level info\ntidy(lm.con)\n\n\n  \n\n\n\nThe fitted regression equation, which is different than the previous fitted equation, is:\n\\[\n\\begin{split}\n\\hat{\\mathrm{Knowledge}_i} = &56.5 + 9.1(\\mathrm{All}_i) + 7.2(\\mathrm{Com}_i) + 9.2(\\mathrm{Lib}_i) + \\\\\n&4.0(\\mathrm{Con\\_Com}_i) + 3.0(\\mathrm{Con\\_Lib}_i) + 20.3(\\mathrm{Lib\\_Con}_i) -7.8(\\mathrm{None}_i)\n\\end{split}\n\\]\nInterpreting these values,\n\nThe average news knowledge score for Americans who get their news from conservative sources is 56.5. The empirical evidence suggests that this is statistically discernible from 0; \\(t(1494)=49.50\\), \\(p&lt;.001\\).\nAmericans who get their news from all three sources (conservative, comedy, and liberal) have a news knowledge score that is 9.1 points higher, on average, than Americans who get their news from conservative sources. The empirical evidence suggests that this is statistically discernible from 0; \\(t(1494)=3.25\\), \\(p=.001\\).\nAmericans who get their news from a comedy source have a news knowledge score that is 7.2 points higher, on average, than Americans who get their news from conservative sources. The empirical evidence suggests that this is statistically discernible from 0; \\(t(1494)=2.00\\), \\(p=.046\\).\nAmericans who get their news from a liberal source have a news knowledge score that is 9.2 points higher, on average, than Americans who get their news from conservative sources. The empirical evidence suggests that this is statistically discernible from 0; \\(t(1494)=4.71\\), \\(p&lt;.001\\).\nAmericans who get their news from conservative and comedy sources have a news knowledge score that is 4 points higher, on average, than Americans who get their news from conservative sources. The empirical evidence suggests that this is NOT statistically discernible from 0; \\(t(1494)=1.35\\), \\(p=.176\\).\nAmericans who get their news from conservative and liberal sources have a news knowledge score that is 3 points higher, on average, than Americans who get their news from conservative sources. The empirical evidence suggests that this is NOT statistically discernible from 0; \\(t(1494)=1.61\\), \\(p=.107\\).\nAmericans who get their news from liberal and comedy sources have a news knowledge score that is 20.3 points higher, on average, than Americans who get their news from conservative sources. The empirical evidence suggests that this is statistically discernible from 0; \\(t(1494)=6.66\\), \\(p&lt;.001\\).\nAmericans who don‚Äôt get their news from any source have a news knowledge score that is 7.8 points lower, on average, than Americans who get their news from conservative sources. The empirical evidence suggests that this is statistically discernible from 0; \\(t(1494)=-5.20\\), \\(p&lt;.001\\).\n\nNote that the last comparison (with the none group) is the comparison we already evaluated in the previous model. The coefficient-level output for this gives redundant information that from the previous model‚Äîthe only difference being that the signs are opposite on the coefficient and t-value since we changed the reference group. (The p-values are identical.)",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html#presenting-results-of-the-pairwise-comparison-tests",
    "href": "05-02-polychotomous-predictors.html#presenting-results-of-the-pairwise-comparison-tests",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "19.4 Presenting Results of the Pairwise Comparison Tests",
    "text": "19.4 Presenting Results of the Pairwise Comparison Tests\nNow we have statistical results from 13 of the 28 comparisons. Before we go on and fit other regression models to evaluate our other pairwise comparisons, let‚Äôs consider how we might want to present these results to a reader. As always, we can do this by presenting the results in the text of the manuscript, in a table, or in a visualization. If the number of pairwise comparisons is small (say three or fewer), presenting them in the text is reasonable as doing so would take less space than using a table or plot. When you have a larger number of comparisons to present, doing so in text is likely not a good choice due to the cognitive burden this would place on the reader.\nA table is a good choice for a small to moderate number of comparisons (e.g., \\(\\leq10\\) comparisons). For example, Table¬†19.2 presents the results for three pairwise comparisons carried out as part of a research study examining the effects of family structure on teen substance use.\n\n\n\nTable¬†19.2: Pairwise comparisons of adolescent substance use between three family structures.\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\nComparison\nMean\nDifference\n\np\n\n\n\n\nTwo-parent vs. Parent/guardian\n0.164\n0.079\n\n\nTwo-parent vs. Single-parent\n0.221\n0.005\n\n\nParent/guardian vs. Single-parent\n0.057\n0.609\n\n\n\n\n\n\n\n\n\nOnce you have more than 10 comparisons, presenting this information in a table can be overwhelming. (If you really need to do this, consider putting the table in an appendix or in online resources rather than in the manuscript itself.) In our case, presenting the results from 28 comparisons would not only make for a long table, but also probably result in readers just skipping over the table. Instead, we will consider presnting our results in a visualization.\nThere are several options for such a visualization. One that I like, which shows the same pairwise comparisons presented in tbl-mean-diffs, is the following:\n\n\n\n\n\n\n\n\nFigure¬†19.4: Pairwise comparisons of average teen substance use for different family structures. Instructions: Read across the row for a family structure to compare substance use with the family structures listed along the top of the chart. The symbols indicate whether the average substance use of the family structure in the row is significantly lower than that of the comparison family structure, significantly higher than that of the comparison family structure, or if there is no statistically discernible difference between the average substance use of the two countries.\n\n\n\n\n\nThe column of mean substance use is handy for readers to see the sample differences. (Including the SD here is not necessary, especially if those are included in a different place in the manuscript.) Note, I listed the family structures from largest mean to smallest mean in the figure (in both the rows and columns). This will put all of the down-pointing triangles in the upper right and the up-pointing triangles in the lower left of the figure. This makes it easier to quickly determine which comparison groups a particular group is hgher or lower than. If you have many, many groups listing them alphabetically makes it easier for readers to find the group they are interested in making comparisons for.\nHere we create a similar type of chart to visualize the pairwise comparisons for our news knowledge example. For now, we will fill in only the 13 pairwise comparisons that we have already made. (We will add to this as we evaluate additional pairwise differences.)\n\n\n\n\n\n\n\n\nFigure¬†19.5: Pairwise comparisons of average news knowledge for different news sources. Instructions: Read across the row for a news sources to compare news knowledge with the news sources listed along the top of the chart. The symbols indicate whether the average news knowledge of the news source in the row is significantly lower than that of the comparison news source, significantly higher than that of the comparison news source, or if there is no statistically discernible difference between the average news knowledge of the two news sources.\n\n\n\n\n\n\nTable-like graphics, such as the pairwise comparison visualizations are often easier to create in Excel (or some other spreadsheet program) than in R. I created these in Excel and then, after turning off the grid lines, took a screenshot and inserted that into this chapter.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html#pairwise-comparisons-for-americans-who-get-their-news-from-the-other-sources",
    "href": "05-02-polychotomous-predictors.html#pairwise-comparisons-for-americans-who-get-their-news-from-the-other-sources",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "19.5 Pairwise Comparisons for Americans who get their News from the Other Sources",
    "text": "19.5 Pairwise Comparisons for Americans who get their News from the Other Sources\nHere we fit the additional regression models needed to get the remaining pairwise comparisons.\n\n# Reference group = All News\nlm.all = lm(knowledge ~ 1 + con + com + lib + con_com + con_lib +\n                      lib_com + none, data = pew)\n\n# Reference group = Comedy News\nlm.com = lm(knowledge ~ 1 + all + con + lib + con_com + con_lib +\n                      lib_com + none, data = pew)\n\n# Reference group = Liberal News\nlm.lib = lm(knowledge ~ 1 + all + con + com + con_com + con_lib +\n                      lib_com + none, data = pew)\n\n# Reference group = Conservative and Comedy News\nlm.con_com = lm(knowledge ~ 1 + all + con + com + lib + con_lib +\n                      lib_com + none, data = pew)\n\n# Reference group = Conservative and Liberal News\nlm.con_lib = lm(knowledge ~ 1 + all + con + com + lib + con_com +\n                      lib_com + none, data = pew)\n\nBelow we display the coefficient-level output for each of the model (click the tab of the model you want to see the results for). We do not write out the fitted equations, but this should be old hat for you by now. ü§ó\n\nAllComedyLiberalConservative and ComedyConservative and Liberal\n\n\n\n# Coefficient-level output\ntidy(lm.all)\n\n\n  \n\n\n\n\n\n\n# Coefficient-level output\ntidy(lm.com)\n\n\n  \n\n\n\n\n\n\n# Coefficient-level output\ntidy(lm.lib)\n\n\n  \n\n\n\n\n\n\n# Coefficient-level output\ntidy(lm.con_com)\n\n\n  \n\n\n\n\n\n\n# Coefficient-level output\ntidy(lm.con_lib)\n\n\n  \n\n\n\n\n\n\nBased on these results, we can now update our visualization of the pairwise comparisons.\n\n\n\n\n\n\n\n\nFigure¬†19.6: Pairwise comparisons of average news knowledge for different news sources. Instructions: Read across the row for a news sources to compare news knowledge with the news sources listed along the top of the chart. The symbols indicate whether the average news knowledge of the news source in the row is significantly lower than that of the comparison news source, significantly higher than that of the comparison news source, or if there is no statistically discernible difference between the average news knowledge of the two news sources.\n\n\n\n\n\n\n19.5.1 Link to the Analysis of Variance Methodology for Testing Mean Differences\nIn your statistics journey, you may have encountered the one-factor analysis of variance (ANOVA). This method is often introduced as a way of testing mean differences when you have more than two groups. The null hypothesis for this method (referred to as the omnibus null hypothesis) is that all group means are equal.\nRecall that the model-level hypothesis could be written such that the difference in each pair of group means is 0, namely:\n\\[\n\\begin{split}\nH_0: &\\bigg(\\mu_{\\mathrm{All}} - \\mu_{\\mathrm{Con}}\\bigg) = \\bigg(\\mu_{\\mathrm{All}} - \\mu_{\\mathrm{Com}}\\bigg) =\\\\ &\\bigg(\\mu_{\\mathrm{All}} - \\mu_{\\mathrm{Lib}}\\bigg) = \\ldots = \\bigg(\\mu_{\\mathrm{Lib\\_Com}} - \\mu_{\\mathrm{None}}\\bigg) = 0\n\\end{split}\n\\]\nNote that the only way for each of these differences to be 0 is if all the means for every news source are equal. This implies that we could also write the model-level null hypothesis as:\n\\[\nH_0: \\mu_{\\mathrm{All}} = \\mu_{\\mathrm{Con}} = \\mu_{\\mathrm{Com}} = \\mu_{\\mathrm{Lib}} = \\mu_{\\mathrm{Con\\_Com}} = \\mu_{\\mathrm{Con\\_Lib}} = \\mu_{\\mathrm{Lib\\_Com}} = \\mu_{\\mathrm{None}}\n\\]\nThis is the same null hypothesis that is associated with the one-factor analysis of variance.\nFitting a regression model with dummy-coded indicator variables gives the exact same results as carrying out a one-factor ANOVA. The difference is that the output from the multiple regression gives \\(\\beta\\)-terms associated with mean differences (to the reference group), and ANOVA is concerned more directly with the group means. But the model-level regression results are identical to those from the ANOVA. Asking whether the model explains variation in the outcome (\\(H_0:\\rho^2=0\\)) is the same as asking whether there are mean differences (\\(H_0: \\mu_{\\mathrm{Two\\mbox{-}Parent}} = \\mu_{\\mathrm{Parent/Guardian}} = \\mu_{\\mathrm{One\\mbox{-}Parent}}\\)); these are just different ways of writing the model-level null hypothesis!",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html#does-news-source-predict-variation-in-news-knowledge-after-accounting-for-other-covariates",
    "href": "05-02-polychotomous-predictors.html#does-news-source-predict-variation-in-news-knowledge-after-accounting-for-other-covariates",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "19.6 Does News Source Predict Variation in News Knowledge After Accounting for Other Covariates?",
    "text": "19.6 Does News Source Predict Variation in News Knowledge After Accounting for Other Covariates?\nOne question we may have is whether the differences we saw in Americans‚Äô average news knowledge persist after we account for other covariates that also explain differences in news knowledge (e.g., age, education, amount of news consumed, and political engagement). To evaluate this, we will fit a regression model that includes these covariates, along with seven of the eight dummy-coded news source predictors to explain variability in news knowledge.\n\n# News source = None is reference group\nlm.none.2 = lm(knowledge ~ 1 + age + education + news + engagement + all + con + \n                 com + lib + con_com + con_lib + lib_com, data = pew)\n\n# Model-level info\nglance(lm.none.2) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     0.359         0.354  18.4      75.8 3.13e-135    11 -6502. 13030. 13099.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1  505985.        1490  1502\n\n\nAt the model-level, differences in news source, age, education level, amount of news consumption, and political engagement explain 35.9% of the variation in American‚Äôs news knowledge. This is statistically discernible from 0 (i.e., the empirical data are not consistent with the hypothesis that this set of predictors does not explain any variation in Americans‚Äô news knowledge), \\(F(11,1490)=75.80\\), \\(p&lt;.001\\).\n\ntidy(lm.none.2)\n\n\n  \n\n\n\nThe fitted regression equation is\n\\[\n\\begin{split}\n\\hat{\\mathrm{Knowledge}_i} = &-29.0 + 0.2(\\mathrm{Age}_i) + 3.3(\\mathrm{Education}_i) + 0.2(\\mathrm{News~Consumption}_i) + 0.2(\\mathrm{Engagement}_i) +\\\\\n& 4.2(\\mathrm{All}_i) + 1.4(\\mathrm{Con}_i) +  8.8(\\mathrm{Com}_i) + 6.7(\\mathrm{Lib}_i) + 8.2(\\mathrm{Con\\_Com}_i) +\\\\\n&0.2(\\mathrm{Con\\_Lib}_i) + 16.1(\\mathrm{Lib\\_Com}_i)\n\\end{split}\n\\]\nThe interpretations are provided below. While we offer them for the four covariates, we note that the only interpretations that we care about are those for our focal predictors of news source.\nIntercept and Covariates\n\nThe average news knowledge score for Americans who have no news source, are 0 years old, have 0 years of education, have no news exposure, and are not politically engaged is -29.0 (extrapolation).\nEach one-year difference in age is associated with a 0.2-point difference in news knowledge score, on average, after controlling for the other predictors in the model.\nEach one-year difference in education is associated with a 3.3-point difference in news knowledge score, on average, after controlling for the other predictors in the model.\nEach one-unit difference in news consumption is associated with a 0.2-point difference in news knowledge score, on average, after controlling for the other predictors in the model.\nEach one-unit difference in political engagement is associated with a 0.2-point difference in news knowledge score, on average, after controlling for the other predictors in the model.\n\nFocal Predictors\n\nAmericans who get their news from all three sources (conservative, comedy, and liberal) have a news knowledge score that is 4.19 points higher than Americans who have no news source, on average, after controlling for the other predictors in the model.\nAmericans who get their news from conservative sources have a news knowledge score that is 1.4 points higher than Americans who have no news source, on average, after controlling for the other predictors in the model.\nAmericans who get their news from comedy sources have a news knowledge score that is 8.8 points higher than Americans who have no news source, on average, after controlling for the other predictors in the model.\nAmericans who get their news from liberal sources have a news knowledge score that is 6.7 points higher than Americans who have no news source, on average, after controlling for the other predictors in the model.\nAmericans who get their news from conservative and comedy sources have a news knowledge score that is 8.2 points higher than Americans who have no news source, on average, after controlling for the other predictors in the model.\nAmericans who get their news from conservative and liberal sources have a news knowledge score that is 0.2 points higher than Americans who have no news source, on average, after controlling for the other predictors in the model.\nAmericans who get their news from liberal and comedy sources have a news knowledge score that is 16.1 points higher than Americans who have no news source, on average, after controlling for the other predictors in the model.\n\n\nAnother methodology you may have encountered in your statistics journey is analysis of covariance (ANCOVA). This method is often introduced as a way of testing mean differences while controlling for other covariates. Again, this is exactly what we are evaluating in the regression model when we included the covariates of age, education level, amount of news consumption, and political engagement. Just as you can carry out ANOVA using regression, you can also carry out an ANCOVA using regression.\n\n\n\n19.6.1 Adjusted Mean Differences and Adjusted Means\nThe mean differences we obtained from the regression model that included our covariates are referred to as controlled mean differences. In the language of ANCOVA, the controlled mean differences are referred to as Adjusted Mean Differences. To seperate this from the mean differences we obtained from the model with no covariates, we refer to those differences as Unadjusted Mean Differences.\nFor example, in the model that did not include any covariates (lm.none), the difference between the news knowledge scores for Americans who get their news from liberal and comedy sources and those that have no news source is 28.1 points. This is the unadjusted mean difference between these two groups of Americans. Once we account for differences explained by age, education level, amount of news consumption, and political engagement, the difference in news knowledge is 16.1 points. This is the controlled (or adjusted) mean difference between these two groups of Americans.\nThe unadjusted mean differences are based on the difference between the unadjusted means. That is we computed the means for the two groups and then computed the difference between them. Earlier we found that the mean news knowledge score for Americans who get their news from liberal and comedy sources was 76.8 and that fr Americans that have no news source was 48.7. The difference (unadjusted mean difference) is \\(76.8-48.7=28.1\\). This is exactly the value that the unadjusted regression model (i.e., the model with no covariates) produces.\nSimilarly, the adjusted mean differences are based on the difference between the adjusted means. So how do we compute the adjusted means? Remember that the predicted values from regression models are means. The predicted values from the unadjusted regression model produces unadjusted means, and the predicted values from the adjusted regression model (i.e., the model with covariates) produces adjusted means. So we need to substitute values into our fitted equation to produce the predicted news knowledge values for each of the different news sources.\nFor the news source predictors we will substitute 0 or 1 into each of the predictors based on the news source we are computing the adjusted mean for. For the covariates, we can use any value we want, but it is typical to substitute the mean values of the covariates when computing adjusted means. Below we compute the adjusted means for each news source.\n\nNoneAllConservativeComedyLiberalConservative and ComedyConservative and LiberalLiberal and Comedy\n\n\n\n# Mean age = 50.94\n# Mean education = 13.95\n# Mean news consumption = 50.27\n# Mean political engagement = 73.41\n\n# Compute adjusted mean for none source\n-29.0 + 0.2*50.94 + 3.3*13.95 + 0.2*50.27 + 0.2*73.41 + \n  4.2*0 + 1.4*0 +  8.8*0 + 6.7*0 + 8.2*0 + 0.2*0 + 16.1*0\n\n[1] 51.959\n\n\n\n\n\n# Mean age = 50.94\n# Mean education = 13.95\n# Mean news consumption = 50.27\n# Mean political engagement = 73.41\n\n# Compute adjusted mean for all source\n-29.0 + 0.2*50.94 + 3.3*13.95 + 0.2*50.27 + 0.2*73.41 + \n  4.2*1 + 1.4*0 +  8.8*0 + 6.7*0 + 8.2*0 + 0.2*0 + 16.1*0\n\n[1] 56.159\n\n\n\n\n\n# Mean age = 50.94\n# Mean education = 13.95\n# Mean news consumption = 50.27\n# Mean political engagement = 73.41\n\n# Compute adjusted mean for conservative source\n-29.0 + 0.2*50.94 + 3.3*13.95 + 0.2*50.27 + 0.2*73.41 + \n  4.2*0 + 1.4*1 +  8.8*0 + 6.7*0 + 8.2*0 + 0.2*0 + 16.1*0\n\n[1] 53.359\n\n\n\n\n\n# Mean age = 50.94\n# Mean education = 13.95\n# Mean news consumption = 50.27\n# Mean political engagement = 73.41\n\n# Compute adjusted mean for comedy source\n-29.0 + 0.2*50.94 + 3.3*13.95 + 0.2*50.27 + 0.2*73.41 + \n  4.2*0 + 1.4*0 +  8.8*1 + 6.7*0 + 8.2*0 + 0.2*0 + 16.1*0\n\n[1] 60.759\n\n\n\n\n\n# Mean age = 50.94\n# Mean education = 13.95\n# Mean news consumption = 50.27\n# Mean political engagement = 73.41\n\n# Compute adjusted mean for liberal source\n-29.0 + 0.2*50.94 + 3.3*13.95 + 0.2*50.27 + 0.2*73.41 + \n  4.2*0 + 1.4*0 +  8.8*0 + 6.7*1 + 8.2*0 + 0.2*0 + 16.1*0\n\n[1] 58.659\n\n\n\n\n\n# Mean age = 50.94\n# Mean education = 13.95\n# Mean news consumption = 50.27\n# Mean political engagement = 73.41\n\n# Compute adjusted mean for conservative and comedy source\n-29.0 + 0.2*50.94 + 3.3*13.95 + 0.2*50.27 + 0.2*73.41 + \n  4.2*0 + 1.4*0 +  8.8*0 + 6.7*0 + 8.2*1 + 0.2*0 + 16.1*0\n\n[1] 60.159\n\n\n\n\n\n# Mean age = 50.94\n# Mean education = 13.95\n# Mean news consumption = 50.27\n# Mean political engagement = 73.41\n\n# Compute adjusted mean for conservative and liberal source\n-29.0 + 0.2*50.94 + 3.3*13.95 + 0.2*50.27 + 0.2*73.41 + \n  4.2*0 + 1.4*0 +  8.8*0 + 6.7*0 + 8.2*0 + 0.2*1 + 16.1*0\n\n[1] 52.159\n\n\n\n\n\n# Mean age = 50.94\n# Mean education = 13.95\n# Mean news consumption = 50.27\n# Mean political engagement = 73.41\n\n# Compute adjusted mean for liberal and comedy source\n-29.0 + 0.2*50.94 + 3.3*13.95 + 0.2*50.27 + 0.2*73.41 + \n  4.2*0 + 1.4*0 +  8.8*0 + 6.7*0 + 8.2*0 + 0.2*0 + 16.1*1\n\n[1] 68.059\n\n\n\n\n\nHere we present the adjusted mean news knowledge scores in diminishing order. (In a manuscript these are often presented, along with the unadjusted means, in a table.)\n\nLiberal and Comedy: 68.06\nComedy: 60.76\nConservative and Comedy: 60.16\nLiberal: 58.66\nAll: 56.16\nConservative: 53.36\nConservative and Liberal: 52.16\nNone: 51.96\n\nUsing these, we can compute the adjusted mean differences. For example the adjusted mean difference between Americans who get their news from liberal and comedy sources and Americans who have no news source is \\(68.06-51.96=16.1\\). This is, again, exactly the value that the adjusted regression model (i.e., the model with covariates) produces as a coefficient.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html#obtaining-the-other-adjusted-pairwise-comparisons",
    "href": "05-02-polychotomous-predictors.html#obtaining-the-other-adjusted-pairwise-comparisons",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "19.7 Obtaining the Other Adjusted Pairwise Comparisons",
    "text": "19.7 Obtaining the Other Adjusted Pairwise Comparisons\nHere we will fit several other models (using the same set of covariates) to obtain the remaining adjusted pairwise comparisons. We will use these results to build another visualization presenting the adjusted mean values and the adjusted comparisons.\n\nI will enter the news source predictors in the model in order from largest to smallest adjusted mean values. While the order is irrelevant to obtaining the results, it will be easier to construct our visualization since the predictor order will math the order they are included in the visualization.\n\n\nLiberal and ComedyComedyConservative and ComedyLiberalAllConservativeConservative and LiberalNone\n\n\n\n# News source = Liberal and Comedy is reference group\nlm.lib_com.2 = lm(knowledge ~ 1 + age + education + news + engagement + com + con_com + lib + all + \n                    con + con_lib + none, data = pew)\n\n# Coefficient-level output\ntidy(lm.lib_com.2)\n\n\n  \n\n\n\n\n\n\n# News source = Comedy is reference group\nlm.com.2 = lm(knowledge ~ 1 + age + education + news + engagement + lib_com + con_com + lib + all + \n                    con + con_lib + none, data = pew)\n\n# Coefficient-level output\ntidy(lm.com.2)\n\n\n  \n\n\n\n\n\n\n# News source = Conservative and Comedy is reference group\nlm.con_com.2 = lm(knowledge ~ 1 + age + education + news + engagement + lib_com + com + lib + all + \n                    con + con_lib + none, data = pew)\n\n# Coefficient-level output\ntidy(lm.con_com.2)\n\n\n  \n\n\n\n\n\n\n# News source = Liberal is reference group\nlm.lib.2 = lm(knowledge ~ 1 + age + education + news + engagement + lib_com + com + con_com + all + \n                    con + con_lib + none, data = pew)\n\n# Coefficient-level output\ntidy(lm.lib.2)\n\n\n  \n\n\n\n\n\n\n# News source = all is reference group\nlm.all.2 = lm(knowledge ~ 1 + age + education + news + engagement + lib_com + com + con_com + lib + \n                    con + con_lib + none, data = pew)\n\n# Coefficient-level output\ntidy(lm.all.2)\n\n\n  \n\n\n\n\n\n\n# News source = conservative is reference group\nlm.con.2 = lm(knowledge ~ 1 + age + education + news + engagement + lib_com + com + con_com + lib + \n                    all + con_lib + none, data = pew)\n\n# Coefficient-level output\ntidy(lm.con.2)\n\n\n  \n\n\n\n\n\n\n# News source = conservative and liberal is reference group\nlm.con_lib.2 = lm(knowledge ~ 1 + age + education + news + engagement + lib_com + com + con_com + lib + \n                    all + con + none, data = pew)\n\n# Coefficient-level output\ntidy(lm.con_lib.2)\n\n\n  \n\n\n\n\n\n\n# News source = conservative and liberal is reference group\nlm.none.2 = lm(knowledge ~ 1 + age + education + news + engagement + lib_com + com + con_com + lib + \n                    all + con + con_lib, data = pew)\n\n# Coefficient-level output\ntidy(lm.none.2)\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†19.7: Pairwise comparisons of adjusted mean news knowledge for different news sources. Means were adjusted for differences in age, education level, amount of news consumed, and political engagement. Instructions: Read across the row for a news sources to compare adjusted mean news knowledge with the news sources listed along the top of the chart. The symbols indicate whether the adjusted mean news knowledge of the news source in the row is significantly lower than that of the comparison news source, significantly higher than that of the comparison news source, or if there is no statistically discernible difference between the adjusted mean news knowledge of the two news sources.\n\n\n\n\n\nComparing the adjusted pairwise comparisons presented in Figure¬†19.7 and the unadjusted pairwise comparisons presented in Figure¬†19.63, we observe several things:\n\nThe level of news knowledge (i.e., the mean) for the groups changed once we adjusted for our set of covariates.\nBased on the adjusted means, the order of the groups (when we rank them from largest to smallest amount of news knowledge) also changed.\nUsing the unadjusted means, we observed statistically discernible differences in 18 of the 28 paired comparisons. But, after controlling for our set of covariates, we now only observe statistically discernible differences in 15 of the 28 paired comparisons. (This suggests that in those 3 comparisons the reason we were observing differences in news knowledge was not really the source of news, but because those groups differed in age, education level, amount of news consumption, or political engagement.)",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html#optional-another-visualizationconfidence-intervals-for-adjusted-means",
    "href": "05-02-polychotomous-predictors.html#optional-another-visualizationconfidence-intervals-for-adjusted-means",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "19.8 Optional: Another Visualization‚ÄîConfidence Intervals for Adjusted Means",
    "text": "19.8 Optional: Another Visualization‚ÄîConfidence Intervals for Adjusted Means\nOne other common method for visually presenting the results from group comparisons is to produce confidence intervals for the adjusted means and then plot those for each group. To do this we are going to create a data frame that we can use (along with a fitted model) to produce adjusted means and standard errors for those means. We will use the fitted model lm.none.2 to produce the adjusted means and standard errors. As a reminder, the syntax for producing lm.none.2 was:\n\n# News source = None is reference group\nlm.none.2 = lm(knowledge ~ 1 + age + education + news + engagement + all + con + \n                 com + lib + con_com + con_lib + lib_com, data = pew)\n\nThe data frame we will create needs to have the values that we will be substituting into the fitted equation to get the adjusted mean values. Each row in the data frame will correspond to a person from a particular group (American who gets their news from a particular news source). Because we have 8 news sources, there will be 8 rows in the data frame. Each column will correspond to a different predictor from the fitted lm(). In our case, since we will be using lm.none.2 to produce the adjusted means, we would need 11 columns. Here is the syntax to create our data frame.\n\nd = data.frame(\n  age        = 50.94,\n  education  = 13.95,\n  news       = 50.27,\n  engagement = 73.41,\n  all        = c(0, 1, 0, 0, 0, 0, 0, 0),\n  con        = c(0, 0, 1, 0, 0, 0, 0, 0),\n  com        = c(0, 0, 0, 1, 0, 0, 0, 0),\n  lib        = c(0, 0, 0, 0, 1, 0, 0, 0), \n  con_com    = c(0, 0, 0, 0, 0, 1, 0, 0),\n  con_lib    = c(0, 0, 0, 0, 0, 0, 1, 0),\n  lib_com    = c(0, 0, 0, 0, 0, 0, 0, 1)\n)\n\n# View d\nd\n\n\n  \n\n\n\nAnd, here are some tips for creating the data frame:\n\nRemember that the data.frame() function defines columns in the data frame.\nThe column names in the data frame have to match the predictor names in the lm() exactly.\n\nThe column names should be given in the same order as the predictors in the lm(). (While this isn‚Äôt strictly necessary it will help to keep things organized.)\n\nEach column will include 8 values (one value for each row).\nThe columns names that are covariates will be set equal to a single value, namely the mean of that covariate. You could also give this a vector and repeat the same value 8 times, but R will do this automatically.\nThe column names corresponding to each of the groups (i.e., our focal dummy variables) will be given a vector of eight values (one for each group we have).\n\nThese eight values will all be 0s except for one value which will be 1.\nThe key is that each value from the vector will be put in a different row, and each row needs to correspond to the dummy coding associated with one of the groups.\n\n\nEach row in d represents an American who gets there news from each of the eight news sources. Notice that the dummy coding in each row corresponds to a particular group. For example, the dummy coding in Row 1 corresponds to the ‚ÄòNone‚Äô group, while that in Row 2 corresponds to the ‚ÄòConservative News‚Äô group.\n\nWhen you are creating your data frame, the vector values are filling a column, not a row. But, you need the dummy coding to correspond to rows. It can be helpful to sketch out the data frame on a piece of paper first, and then write the code to create that data frame. Always look at the resulting data you create to be sure it has the correct structure!\n\nOnce we have the data, we can use the predict() function to get predicted values (i.e., adjusted means) and standard errors. To do this, we give the function the name of the regression object we are using (lm.none.2). We also include the newdata= argument, which takes the name of the data frame we want to use for the predictions. Finally, we include se = TRUE to output the standard errors.\n\n# Obtain adjusted means and standard errors for each row in d\npredict(lm.none.2, newdata = d, se = TRUE)\n\n$fit\n       1        2        3        4        5        6        7        8 \n54.44942 58.64027 55.83410 63.25640 61.16513 62.60476 54.67625 70.56547 \n\n$se.fit\n        1         2         3         4         5         6         7         8 \n0.9739073 2.3062504 0.9757177 2.8935646 1.3579693 2.3997123 1.4044781 2.4375348 \n\n$df\n[1] 1490\n\n$residual.scale\n[1] 18.4279\n\n\nThe adjusted mean values are provided in the $fit part of the output. There should be 8 values, one for each row in d. So the first fitted value (54.44942) is the adjusted mean for the first row in d, which corresponds to the ‚ÄòNone‚Äô group.4 Similarly there are 8 standard errors (in the $se.fit part of the output), each corresponding to a row in d. So the SE for the ‚ÄòNone‚Äô group is 0.9739073.\nWe are going to create a second data frame that includes the 8 group names (based on the order in d), the adjusted mean values, and the SEs. This will be the data that we use to create our plot of the CIs.\n\n# Create data frame\nplot_data = data.frame(\n  source = c(\"None\", \"All\", \"Conservative\", \"Comedy\", \"Liberal\", \"Conservative and Comedy\", \n             \"Conservative and Liberal\", \"Liberal and Comedy\"),\n  m = c(54.44942, 58.64027, 55.83410, 63.25640, 61.16513, 62.60476, 54.67625, 70.56547),\n  se = c(0.9739073, 2.3062504, 0.9757177, 2.8935646, 1.3579693, 2.3997123, 1.4044781, 2.4375348)\n)\n\n# View data\nplot_data\n\n\n  \n\n\n\nNow, we need to create the lower and upper limits of the CI as new columns in the data frame. To do this, recall that the formula for creating a CI is:\n\\[\n\\mathrm{CI} = \\mathrm{Estimate} \\pm t^*(\\mathrm{SE})\n\\]\nwhere the estimate in our example is the adjusted mean, SE is the standard error, and \\(t^*\\) is a multiplier value based on the residual degrees of freedom for the regression model.5 To determine \\(t^*\\), we are going to use the qt() function. This function takes two arguments:\n\nThe first argument is a value between 0 and 1 that corresponds to the confidence level you want. For a 95% CI this value will be 0.975.6\nThe second argument, df=, provides the residual degrees-of-freedom for the regression model. (Note this is also given in the predict() output.)\n\n\n# Compute t-star\nqt(.975, df = 1490)\n\n[1] 1.961557\n\n\nNow we can mutate() on the lower and upper limits of the CI for each adjusted mean.\n\n# Compute CI limits\nplot_data = plot_data |&gt;\n  mutate(\n    lower = m - 1.961557*se,\n    upper = m + 1.961557*se\n  )\n\n# View data\nplot_data\n\n\n  \n\n\n\nLastly, we can create our visualization of the CIs.\n\n# Create plot\nggplot(data = plot_data, aes(x = m, y = source)) +\n  #Create CI\n  geom_segment( \n    aes(x = lower, y = source, xend = upper, yend = source),\n    color = \"#ff2f92\",\n    linewidth = 1.5\n    ) + \n  #Add adjusted mean\n  geom_point( \n    size = 3,\n    color = \"#ff2f92\"\n    ) + \n  theme_minimal() +\n  xlab(\"Adjusted mean news knowledge score\") +\n  ylab(\"News source(s)\") +\n  xlim(50, 80)\n\n\n\n\n\n\n\nFigure¬†19.8: 95% confidence intervals for the adjusted mean news knowledge scores for Americans who get their news from eight different sources. The means are adjusted for differences in age, education level, amount of news consumed, and political engagement.\n\n\n\n\n\nIntervals that overlap indicate that those groups are not different in their adjusted mean scores. For example, the ‚ÄòNone‚Äô group and the ‚ÄòConservative and Liberal‚Äô intervals overlap each other. This suggests that their adjusted mean news knowledge scores might be the same (no statistical difference is discernible).",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-02-polychotomous-predictors.html#footnotes",
    "href": "05-02-polychotomous-predictors.html#footnotes",
    "title": "19¬† Polychotomous Categorical Predictors",
    "section": "",
    "text": "In a balanced sample, the sample size would be equal across categories. This typically happens only when participants are randomly assigned to levels of the categorical predictor. Almost all observational data is unbalanced.‚Ü©Ô∏é\nSince the columns conservative_news, liberal_news and comedy_news already exist in the data, and they are dummy variables, you would onlyneed to create the five other dummy variables. Here we create all eight for completeness.‚Ü©Ô∏é\nBe careful as the order of groups in the visualization is different in the two visualizations!‚Ü©Ô∏é\nNote that these values are what we obtained for the adjusted means within rounding.‚Ü©Ô∏é\nWe often use \\(t^*=2\\) when we want a rough estimate.‚Ü©Ô∏é\nWe can compute this as \\(1 - \\bigg(\\frac{1 -\\mathrm{Conf.~Level}}{2}\\bigg)\\). IN our exampe, for a 95% CI, \\(1 - \\bigg(\\frac{1 -0.95}{2}\\bigg) = 0.975\\).‚Ü©Ô∏é",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Polychotomous Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "05-03-multiple-comparisons.html",
    "href": "05-03-multiple-comparisons.html",
    "title": "20¬† Multiple Comparisons",
    "section": "",
    "text": "20.1 \\(\\alpha\\)-Level and Errors\nRecall that when we evaluated the difference between each pair of news sources, we did so by comparing the p-value to our \\(\\alpha\\)-level of 0.05. Remember also that the alpha-value is determined by the researcher and determines the Type I error rate for the study, where a Type I error is the probability of rejecting the null hypothesis if it is really true. In our study, this would mean we claim there is a difference in news knowledge between two news sources, but there really isn‚Äôt.\nRemembering Type I and II errors‚Ä¶simplified by Flowing Data.\nOne way to think about a Type I error is that it represents a false discovery. The data have mislead the researcher into saying there is an effect when in fact there isn‚Äôt. When we use an \\(alpha\\)-level of 0.05, we are saying that we are OK making a false discovery in 5% of the hypothesis tests we will ever evaluate.\nImagine a researcher who evaluates 1000 hypothesis tests during their career. Let‚Äôs imagine also that this researcher always does a sample size analysis prior to every research project and always has a large enough sample size to have statistical power of 0.8, a commonly used value in the social and educational sciences. (That is they would be able to detect a true effect 80% of the time that there actually is an effect.) Lastly, let‚Äôs assume that half of all the hypothesis that this research evaluates are in reality true1. If this researcher always used an \\(alpha\\)-value of 0.05, then:\nThink of how many hypothesis tests you will carry out in your career, it will likely be more than 1000, and 5% of those will be false discoveries! This is alarming, but is expected when we use an \\(alpha\\)-value of 0.05. What is more alarming is that if you only consider the 450 ‚Äúpublishable‚Äù hypotheses (i.e., those for which you found an effect, including the false discoveries), the false positive rate is about 11%. This is much higher than the advertised 5% rate.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Multiple Comparisons</span>"
    ]
  },
  {
    "objectID": "05-03-multiple-comparisons.html#alpha-level-and-errors",
    "href": "05-03-multiple-comparisons.html#alpha-level-and-errors",
    "title": "20¬† Multiple Comparisons",
    "section": "",
    "text": "Of the 1000 tests, they would be able to detect 400 true effects which could be written about in manuscripts.\nOf the 1000 tests, they would make 50 false discoveries‚Äîthat is they would publish about a false claim 50 times in their career.\n\n\n\n\n20.1.1 Multiple Tests on the Same Data\nWhen a researcher carries out multiple hypothesis tests on the same data, it turns out that the probability of making false discoveries gets higher than value we set for \\(\\alpha\\). This is especially problematic when researchers are coming at the data without any a priori hypotheses to be tested, which are generally based on relationships identified in the theoretical literature. Statisticians refer to this as taking an Exploratory Approach with hypothesis testing.2 Another way to think about the exploratory approach is that the researcher is ‚Äúdata dredging‚Äù‚Äîthey are testing a lot of different effects to see what pops.\nAnother common situation in which the probability of making false discoveries gets higher than value we set for \\(\\alpha\\) is when researchers have multiple groups that they are testing differences between. This is exactly the situation we have in our news knowledge study! In our study we had eight different groups that we were evaluating differences between. Having multiple groups that you are comparing leads to higher than specified rates of false discovery regardless of whether the approach is exploratory or confirmatory.\nWhalley (2018) offers a nice metaphor about buying lottery tickets to help you understand why testing differences between multiple groups increases the number of false discoveries. He writes, ‚Äúif you buy more tickets you have a larger change of winning a prize. [For example], with three comparisons between the groups (tickets) we have a 15% chance of winning a prize, rather than the 5% we intended.‚Äù That is, mathematically, we can think about the false positive rate as a function of the number of hypothesis tests you conduct. Specifically,\n\\[\n\\mathrm{False~Positive~Rate} = (\\mathrm{Number~of~Tests~Evaluated}) \\times 0.05\n\\]\nIf you were only doing one test, the false positive rate would be 0.05, our designated \\(\\alpha\\)-value. For three tests, the false positive rate would be \\(3\\times.05=.15\\), much higher than the designated \\(\\alpha\\)-value. For our news knowledge example, we carried out 28 tests. The false positive rate in our study is \\(28\\times.05&gt;1\\); that is we are essentially guaranteed to have at least one false discovery!",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Multiple Comparisons</span>"
    ]
  },
  {
    "objectID": "05-03-multiple-comparisons.html#fixing-the-problem",
    "href": "05-03-multiple-comparisons.html#fixing-the-problem",
    "title": "20¬† Multiple Comparisons",
    "section": "20.2 Fixing the Problem",
    "text": "20.2 Fixing the Problem\nThere are two approaches to fixing this problem: (1) controlling for the familywise error rate, and (2) controlling for the false discovery rate. Both of these methods, in practice, involve penalizing the size of the p-value (making it bigger) based on the number of tests you are evaluating. We refer to this as ‚Äúadjusting the \\(p\\)-values‚Äù.\n\n\n20.2.1 Controlling the Family-Wise Error Eate\nThe first approach for adjusting \\(p\\)-values is to control for the familywise error rate. The familywise-error rate is defined as the probability of making AT LEAST ONE Type I Error in all of the hypothesis tests that you are evaluating. As an example consider a situation in which we were conducting hypothesis tests to evaluate pairwise differences in three groups, A, B, and C. We would be carrying out the following hypothesis tests:\n\nHypothesis Test 1: A vs.¬†B\nHypothesis Test 2: A vs.¬†C\nHypothesis Test 3: B vs.¬†C\n\nYou could make a Type I error in HT 1, in HT 2, or in HT 3, respectively. You could also make a Type I error in HT 1 and HT 2, but not in HT 3. Or, you could make a Type I error in HT 1 and HT 3, but not in HT 2. Or, you could make a Type I error in HT 2 and HT 3, but not in HT 1. Or, you could make a Type I error in all three tests! In controlling for family-wise error, we would want the total error rate across all of those possibilities to be no more than our \\(\\alpha\\)-value (We would refer to this as the family-wise \\(\\alpha\\)-value or \\(\\alpha_{\\mathrm{FW}}\\)). Mathematically,\n\\[\n\\begin{split}\n\\alpha_{\\mathrm{FW}} = P\\biggl(\\mathrm{Type~I~error~in~}&(\\mathrm{HT1}) \\lor (\\mathrm{HT2}) \\lor (\\mathrm{HT3}) \\lor \\\\\n&(\\mathrm{HT1~and~HT2}) \\lor (\\mathrm{HT1~and~HT3}) \\lor (\\mathrm{HT2~and~HT3}) \\lor \\\\\n&(\\mathrm{HT1~and~HT2~and~HT3})\\biggr)\n\\end{split}\n\\]\nMost social and educational scientists who take this approach set their family-wise error rate to 0.05.\n\n\n20.2.1.1 Dunn-Bonferroni Adjustments\nAn Italian mathematician named Carlo Emilio Bonferroni generalized a finding from probability theory (Boole‚Äôs inequality) to determine the upper bound on making a Type I error in k tests (Dunn, 1961). (k here refers to the number of tests.) Statistician Olive Jean Dunn developed the mathematical details of using Bonferroni‚Äôs results and was the first to apply them to the problem of multiple comparisons. This inequality is:\n\\[\nP(\\mathrm{Type~I~error}) &lt; 1 - (1 - \\alpha_{\\mathrm{PC}})^k\n\\]\nwhere \\(\\alpha_{\\mathrm{PC}}\\) is the alpha level for each test (the per-comparison alpha value), and k is the number of tests (comparisons) for the effect. This is where the shortcut of multiplying the number of tests by the \\(\\alpha\\)-level comes from; it is an approximation for this inequality. That is,\n\\[\n1 - (1 - \\alpha_{\\mathrm{PC}})^k \\approx k \\times \\alpha_{\\mathrm{PC}}\n\\]\nThat means, if we want our family-wise error rate to be 0.05, we can set this to be equal to 0.05 and solve for the \\(\\alpha_{\\mathrm{PC}}\\) based on the number of tests be evaluated. In our news knowledge example, there are 28 different tests we are evaluating. So to determine the per-comparison alpha value, we would need to solve the following:\n\\[\n\\begin{split}\n28 \\times \\alpha_{\\mathrm{PC}} &= 0.05 \\\\[2ex]\n\\alpha_{\\mathrm{PC}} &= \\frac{0.05}{28} \\\\[2ex]\n&= 0.001785714\n\\end{split}\n\\] That is, rather than comparing the p-value we got to 0.05, we should have been comparing the p-value to 0.001785714.\nIn practice, we don‚Äôt adjust the \\(alpha\\)-value, but instead adjust the p-value. The easiest way to make these adjustments is to multiply each p-value for the group comparisons by the number of tests being evaluated. If we have k tests, then:\n\\[\np_{\\mathrm{Adjusted}}=p_{\\mathrm{Original}} \\times k\n\\]\nIn our example,\n\\[\np_{\\mathrm{Adjusted}}=p_{\\mathrm{Original}} \\times 28\n\\]\n\nThis p-value adjustment is referred to as the Dunn-Bonferroni adjustment.3\n\nConsider the 28 p-values for our pairwise comparisons of news knowledge from the model that included covariates (from lm.none.2). To compute the Dunn-Bonferroni adjusted p-values for these comparisons, we could use the followwing syntax.\n\nc(\n  0.2170, #All vs. Comedy                              \n  0.2550, #All vs. Conservative                        \n  0.2209, #All vs. Conservative_Comedy                 \n  0.1142, #All vs. Conservative_Liberal                \n  0.3514, #All vs. Liberal                             \n  0.0003, #All vs. Liberal_Comedy                      \n  0.1158, #All vs. None                                \n  0.0155, #Comedy vs. Conservative                     \n  0.8630, #Comedy vs. Conservative_Comedy              \n  0.0084, #Comedy vs. Conservative_Liberal             \n  0.5109, #Comedy vs. Liberal                          \n  0.0536, #Comedy vs. Liberal_Comedy                   \n  0.0037, #Comedy vs. None                             \n  0.0086, #Conservative vs. Conservative_Comedy        \n  0.4859, #Conservative vs. Conservative_Liberal       \n  0.0016, #Conservative vs. Liberal                    \n  0.0000000289, #Conservative vs. Liberal_Comedy             \n  0.3307, #Conservative vs. None                       \n  0.0033, #Conservative_Comedy vs. Conservative_Liberal\n  0.6060, #Conservative_Comedy vs. Liberal             \n  0.0190, #Conservative_Comedy vs. Liberal_Comedy      \n  0.0022, #Conservative_Comedy vs. None                \n  0.0012, #Conservative_Liberal vs. Liberal            \n  0.00000000826, #Conservative_Liberal vs. Liberal_Comedy     \n  0.9042, #Conservative_Liberal vs. None               \n  0.0008, #Liberal vs. Liberal_Comedy                  \n  0.0000477, #Liberal vs. None                            \n  0.00000000284  #Liberal_Comedy vs. None                     \n  ) * 28\n\n [1]  6.07600000000  7.14000000000  6.18520000000  3.19760000000  9.83920000000\n [6]  0.00840000000  3.24240000000  0.43400000000 24.16400000000  0.23520000000\n[11] 14.30520000000  1.50080000000  0.10360000000  0.24080000000 13.60520000000\n[16]  0.04480000000  0.00000080920  9.25960000000  0.09240000000 16.96800000000\n[21]  0.53200000000  0.06160000000  0.03360000000  0.00000023128 25.31760000000\n[26]  0.02240000000  0.00133560000  0.00000007952\n\n\nWe can compare these adjusted p-values to 0.05 to evaluate whether groups differ in their average news knowledge. There are now far fewer groups that differ in their average news knowledge.\n\nAll vs.¬†Liberal_Comedy (\\(p=.008\\))\nConservative vs.¬†Liberal (\\(p=.045\\))\nConservative vs.¬†Liberal_Comedy (\\(p&lt;.001\\))\nConservative_Liberal vs.¬†Liberal (\\(p=.034\\))\nConservative_Liberal vs.¬†Liberal_Comedy (\\(p&lt;.001\\))\nLiberal vs.¬†Liberal_Comedy (\\(p=.022\\))\n\nLiberal vs.¬†None (\\(p=.001\\))\n\nLiberal_Comedy vs.¬†None (\\(p&lt;.001\\))\n\nOf the 28 comparisons, we found only 8 statistically discernible differences. Compare this to the 15 statistically discernible differences we found when we used the unadjusted p-values (in the previous chapter). This means that 7 of those previous findings were likely false discoveries!\n\nIn practice, since p-values have limits of 0 and 1, any adjusted p-value that exceeds 1 we limit to 1 when we report them.\n\n\n\n\n20.2.1.2 Obtaining the Dunn-Bonferroni p-Values Directly\nIn practice, you are not going to list all of the unadjusted p-values in a vector and multiply by k. Instead, we are going to use the emmeans() function from the {emmeans} package to obtain the Dunn-Bonferroni p-values. This argument takes three arguments:\n\nThe name of a model object that has been fitted using a true categorical predictor in the lm() function (not with dummy variables).\nThe argument specs=pairwise ~predictor (where predictor is the name of the categorical predictor on which you want to do pairwise comparisons).\nThe argument adjust= which takes a character string that specifies the adjustment method to use.\n\nThe first thing we need to do, is re-fit the model using the actual categorical predictor (news_source) rather than the dummy variables.\n\n# Fit model using categorical predictor\nlm.news_source = lm(knowledge ~ 1 + age + education + news + engagement + news_source, data = pew)\n\nWhen you use the categorical predictor (rather than the set of dummy variables), R will create the set of dummy variables for you. It will also choose the reference group for you. It does this alphabetically, so in our example, the reference group it will choose is ‚ÄúAll‚Äù. You can see this by looking at the coefficient-level output of the fitted model.\n\n# Coefficient-level output\ntidy(lm.news_source)\n\n\n  \n\n\n\nNow, we can use that model in our emmeans() function. Since we are interested in the pairwise comparisons between the different news sources, the second argument in the function will be specs = pairwise ~news_source. Before we make any adjustments, let‚Äôs double-check that the function works by having it compute the unadjusted p-values for the differences. To get the unadjusted differences we will use adjust=\"none\".\n\n# Obtain the unadjusted p-values for pairwise differences\nemmeans(lm.news_source, specs = pairwise ~news_source, adjust = \"none\")\n\n$emmeans\n news_source          emmean    SE   df lower.CL upper.CL\n All                    58.6 2.306 1490     54.1     63.2\n Comedy                 63.3 2.894 1490     57.6     68.9\n Conservative           55.8 0.976 1490     53.9     57.7\n Conservative_Comedy    62.6 2.400 1490     57.9     67.3\n Conservative_Liberal   54.7 1.404 1490     51.9     57.4\n Liberal                61.2 1.358 1490     58.5     63.8\n Liberal_Comedy         70.6 2.438 1490     65.8     75.3\n None                   54.5 0.974 1490     52.5     56.4\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                                   estimate   SE   df t.ratio p.value\n All - Comedy                                 -4.616 3.74 1490  -1.235  0.2170\n All - Conservative                            2.806 2.46 1490   1.139  0.2550\n All - Conservative_Comedy                    -3.964 3.24 1490  -1.225  0.2209\n All - Conservative_Liberal                    3.964 2.51 1490   1.581  0.1142\n All - Liberal                                -2.525 2.71 1490  -0.932  0.3514\n All - Liberal_Comedy                        -11.925 3.27 1490  -3.649  0.0003\n All - None                                    4.191 2.66 1490   1.573  0.1158\n Comedy - Conservative                         7.422 3.06 1490   2.423  0.0155\n Comedy - Conservative_Comedy                  0.652 3.78 1490   0.173  0.8630\n Comedy - Conservative_Liberal                 8.580 3.25 1490   2.639  0.0084\n Comedy - Liberal                              2.091 3.18 1490   0.658  0.5109\n Comedy - Liberal_Comedy                      -7.309 3.78 1490  -1.931  0.0536\n Comedy - None                                 8.807 3.03 1490   2.907  0.0037\n Conservative - Conservative_Comedy           -6.771 2.57 1490  -2.633  0.0086\n Conservative - Conservative_Liberal           1.158 1.66 1490   0.697  0.4859\n Conservative - Liberal                       -5.331 1.69 1490  -3.162  0.0016\n Conservative - Liberal_Comedy               -14.731 2.61 1490  -5.635  &lt;.0001\n Conservative - None                           1.385 1.42 1490   0.973  0.3307\n Conservative_Comedy - Conservative_Liberal    7.929 2.70 1490   2.941  0.0033\n Conservative_Comedy - Liberal                 1.440 2.79 1490   0.516  0.6060\n Conservative_Comedy - Liberal_Comedy         -7.961 3.39 1490  -2.349  0.0190\n Conservative_Comedy - None                    8.155 2.66 1490   3.070  0.0022\n Conservative_Liberal - Liberal               -6.489 1.99 1490  -3.254  0.0012\n Conservative_Liberal - Liberal_Comedy       -15.889 2.74 1490  -5.796  &lt;.0001\n Conservative_Liberal - None                   0.227 1.88 1490   0.120  0.9042\n Liberal - Liberal_Comedy                     -9.400 2.79 1490  -3.375  0.0008\n Liberal - None                                6.716 1.65 1490   4.078  &lt;.0001\n Liberal_Comedy - None                        16.116 2.70 1490   5.977  &lt;.0001\n\n\nThe output has two parts to it. In the first part ($emmeans) we are given the mean news knowledge for each news source. Because we used a model that included covariates, these are the covariate adjusted means. We are also provided the standard errors, and the confidence interval limits for those means. (We are also given the residual degrees-of-freedom used to create those intervals.) Note that these are the same confidence limits we used to create our plot of the CIs in the previous chapter!\nIn the second part of the output ($contrasts4), we are given each of the pairwise differences, as well as the SEs, t-values, and p-values associated with those differences. These are the same values we get from the lm() output. The nice thing is we are given all of the pairwise differences in an organized manner without having to fitt many different lm() models using differnt reference groups.\nTo obtain the Dunn-Bonferroni adjusted p-values, we will update the argument adjust= to adjust=\"bonferroni\".\n\n# Obtain the Dunn-Bonferroni adjusted p-values for pairwise differences\nemmeans(lm.news_source, specs = pairwise ~news_source, adjust = \"bonferroni\")\n\n$emmeans\n news_source          emmean    SE   df lower.CL upper.CL\n All                    58.6 2.306 1490     54.1     63.2\n Comedy                 63.3 2.894 1490     57.6     68.9\n Conservative           55.8 0.976 1490     53.9     57.7\n Conservative_Comedy    62.6 2.400 1490     57.9     67.3\n Conservative_Liberal   54.7 1.404 1490     51.9     57.4\n Liberal                61.2 1.358 1490     58.5     63.8\n Liberal_Comedy         70.6 2.438 1490     65.8     75.3\n None                   54.5 0.974 1490     52.5     56.4\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                                   estimate   SE   df t.ratio p.value\n All - Comedy                                 -4.616 3.74 1490  -1.235  1.0000\n All - Conservative                            2.806 2.46 1490   1.139  1.0000\n All - Conservative_Comedy                    -3.964 3.24 1490  -1.225  1.0000\n All - Conservative_Liberal                    3.964 2.51 1490   1.581  1.0000\n All - Liberal                                -2.525 2.71 1490  -0.932  1.0000\n All - Liberal_Comedy                        -11.925 3.27 1490  -3.649  0.0076\n All - None                                    4.191 2.66 1490   1.573  1.0000\n Comedy - Conservative                         7.422 3.06 1490   2.423  0.4348\n Comedy - Conservative_Comedy                  0.652 3.78 1490   0.173  1.0000\n Comedy - Conservative_Liberal                 8.580 3.25 1490   2.639  0.2352\n Comedy - Liberal                              2.091 3.18 1490   0.658  1.0000\n Comedy - Liberal_Comedy                      -7.309 3.78 1490  -1.931  1.0000\n Comedy - None                                 8.807 3.03 1490   2.907  0.1036\n Conservative - Conservative_Comedy           -6.771 2.57 1490  -2.633  0.2396\n Conservative - Conservative_Liberal           1.158 1.66 1490   0.697  1.0000\n Conservative - Liberal                       -5.331 1.69 1490  -3.162  0.0447\n Conservative - Liberal_Comedy               -14.731 2.61 1490  -5.635  &lt;.0001\n Conservative - None                           1.385 1.42 1490   0.973  1.0000\n Conservative_Comedy - Conservative_Liberal    7.929 2.70 1490   2.941  0.0929\n Conservative_Comedy - Liberal                 1.440 2.79 1490   0.516  1.0000\n Conservative_Comedy - Liberal_Comedy         -7.961 3.39 1490  -2.349  0.5313\n Conservative_Comedy - None                    8.155 2.66 1490   3.070  0.0611\n Conservative_Liberal - Liberal               -6.489 1.99 1490  -3.254  0.0326\n Conservative_Liberal - Liberal_Comedy       -15.889 2.74 1490  -5.796  &lt;.0001\n Conservative_Liberal - None                   0.227 1.88 1490   0.120  1.0000\n Liberal - Liberal_Comedy                     -9.400 2.79 1490  -3.375  0.0212\n Liberal - None                                6.716 1.65 1490   4.078  0.0013\n Liberal_Comedy - None                        16.116 2.70 1490   5.977  &lt;.0001\n\nP value adjustment: bonferroni method for 28 tests \n\n\nIn the $contrasts part of the output, the p-values shown are the Dunn-Bonferroni adjust p-values. . Note that the output in $emmeans section remains exactly the same as when we used adjust=\"none\". This is because the $emmeans section will always be the model predicted means from the fitted lm().\nWe can display the results of the Dunn-Bonferroni pairwise differences in a visualization similar to those we created previously. Figure¬†20.1 shows one such visualization. Note that the adjusted mean values have been updated based on the values from the $emmeans part of the output. (These values should be more exact as we rounded extensively in the computations of these values.)\n\n\n\n\n\n\n\n\nFigure¬†20.1: Pairwise comparisons of adjusted mean news knowledge for different news sources. Means were adjusted for differences in age, education level, amount of news consumed, and political engagement. Statistical comparisons have been adjusted for multiple comparisons using the Dunn-Bonferroni adjustment. Instructions: Read across the row for a news sources to compare adjusted mean news knowledge with the news sources listed along the top of the chart. The symbols indicate whether the adjusted mean news knowledge of the news source in the row is significantly lower than that of the comparison news source, significantly higher than that of the comparison news source, or if there is no statistically discernible difference between the adjusted mean news knowledge of the two news sources.\n\n\n\n\n\n\nThere are many other methods to control the familywise error rate. Some other popular methods include the Tukey adjustment (Tukey, 1949), the Scheff√© adjustment (Scheff√©, 1959), and the Holm adjustment (Holm, 1979). Each method gives different p-values based on the mathematics of the adjustments, but they are all pretty similar. The Dunn-Bonferroni method is the most popular method used in the educational and social sciences to control the familywise error rate.\n\n\n\n\n\n20.2.2 Controlling the False Discovery Rate\nThe second approach to adjusting p-values is to control for the false discovery rate. While controlling for the familywise error rate attends to controlling false discoveries, the disadvantage is that those methods increase the Type II error rate; that is they will increase the probability of incorrectly failing to reject the null hypothesis. This means that they will lead to neglecting to find differences that might be theoretically or clinically relevant. Controlling the false discovery rate rather than the familywise error rate attends to this by minimizing the number of false discoveries (Type I errors), while at the same time trying to avoid Type II errors.\n\n\n20.2.2.1 Benjamini-Hochberg Adjusments to the p-Values\nThe primary method for controlling the false discovery rate used in the social and educational sciences is the Benjamin-Hochberg adjustment to the p-values. To obtain these, we can use the same emmeans() function with the argument adjust=\"BH\".\n\n# Obtain the Benjamini-Hochberg adjusted p-values for pairwise differences\nemmeans(lm.news_source, specs = pairwise ~news_source, adjust = \"BH\")\n\n$emmeans\n news_source          emmean    SE   df lower.CL upper.CL\n All                    58.6 2.306 1490     54.1     63.2\n Comedy                 63.3 2.894 1490     57.6     68.9\n Conservative           55.8 0.976 1490     53.9     57.7\n Conservative_Comedy    62.6 2.400 1490     57.9     67.3\n Conservative_Liberal   54.7 1.404 1490     51.9     57.4\n Liberal                61.2 1.358 1490     58.5     63.8\n Liberal_Comedy         70.6 2.438 1490     65.8     75.3\n None                   54.5 0.974 1490     52.5     56.4\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                                   estimate   SE   df t.ratio p.value\n All - Comedy                                 -4.616 3.74 1490  -1.235  0.3093\n All - Conservative                            2.806 2.46 1490   1.139  0.3400\n All - Conservative_Comedy                    -3.964 3.24 1490  -1.225  0.3093\n All - Conservative_Liberal                    3.964 2.51 1490   1.581  0.1802\n All - Liberal                                -2.525 2.71 1490  -0.932  0.4278\n All - Liberal_Comedy                        -11.925 3.27 1490  -3.649  0.0015\n All - None                                    4.191 2.66 1490   1.573  0.1802\n Comedy - Conservative                         7.422 3.06 1490   2.423  0.0311\n Comedy - Conservative_Comedy                  0.652 3.78 1490   0.173  0.8950\n Comedy - Conservative_Liberal                 8.580 3.25 1490   2.639  0.0184\n Comedy - Liberal                              2.091 3.18 1490   0.658  0.5722\n Comedy - Liberal_Comedy                      -7.309 3.78 1490  -1.931  0.0939\n Comedy - None                                 8.807 3.03 1490   2.907  0.0094\n Conservative - Conservative_Comedy           -6.771 2.57 1490  -2.633  0.0184\n Conservative - Conservative_Liberal           1.158 1.66 1490   0.697  0.5669\n Conservative - Liberal                       -5.331 1.69 1490  -3.162  0.0056\n Conservative - Liberal_Comedy               -14.731 2.61 1490  -5.635  &lt;.0001\n Conservative - None                           1.385 1.42 1490   0.973  0.4208\n Conservative_Comedy - Conservative_Liberal    7.929 2.70 1490   2.941  0.0093\n Conservative_Comedy - Liberal                 1.440 2.79 1490   0.516  0.6526\n Conservative_Comedy - Liberal_Comedy         -7.961 3.39 1490  -2.349  0.0354\n Conservative_Comedy - None                    8.155 2.66 1490   3.070  0.0068\n Conservative_Liberal - Liberal               -6.489 1.99 1490  -3.254  0.0047\n Conservative_Liberal - Liberal_Comedy       -15.889 2.74 1490  -5.796  &lt;.0001\n Conservative_Liberal - None                   0.227 1.88 1490   0.120  0.9042\n Liberal - Liberal_Comedy                     -9.400 2.79 1490  -3.375  0.0035\n Liberal - None                                6.716 1.65 1490   4.078  0.0003\n Liberal_Comedy - None                        16.116 2.70 1490   5.977  &lt;.0001\n\nP value adjustment: BH method for 28 tests \n\n\nUsing this p-value adjustment method, we find 13 statistically discernible differences. These are displayed in Figure¬†20.2.\n\n\n\n\n\n\n\n\nFigure¬†20.2: Pairwise comparisons of adjusted mean news knowledge for different news sources. Means were adjusted for differences in age, education level, amount of news consumed, and political engagement. Statistical comparisons have been adjusted for multiple comparisons using the Benjamini-Hochberg adjustment. Instructions: Read across the row for a news sources to compare adjusted mean news knowledge with the news sources listed along the top of the chart. The symbols indicate whether the adjusted mean news knowledge of the news source in the row is significantly lower than that of the comparison news source, significantly higher than that of the comparison news source, or if there is no statistically discernible difference between the adjusted mean news knowledge of the two news sources.\n\n\n\n\n\nIf we compare the three sets of p-values, there are some things you can see:\n\nThe unadjusted p-values are the smallest. While you are more likely to ‚Äúfind‚Äù effects, some (or most) of these may be false discoveries.\nThe Dunn-Bonferroni adjusted p-values are the largest. Controlling for familywise error rates really protects against making Type I error. To do this it heavily penalizes the p-values (makes them larger).\nThe Benjamini-Hochberg adjusted p-values are somewhere between the unadjusted and Dunn-Bonferroni p-values. While this helps protect against false discoveries (they are larger than the unadjusted p-values so you are less likely to find effects), it does so with a less heavy penalty than the Dunn-Bonferroni penalty. This protects against Type II errors.\n\n\nIn the Dunn-Bonferroni method, each of the 28 p-values was penalized by the exact same amount; each of the unadjusted p-values was multiplied by 28. The way that the Benjamini-Hochberg method protects against Type II errors is that it penalizes the p-values differentially. While the exact methodology is beyond the scope of the course, if you are interested you can read the original paper in which the method was described (Benjamini & Hochberg, 1995).",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Multiple Comparisons</span>"
    ]
  },
  {
    "objectID": "05-03-multiple-comparisons.html#which-adjustment-method-should-you-use",
    "href": "05-03-multiple-comparisons.html#which-adjustment-method-should-you-use",
    "title": "20¬† Multiple Comparisons",
    "section": "20.3 Which Adjustment Method Should You Use?",
    "text": "20.3 Which Adjustment Method Should You Use?\nThere is no right answer to this question. Controlling for the familywise error rate or for the false discovery rate needs to be decided by the reseracher. There are good reasons to choose either. In general if you want to really protect against Type I errors, you would control the familywise error rate. This usually occurs when the researcher has adopted a confirmatory approach to the data analysis. On the other hand, if you worry about false discovery, but not at the expense of not discovering ‚Äòtrue‚Äô effects, then controlling for the false discovery rate is more appropriate. This is a better fit when the researcher is undertaking an exploratory approach to the data analysis. You should also note that some fields (e.g., neuroscience) have particular proclivities for how to adjust p-values for multiple comparisons.\nRegardless of the approach, you should decide which adjustment method you will use before you do the analysis. In the educational and social sciences, the Dunn‚ÄìBonferroni method has been historically the most popular method (probably because it was easy to implement before computing), although historical popularity is probably not the best manner of choosing a methodology.\nIf you are unsure about which procedure to use, for many analyses the Benjamini-Hochberg adjustment method is a good choice. There is a growing pool of research evidence that suggests controlling FDR may be the ‚Äúbest‚Äù solution to the problem of multiple comparisons (Williams et al., 1999). Moreover, the Institute of Education Sciences has recommended the Benjamini-Hochberg adjustment method in its Procedures Handbook (What Works Clearinghouse, 2020).",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Multiple Comparisons</span>"
    ]
  },
  {
    "objectID": "05-03-multiple-comparisons.html#references",
    "href": "05-03-multiple-comparisons.html#references",
    "title": "20¬† Multiple Comparisons",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenjamini, Y., & Hochberg, Y. (1995). Controlling the false discovery rate: A practical and powerful approach to multiple testing. Journal of the Royal Statistical Society, Series B, 57(1), 289‚Äî300.\n\n\nDunn, O. J. (1961). Multiple comparisons among means. Journal of the American Statistical Association, 56(293), 52‚Äì64.\n\n\nHolm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6(2), 65‚Äì70. http://www.jstor.org/stable/4615733\n\n\nScheff√©, H. (1959). The analysis of variance. Wiley.\n\n\nTukey, J. W. (1949). Comparing individual means in the Analysis of Variance. Biometrics, 5(2), 99‚Äì114.\n\n\nWhalley, B. (2018). Just enough r. https://benwhalley.github.io/just-enough-r/\n\n\nWhat Works Clearinghouse. (2020). Procedures handbook, version 4.1 (No. ED602035). National Center for Education Evaluation; Regional Assistance, Institute of Education Sciences, U.S. Department of Education. http://ies.ed.gov/ncee/wwc/Handbooks\n\n\nWilliams, V. S. L., Jones, L. V., & Tukey, J. W. (1999). Controlling error in multiple comparisons, with examples from state-to-state differences in educational achievement. Journal of Educational and Behavioral Statistics, 24(1), 42‚Äì69.",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Multiple Comparisons</span>"
    ]
  },
  {
    "objectID": "05-03-multiple-comparisons.html#footnotes",
    "href": "05-03-multiple-comparisons.html#footnotes",
    "title": "20¬† Multiple Comparisons",
    "section": "",
    "text": "This is probably high in practice.‚Ü©Ô∏é\nAlternatively, when researchers spell out ALL of the hypotheses they will test prior to looking at the data (and those tests are driven from the literature), they are taking a confirmatory approach to hypothesis testing.‚Ü©Ô∏é\nIn our patriarchal society, unfortunately Olive Dunn‚Äôs name is often removed from the nomenclature, and this adjustment gets referred to as the ‚ÄúBonferroni adjustment‚Äù.‚Ü©Ô∏é\nA ‚Äúcontrast‚Äù is what statisticians call a difference; they are contrasting two groups.‚Ü©Ô∏é",
    "crumbs": [
      "Categorical Predictors",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Multiple Comparisons</span>"
    ]
  },
  {
    "objectID": "06-00-interaction-effects.html",
    "href": "06-00-interaction-effects.html",
    "title": "Interaction Effects",
    "section": "",
    "text": "In this unit you will learn about interaction effects and how they can be included in the regression model.",
    "crumbs": [
      "Interaction Effects"
    ]
  },
  {
    "objectID": "06-01-intro-to-interaction-effects.html",
    "href": "06-01-intro-to-interaction-effects.html",
    "title": "21¬† Introduction to Interaction Effects",
    "section": "",
    "text": "21.1 Data Exploration\nTo begin, as always, we would plot the marginal distributions of guilt (guilt) and amount of work contact outside normal working hours (contact). We will also examine the scatterplot to look at the relationship between amount of work contact outside normal working hours and guilt. We will also examine summary measures for each distribution and the correlation matrix.\n# Density plot of pre-test scores\np1 = ggplot(data = work, aes(x = guilt)) +\n  geom_density() +\n  theme_bw() +\n  xlab(\"Guilt\") +\n  ylab(\"Probability density\")\n\n# Density plot of post-test scores\np2 = ggplot(data = work, aes(x = contact)) +\n  geom_density() +\n  theme_bw() +\n  xlab(\"Amount of work contact outside normal working hours\") +\n  ylab(\"Probability density\")\n\n# Scatterplot of post- vs. pre-test scores\np3 = ggplot(data = work, aes(x = contact, y = guilt)) +\n  geom_point() +\n  theme_bw() +\n  xlab(\"Amount of work contact outside normal working hours\") +\n  ylab(\"Guilt\")\n\n# Layout plots\np1 | p2 | p3\n\n# Compute summary statistics\nwork |&gt;\n  summarize(\n    M_guilt  = mean(guilt),\n    SD_guilt = sd(guilt),\n    M_contact  = mean(contact),\n    SD_contact = sd(contact),\n    N = n()\n  )\n\n\n\n\n\n\n\n\nFigure¬†21.1: Density plots of guilt and amount of work contact outside normal working hours, as well as, the scatterplot showing the relationship between these measures.\n\n\n\n# Correlation\nwork |&gt;\n  select(guilt, contact) |&gt;\n  correlate() |&gt;\n  fashion(decimals = 2)\n\n\n\n\n\n\n\n\nFigure¬†21.2: Density plots of guilt and amount of work contact outside normal working hours, as well as, the scatterplot showing the relationship between these measures.\n\n\n\n\n\n\n\n\n\n\nFigure¬†21.3: Density plots of guilt and amount of work contact outside normal working hours, as well as, the scatterplot showing the relationship between these measures.\nThe distribution of guilt is unimodal and roughly symmetric. The mean level of guilt is 24.50 on a 50-pt scale (\\(SD=9.10\\)). The distribution of work contact outside normal working hours is also unimodal and symmetric. The mean amount of contact is 5.47 on a 10-pt scale (\\(SD=1.88\\)). There seems to be a moderate to strong, positive, linear relationship between the amount of work contact outside normal working hours and guilt (\\(r=0.60\\)). Employees who are contacted about work outside of normal working hours more often tend to have higher levels of guilt.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduction to Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-01-intro-to-interaction-effects.html#examining-the-effect-of-work-contact-on-guilt",
    "href": "06-01-intro-to-interaction-effects.html#examining-the-effect-of-work-contact-on-guilt",
    "title": "21¬† Introduction to Interaction Effects",
    "section": "21.2 Examining the Effect of Work Contact on Guilt",
    "text": "21.2 Examining the Effect of Work Contact on Guilt\nWe will begin by fitting a regression model that regresses guilt on amount of work contact. We will also fit two additional models: one that controls for differences in gender and a second that controls for differences in level of job authority and marital status in addition to gender.\n\n# Fit models\nlm.a = lm(guilt ~ 1 + contact, data = work)\nlm.b = lm(guilt ~ 1 + contact + female, data = work)\nlm.c = lm(guilt ~ 1 + contact + female + authority + married, data = work)\n\n# Model-level output\n# glance(lm.a)\n# glance(lm.b)\n# glance(lm.c)\n\n# Coefficient-level output\n# tidy(lm.a, conf.int = TRUE)\n# tidy(lm.b, conf.int = TRUE)\n# tidy(lm.c, conf.int = TRUE)\n\n\n\nTable 1. Coefficients [95% confidence intervals] for a taxonomy of OLS regression models to explain variation in guilt for employees. All models were fitted with n=300 observations.\n\n\n\n\n\n\nModel A\n\n\nModel B\n\n\nModel C\n\n\n\n\n\n\nWork contact\n\n\n2.89[2.45, 3.33]\n\n\n3.13[2.71, 3.55]\n\n\n3.22[2.96, 3.48]\n\n\n\n\nFemale\n\n\n\n\n5.308[3.68, 6.91]\n\n\n3.72[2.71, 4.72]\n\n\n\n\nJob authority\n\n\n\n\n\n\n-4.44[-4.83, -4.04]\n\n\n\n\nMarried\n\n\n\n\n\n\n2.06[1.00, 3.12]\n\n\n\n\nConstant\n\n\n8.73[6.18, 11.3]\n\n\n4.24[1.49, 7.00]\n\n\n6.86[5.02, 8.70]\n\n\n\n\nR2\n\n\n0.357\n\n\n0.436\n\n\n0.791\n\n\n\n\nRMSE\n\n\n7.30\n\n\n6.85\n\n\n4.19\n\n\n\n\nNote: Female and Married are dummy-coded indicator variables indicating gender and marital status, respectively.\n\n\n\n\nBased on Model A, there is a positive effect of work contact outside normal working hours and guilt, and this is statistically discernible from 0. In Model B, we find that this relationship persists, and is of larger magnitude, after accounting for differences in gender. We also find that females have higher levels of guilt than non-females, controlling for differences in the amount of work contact outside normal working hours. The results from Model C indicates that the relationship between work contact outside normal working hours and guilt still persists, even after accounting for differences in gender, job authority and marital status. This model also suggests that after accounting for differences in work contact outside normal working hours, job authority and marital status, females continue to have more guilt than non-females.\nVisually, we can display the effects of boundary-spanning work and gender (from Model C) by plotting the fitted partial regression lines. To do so, we will partial out job authority by setting it to its mean value of 0.82. We will also partial out marital status by setting its value to 0 (non-married).\n\\[\n\\begin{split}\n\\mathbf{Females:~} \\hat{\\mathrm{Guilt}} &= 6.86 + 3.22(\\mathrm{Work~Contact}_i) + 3.72(1) - 4.44(0.82) + 2.06(0) \\\\[2ex]\n&= 6.94 + 3.22(\\mathrm{Work~Contact}_i) \\\\[4ex]\n\\mathbf{Non\\mbox{-}Females:~} \\hat{\\mathrm{Guilt}} &= 6.86 + 3.22(\\mathrm{Work~Contact}_i) + 3.72(0) - 4.44(0.82) + 2.06(0) \\\\[2ex]\n&= 3.22 + 3.22(\\mathrm{Work~Contact}_i)\n\\end{split}\n\\]\n\nggplot(data = work, aes(x = contact, y = guilt)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Amount of boundary-spanning work\") +\n  ylab(\"Predicted home-life/work guilt\") +\n  geom_abline(intercept = 6.94, slope = 3.22, linetype = \"solid\", color = \"#424651\") +\n  geom_abline(intercept = 3.22, slope = 3.22, linetype = \"dashed\", color = \"#f5853f\")\n\n\n\n\n\n\n\nFigure¬†21.4: Partial fitted regression lines showing model-predicted guilt as a function of the amount of work contact outside normal working hours for females (charcoal, solid line) and non-females (mango, dashed line). The effects of job authority (mean value) and marital status (non-married) have been partialed out.\n\n\n\n\n\nThis display helps us see that the effect of work contact outside normal working hours (slopes of the lines) is THE SAME for both females and non-females, and is 3.22. We also see that females report higher levels of guilt than non-females, and that this difference in guilt is THE SAME regardless of how much work contact outside normal working hours is experienced.\n\nRemember, this type of model where the effect of a predictor is THE SAME for each level of another predictor is referred to as a main-effects model.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduction to Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-01-intro-to-interaction-effects.html#statistical-interactions-differential-effects",
    "href": "06-01-intro-to-interaction-effects.html#statistical-interactions-differential-effects",
    "title": "21¬† Introduction to Interaction Effects",
    "section": "21.3 Statistical Interactions: Differential Effects",
    "text": "21.3 Statistical Interactions: Differential Effects\nUnfortunately, the models we have interpreted and evaluated thus far do no allow us to answer whether the effect of work contact on guilt is DIFFERENT across gender. Differential effects of work contact on guilt would imply that the slopes of the regression lines showing the effect of work contact for females and non-females would not be equal (i.e., the fitted regression lines are not parallel). The main-effects models assume that the effect of work contact on guilt is the SAME for females and non-females. In this model the slopes of the regression lines showing the effect of work contact would be the same (i.e., parallel regression lines). In statistical terms we describe differential effects as interaction effects. We would say there is an interaction effect between work contact outside of normal working hours and gender on guilt\n\n\n\n\n21.3.1 Evaluating an Interaction Effect\nWe can initally evaluate whether there is an interaction effect in the sample by re-creating the scatterplot between work contact and guilt and plotting different regression lines for each gender. To do this we include group= in the aesthetic. Because the column we are grouping on (female) is numbers‚Äîremember it is dummy coded‚Äîwe force R to treat it as categorical by calling the factor() function on it. In addition to grouping by female, we also color by it so that we can better evaluate the different regression lines.\n\nggplot(data = work, aes(x = contact, y = guilt, group = factor(female), color = factor(female))) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  scale_color_manual(\n    name = \"\",\n    values = c(\"#F5853F\", \"#424651\"),\n    labels = c(\"Non-females\", \"Females\")\n    ) +\n  xlab(\"Work contact outside normal working hours\") +\n  ylab(\"Guilt\")\n\n\n\n\n\n\n\nFigure¬†21.5: Scatterplot of guilt versus work contact conditioned on gender. The fitted simple regression lines have also been included.\n\n\n\n\n\nThe two regression lines are not parallel; the effect of work contact outside normal working hours on guilt is different for females and non-females. This is evidence of an interaction in the sample data. The empirical data suggests that the effect of work contact outside normal working hours on guilt is positive for females and non-females, but that the magnitude (slope) of this relationship may be higher for females. In other words, increased amounts of work contact outside normal working hours may be associated with more guilt for females than for non-females.\nThe inferential question is now: Is this difference in effects (i.e., slopes) that we are seeing in the sample data ‚Äúreal‚Äù, or is it an artifact of sampling error? To evaluate this we need to fit a regression model where the effect of work contact on guilt is allowed to differ by gender. To do this, we create another predictor that is the product of the two predictors we believe interact and include that product term in the regression model along with the original predictors we used to create it (i.e., also include the constituent main-effects). In our example, we multiply the dummy-coded female predictor by the work contact (contact) predictor to create an interaction term. Then we fit a model that includes the dummy-coded female predictor, the work contact predictor, and the newly created interaction term.\n\n# Create interaction term\nwork = work |&gt;\n  mutate(\n    contact_female = contact * female\n    )\n\n# View data\nwork\n\n\n  \n\n\n# Fit interaction model\nlm.d = lm(guilt ~ 1 + contact + female + contact_female, data = work)\n\n# Model-level output\nglance(lm.d)\n\n\n  \n\n\n# Coefficient-level output\ntidy(lm.d)\n\n\n  \n\n\n\nFor now we will focus on the coefficient-level output. The fitted equation is:\n\\[\n\\hat{\\mathrm{Guilt}}_i = 7.22 + 2.62(\\mathrm{Work~Contact}_i) + 0.73(\\mathrm{Female}_i) + 0.81(\\mathrm{Work~Contact}_i)(\\mathrm{Female}_i)\n\\]\nIf we substitute in the appropriate dummy-coding we can obtain the fitted equations for females and non-females.\nNon-female Fitted Equation\n\\[\n\\begin{split}\n\\hat{\\mathrm{Guilt}}_i &= 7.22 + 2.62(\\mathrm{Work~Contact}_i) + 0.73(0) + 0.81(\\mathrm{Work~Contact}_i)(0) \\\\[2ex]\n&= 7.22 + 2.62(\\mathrm{Work~Contact}_i)\n\\end{split}\n\\]\nFemale Fitted Equation\n\\[\n\\begin{split}\n\\hat{\\mathrm{Guilt}}_i &= 7.22 + 2.62(\\mathrm{Work~Contact}_i) + 0.73(1) + 0.81(\\mathrm{Work~Contact}_i)(1) \\\\[2ex]\n&= 7.95 + 3.43(\\mathrm{Work~Contact}_i)\n\\end{split}\n\\]\nNotice that the inclusion of the interaction term allows the slopes in the two fitted equations to be different. Moreover, the female slope of \\(B=3.43\\) is 0.81 units higher than the non-female slope of \\(B=2.62\\). This difference in slopes is expressed by the estimated coefficient for the interaction term. If the female and non-female slopes are the same, the interaction term would be 0 (i.e., no difference). So to evaluate whether there is a ‚Äúreal‚Äù difference in slopes or if it is just due to sampling error, we need to evaluate the null hypothesis that the interaction term is 0. The hypothesis test associated with the interaction term in the tidy() output evaluates exactly this, namely:\n\\[\nH_0: \\beta_{\\mathrm{Interaction}} = 0\n\\]\nIn our example, the inferential results suggest that there is some evidence that the empirical data may not be compatible with the hypothesis that the difference in slopes is 0; \\(t(296)=1.85\\), \\(p=.065\\). This suggests that the effect of work contact outside normal working hours on guilt for females may be different than that for non-females.1\n\nModels that include interaction (i.e., product) terms are referred to as interaction models. The key term in these models is often the interaction term and not the constituent main-effects.\n\n\n\n\n21.3.2 Mathematical Expression of the Interaction Model\nIn general, the interaction model (with two predictors) can be written as,\n\\[\n\\begin{split}\nY_i = \\beta_0 + \\beta_1(X_{1i}) &+ \\beta_2(X_{2i}) + \\beta_3\\left(X_{1i}\\right)\\left(X_{2i}\\right) + \\epsilon_i, \\quad \\mathrm{where}\\\\[2ex]\n& \\epsilon_i \\overset{i.i.d.}{\\sim} \\mathcal{N}\\big(0,\\sigma^2_{\\epsilon}\\big)\n\\end{split}\n\\]\nTo further understand the terms in the interaction model, we will write out the interaction model using the context of our example. (For ease of writing, we will drop the part of the model that specifies the model‚Äôs assumptions.)\n\\[\n\\mathrm{Guilt}_i = \\beta_0 + \\beta_1(\\mathrm{Work~Contact}_i) + \\beta_2(\\mathrm{Female}_i) + \\beta_3(\\mathrm{Work~Contact}_i)(\\mathrm{Female}_i) + \\epsilon_i\n\\]\n\nNotice that in the interaction model, if \\(\\beta_3\\), the coefficient on the interaction term, is zero, the equation reduces to the equation for the main-effects model, namely:\n\\[\n\\begin{split}\nY_i = \\beta_0 &+ \\beta_1(X_{1i}) + \\beta_2(X_{2i}) + \\epsilon_i, \\quad \\mathrm{where}\\\\[2ex]\n& \\epsilon_i \\overset{i.i.d.}{\\sim} \\mathcal{N}\\big(0,\\sigma^2_{\\epsilon}\\big)\n\\end{split}\n\\]\nBecause of this, in practice, if the observed data are compatible with the null hypothesis that the coefficient for the interaction term is zero, some researchers drop the interaction term from the model, and re-fit the model using the main-effects model.\n\nSince the predictor \\(\\mathrm{Female}_i\\) is a dummy coded predictor (0 for non-females; 1 for females), we can use substitute those values into the model and write the regression model associated with non-females and that for females.\nRegression Model for Non-females (Reference Group)\n\\[\n\\begin{split}\n\\mathrm{Guilt}_i &= \\beta_0 + \\beta_1(\\mathrm{Work~Contact}_i) + \\beta_2(0) + \\beta_3(\\mathrm{Work~Contact}_i)(0) + \\epsilon_i \\\\[2ex]\n&= \\beta_0 + \\beta_1(\\mathrm{Work~Contact}_i) + \\epsilon_i \\\\\n\\end{split}\n\\]\nRegression Model for Females\n\\[\n\\begin{split}\n\\mathrm{Guilt}_i &= \\beta_0 + \\beta_1(\\mathrm{Work~Contact}_i) + \\beta_2(1) + \\beta_3(\\mathrm{Work~Contact}_i)(1) + \\epsilon_i \\\\[2ex]\n&= \\beta_0 + \\beta_1(\\mathrm{Work~Contact}_i) + \\beta_2 + \\beta_3(\\mathrm{Work~Contact}_i) + \\epsilon_i \\\\[2ex]\n&= \\bigg[\\beta_0 + \\beta_2\\bigg] + \\bigg[\\beta_1 + \\beta_3\\bigg](\\mathrm{Work~Contact}_i) + \\epsilon_i \\\\\n\\end{split}\n\\]\nWe can use these equations to understand what each term in the interaction model represents:\n\nThe intercept term from the interaction model (\\(\\beta_0\\)) turns out to be the intercept term for the reference group (non-females in our example).\nThe slope term associated with boundary-spanning work from the interaction model (\\(\\beta_1\\)) turns out to be the effect of boundary-spanning work for the reference group (non-females in our example).\nThe slope term associated with the dummy-coded female predictor from the interaction model (\\(\\beta_2\\)) turns out to be the difference in intercept between the group coded 1 and the reference group (difference in the female and non-female intercepts in our example).\nThe slope term associated with the interaction predictor from the interaction model (\\(\\beta_3\\)) turns out to be the difference in slopes between the group coded 1 and the reference group (difference in the female and non-female slopes in our example).\n\n\n\n\n21.3.3 Interpreting the Fitted Model‚Äôs Coefficients\nHere we will use the interaction model we fitted earlier to understand how to interpret the different coefficients in the model. Recall that the fitted equation was,\n\\[\n\\hat{\\mathrm{Guilt}}_i = 7.22 + 2.62(\\mathrm{Work~Contact}_i) + 0.73(\\mathrm{Female}_i) + 0.81(\\mathrm{Work~Contact}_i)(\\mathrm{Female}_i)\n\\]\n\nThe intercept term (\\(\\hat\\beta_0=7.22\\)) indicates that non-females (reference group) who experience no work contact outside of normal working hours have a guilt level of 7.22, on average.\nThe slope term associated with work contact outside of normal working hours (\\(\\hat\\beta_1=2.62\\)) indicates that, for non-females (reference group), each one-unit difference in the amount of work contact outside of normal working hours is associated with a 2.62-unit difference in guilt, on average.\nThe slope term associated with the dummy-coded female predictor (\\(\\hat\\beta_2=0.73\\)) indicates that females who experience no work contact outside of normal working hours have a guilt level that is 0.73-units higher, on average, than non-females who experience no work contact outside of normal working hours.\nThe slope term associated with the interaction predictor (\\(\\hat\\beta_3=0.81\\)) indicates that, for females, the effect of work contact outside of normal working hours on guilt is 0.81-units higher, on average, than the effect of work contact outside of normal working hours on guilt for non-females. In other words, for females, each one-unit increase in the amount of work contact outside of normal working hours is associated with a 3.43-unit difference in guilt, on average‚Äîthis is 0.81-units higher than the same effect for non-females.\n\n\nIn general, the easiest way to determine how to interpret the coefficients is to actually compute the partial regression equations for both groups based on the fitted interaction equation like we did earlier. Then you can just interpret the intercept and slope terms for the groups independently.\n\n\n\n\n21.3.4 Plotting the Fitted Equation for the Interaction Model\nAlmost always, plotting the fitted model is a good idea once you have fitted an interaction model. To do this we use geom_abline() to plot the non-female and female fitted lines.\n\nggplot(data = work, aes(x = contact, y = guilt)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Work contact outside normal working hours\") +\n  ylab(\"Predicted guilt\") +\n  geom_abline(intercept = 7.95, slope = 3.43, linetype = \"solid\", color = \"#424651\") + #Females\n  geom_abline(intercept = 7.22, slope = 2.62, linetype = \"dashed\", color = \"#f5853f\") #Non-females\n\n\n\n\n\n\n\nFigure¬†21.6: Fitted regression lines showing model-predicted guilt as a function of work contact outside normal working hours for females (charcoal, solid line) and non-females (mango, dashed line).\n\n\n\n\n\nIn this plot, we can see some of the same effects we interpreted from the coefficients:\n\nFemales have a higher intercept than non-females,\nThe effect of work contact outside normal working hours for females is higher in magnitude than that for non-females.\n\nThe plot also allows us to see other things as well. For example,\n\nThe lines do not cross at work contact values represented in the data. This implies that females are predicted to have more guilt than non-females, on average, regardless of how much work contact outside normal working hours they experience.\nBut, this differential diminishes for lower levels of work contact outside normal working hours (i.e., the lines are closer together at low values of X).\n\nIn the social sciences sometimes this observed pattern of one group ALWAYS having a higher predicted level of the outcome within the range of X-values is referred to as an ordinal interaction. If the lines had crossed, that would imply that for some values of X, one group had higher predicted levels of the outcome, while for other values of X the other group had higher predicted levels of the outcome. This would be referred to as a disordinal interaction. It is generally better to show the plot and describe the effects for both groups rather than just stating that the interaction was ordinal or disordinal in nature.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduction to Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-01-intro-to-interaction-effects.html#adding-covariates-into-the-model",
    "href": "06-01-intro-to-interaction-effects.html#adding-covariates-into-the-model",
    "title": "21¬† Introduction to Interaction Effects",
    "section": "21.4 Adding Covariates into the Model",
    "text": "21.4 Adding Covariates into the Model\nTwo important covariates identified in the literature that may be confounding the relationship between work contact outside normal working hours and guilt are: (1) an employee‚Äôs level of job authority, and (2) marital status. Like the main-effects models we have previously fitted, we can also control for effects in the interaction model. Here we include both covariates in the model to further examine whether there are differential effects of work contact outside normal working hours on guilt by gender after controlling for job authority and marital status.\n\n# Fit interaction model\nlm.e = lm(guilt ~ 1 + contact + female + authority + married + contact_female, data = work)\n\n# Model-level output\nglance(lm.e)\n\n\n  \n\n\n# Coefficient-level output\ntidy(lm.e)\n\n\n  \n\n\n\nThe model explains 79.5% of the variation in guilt, which is more than we expect just because of sampling error; \\(F(5,294)=228.00\\), \\(p&lt;.001\\). The fitted equation is,\n\\[\n\\begin{split}\n\\hat{\\mathrm{Guilt}}_i = &9.38 + 2.79(\\mathrm{Work~Contact}_i) - 0.18(\\mathrm{Female}_i) - 4.42(\\mathrm{Authority}_i) + 2.08(\\mathrm{Married}_i) + \\\\\n&0.69(\\mathrm{Work~Contact}_i)(\\mathrm{Female}_i)\n\\end{split}\n\\]\nTo answer our research question, the coefficient that matters here is the interaction term. The inferential results suggest that after controlling for differences in level of job authority and marital status, there does seem to be a differential effect of work contact outside normal working hours by gender; \\(t(294)=2.59\\). \\(p=0.010\\). In practice, we would probably eschew any further coefficient interpretation, but for pedagogical purposes the interpretation of each coefficient is:\n\nThe intercept term (\\(\\hat\\beta_0=9.38\\)) indicates that non-married, non-females with no job authority, who experience no work contact outside normal working hours, have a guilt level of 9.38, on average.\nThe slope term associated with work contact outside normal working hours (\\(\\hat\\beta_1=2.79\\)) indicates that, for non-females, each one-unit difference in the amount of work contact outside normal working hours is associated with a 2.79-unit difference inguilt, on average, controlling for differences in amount of job authority and marital status.\nThe slope term associated with the dummy-coded female predictor (\\(\\hat\\beta_2=-0.18\\)) indicates that females who experience no work contact outside normal working hours have a guilt level that is 0.18-units lower, on average, than non-females who experience no work contact outside normal working hours, controlling for differences in amount of job authority and marital status.\nThe slope term associated with job authority (\\(\\hat\\beta_3=-4.42\\)) indicates that, controlling for differences in gender and amount of work contact outside normal working hours, each one-unit difference in job authority is associated with a \\(4.42\\)-unit decrease in guilt, on average.\nThe slope term associated with the dummy-coded marital status predictor (\\(\\hat\\beta_4=2.08\\)) indicates that married employees have a guilt level that is, on average, 2.08-units higher than their non-married peers, controlling for differences in the amount of work contact outside normal working hours and gender.\nThe slope term associated with the interaction predictor (\\(\\hat\\beta_5=0.69\\)) indicates that for females, the effect of work contact outside normal working hours on guilt is 0.69-units higher, on average, than the effect of work contact outside normal working hours on guilt for non-females, controlling for differences in job authority and marital status. In other words, for females, each one-unit increase in the amount of work contact outside normal working hours is associated with an additional 0.69-unit difference in guilt relative to non-females, on average.\n\n\n\n21.4.1 Plotting the Results of the Model\nTo further aid our understanding of the results from fitting the interaction model, we will create several plots to visualize the different effects of interest. In these plots, we will control for job authority by setting it to the mean value of 0.82. Since marital status is also a covariate, in practice you might also set it to a fixed value and partial it out of the plot. However, here we will show this effect so you can begin to visualize differences between main-effects and interaction effects. To do this we will need to obtain four different partial fitted equations and plot them.\nNon-female, non-married\n\\[\n\\begin{split}\n\\hat{\\mathrm{Guilt}}_i &= 9.38 + 2.79(\\mathrm{Work~Contact}_i) - 0.18(0) - 4.42(0.82) + 2.08(0) +  0.69(\\mathrm{Work~Contact}_i)(0) \\\\[2ex]\n&= 5.76 + 2.79(\\mathrm{Work~Contact}_i)\n\\end{split}\n\\]\nNon-female, married\n\\[\n\\begin{split}\n\\hat{\\mathrm{Guilt}}_i &= 9.38 + 2.79(\\mathrm{Work~Contact}_i) - 0.18(0) - 4.42(0.82) + 2.08(1) +  0.69(\\mathrm{Work~Contact}_i)(0) \\\\[2ex]\n&= 7.84 + 2.79(\\mathrm{Work~Contact}_i)\n\\end{split}\n\\]\nFemale, non-married\n\\[\n\\begin{split}\n\\hat{\\mathrm{Guilt}}_i &= 9.38 + 2.79(\\mathrm{Work~Contact}_i) - 0.18(1) - 4.42(0.82) + 2.08(0) +  0.69(\\mathrm{Work~Contact}_i)(1) \\\\[2ex]\n&= 5.58 + 3.48(\\mathrm{Work~Contact}_i)\n\\end{split}\n\\]\nFemale, married\n\\[\n\\begin{split}\n\\hat{\\mathrm{Guilt}}_i &= 9.38 + 2.79(\\mathrm{Work~Contact}_i) - 0.18(1) - 4.42(0.82) + 2.08(1) +  0.69(\\mathrm{Work~Contact}_i)(1) \\\\[2ex]\n&= 7.66 + 3.48(\\mathrm{Work~Contact}_i)\n\\end{split}\n\\]\n\n# Female\np1 = ggplot(data = work, aes(x = contact, y = guilt)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Work contact outside normal working hours\") +\n  ylab(\"Predicted guilt\") +\n  geom_abline(intercept = 7.66, slope = 3.48, linetype = \"dashed\", color = \"#424651\") + #Married\n  geom_abline(intercept = 5.58, slope = 3.48, linetype = \"solid\", color = \"#424651\") +  #Not married\n  ggtitle(\"Female\")\n\n# Non-female\np2 = ggplot(data = work, aes(x = contact, y = guilt)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Work contact outside normal working hours\") +\n  ylab(\"Predicted guilt\") +\n  geom_abline(intercept = 7.84, slope = 2.79, linetype = \"dashed\", color = \"#f5853f\") + #Married\n  geom_abline(intercept = 5.76, slope = 2.79, linetype = \"solid\", color = \"#f5853f\") +  #Not married\n  ggtitle(\"Non-female\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†21.7: Fitted regression lines showing model-predicted guilt as a function of work contact outside normal working hours for married (dashed lines) and non-married (solid lines) employees conditioned on gender. Job authority is controlled by setting this to its mean value.\n\n\n\n\n\nNotice that the slope of the lines represents the effect of work contact outside normal working hours on guilt, and that this effect differs by gender; the lines across gender are not parallel. Across marital status, however, the slopes are the same (at least within gender); parallel lines. This is because marital status was only included in the model as a main effect, whereas gender was included as part of an interaction effect.\nWe could also have facetted on marital status rather than gender. In this plot, the partial fitted lines within each panel of the plot are not parallel, but the set of lines are parallel across panels.\n\n# Non-married\np1 = ggplot(data = work, aes(x = contact, y = guilt)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Work contact outside normal working hours\") +\n  ylab(\"Predicted guilt\") +\n  geom_abline(intercept = 5.76, slope = 2.79, linetype = \"solid\", color = \"#f5853f\") +  #Non-female\n  geom_abline(intercept = 5.58, slope = 3.48, linetype = \"dashed\", color = \"#424651\") + #Female\n  ggtitle(\"Non-married\")\n\n# Married\np2 = ggplot(data = work, aes(x = contact, y = guilt)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Work contact outside normal working hours\") +\n  ylab(\"Predicted guilt\") +\n  geom_abline(intercept = 7.84, slope = 2.79, linetype = \"solid\", color = \"#f5853f\") +  #Non-female\n  geom_abline(intercept = 7.66, slope = 3.48, linetype = \"dashed\", color = \"#424651\") + #Female\n  ggtitle(\"Married\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†21.8: Fitted regression lines showing model-predicted guilt as a function of work contact outside normal working hours for females (charcoal, dashed line) and non-females (mango, solid line) conditioned on marital status. Job authority is controlled by setting this to its mean value.\n\n\n\n\n\n\nWhich plot should you use? It depends on what you want to emphasize. Here I would choose to use the second plot in a publication because the interaction (which is the focus of the research question) is easier to see within each facet. The fact that the lines in the married facet are higher than those in the non-married facet is of less importance since marital status was a covariate. (In the first plot, it is easier to see the marital status main-effect.)",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduction to Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-01-intro-to-interaction-effects.html#evaluating-the-distributional-assumptions",
    "href": "06-01-intro-to-interaction-effects.html#evaluating-the-distributional-assumptions",
    "title": "21¬† Introduction to Interaction Effects",
    "section": "21.5 Evaluating the Distributional Assumptions",
    "text": "21.5 Evaluating the Distributional Assumptions\nJust like main-effects models, we need to examine the distributional assumptions for any adopted interaction models. We do this in the exact same way we did for main effects models.\n\n# Create augmented data\naug_e = augment(lm.e)\n\n# Examine normality assumption\np1 = ggplot(data = aug_e, aes(x = .std.resid)) +\n  stat_density_confidence(model = \"normal\") +\n  stat_density(geom = \"line\") +\n  theme_bw() +\n  xlab(\"Standardized Residuals\") +\n  ylab(\"Probability density\")\n\n# Examine other assumptions\np2 = ggplot(data = aug_e, aes(x = .fitted, y = .std.resid)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  geom_hline(yintercept = 0) +\n  theme_bw() +\n  xlab(\"Fitted Values\") +\n  ylab(\"Standardized Residuals\")\n\n# Layout plots\np1 | p2\n\n\n\n\n\n\n\nFigure¬†21.9: LEFT: Density plot of the marginal distribution of standardized residuals from the fitted regression model (raspberry line). The sampling uncertainty associated with the normal distribution is also displayed (blue shaded area). RIGHT: Scatterplot of the standardized residuals versus the fitted values from Model E. A horizontal line at \\(Y=0\\) shows the expected mean residual under the linearity assumption and the shaded, grey region indicates the expected uncertainty. The loess line (blue) is also displayed.\n\n\n\n\n\nBased on the density plot of the standardized residuals, the normality assumption seems tenable. The scatterplot of the model‚Äôs standardized residuals versus its fitted values suggests that the average residual is close to zero for each fitted value, indicating that the assumption that the average residual at each fitted value is 0 (i.e., the ‚Äúlinearity‚Äù assumption) seems tenable. The assumption of equal variances also seems tenable given this plot. Although not seen in the plot, there may be some question of independence. For example, some these employees may work in the same division, or have the same supervisor. As such, the amount of guilt for these employees may be more related.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduction to Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-01-intro-to-interaction-effects.html#two-interpretations-of-an-interaction-effect",
    "href": "06-01-intro-to-interaction-effects.html#two-interpretations-of-an-interaction-effect",
    "title": "21¬† Introduction to Interaction Effects",
    "section": "21.6 Two Interpretations of an Interaction Effect",
    "text": "21.6 Two Interpretations of an Interaction Effect\nThere are always two interpretations of an interaction effect.\n\nThe effect of \\(X_1\\) on \\(Y\\) differs depending on the level of \\(X_2\\).\nThe effect of \\(X_2\\) on \\(Y\\) differs depending on the level of \\(X_1\\).\n\nFor example, in our example, we interpreted the interaction as:\n\nThe effect of work contact outside normal working hours on guilt is different for females and non-females.\n\nIn the second visual display we created, this interpretation focused on the difference in slopes. We could also interpret the interaction as:\n\nThe effect of gender on guilt is different depending on the amount of work contact outside normal working hours.\n\nIn the visual display, this interpretation would focus on the vertical distance between the partial regression lines. For example, focusing on the non-married panel of the plotted results from Model E, rather than focus on the slopes of the lines, look at the vertical distance between lines; this is the effect of gender.\n\n# Non-married\nggplot(data = work, aes(x = contact, y = guilt)) +\n  geom_point(alpha = 0) +\n  theme_bw() +\n  xlab(\"Work contact outside normal working hours\") +\n  ylab(\"Predicted guilt\") +\n  geom_abline(intercept = 5.76, slope = 2.79, linetype = \"solid\", color = \"#f5853f\") +  #Non-female\n  geom_abline(intercept = 5.58, slope = 3.48, linetype = \"dashed\", color = \"#424651\") + #Female\n  ggtitle(\"Non-married\")\n\n\n\n\n\n\n\nFigure¬†21.10: Fitted regression lines showing model-predicted guilt as a function of work contact outside normal working hours for non-married females (charcoal, dash line) and non-females (mango, solid line). Job authority is controlled by setting this to its mean value.\n\n\n\n\n\nIn this plot, the effect of gender differs depending on the amount of boundary-spanning work. For low amounts of work contact outside normal working hour the gender effect is small, and for higher amounts of work contact outside normal working hours the gender effect is larger. Moreover, the direction of the effect switches within the range of our data (i.e., the interaction is disordinal). That is, at the lowest level of work contact outside normal working hours, non-females have a higher level of guilt, but for higher levels of work contact outside normal working hours, females have more guilt than non-females.\n\nWhich interpretation of the interaction effect you use is up to you. Try them both. Although they both describe the same interaction, trying the different interpretations can sometimes lead to more information about or more natural ways of describing the effects.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduction to Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-01-intro-to-interaction-effects.html#references",
    "href": "06-01-intro-to-interaction-effects.html#references",
    "title": "21¬† Introduction to Interaction Effects",
    "section": "References",
    "text": "References\n\n\n\n\nGlavin, P., Schieman, S., & Reid, S. (2011). Boundary-spanning work demands and their consequences for guilt and psychological distress. Journal of Health and Social Behavior, 52(1), 43‚Äì57.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduction to Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-01-intro-to-interaction-effects.html#footnotes",
    "href": "06-01-intro-to-interaction-effects.html#footnotes",
    "title": "21¬† Introduction to Interaction Effects",
    "section": "",
    "text": "Because the p-value is close to .05 and we have yet to introduce any covariates I am withholding judgment about whether the interaction effect is statistically discernible from 0 at this point.‚Ü©Ô∏é",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduction to Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-02-more-interaction-effects.html",
    "href": "06-02-more-interaction-effects.html",
    "title": "22¬† More Interaction Effects",
    "section": "",
    "text": "22.1 Data Exploration\nTo begin, as always, we would typically plot the marginal distributions of fertility rate and any predictors. Since you have already done this for Assignment 05, we will skip this exploration here. Ideally, we would only include an interaction effect in the model if there is support for this in the theoretical/substantive literature. However, barring this support, we might explore the sample data for empirical evidence of the interaction (generally via plots of the data). Exploring an interaction effect between two quantitative variables poses some unique challenges.\nTo understand those challenges consider how we explored the interaction between sex and boundary-spanning work on guilt in a previous set of notes. We created a separate scatterplot of the effect of boundary-spanning work on guilt for males and females, and evaluated whether the fitted line for males and females were parallel. In other words, we need to examine the relationship between X1 and Y for different levels of X2.\nIn this chapter, we are evaluating whether there is an interaction between contraception use and female education level on fertility rates. As such, we need to examine the effect of contraception use on fertility rates at different levels of female education. But, since female education is continuous, there are a lot of levels in the data! Rather than look at all of these levels, we generally choose a small number of levels of female education. Another challenge is that in continuous variables, there are typically very few observations at a specific value of that variable, so instead of selecting specific values, we typically cut the variable into distinct ranges of values.\nHere we empirically identify distinct ranges for female education by examining the summary() output associated with that variable.\nfert |&gt;\n  select(educ_female) |&gt;\n  summary()\n\n  educ_female    \n Min.   : 0.600  \n 1st Qu.: 4.800  \n Median : 8.000  \n Mean   : 7.494  \n 3rd Qu.:10.250  \n Max.   :13.000\nBased on the quartiles, we might choose four distinct ranges of female education:\nThere are several R functions that can be employed to discretize a continuous variable. We will use the case_when() function from the {dplyr} package (or {tidyverse}) to create a new variable that has four different categories, one for each distinct range. (Read more about using case_when() here.)\n# Discretize female education level\nfert = fert |&gt;\n  mutate(\n    female_educ_discrete = case_when(\n      educ_female &lt; 4.8 ~ \"Quartile 1\",\n      educ_female &gt;= 4.8 & educ_female &lt; 8 ~ \"Quartile 2\",\n      educ_female &gt;= 8 & educ_female &lt; 10.25 ~ \"Quartile 3\",\n      educ_female &gt;= 10.25 ~ \"Quartile 4\"\n      )\n  )\n\n# View data\nfert\nNow we have discretized female education level, we can use our new discretized variable to examine the potential interaction with contraception use.\nggplot(data = fert, aes(x = contraceptive, y = fertility_rate, color = female_educ_discrete)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n    theme_bw() +\n    xlab(\"Contraception use\") +\n    ylab(\"Fertility rate\") +\n  scale_color_brewer(palette = \"Set2\") +\n  facet_wrap(~female_educ_discrete, nrow = 1) +\n  guides(color = FALSE)\n\n\n\n\n\n\n\nFigure¬†22.1: Scatterplot displaying the relationship between contraception use and fertility rate conditioned on female education level. RIGHT: Density plot of standardized amount of boundary-spanning work conditioned on gender.\nThe empirical evidence is consistent with there being an interaction effect between contraception use and female education level on fertility rate in the sample; the effect of contraception use on fertility rate differs depending on the level of female education. It looks like the absolute magnitude of the effect of contraception use on fertility rate decreases for higher levels of female education.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>More Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-02-more-interaction-effects.html#data-exploration",
    "href": "06-02-more-interaction-effects.html#data-exploration",
    "title": "22¬† More Interaction Effects",
    "section": "",
    "text": "Female education level \\(&lt; 4.8\\)\n\\(4.8 \\leq\\) Female education level \\(&lt; 8\\)\n\\(8 \\leq\\) Female education level \\(&lt; 10.25\\)\n\\(10.25 \\leq\\) Female education level\n\n\nNote that you will want to use the entire range of data to explore effects, otherwise, you might see a spurious relationship. Also, and this is VERY IMPORTANT, This discretizing is ONLY carried out to create the plot. When we fit the actual interaction in the regression model, we use the continuous predictor.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>More Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-02-more-interaction-effects.html#fit-the-interaction-model",
    "href": "06-02-more-interaction-effects.html#fit-the-interaction-model",
    "title": "22¬† More Interaction Effects",
    "section": "22.2 Fit the Interaction Model",
    "text": "22.2 Fit the Interaction Model\nTo fit the interaction model, use the constituent main effects and the interaction term to predict fertility rates. VERY IMPORTANT‚ÄîUse the original quantitative female education level predictor, not the discretized variable in the model. We will also use the colon (:) notation to include the interaction term in the model. The colon implicitly creates the product term and includes it in the model (without having to initially create a product term).\n\n# Fit model\nlm.a = lm(fertility_rate ~ 1 + educ_female + contraceptive + educ_female:contraceptive, data = fert)\n\n# Model-level output\nglance(lm.a) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.709         0.701 0.758      97.2 5.59e-32     3  -139.  289.  303.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1     68.9         120   124\n\n# Coefficient-level output\ntidy(lm.a)\n\n\n  \n\n\n\nModel A explains 70.9% of the variation in fertility rates which is not very consistent with the null hypothesis that the model explains no variation; \\(F(3,120)=97.23\\), \\(p&lt;.001\\).\nTo examine whether there is an interaction effect in the population, we evaluate the evidence from the coefficient-level output. The p-value associated with the interaction term (\\(p=.0007\\)) suggests that the empirical evidence is inconsistent with the hypothesis of no interaction effect. We do believe that there is an interaction between contraceptive use and female level of education. Because the interaction effect is statistically relevant, we do not interpret any of the constituent main-effects in the model.\n\n\n22.2.1 Plot of the Interaction Model\nTo further understand the nature of the interaction, we will create a plot of the effect of contraception use on fertility rates for different levels of female education. (Or, you could create a plot of the effect of female education level on fertility rates for different values of contraception use.) Here we will choose female education values of 5, 8, and 10 (the nearest integer values to the 25th, 50th, and 75th percentile values) to create the plot. First we will substitute these values into the fitted equation to find the partial equation for each selected female education level:\n\\[\n\\hat{\\mathrm{Fertility~rate}_i} = 6.84 - 0.41(\\mathrm{Education~level}_i) - 0.05(\\mathrm{Contraceptive~use}_i) + 0.004(\\mathrm{Contraceptive~use}_i)(\\mathrm{Education~level}_i)\n\\] \n\n22.2.1.1 Female education level of 5\n\\[\n\\begin{split}\n\\hat{\\mathrm{Fertility~rate}_i} &= 6.84 - 0.41(5) - 0.05(\\mathrm{Contraceptive~use}_i) + 0.004(5)(\\mathrm{Contraceptive~use}_i)\\\\\n&= 6.84 - 2.05 - 0.05(\\mathrm{Contraceptive~use}_i) + 0.02(\\mathrm{Contraceptive~use}_i) \\\\\n&= 4.79 - 0.03(\\mathrm{Contraceptive~use}_i)\n\\end{split}\n\\]\n\n\n\n22.2.1.2 Female education level of 8\n\\[\n\\begin{split}\n\\hat{\\mathrm{Fertility~rate}_i} &= 6.84 - 0.41(8) - 0.05(\\mathrm{Contraceptive~use}_i) + 0.004(8)(\\mathrm{Contraceptive~use}_i)\\\\\n&= 6.84 - 3.28 - 0.05(\\mathrm{Contraceptive~use}_i) + 0.032(\\mathrm{Contraceptive~use}_i) \\\\\n&= 3.56 - 0.018(\\mathrm{Contraceptive~use}_i)\n\\end{split}\n\\]\n\n\n\n22.2.1.3 Female education level of 10\n\\[\n\\begin{split}\n\\hat{\\mathrm{Fertility~rate}_i} &= 6.84 - 0.41(10) - 0.05(\\mathrm{Contraceptive~use}_i) + 0.004(10)(\\mathrm{Contraceptive~use}_i)\\\\\n&= 6.84 - 4.1 - 0.05(\\mathrm{Contraceptive~use}_i) + 0.04(\\mathrm{Contraceptive~use}_i) \\\\\n&= 2.74 - 0.01(\\mathrm{Contraceptive~use}_i)\n\\end{split}\n\\]\nNow we can create out plot of fertility rates versus contraception use and add the three partial regression lines.\n\n# Plot the fitted model\nggplot(data = fert, aes(x = contraceptive, y = fertility_rate)) +\n  geom_point(alpha = 0) +\n  geom_abline(intercept = 4.79, slope = -0.03, color = \"#022f40\", linetype = \"dotted\") +\n  geom_abline(intercept = 3.56, slope = -0.018, color = \"#f26419\", linetype = \"dashed\") +\n  geom_abline(intercept = 2.74, slope = -0.01, color = \"#758e4f\", linetype = \"solid\") +\n  theme_bw() +\n  xlab(\"Contraceptive use\") +\n  ylab(\"Fertility rate\")\n\n\n\n\n\n\n\nFigure¬†22.2: Plot of fertility rate as a function of contraceptive use and female education level. Partial regression lines are displayed for female education levels of 5th grade (blue, dotted line), 8th grade (orange, dashed line) and 10th grade (green, solid line).\n\n\n\n\n\nBased on the plot, we can see there is an ordinal interaction between contraceptive use and female education level (the lines do not cross in our plot). The effect of contraceptive use on fertility rate varies by level of female education. The largest effect of contraceptive use on fertility rate (highest absolute slope) is for countries that have the lowest female education level. This effect diminishes for countries with higher levels of female education (the magnitude of the slopes get smaller).\nRemember that every interaction effect has two interpretations. We can also focus on the the effect of female education level. In our data, the effect of female education level on fertility rate varies for different levels of contraceptive use. For countries with low rates of contraceptive use, there are large differences between the predicted average fertility rates by female education level (the distance between the lines is large). These differences diminish for countries with higher levels of contraceptive use.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>More Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-02-more-interaction-effects.html#interpreting-the-individual-effects-from-the-tidy-output",
    "href": "06-02-more-interaction-effects.html#interpreting-the-individual-effects-from-the-tidy-output",
    "title": "22¬† More Interaction Effects",
    "section": "22.3 Interpreting the Individual Effects from the tidy() Output",
    "text": "22.3 Interpreting the Individual Effects from the tidy() Output\nIn practice, it is enough to say there is an interaction, and to use the plot of the results to interpret the nature of the interaction effects rather than to interpret the actual coefficient values estimated by the lm() function. This being said, in simple models, we can actually interpret the coefficients more directly. To do this, write out the fitted equations for countries that differ in female education level by 1 year. We will write the fitted equations for countries that have a female education level of 0 years and those with a female education level of 1 year. (Do the substitution yourself to verify these equations.)\n\\[\n\\begin{split}\n\\mathbf{0~years:~}\\hat{\\mathrm{Fertility~rate}_i} &= 6.84 - 0.048(\\mathrm{Contraceptive~use}_i) \\\\\n\\mathbf{1~year:~}\\hat{\\mathrm{Fertility~rate}_i} &= \\left[6.84 -0.408 \\right] + \\left[ -0.0479 + 0.00350 \\right](\\mathrm{Contraceptive~use}_i)\\\\\n\\end{split}\n\\]\n\nThe intercept (\\(\\hat{\\beta_0}=6.84\\)) is the average fertility rate for countries with a female education level of 0 years and contraception use of 0. (extrapolation).\nThe coefficient associated with contraceptive use (\\(\\hat{\\beta_1}=-0.048\\)) is the effect of contraceptive use on fertility rate for countries with a female education level of 0 years.\nThe coefficient associated with female education (\\(\\hat{\\beta_2}=-0.408\\)) is the difference in average fertility rates between countries with contraceptive use = 0 and countries with contraceptive use = 1. Alternatively, it is the difference in intercepts between countries whose female education level differs by one year.\nThe coefficient associated with the interaction term (\\(\\hat{\\beta_3}=0.00350\\)) is the difference in slopes (effect of contraceptive use on fertility rate) between countries whose female education level differs by one year.\n\nIt cannot be iterated enough that although we can interpret the coefficients directly, in practice, the plot of the interaction model is much more informative and far less complicated for readers to understand.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>More Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-02-more-interaction-effects.html#adding-covariates",
    "href": "06-02-more-interaction-effects.html#adding-covariates",
    "title": "22¬† More Interaction Effects",
    "section": "22.4 Adding Covariates",
    "text": "22.4 Adding Covariates\nIs there an interaction between contraception use and female education level on fertility rates after we control for differences in infant mortality rate?\n\n# Fit model\nlm.b = lm(fertility_rate ~ 1 + educ_female + contraceptive + infant_mortality + educ_female:contraceptive, data = fert)\n\n# Model-level output\nglance(lm.b) |&gt;\n  print(width = Inf)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.748         0.739 0.708      88.2 1.18e-34     4  -131.  273.  290.\n  deviance df.residual  nobs\n     &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1     59.6         119   124\n\n# Coefficient-level output\ntidy(lm.b)\n\n\n  \n\n\n\nModel B explains 74.8% of the variation in fertility rates which is inconsistent with the null hypothesis that the model explains no variation; \\(F(4,119)=88.16\\), \\(p&lt;.001\\).\nTo examine whether there is an interaction effect, after controlling for differences in infant mortality rates, we again evaluate the evidence from the coefficient-level output. Based on the p-value associated with the interaction term (\\(p=.012\\)), the empirical evidence is consistent with there being an interaction effect between contraceptive use and female level of education, after controlling for differences in countries‚Äô infant mortality rates.\nHow would we interpret the effects in the model?\n\nFemale education level: Since this effect is part of an interaction term, we would interpret the interaction, namely, controlling for differences in infant mortality rates, the effect of female education level on fertility rates depends on contraceptive use.\nContraceptive use: Since this effect is part of an interaction term, we would only interpret the interaction, namely, controlling for differences in infant mortality rates, the effect of contraceptive use on fertility rates depends on female education level.\nInfant mortality: Since this is not part of any interaction term, we interpret this as we would any other effect included in a multiple regression model, namely, controlling for differences in female education level and contraceptive use, each one-percentage point difference in infant mortality rate is associated with a 0.02-unit difference in fertility rates, on average.\n\nTo better understand the nature of the effects, especially the interaction, we will plot the fitted model. We choose female education values of 5, and 10 (the nearest integer values to the 25th and 75th percentile values) to create my plot. We also choose infant mortality values of 7 and 41 (the nearest integer values to the 25th and 75th percentile values) to show the effect of infant mortality rate.\n\n\n22.4.0.1 Female education level of 5; Infant mortality rate of 7\n\\[\n\\begin{split}\n\\hat{\\mathrm{Fertility~rate}_i} &= 4.82 - 0.271(5) - 0.03(\\mathrm{Contraceptive~use}_i) + 0.02(7) + 0.002(5)(\\mathrm{Contraceptive~use}_i)\\\\\n&= 3.61 - 0.02(\\mathrm{Contraceptive~use}_i)\n\\end{split}\n\\]\n\n\n\n22.4.0.2 Female education level of 5; Infant mortality rate of 41\n\\[\n\\begin{split}\n\\hat{\\mathrm{Fertility~rate}_i} &= 4.82 - 0.271(5) - 0.03(\\mathrm{Contraceptive~use}_i) + 0.02(41) + 0.002(5)(\\mathrm{Contraceptive~use}_i)\\\\\n&= 4.29 - 0.02(\\mathrm{Contraceptive~use}_i)\n\\end{split}\n\\]\n\n\n\n22.4.0.3 Female education level of 10; Infant mortality rate of 7\n\\[\n\\begin{split}\n\\hat{\\mathrm{Fertility~rate}_i} &= 4.82 - 0.271(10) - 0.03(\\mathrm{Contraceptive~use}_i) + 0.02(7) + 0.002(10)(\\mathrm{Contraceptive~use}_i)\\\\\n&= 2.25 - 0.01(\\mathrm{Contraceptive~use}_i)\n\\end{split}\n\\]\n\n\n\n22.4.0.4 Female education level of 10; Infant mortality rate of 41\n\\[\n\\begin{split}\n\\hat{\\mathrm{Fertility~rate}_i} &= 4.82 - 0.271(10) - 0.03(\\mathrm{Contraceptive~use}_i) + 0.02(41) + 0.002(10)(\\mathrm{Contraceptive~use}_i)\\\\\n&= 2.93 - 0.01(\\mathrm{Contraceptive~use}_i)\n\\end{split}\n\\]\nNow we can create out plot of fertility rates versus contraception use and add the four partial regression lines.\n\n# Plot the fitted model (infant mortality rate = 7)\np1 = ggplot(data = fert, aes(x = contraceptive, y = fertility_rate)) +\n  geom_point(alpha = 0) +\n  geom_abline(intercept = 3.61, slope = -0.02, color = \"#f26419\", linetype = \"solid\") +\n  geom_abline(intercept = 2.25, slope = -0.01, color = \"#022f40\", linetype = \"dashed\") +\n  theme_bw() +\n  xlab(\"Contraceptive use\") +\n  ylab(\"Fertility rate\") +\n  ggtitle(\"Infant mortality rate at the first quartile (7%)\")\n\n# Plot the fitted model (infant mortality rate = 41)\np2 = ggplot(data = fert, aes(x = contraceptive, y = fertility_rate)) +\n  geom_point(alpha = 0) +\n  geom_abline(intercept = 4.29, slope = -0.02, color = \"#f26419\", linetype = \"solid\") +\n  geom_abline(intercept = 2.93, slope = -0.01, color = \"#022f40\", linetype = \"dashed\") +\n  theme_bw() +\n  xlab(\"Contraceptive use\") +\n  ylab(\"Fertility rate\") +\n  ggtitle(\"Infant mortality rate at the third quartile (41%)\")\n\n# Layout side-by-side plot\np1 | p2\n\n\n\n\n\n\n\nFigure¬†22.3: Plot of fertility rate as a function of contraceptive use, female education level, and infant mortality rate. Partial regression lines are displayed for female education levels of 5th grade (orange, solid line), 8th grade (blue, dashed line) for countries with infant mortality rates at the first (7%) and third (41%) quartile values.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>More Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-02-more-interaction-effects.html#higher-order-interactions",
    "href": "06-02-more-interaction-effects.html#higher-order-interactions",
    "title": "22¬† More Interaction Effects",
    "section": "22.5 Higher Order Interactions",
    "text": "22.5 Higher Order Interactions\nInteractions between two predictors (e.g., female education level and contraceptive use) are referred to as first order interactions. In the previous section, the model we fitted included a main-effect of infant mortality rate and a first order interaction between female education level and contraceptive use. The main-effect of infant mortality rate in this model suggested that the first order interaction between female education level and contraceptive use was THE SAME for every level of infant mortality rate.\nWe could also fit a model that posits that the first order interaction between female education level and contraceptive use IS DIFFERENT for different levels of infant mortality rate. This is technically an interaction between infant mortality rate and the first order interaction between female education level and contraceptive use. It is an interaction of an interaction. This is called a second order interaction.\nTo fit such a model, we would need to include the second order interaction between infant mortality rate, female education level and contraceptive use; the product of the three main effects. Since we are including an interaction, we need to include all three constituent main effects AND since it is a higher order interaction, we need to include all constituent lower order interactions; in this case all constituent first order interactions. As such the predictors would include:\n\nMain-Effects:\n\neduc_female\ncontraceptive\ninfant_mortality\n\nFirst Order Interactions:\n\neduc_female:contraceptive\neduc_female:infant_mortality\ncontraceptive:infant_mortality\n\nSecond Order Interaction:\n\neduc_female:contraceptive:infant_mortality\n\n\nWe fit the model below.\n\n# Fit model\nlm.c = lm(fertility_rate ~ 1 + educ_female + contraceptive + infant_mortality + \n            educ_female:contraceptive + infant_mortality:contraceptive + educ_female:infant_mortality +\n            educ_female:contraceptive:infant_mortality, data = fert)\n\n# Coefficient-level output\ntidy(lm.c)\n\n\n  \n\n\n\nThe fitted equation is:\n\\[\n\\begin{split}\n\\hat{\\mathrm{Fertility~rate}_i} &= 7.02 - 0.512(\\mathrm{Female~education}_i) - 0.08(\\mathrm{Contraceptive~use}_i) - 0.02(\\mathrm{Infant~mortality}_i) + \\\\\n& 0.007(\\mathrm{Female~education}_i)(\\mathrm{Contraceptive~use}_i) + 0.001(\\mathrm{Contraceptive~use}_i)(\\mathrm{Infant~mortality}_i) + \\\\\n& 0.005(\\mathrm{Female~education}_i)(\\mathrm{Infant~mortality}_i) \\\\\n&- 0.0001(\\mathrm{Female~education}_i)(\\mathrm{Contraceptive~use}_i)(\\mathrm{Infant~mortality}_i)\n\\end{split}\n\\]\nThe p-value associated with the second order interaction term (\\(p=.0469\\)) suggests that there is a second order interaction effect between female education level, contraceptive use, and infant mortality rate on fertility rates. To interpret this, plot the model results. Again, pick values for female education level and infant mortality rate, substitute them into the fitted equation, and reduce it. I again used 5 and 10 for female education level and 7 and 41 for infant mortality rate. (Note: Algebra not shown.)\n\n# Plot the fitted model (infant mortality rate = 7)\np1 = ggplot(data = fert, aes(x = contraceptive, y = fertility_rate)) +\n  geom_point(alpha = 0) +\n  geom_abline(intercept = 4.49, slope = -0.04, color = \"#f26419\", linetype = \"solid\") +\n  geom_abline(intercept = 2.09, slope = -0.005, color = \"#022f40\", linetype = \"dashed\") +\n  theme_bw() +\n  xlab(\"Contraceptive use\") +\n  ylab(\"Fertility rate\") +\n  ggtitle(\"Infant mortality rate at the first quartile (7%)\")\n\n# Plot the fitted model (infant mortality rate = 41)\np2 = ggplot(data = fert, aes(x = contraceptive, y = fertility_rate)) +\n  geom_point(alpha = 0) +\n  geom_abline(intercept = 4.65, slope = -0.02, color = \"#f26419\", linetype = \"solid\") +\n  geom_abline(intercept = 3.02, slope = -0.008, color = \"#022f40\", linetype = \"dashed\") +\n  theme_bw() +\n  xlab(\"Contraceptive use\") +\n  ylab(\"Fertility rate\") +\n  ggtitle(\"Infant mortality rate at the third quartile (41%)\")\n\n# Layout side-by-side plot\np1 | p2\n\n\n\n\n\n\n\nFigure¬†22.4: Plot of fertility rate as a function of contraceptive use, female education level, and infant mortality rate. Partial regression lines are displayed for female education levels of 5th grade (orange, solid line), 8th grade (blue, dashed line) for countries with infant mortality rates at the first (7%) and third (41%) quartile values.\n\n\n\n\n\n\nThe plots show that the interaction between contraceptive use and female education level on fertility rates DIFFERS by infant mortality rate.\nThis also suggests that the interaction between contraceptive use and infant mortality rate on fertility rates DIFFERS by level of female education.\nFinally, it also implies that the interaction between female education level and infant mortality rate on fertility rates DIFFERS by level of contraceptive use.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>More Interaction Effects</span>"
    ]
  },
  {
    "objectID": "06-02-more-interaction-effects.html#some-advice-for-fitting-interaction-models",
    "href": "06-02-more-interaction-effects.html#some-advice-for-fitting-interaction-models",
    "title": "22¬† More Interaction Effects",
    "section": "22.6 Some Advice for Fitting Interaction Models",
    "text": "22.6 Some Advice for Fitting Interaction Models\nIn general, only fit interaction terms that include focal predictors that are germane to your research question. Do not fit interaction terms that are composed of all control predictors. This has the implication that if you do not have a focal predictor (i.e., the analysis is purely exploratory) you should probably not fit interaction terms.\nA second piece of advice is that unless there is specific theoretical reason to fit higher order interactions with your focal predictors, avoid them. This also is good advice for first order interaction terms as well. This is because adding higher-order interactions tends to overfit the model to the sample data. Subsequently, these interactions do not tend to hold up when fitted on future data in future analysis; the model is too specific to the data it was fitted on and does not generalize.",
    "crumbs": [
      "Interaction Effects",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>More Interaction Effects</span>"
    ]
  },
  {
    "objectID": "07-00-data-codebooks.html",
    "href": "07-00-data-codebooks.html",
    "title": "Data Codebooks",
    "section": "",
    "text": "In this section you can find the codebook associated with each of the datasets used in the book.",
    "crumbs": [
      "Data Codebooks"
    ]
  },
  {
    "objectID": "07-01-broadband.html",
    "href": "07-01-broadband.html",
    "title": "23¬† broadband.csv",
    "section": "",
    "text": "Russell Brandom and William Joel in an article for The Verge wrote,\n\n‚ÄúIf broadband access was a problem before 2020, the pandemic turned it into a crisis. As everyday businesses moved online, city council meetings or court proceedings became near-inaccessible to anyone whose connection couldn‚Äôt support a Zoom call.‚Äù\n\nBut, who in America has access to broadband internet? As part of their ongoing work to improve software and service performance and security, Microsoft collected router speed data from individuals who accessed their cloud services. After aggregating and anonymizing these data, they made these data available publicly to help researchers and policymakers understand and improve problems related to broadband access.\nThe data in broadband.csv, collected by Microsoft (2021), give us much better insight as to the true broadband access (defined as internet download speeds of at least 25 Mbps) of Americans as, to date, most studies of broadband access have used data collated by the FCC that is based on individual Internet Service Providers‚Äô descriptions of the areas they serve. To better contextualize this, the data have also been augmented with several county-level poverty and education indicators. The variables are:\n\nstate: State postal code\ncounty: County name\nfips: Five-digit Federal Information Processing Standards code which uniquely identified counties and county equivalents in the United States\nrural_urban: Rural-urban continuum code\n\n1: Metropolitan - Counties in metropolitan areas of 1 million population or more\n2: Metropolitan - Counties in metropolitan areas of 250,000 to 1 million population\n3: Metropolitan - Counties in metropolitan areas of fewer than 250,000 population\n4: Nonmetropolitan - Urban population of 20,000 or more, adjacent to a metropolitan area\n5: Nonmetropolitan - Urban population of 20,000 or more, not adjacent to a metropolitan area\n6: Nonmetropolitan - Urban population of 2,500 to 19,999, adjacent to a metropolitan area\n7: Nonmetropolitan - Urban population of 2,500 to 19,999, not adjacent to a metropolitan area\n8: Nonmetropolitan - Completely rural or less than 2,500 urban population, adjacent to a metropolitan area\n9: Nonmetropolitan - Completely rural or less than 2,500 urban population, not adjacent to a metropolitan area\n\nmetro: Classification of the county as metropolitan (metro) or nonmetropolitan (nonmetro) based on the rural-urban continuum code\nfcc_availability: Proportion of people in the county with access to fixed terrestrial broadband at speeds of 25 Mbps/3 Mbps as of the end of 2019 as measured by the FCC\nmicrosoft_useage: Proportion of people in the county that use the internet at broadband speeds estimated by Microsoft\npct_poverty: Estimate of the percentage of people (of all ages) in the county living in poverty in 2019\nmedian_income: Estimate of median household income in the county in 2019\nlt_hs_2019: Percentage of the county with less than a high school diploma (2015‚Äì2019)\nhs_2019: Percentage of the county with a high school diploma (2015‚Äì2019)\nsome_college_2019: Percentage of the county with some college or an associate‚Äôs degree (2015‚Äì2019)\ncollege_2019: Percentage of the county with a bachelor‚Äôs degree, or higher (2015‚Äì2019)\n\n\n\n23.0.1 Preview\n\n\nCode\n# Import Data\nbroadband = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/broadband.csv\")\n\n# View data\nbroadband\n\n\n\n  \n\n\n\n\n\n\n23.0.2 References\nBrandom, R., & Joel, W. (2021, May 10). This is a map of America‚Äôs broadband problem: A county-by-county look at the broadband gap. The Verge.\nEconomic Research Service, U.S. Department of Agriculture. (2021). County-Level Data Sets.\nMicrosoft. (2021). United States Broadband Usage Percentages Dataset. Github repository.",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>broadband.csv</span>"
    ]
  },
  {
    "objectID": "07-01-comic-characters.html",
    "href": "07-01-comic-characters.html",
    "title": "24¬† comic-characters.csv",
    "section": "",
    "text": "The data in comic-characters.csv contains data on 14 attributes for 23,272 comic characters. These data were scraped in 2014 from from Marvel Wikia and DC Wikia by FiveThirtyEight and used in the story Comic Books Are Still Made By Men, For Men And About Men. The variables are:\n\ncharacter: The name of the character\ncomic: If the character appears in DC Comics or Marvel Comics\nreality: Comic reality the character appears in\nidentity: The identity status of the character (Secret Identity, Public identity, No Dual Identity)\nalignment: If the character is Good, Bad or Neutral\neye_color: Eye color of the character\nhair_color: Hair color of the character\nsex: Sex of the character (e.g.¬†Male, Female, etc.)\nlgbtq: If the character is identified as LGBTQ\nlgbtq_note: Additional information if the character is identified as LGBTQ\nalive: If the character is alive or deceased\nappearances: The number of appearances of the character in comic books (as of September 2, 2014)\nfirst_appear_date: The month and year of the character‚Äôs first appearance in a comic book, if available\nfirst_appear_year: The year of the character‚Äôs first appearance in a comic book, if available\n\n\n\n24.0.1 Preview\n\n\nCode\n# Import Data\ncomics = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/comic-characters.csv\")\n\n# View data\ncomics",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>comic-characters.csv</span>"
    ]
  },
  {
    "objectID": "07-03-fertility.html",
    "href": "07-03-fertility.html",
    "title": "25¬† fertility.csv",
    "section": "",
    "text": "Human overpopulation is a growing concern and has been associated with depletion of Earth‚Äôs natural resources (water is a big one that ) and degredation of the environment. This, in turn, has social and economic consequences such as global tension over resources such as water and food, higher cost of living and higher unemployment rates. The data in fertility.csv were collected from several sources (e.g., World Bank) and are thought to correlate with fertility rates, a measure directly linked to population. The variables are:\n\ncountry: Country name\nregion: Region of the world\nfertility_rate: Average number of children that would be born to a woman if she were to live to the end of her childbearing years and bear children in accordance with age-specific fertility rates.\neduc_female: Average number of years of formal education (schooling) for females\ninfant_mortality: Number of infants dying before reaching one year of age, per 1,000 live births in a given year.\ncontraceptive: Percentage of women who are practicing, or whose sexual partners are practicing, any form of contraception. It is usually measured for women ages 15‚Äì49 who are married or in union.\ngni_class: Categorization based on country‚Äôs gross national income per capita (calculated using the World Bank Atlas method)\n\nLow: Low-income economies; GNI per capita of $1,025 or less;\nLow/Middle: Lower-middle-income economies; GNI per capita between $1,026 and $3,995;\nUpper/Middle: Upper middle-income economies; GNI per capita between $3,996 and $12,375;\nUpper: High-income economies; GNI per capita of $12,376 or more.\n\nhigh_gni: Dummy variable indicating if the country is has an upper-middle or high income economy (low- or low/middle-income = 0; upper/middle or upper income = 1)\n\n\n\n25.0.1 Preview\n\n\nCode\n# Import Data\nfertility = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/fertility.csv\")\n\n# View data\nfertility\n\n\n\n  \n\n\n\n\n\n\n25.0.2 References\nRoser, M. (2017). Fertility rate. Our world in data.\nUNICEF. (2016). State of the world‚Äôs children 2016. United Nations Population Division‚Äôs World Contraceptive Use, household surveys including Demographic and Health Surveys and Multiple Indicator Cluster Surveys.\nWorld Bank (2019). World Bank open data.",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>fertility.csv</span>"
    ]
  },
  {
    "objectID": "07-04-gapminder.html",
    "href": "07-04-gapminder.html",
    "title": "26¬† gapminder.csv",
    "section": "",
    "text": "The data in gapminder.csv contains data on 6 attributes for 193 countries. These data, based on 2017 measures collected by World Bank, were compiled by gapminder.org and made available free under the CC-BY license. The variables are:\n\ncountry: The name of the country\nregion: The world region (Africa, Americas, Asia, or Europe)\nincome: Income per person based on the gross domestic product per person, adjusted for differences in purchasing power (in international dollars, fixed for 2017 prices)\nlife_exp: Average number of years a newborn child would live if current mortality patterns were to stay the same\nco2: Carbon dioxide emissions per person from the burning of fossil fuels (metric tonnes of CO2 per person)\nco2_change: Indicator of whether the carbon dioxide emissions per person from the burning of fossil fuels has increased or decreased since 2007 (10 year span)\npopulation: Population of the country, in millions\n\n\n\n26.0.1 Preview\n\n\nCode\n# Import Data\ngapminder = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/gapminder.csv\")\n\n# View data\ngapminder\n\n\n\n  \n\n\n\n\n\n\n26.0.2 References\nCollege Board. (2020). SAT suite of assessments annual report. Author.\nNEA Research. (2021). Rankings of the states 2020 and estimates of school statistics 2021. National Education Association.",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>gapminder.csv</span>"
    ]
  },
  {
    "objectID": "07-05-keith-gpa.html",
    "href": "07-05-keith-gpa.html",
    "title": "27¬† keith-gpa.csv",
    "section": "",
    "text": "This data, stored in keith-gpa.csv includes three attributes on \\(n = 100\\) 8th-grade students. These data come from Keith (2015). The attributes are:\n\ngpa: Overall Grade-point average (GPA) in all subjects (on a standard 100-point scale)\nhomework: Average time spent on homework per week across all subjects (in hours)\nparent_ed: Education-level (in years of schooling) for the parent with the highest level of education\n\n\n\n27.0.1 Preview\n\n\nCode\n# Import Data\nkeith = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/keith-gpa.csv\")\n\n# View data\nkeith\n\n\n\n  \n\n\n\n\n\n\n27.0.2 References\n\n\n\n\n\nKeith, T. V. (2015). Multiple regression and beyond: An introduction to multiple regression and structural equation modeling (2nd ed.). Routledge.",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>keith-gpa.csv</span>"
    ]
  },
  {
    "objectID": "07-06-mn-schools.html",
    "href": "07-06-mn-schools.html",
    "title": "28¬† mn-schools.csv",
    "section": "",
    "text": "The data in mnSchools.csv were collected from http://www.collegeresults.org and contain 2011 institutional data for \\(n=33\\) Minnesota colleges and universities. The attributes include:\n\nname: College/university name\ngrad: Six-year graduation rate (as a percentage)\nsector: Educational sector (Public; Private)\nsat: Estimated median composite SAT score (in hundreds)\ntuition: Amount of tuition and required fees covering a full academic year for a typical student (in thousands of U.S. dollars)\n\n\n\n28.0.1 Preview\n\n\nCode\n# Import Data\nmn = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/mn-schools.csv\")\n\n# View data\nmn",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>mn-schools.csv</span>"
    ]
  },
  {
    "objectID": "07-07-pew.html",
    "href": "07-07-pew.html",
    "title": "29¬† pew.csv",
    "section": "",
    "text": "This data, stored in pew.csv are a subset of data collected from a telephone survey conducted in February 2007 by the Pew Research Center for The People and The Press to evaluate how much Americans know about national and international affairs. The sample of 1,502 Americans constitute a national probability sample representative of the American public. The attributes are:\n\nid: ID variable\nknowledge: Respondent‚Äôs score on the News Knowledge Test. Scores range between 0 (which indicates no news knowledge) and 100 (a perfect score).\nnews_source: Source of the respondent‚Äôs news. They were asked whether they get their news from conservative sources (e.g., Rush Limbaugh, the O‚ÄôReilly factor), liberal sources (e.g., NPR, News Hour with Jim Lehrer), or comedy sources (e.g.,Daily Show, Colbert Report). These were then combined to form this attribute. Sources include: All, Comedy, Conservative, Conservative_Comedy, Conservative_Liberal, Liberal, Liberal_Comedy, and None.\nnews: Index of the respondent‚Äôs news exposure, based on answers to 10 items about use of various news sources. Scores range from 0 (no news exposure) to 100 (maximum involvement with all 10 sources)\nideology: Index of political ideology. Scores range from 0 (liberal as possible) to 100 (conservative as possible).\nengagement: Index of political engagement, based on responses to five items about personal involvement with political issues and activities. Scores range between 0 (no political engagement) and 100 (maximum engagement)\nage: Respondent‚Äôs age (in years)\neducation: Highest grade-level completed from 8 to 18 (a post masters degree)\nfemale: Sex indicator (No = Not female; Yes = Female)\n\n\n\n29.0.1 Preview\n\n\nCode\n# Import Data\npew = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/pew.csv\")\n\n# View data\npew\n\n\n\n  \n\n\n\n\n\n\n29.0.2 References",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>pew.csv</span>"
    ]
  },
  {
    "objectID": "07-08-riverview.html",
    "href": "07-08-riverview.html",
    "title": "30¬† riverview.csv",
    "section": "",
    "text": "The data in riverview.csv come from Lewis-Beck & Lewis-Beck (2016) and contain five attributes collected from a random sample of \\(n=32\\) employees working for the city of Riverview, a hypothetical midwestern city. The attributes include:\n\neducation: Years of formal education\nincome: Annual income (in thousands of U.S. dollars)\nseniority: Years of seniority\ngender: Employee‚Äôs gender\nparty: Political party affiliation\n\n\n\n30.0.1 Preview\n\n\nCode\n# Import Data\ncity = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/riverview.csv\")\n\n# View data\ncity\n\n\n\n  \n\n\n\n\n\n\n30.0.2 References\n\n\n\n\nLewis-Beck, C., & Lewis-Beck, M. (2016). Applied regression: An introduction (2nd ed.). Sage.",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>riverview.csv</span>"
    ]
  },
  {
    "objectID": "07-09-scoobydoo.html",
    "href": "07-09-scoobydoo.html",
    "title": "31¬† scoobydoo.csv",
    "section": "",
    "text": "Scooby-Doo is a popular television and movie franchise in the United States which has been airing for over 50 years! Scoobypedia (an encyclopedia of the franchise) describes the show as follows:\n\nThe show follows the iconic mystery solving detectives, know as Mystery Inc., as they set out to solve crime and unmask criminals, bent on revenge or committing criminal acts for their own personal gain.\n\nMystery Inc.¬†is an amateur crime-solving group of friends composed of Fred Jones (the team‚Äôs leader), Daphne Blake (fashionista and musician), Velma Dinkley (bespectacled resident genius), Shaggy Rogers (owner and best friend to Scooby-Doo), and Scooby-Doo (the talking dog mascot).\nThe data in scoobydoo.csv are a subset of data collected by plummye who ‚Äú[t]ook ~1 year to watch every Scooby-Doo iteration and track every variable.‚Äù There are 372 cases in the data.\nThe variables are:\n\ntitle: Title of the episode or movie\nseries_name: Name of the series in which the episode takes place. For movies this is the grouping classification from Scoobypedia.\ndate_aired: Dated aired in United States.\nengagement: Engagement measure based on the log-number of reviews on IMDb. Higher values indicate more engagement.\ncaught_by: Which Mystery Inc.¬†members caught the villain\n\nFred/Daphne/Velma: Villain caught by Fred Jones, Daphne Blake, Velma Dinkley, or some combination of these three Mystery Inc.¬†members;\nShaggy/Scooby: Villain caught by either Shaggy Rogers, Scooby-Doo, or both;\nCombo: Villain caught by a combination of the five Mystery Inc.¬†members;\nOther: Villain caught by non-Mystery Inc.¬†member.\n\nimdb_rating: Weighted average of all individual IMDb ratings (from 1 to 10)\nformat: Type of media (TV or Movie)\ncatchphrase: Number of times any catchphrase (e.g., zoinks, rooby rooby roo) was uttered in the episode or movie\n\n\n\n31.0.1 Preview\n\n\nCode\n# Import Data\nscoobydoo = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/scoobydoo.csv\")\n\n# View Data\nscoobydoo",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>scoobydoo.csv</span>"
    ]
  },
  {
    "objectID": "07-09-spice-girls.html",
    "href": "07-09-spice-girls.html",
    "title": "32¬† spice-girls.csv",
    "section": "",
    "text": "The data in spice-girls.csv contain five attributes about the Spice Girls. The attributes include:\n\nspice_name: Nickname of the Spice Girl\nage: Age the Spice Girl joined the band\noriginal_member: Spice Girl was an original member (TRUE; FALSE)\nsolo_nominations: Number of award nominations as a solo artist\nreal_name: Real name of the Spice Girl\n\n\n\n32.0.1 Preview\n\n\nCode\n# Import Data\nspice = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/spice-girls.csv\")\n\n# View Data\nspice",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>spice-girls.csv</span>"
    ]
  },
  {
    "objectID": "07-11-state-education.html",
    "href": "07-11-state-education.html",
    "title": "33¬† state-education.csv",
    "section": "",
    "text": "This data, stored in state-education.csv includes state-level aggregate data on six attributes. The attributes, collected for all 50 states and the District of Columbia, are:\n\nstate: State name\npostal: State postal code\nregion: Region of the country identified by the National Education Association (Far West, Great Lakes, Mid East, New England, Plains, Rocky Mountains, Southeast, Southwest)\nsat_participate: Percentage of students in the state who took the SAT.\nsat_ebrw: Average score on the Evidence-Based Reading and Writing (EBRW) scale in the state.\nsat_math: Average score on the math scale in the state.\nsat_total: Average total SAT score in the state.\nsalary_2020_21: Average 2020‚Äì2021 public teacher salary in the state.\n\nNote: All of the SAT data is based on students in the class of 2020 who took the current SAT during high school. The SAT is made up of three sections: (1) Reading, (2) Writing and Language (also just called Writing), and (3) Math. The Math section is scored on a scale of 200‚Äì800. The Reading and Writing sections are combined to give an Evidence-Based Reading and Writing (EBRW) score, also ranging from 200‚Äì800. By combining the Math and EBRW scores, we get a total SAT score ranging from 400‚Äì1600.\n\n\n33.0.1 Preview\n\n\nCode\n# Import Data\nstate_educ = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/state-education.csv\")\n\n# View Data\nstate_educ\n\n\n\n  \n\n\n\n\n\n\n33.0.2 References\nCollege Board. (2020). SAT suite of assessments annual report. Author.\nNEA Research. (2021). Rankings of the states 2020 and estimates of school statistics 2021. National Education Association.",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>state-education.csv</span>"
    ]
  },
  {
    "objectID": "07-10-work-demands.html",
    "href": "07-10-work-demands.html",
    "title": "34¬† work-demands.csv",
    "section": "",
    "text": "Research has documented the importance of a healthy work-life balance. The data in work-demands.csv were simulated to mimic the effects of receiving work-related contact outside of normal work hours found in the literature on psychological outcomes. The variables in the data are:\n\nguilt: Measure of guilt (as a transitory affective state) related to home-life balance. This was measured using survey questions such as, ‚ÄúIn the past seven days, on how many days have you felt guilty?‚Äù Higher values indicate more perceived guilt.\ncontact: Measure of work contact/demands outside of normal working hours. Measured using survey items such as, ‚Äúhow often do coworkers, supervisors, managers, customers, or clients contact you about work-related matters outside normal work hours?‚Äù. Higher values indicate higher degrees of boundary-spanning work demands.\nfemale: Dummy-coded indicator of sex (0 = Not female; 1 = Female)\nauthority: Standardized measure of job authority. Measured using survey items such as: ‚ÄúDo you influence or set the rate of pay received by others?‚Äù and ‚ÄúDo you have the authority to hire or fire others?‚Äù. Higher values indicate more authority.\nmarried: Dummy-coded indicator of marital status (0 = Not married; 1 = Married)\n\n\n\n34.0.1 Preview\n\n\nCode\n# Import Data\nwork = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/modeling/main/data/work-demands.csv\")\n\n# View data\nwork\n\n\n\n  \n\n\n\n\n\n\n34.0.2 References\nGlavin, P., Schieman, S., & Reid, S. (2011). Boundary-spanning work demands and their consequences for guilt and psychological distress. Journal of Health and Social Behavior, 52(1) 43‚Äì57. doi: 10.1177/0022146510395023",
    "crumbs": [
      "Data Codebooks",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>work-demands.csv</span>"
    ]
  }
]